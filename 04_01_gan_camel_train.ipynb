{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.GAN import GAN\n",
    "from utils.loaders import load_safari\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'gan'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'camel'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train) = load_safari(DATA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f44a66b2d30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[200,:,:,0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0530 17:48:55.910859 139935311443712 deprecation.py:506] From /home/comadan/.venv/gdl/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W0530 17:48:58.153673 139935311443712 deprecation.py:323] From /home/comadan/.venv/gdl/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "gan = GAN(input_dim = (28,28,1)\n",
    "        , discriminator_conv_filters = [64,64,128,128]\n",
    "        , discriminator_conv_kernel_size = [5,5,5,5]\n",
    "        , discriminator_conv_strides = [2,2,2,1]\n",
    "        , discriminator_batch_norm_momentum = None\n",
    "        , discriminator_activation = 'relu'\n",
    "        , discriminator_dropout_rate = 0.4\n",
    "        , discriminator_learning_rate = 0.0008\n",
    "        , generator_initial_dense_layer_size = (7, 7, 64)\n",
    "        , generator_upsample = [2,2, 1, 1]\n",
    "        , generator_conv_filters = [128,64, 64,1]\n",
    "        , generator_conv_kernel_size = [5,5,5,5]\n",
    "        , generator_conv_strides = [1,1, 1, 1]\n",
    "        , generator_batch_norm_momentum = 0.9\n",
    "        , generator_activation = 'relu'\n",
    "        , generator_dropout_rate = None\n",
    "        , generator_learning_rate = 0.0004\n",
    "        , optimiser = 'rmsprop'\n",
    "        , z_dim = 100\n",
    "        )\n",
    "\n",
    "if mode == 'build':\n",
    "    gan.save(RUN_FOLDER)\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_0 (Conv2D (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_1 (Conv2D (None, 7, 7, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_2 (Conv2D (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_3 (Conv2D (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 720,833\n",
      "Trainable params: 720,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_0 (Conv2D)    (None, 14, 14, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "generator_conv_1 (Conv2D)    (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_2 (Conv2DTran (None, 28, 28, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_3 (Conv2DTran (None, 28, 28, 1)         1601      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 844,161\n",
      "Trainable params: 837,377\n",
      "Non-trainable params: 6,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 6000\n",
    "PRINT_EVERY_N_BATCHES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0530 17:48:58.985942 139935311443712 module_wrapper.py:139] From /home/comadan/.venv/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "/home/comadan/.venv/gdl/lib/python3.6/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: (0.736)(R 0.685, F 0.788)] [D acc: (0.406)(0.812, 0.000)] [G loss: 0.671] [G acc: 1.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comadan/.venv/gdl/lib/python3.6/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [D loss: (1.057)(R 0.636, F 1.478)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.674] [G acc: 1.000]\n",
      "2 [D loss: (0.682)(R 0.670, F 0.694)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.661] [G acc: 1.000]\n",
      "3 [D loss: (0.676)(R 0.657, F 0.695)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.622] [G acc: 1.000]\n",
      "4 [D loss: (0.661)(R 0.617, F 0.705)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.421] [G acc: 1.000]\n",
      "5 [D loss: (0.579)(R 0.449, F 0.709)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.018] [G acc: 1.000]\n",
      "6 [D loss: (0.373)(R 0.038, F 0.709)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.000] [G acc: 1.000]\n",
      "7 [D loss: (0.365)(R 0.001, F 0.730)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.001] [G acc: 1.000]\n",
      "8 [D loss: (0.400)(R 0.011, F 0.788)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.031] [G acc: 1.000]\n",
      "9 [D loss: (1.335)(R 0.087, F 2.582)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.410] [G acc: 1.000]\n",
      "10 [D loss: (0.734)(R 0.469, F 1.000)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.513] [G acc: 1.000]\n",
      "11 [D loss: (0.692)(R 0.535, F 0.849)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.559] [G acc: 1.000]\n",
      "12 [D loss: (0.701)(R 0.542, F 0.860)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.607] [G acc: 1.000]\n",
      "13 [D loss: (0.686)(R 0.571, F 0.802)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.642] [G acc: 1.000]\n",
      "14 [D loss: (0.674)(R 0.574, F 0.774)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.662] [G acc: 1.000]\n",
      "15 [D loss: (0.662)(R 0.572, F 0.752)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.680] [G acc: 1.000]\n",
      "16 [D loss: (0.634)(R 0.527, F 0.742)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.691] [G acc: 0.828]\n",
      "17 [D loss: (0.595)(R 0.461, F 0.728)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.696] [G acc: 0.000]\n",
      "18 [D loss: (0.503)(R 0.296, F 0.709)] [D acc: (0.508)(1.000, 0.016)] [G loss: 0.697] [G acc: 0.000]\n",
      "19 [D loss: (0.397)(R 0.103, F 0.691)] [D acc: (0.891)(1.000, 0.781)] [G loss: 0.707] [G acc: 0.000]\n",
      "20 [D loss: (0.346)(R 0.012, F 0.679)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.743] [G acc: 0.000]\n",
      "21 [D loss: (0.329)(R 0.005, F 0.654)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.846] [G acc: 0.000]\n",
      "22 [D loss: (0.277)(R 0.006, F 0.549)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.227] [G acc: 1.000]\n",
      "23 [D loss: (1.152)(R 0.001, F 2.304)] [D acc: (0.500)(1.000, 0.000)] [G loss: 6.309] [G acc: 0.000]\n",
      "24 [D loss: (2.632)(R 4.714, F 0.549)] [D acc: (0.500)(0.000, 1.000)] [G loss: 1.010] [G acc: 0.000]\n",
      "25 [D loss: (0.441)(R 0.401, F 0.481)] [D acc: (0.938)(0.875, 1.000)] [G loss: 1.088] [G acc: 0.000]\n",
      "26 [D loss: (0.376)(R 0.276, F 0.476)] [D acc: (0.977)(0.953, 1.000)] [G loss: 0.970] [G acc: 0.000]\n",
      "27 [D loss: (0.893)(R 0.217, F 1.569)] [D acc: (0.469)(0.938, 0.000)] [G loss: 0.607] [G acc: 0.953]\n",
      "28 [D loss: (0.841)(R 0.260, F 1.422)] [D acc: (0.477)(0.953, 0.000)] [G loss: 0.697] [G acc: 0.375]\n",
      "29 [D loss: (0.535)(R 0.355, F 0.714)] [D acc: (0.617)(1.000, 0.234)] [G loss: 0.728] [G acc: 0.156]\n",
      "30 [D loss: (0.466)(R 0.223, F 0.708)] [D acc: (0.703)(1.000, 0.406)] [G loss: 0.814] [G acc: 0.016]\n",
      "31 [D loss: (0.513)(R 0.179, F 0.848)] [D acc: (0.531)(1.000, 0.062)] [G loss: 0.788] [G acc: 0.016]\n",
      "32 [D loss: (0.442)(R 0.259, F 0.624)] [D acc: (0.922)(0.984, 0.859)] [G loss: 0.802] [G acc: 0.062]\n",
      "33 [D loss: (0.541)(R 0.207, F 0.874)] [D acc: (0.555)(0.984, 0.125)] [G loss: 0.980] [G acc: 0.000]\n",
      "34 [D loss: (0.365)(R 0.216, F 0.514)] [D acc: (0.977)(0.984, 0.969)] [G loss: 0.870] [G acc: 0.094]\n",
      "35 [D loss: (0.775)(R 0.238, F 1.312)] [D acc: (0.477)(0.922, 0.031)] [G loss: 1.000] [G acc: 0.000]\n",
      "36 [D loss: (0.610)(R 0.541, F 0.680)] [D acc: (0.688)(0.766, 0.609)] [G loss: 0.727] [G acc: 0.359]\n",
      "37 [D loss: (0.765)(R 0.252, F 1.279)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.806] [G acc: 0.000]\n",
      "38 [D loss: (0.652)(R 0.556, F 0.747)] [D acc: (0.578)(0.891, 0.266)] [G loss: 0.777] [G acc: 0.062]\n",
      "39 [D loss: (0.605)(R 0.423, F 0.788)] [D acc: (0.617)(0.984, 0.250)] [G loss: 0.813] [G acc: 0.016]\n",
      "40 [D loss: (0.624)(R 0.434, F 0.815)] [D acc: (0.555)(0.969, 0.141)] [G loss: 0.819] [G acc: 0.016]\n",
      "41 [D loss: (0.690)(R 0.413, F 0.966)] [D acc: (0.492)(0.984, 0.000)] [G loss: 0.773] [G acc: 0.031]\n",
      "42 [D loss: (0.692)(R 0.516, F 0.868)] [D acc: (0.477)(0.891, 0.062)] [G loss: 0.732] [G acc: 0.188]\n",
      "43 [D loss: (0.680)(R 0.520, F 0.840)] [D acc: (0.484)(0.875, 0.094)] [G loss: 0.718] [G acc: 0.125]\n",
      "44 [D loss: (0.688)(R 0.538, F 0.838)] [D acc: (0.516)(0.922, 0.109)] [G loss: 0.718] [G acc: 0.094]\n",
      "45 [D loss: (0.675)(R 0.565, F 0.784)] [D acc: (0.547)(0.922, 0.172)] [G loss: 0.715] [G acc: 0.125]\n",
      "46 [D loss: (0.654)(R 0.535, F 0.772)] [D acc: (0.570)(0.969, 0.172)] [G loss: 0.698] [G acc: 0.375]\n",
      "47 [D loss: (0.674)(R 0.500, F 0.848)] [D acc: (0.516)(0.984, 0.047)] [G loss: 0.716] [G acc: 0.219]\n",
      "48 [D loss: (0.685)(R 0.531, F 0.840)] [D acc: (0.500)(0.938, 0.062)] [G loss: 0.717] [G acc: 0.172]\n",
      "49 [D loss: (0.654)(R 0.539, F 0.769)] [D acc: (0.508)(0.891, 0.125)] [G loss: 0.711] [G acc: 0.312]\n",
      "50 [D loss: (0.675)(R 0.508, F 0.842)] [D acc: (0.492)(0.938, 0.047)] [G loss: 0.727] [G acc: 0.156]\n",
      "51 [D loss: (0.645)(R 0.536, F 0.754)] [D acc: (0.602)(0.938, 0.266)] [G loss: 0.728] [G acc: 0.109]\n",
      "52 [D loss: (0.662)(R 0.475, F 0.849)] [D acc: (0.523)(0.922, 0.125)] [G loss: 0.757] [G acc: 0.000]\n",
      "53 [D loss: (0.631)(R 0.548, F 0.715)] [D acc: (0.664)(0.922, 0.406)] [G loss: 0.746] [G acc: 0.047]\n",
      "54 [D loss: (0.618)(R 0.426, F 0.810)] [D acc: (0.562)(0.953, 0.172)] [G loss: 0.794] [G acc: 0.016]\n",
      "55 [D loss: (0.601)(R 0.472, F 0.730)] [D acc: (0.633)(0.938, 0.328)] [G loss: 0.837] [G acc: 0.000]\n",
      "56 [D loss: (0.616)(R 0.397, F 0.836)] [D acc: (0.516)(0.953, 0.078)] [G loss: 0.789] [G acc: 0.000]\n",
      "57 [D loss: (0.579)(R 0.468, F 0.691)] [D acc: (0.758)(0.906, 0.609)] [G loss: 0.803] [G acc: 0.047]\n",
      "58 [D loss: (0.627)(R 0.250, F 1.004)] [D acc: (0.547)(0.969, 0.125)] [G loss: 0.849] [G acc: 0.000]\n",
      "59 [D loss: (0.675)(R 0.673, F 0.677)] [D acc: (0.617)(0.500, 0.734)] [G loss: 0.758] [G acc: 0.000]\n",
      "60 [D loss: (0.596)(R 0.479, F 0.713)] [D acc: (0.719)(0.922, 0.516)] [G loss: 0.765] [G acc: 0.000]\n",
      "61 [D loss: (0.556)(R 0.352, F 0.759)] [D acc: (0.648)(0.969, 0.328)] [G loss: 0.791] [G acc: 0.000]\n",
      "62 [D loss: (0.530)(R 0.340, F 0.720)] [D acc: (0.719)(0.953, 0.484)] [G loss: 0.795] [G acc: 0.016]\n",
      "63 [D loss: (0.492)(R 0.239, F 0.746)] [D acc: (0.719)(0.984, 0.453)] [G loss: 0.808] [G acc: 0.000]\n",
      "64 [D loss: (0.466)(R 0.265, F 0.668)] [D acc: (0.875)(0.984, 0.766)] [G loss: 0.828] [G acc: 0.000]\n",
      "65 [D loss: (0.370)(R 0.087, F 0.652)] [D acc: (0.883)(1.000, 0.766)] [G loss: 0.971] [G acc: 0.000]\n",
      "66 [D loss: (0.369)(R 0.126, F 0.611)] [D acc: (0.930)(0.984, 0.875)] [G loss: 1.039] [G acc: 0.000]\n",
      "67 [D loss: (0.378)(R 0.090, F 0.665)] [D acc: (0.859)(0.984, 0.734)] [G loss: 1.401] [G acc: 0.000]\n",
      "68 [D loss: (0.624)(R 0.470, F 0.778)] [D acc: (0.602)(0.750, 0.453)] [G loss: 0.889] [G acc: 0.000]\n",
      "69 [D loss: (0.325)(R 0.049, F 0.601)] [D acc: (0.891)(0.969, 0.812)] [G loss: 1.287] [G acc: 0.000]\n",
      "70 [D loss: (0.400)(R 0.207, F 0.594)] [D acc: (0.922)(0.969, 0.875)] [G loss: 1.061] [G acc: 0.000]\n",
      "71 [D loss: (0.280)(R 0.071, F 0.488)] [D acc: (0.992)(0.984, 1.000)] [G loss: 1.134] [G acc: 0.031]\n",
      "72 [D loss: (1.157)(R 0.012, F 2.303)] [D acc: (0.508)(1.000, 0.016)] [G loss: 2.755] [G acc: 0.000]\n",
      "73 [D loss: (1.312)(R 2.162, F 0.462)] [D acc: (0.492)(0.000, 0.984)] [G loss: 1.188] [G acc: 0.000]\n",
      "74 [D loss: (0.550)(R 0.626, F 0.475)] [D acc: (0.758)(0.516, 1.000)] [G loss: 0.963] [G acc: 0.031]\n",
      "75 [D loss: (0.760)(R 0.306, F 1.215)] [D acc: (0.578)(0.938, 0.219)] [G loss: 1.024] [G acc: 0.016]\n",
      "76 [D loss: (0.673)(R 0.663, F 0.683)] [D acc: (0.602)(0.547, 0.656)] [G loss: 0.923] [G acc: 0.031]\n",
      "77 [D loss: (0.845)(R 0.531, F 1.159)] [D acc: (0.469)(0.781, 0.156)] [G loss: 0.962] [G acc: 0.000]\n",
      "78 [D loss: (0.719)(R 0.704, F 0.734)] [D acc: (0.453)(0.453, 0.453)] [G loss: 0.859] [G acc: 0.000]\n",
      "79 [D loss: (0.711)(R 0.690, F 0.732)] [D acc: (0.398)(0.484, 0.312)] [G loss: 0.830] [G acc: 0.016]\n",
      "80 [D loss: (0.679)(R 0.668, F 0.689)] [D acc: (0.594)(0.531, 0.656)] [G loss: 0.818] [G acc: 0.031]\n",
      "81 [D loss: (0.648)(R 0.597, F 0.700)] [D acc: (0.656)(0.781, 0.531)] [G loss: 0.810] [G acc: 0.016]\n",
      "82 [D loss: (0.643)(R 0.552, F 0.734)] [D acc: (0.664)(0.812, 0.516)] [G loss: 0.770] [G acc: 0.156]\n",
      "83 [D loss: (0.736)(R 0.487, F 0.984)] [D acc: (0.469)(0.891, 0.047)] [G loss: 0.758] [G acc: 0.109]\n",
      "84 [D loss: (0.687)(R 0.602, F 0.772)] [D acc: (0.516)(0.766, 0.266)] [G loss: 0.853] [G acc: 0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 [D loss: (0.647)(R 0.552, F 0.742)] [D acc: (0.602)(0.812, 0.391)] [G loss: 0.945] [G acc: 0.000]\n",
      "86 [D loss: (0.635)(R 0.569, F 0.701)] [D acc: (0.656)(0.844, 0.469)] [G loss: 0.882] [G acc: 0.000]\n",
      "87 [D loss: (0.678)(R 0.544, F 0.812)] [D acc: (0.539)(0.844, 0.234)] [G loss: 0.843] [G acc: 0.016]\n",
      "88 [D loss: (0.650)(R 0.476, F 0.824)] [D acc: (0.594)(0.953, 0.234)] [G loss: 0.870] [G acc: 0.000]\n",
      "89 [D loss: (0.585)(R 0.498, F 0.672)] [D acc: (0.750)(0.812, 0.688)] [G loss: 0.830] [G acc: 0.000]\n",
      "90 [D loss: (0.582)(R 0.329, F 0.834)] [D acc: (0.578)(0.953, 0.203)] [G loss: 0.862] [G acc: 0.000]\n",
      "91 [D loss: (0.521)(R 0.405, F 0.638)] [D acc: (0.875)(0.906, 0.844)] [G loss: 0.862] [G acc: 0.000]\n",
      "92 [D loss: (0.586)(R 0.259, F 0.912)] [D acc: (0.625)(0.938, 0.312)] [G loss: 0.933] [G acc: 0.000]\n",
      "93 [D loss: (0.622)(R 0.636, F 0.608)] [D acc: (0.719)(0.531, 0.906)] [G loss: 0.847] [G acc: 0.000]\n",
      "94 [D loss: (0.524)(R 0.326, F 0.722)] [D acc: (0.727)(0.891, 0.562)] [G loss: 0.850] [G acc: 0.016]\n",
      "95 [D loss: (0.575)(R 0.354, F 0.797)] [D acc: (0.719)(0.906, 0.531)] [G loss: 0.877] [G acc: 0.000]\n",
      "96 [D loss: (0.568)(R 0.500, F 0.635)] [D acc: (0.773)(0.750, 0.797)] [G loss: 0.831] [G acc: 0.094]\n",
      "97 [D loss: (0.942)(R 0.303, F 1.581)] [D acc: (0.500)(0.953, 0.047)] [G loss: 0.888] [G acc: 0.000]\n",
      "98 [D loss: (0.747)(R 0.521, F 0.972)] [D acc: (0.422)(0.766, 0.078)] [G loss: 0.897] [G acc: 0.000]\n",
      "99 [D loss: (0.596)(R 0.604, F 0.588)] [D acc: (0.766)(0.625, 0.906)] [G loss: 0.880] [G acc: 0.000]\n",
      "100 [D loss: (0.470)(R 0.328, F 0.612)] [D acc: (0.867)(0.906, 0.828)] [G loss: 0.884] [G acc: 0.031]\n",
      "101 [D loss: (0.672)(R 0.220, F 1.123)] [D acc: (0.617)(0.984, 0.250)] [G loss: 1.009] [G acc: 0.000]\n",
      "102 [D loss: (0.601)(R 0.619, F 0.582)] [D acc: (0.781)(0.594, 0.969)] [G loss: 0.880] [G acc: 0.031]\n",
      "103 [D loss: (1.321)(R 0.364, F 2.278)] [D acc: (0.492)(0.969, 0.016)] [G loss: 1.021] [G acc: 0.000]\n",
      "104 [D loss: (0.663)(R 0.731, F 0.595)] [D acc: (0.633)(0.375, 0.891)] [G loss: 0.877] [G acc: 0.000]\n",
      "105 [D loss: (0.689)(R 0.644, F 0.734)] [D acc: (0.570)(0.609, 0.531)] [G loss: 0.832] [G acc: 0.031]\n",
      "106 [D loss: (0.670)(R 0.597, F 0.743)] [D acc: (0.539)(0.625, 0.453)] [G loss: 0.811] [G acc: 0.188]\n",
      "107 [D loss: (0.790)(R 0.621, F 0.958)] [D acc: (0.469)(0.672, 0.266)] [G loss: 0.823] [G acc: 0.062]\n",
      "108 [D loss: (0.680)(R 0.650, F 0.711)] [D acc: (0.578)(0.609, 0.547)] [G loss: 0.789] [G acc: 0.125]\n",
      "109 [D loss: (0.748)(R 0.647, F 0.850)] [D acc: (0.430)(0.594, 0.266)] [G loss: 0.805] [G acc: 0.062]\n",
      "110 [D loss: (0.721)(R 0.708, F 0.733)] [D acc: (0.430)(0.406, 0.453)] [G loss: 0.763] [G acc: 0.203]\n",
      "111 [D loss: (0.733)(R 0.683, F 0.782)] [D acc: (0.422)(0.516, 0.328)] [G loss: 0.784] [G acc: 0.125]\n",
      "112 [D loss: (0.733)(R 0.714, F 0.751)] [D acc: (0.391)(0.312, 0.469)] [G loss: 0.771] [G acc: 0.125]\n",
      "113 [D loss: (0.704)(R 0.736, F 0.672)] [D acc: (0.469)(0.234, 0.703)] [G loss: 0.745] [G acc: 0.172]\n",
      "114 [D loss: (0.713)(R 0.718, F 0.707)] [D acc: (0.438)(0.328, 0.547)] [G loss: 0.772] [G acc: 0.125]\n",
      "115 [D loss: (0.684)(R 0.717, F 0.651)] [D acc: (0.492)(0.297, 0.688)] [G loss: 0.750] [G acc: 0.188]\n",
      "116 [D loss: (0.691)(R 0.734, F 0.648)] [D acc: (0.445)(0.219, 0.672)] [G loss: 0.736] [G acc: 0.297]\n",
      "117 [D loss: (0.708)(R 0.695, F 0.720)] [D acc: (0.445)(0.422, 0.469)] [G loss: 0.730] [G acc: 0.328]\n",
      "118 [D loss: (0.672)(R 0.736, F 0.608)] [D acc: (0.547)(0.281, 0.812)] [G loss: 0.701] [G acc: 0.391]\n",
      "119 [D loss: (0.760)(R 0.717, F 0.804)] [D acc: (0.312)(0.453, 0.172)] [G loss: 0.788] [G acc: 0.094]\n",
      "120 [D loss: (0.636)(R 0.696, F 0.576)] [D acc: (0.703)(0.453, 0.953)] [G loss: 0.788] [G acc: 0.172]\n",
      "121 [D loss: (0.705)(R 0.660, F 0.750)] [D acc: (0.500)(0.562, 0.438)] [G loss: 0.888] [G acc: 0.031]\n",
      "122 [D loss: (0.726)(R 0.660, F 0.792)] [D acc: (0.469)(0.609, 0.328)] [G loss: 0.756] [G acc: 0.219]\n",
      "123 [D loss: (0.727)(R 0.659, F 0.795)] [D acc: (0.469)(0.625, 0.312)] [G loss: 0.766] [G acc: 0.172]\n",
      "124 [D loss: (0.704)(R 0.679, F 0.730)] [D acc: (0.500)(0.609, 0.391)] [G loss: 0.732] [G acc: 0.219]\n",
      "125 [D loss: (0.705)(R 0.709, F 0.701)] [D acc: (0.438)(0.375, 0.500)] [G loss: 0.735] [G acc: 0.188]\n",
      "126 [D loss: (0.680)(R 0.724, F 0.637)] [D acc: (0.562)(0.312, 0.812)] [G loss: 0.723] [G acc: 0.328]\n",
      "127 [D loss: (0.672)(R 0.722, F 0.621)] [D acc: (0.539)(0.359, 0.719)] [G loss: 0.713] [G acc: 0.328]\n",
      "128 [D loss: (0.692)(R 0.716, F 0.668)] [D acc: (0.484)(0.422, 0.547)] [G loss: 0.707] [G acc: 0.391]\n",
      "129 [D loss: (0.588)(R 0.700, F 0.475)] [D acc: (0.703)(0.469, 0.938)] [G loss: 0.714] [G acc: 0.484]\n",
      "130 [D loss: (0.785)(R 0.930, F 0.640)] [D acc: (0.539)(0.359, 0.719)] [G loss: 1.248] [G acc: 0.000]\n",
      "131 [D loss: (0.736)(R 0.723, F 0.749)] [D acc: (0.414)(0.344, 0.484)] [G loss: 0.885] [G acc: 0.000]\n",
      "132 [D loss: (0.719)(R 0.692, F 0.746)] [D acc: (0.422)(0.500, 0.344)] [G loss: 0.742] [G acc: 0.172]\n",
      "133 [D loss: (0.688)(R 0.708, F 0.669)] [D acc: (0.555)(0.391, 0.719)] [G loss: 0.739] [G acc: 0.109]\n",
      "134 [D loss: (0.672)(R 0.696, F 0.647)] [D acc: (0.578)(0.406, 0.750)] [G loss: 0.750] [G acc: 0.141]\n",
      "135 [D loss: (0.641)(R 0.717, F 0.564)] [D acc: (0.617)(0.406, 0.828)] [G loss: 0.741] [G acc: 0.156]\n",
      "136 [D loss: (0.606)(R 0.728, F 0.484)] [D acc: (0.602)(0.406, 0.797)] [G loss: 0.688] [G acc: 0.453]\n",
      "137 [D loss: (0.681)(R 0.778, F 0.585)] [D acc: (0.609)(0.438, 0.781)] [G loss: 0.658] [G acc: 0.672]\n",
      "138 [D loss: (0.561)(R 0.646, F 0.477)] [D acc: (0.758)(0.703, 0.812)] [G loss: 0.644] [G acc: 0.703]\n",
      "139 [D loss: (0.826)(R 0.774, F 0.878)] [D acc: (0.273)(0.516, 0.031)] [G loss: 0.811] [G acc: 0.031]\n",
      "140 [D loss: (0.695)(R 0.698, F 0.692)] [D acc: (0.469)(0.469, 0.469)] [G loss: 0.739] [G acc: 0.078]\n",
      "141 [D loss: (0.666)(R 0.663, F 0.669)] [D acc: (0.633)(0.734, 0.531)] [G loss: 0.711] [G acc: 0.344]\n",
      "142 [D loss: (0.654)(R 0.692, F 0.615)] [D acc: (0.688)(0.672, 0.703)] [G loss: 0.721] [G acc: 0.328]\n",
      "143 [D loss: (0.721)(R 0.693, F 0.749)] [D acc: (0.430)(0.594, 0.266)] [G loss: 0.715] [G acc: 0.172]\n",
      "144 [D loss: (0.664)(R 0.671, F 0.656)] [D acc: (0.641)(0.656, 0.625)] [G loss: 0.737] [G acc: 0.141]\n",
      "145 [D loss: (0.736)(R 0.738, F 0.733)] [D acc: (0.328)(0.375, 0.281)] [G loss: 0.722] [G acc: 0.078]\n",
      "146 [D loss: (0.688)(R 0.666, F 0.711)] [D acc: (0.555)(0.734, 0.375)] [G loss: 0.721] [G acc: 0.141]\n",
      "147 [D loss: (0.698)(R 0.666, F 0.730)] [D acc: (0.477)(0.703, 0.250)] [G loss: 0.723] [G acc: 0.078]\n",
      "148 [D loss: (0.698)(R 0.688, F 0.709)] [D acc: (0.477)(0.594, 0.359)] [G loss: 0.722] [G acc: 0.109]\n",
      "149 [D loss: (0.692)(R 0.679, F 0.705)] [D acc: (0.547)(0.609, 0.484)] [G loss: 0.731] [G acc: 0.031]\n",
      "150 [D loss: (0.692)(R 0.682, F 0.703)] [D acc: (0.523)(0.578, 0.469)] [G loss: 0.724] [G acc: 0.078]\n",
      "151 [D loss: (0.694)(R 0.681, F 0.707)] [D acc: (0.539)(0.547, 0.531)] [G loss: 0.727] [G acc: 0.000]\n",
      "152 [D loss: (0.690)(R 0.688, F 0.691)] [D acc: (0.586)(0.500, 0.672)] [G loss: 0.722] [G acc: 0.031]\n",
      "153 [D loss: (0.687)(R 0.669, F 0.705)] [D acc: (0.602)(0.734, 0.469)] [G loss: 0.730] [G acc: 0.016]\n",
      "154 [D loss: (0.684)(R 0.671, F 0.698)] [D acc: (0.586)(0.609, 0.562)] [G loss: 0.733] [G acc: 0.062]\n",
      "155 [D loss: (0.687)(R 0.684, F 0.690)] [D acc: (0.578)(0.484, 0.672)] [G loss: 0.737] [G acc: 0.078]\n",
      "156 [D loss: (0.690)(R 0.657, F 0.724)] [D acc: (0.570)(0.672, 0.469)] [G loss: 0.739] [G acc: 0.031]\n",
      "157 [D loss: (0.684)(R 0.670, F 0.697)] [D acc: (0.547)(0.547, 0.547)] [G loss: 0.748] [G acc: 0.047]\n",
      "158 [D loss: (0.694)(R 0.666, F 0.721)] [D acc: (0.516)(0.625, 0.406)] [G loss: 0.761] [G acc: 0.000]\n",
      "159 [D loss: (0.684)(R 0.688, F 0.681)] [D acc: (0.570)(0.438, 0.703)] [G loss: 0.741] [G acc: 0.031]\n",
      "160 [D loss: (0.711)(R 0.650, F 0.771)] [D acc: (0.477)(0.672, 0.281)] [G loss: 0.740] [G acc: 0.016]\n",
      "161 [D loss: (0.686)(R 0.699, F 0.673)] [D acc: (0.570)(0.375, 0.766)] [G loss: 0.741] [G acc: 0.047]\n",
      "162 [D loss: (0.693)(R 0.653, F 0.734)] [D acc: (0.477)(0.578, 0.375)] [G loss: 0.748] [G acc: 0.016]\n",
      "163 [D loss: (0.683)(R 0.671, F 0.694)] [D acc: (0.602)(0.547, 0.656)] [G loss: 0.750] [G acc: 0.047]\n",
      "164 [D loss: (0.691)(R 0.680, F 0.702)] [D acc: (0.516)(0.484, 0.547)] [G loss: 0.740] [G acc: 0.016]\n",
      "165 [D loss: (0.689)(R 0.659, F 0.718)] [D acc: (0.578)(0.516, 0.641)] [G loss: 0.744] [G acc: 0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 [D loss: (0.686)(R 0.697, F 0.675)] [D acc: (0.586)(0.375, 0.797)] [G loss: 0.738] [G acc: 0.000]\n",
      "167 [D loss: (0.712)(R 0.672, F 0.751)] [D acc: (0.422)(0.531, 0.312)] [G loss: 0.731] [G acc: 0.000]\n",
      "168 [D loss: (0.683)(R 0.688, F 0.679)] [D acc: (0.625)(0.469, 0.781)] [G loss: 0.729] [G acc: 0.031]\n",
      "169 [D loss: (0.686)(R 0.665, F 0.706)] [D acc: (0.492)(0.500, 0.484)] [G loss: 0.730] [G acc: 0.031]\n",
      "170 [D loss: (0.690)(R 0.598, F 0.782)] [D acc: (0.547)(0.812, 0.281)] [G loss: 0.731] [G acc: 0.000]\n",
      "171 [D loss: (0.671)(R 0.648, F 0.695)] [D acc: (0.625)(0.531, 0.719)] [G loss: 0.737] [G acc: 0.047]\n",
      "172 [D loss: (0.767)(R 0.582, F 0.952)] [D acc: (0.445)(0.672, 0.219)] [G loss: 0.737] [G acc: 0.000]\n",
      "173 [D loss: (0.687)(R 0.710, F 0.665)] [D acc: (0.594)(0.203, 0.984)] [G loss: 0.739] [G acc: 0.000]\n",
      "174 [D loss: (0.678)(R 0.671, F 0.686)] [D acc: (0.562)(0.438, 0.688)] [G loss: 0.738] [G acc: 0.000]\n",
      "175 [D loss: (0.688)(R 0.625, F 0.752)] [D acc: (0.531)(0.688, 0.375)] [G loss: 0.741] [G acc: 0.016]\n",
      "176 [D loss: (0.683)(R 0.665, F 0.702)] [D acc: (0.516)(0.438, 0.594)] [G loss: 0.738] [G acc: 0.000]\n",
      "177 [D loss: (0.678)(R 0.652, F 0.705)] [D acc: (0.602)(0.516, 0.688)] [G loss: 0.742] [G acc: 0.000]\n",
      "178 [D loss: (0.676)(R 0.625, F 0.727)] [D acc: (0.508)(0.547, 0.469)] [G loss: 0.748] [G acc: 0.000]\n",
      "179 [D loss: (0.662)(R 0.662, F 0.663)] [D acc: (0.734)(0.484, 0.984)] [G loss: 0.745] [G acc: 0.000]\n",
      "180 [D loss: (0.652)(R 0.565, F 0.740)] [D acc: (0.539)(0.734, 0.344)] [G loss: 0.730] [G acc: 0.141]\n",
      "181 [D loss: (0.969)(R 0.488, F 1.450)] [D acc: (0.438)(0.812, 0.062)] [G loss: 0.755] [G acc: 0.016]\n",
      "182 [D loss: (0.684)(R 0.694, F 0.675)] [D acc: (0.609)(0.375, 0.844)] [G loss: 0.742] [G acc: 0.031]\n",
      "183 [D loss: (0.669)(R 0.659, F 0.680)] [D acc: (0.633)(0.484, 0.781)] [G loss: 0.739] [G acc: 0.031]\n",
      "184 [D loss: (0.693)(R 0.645, F 0.740)] [D acc: (0.484)(0.609, 0.359)] [G loss: 0.717] [G acc: 0.141]\n",
      "185 [D loss: (0.701)(R 0.611, F 0.792)] [D acc: (0.445)(0.703, 0.188)] [G loss: 0.724] [G acc: 0.156]\n",
      "186 [D loss: (0.726)(R 0.653, F 0.800)] [D acc: (0.453)(0.500, 0.406)] [G loss: 0.743] [G acc: 0.078]\n",
      "187 [D loss: (0.714)(R 0.717, F 0.712)] [D acc: (0.359)(0.109, 0.609)] [G loss: 0.728] [G acc: 0.016]\n",
      "188 [D loss: (0.689)(R 0.706, F 0.671)] [D acc: (0.539)(0.188, 0.891)] [G loss: 0.726] [G acc: 0.031]\n",
      "189 [D loss: (0.690)(R 0.705, F 0.676)] [D acc: (0.531)(0.266, 0.797)] [G loss: 0.724] [G acc: 0.109]\n",
      "190 [D loss: (0.697)(R 0.698, F 0.696)] [D acc: (0.445)(0.266, 0.625)] [G loss: 0.735] [G acc: 0.031]\n",
      "191 [D loss: (0.686)(R 0.695, F 0.677)] [D acc: (0.586)(0.266, 0.906)] [G loss: 0.723] [G acc: 0.047]\n",
      "192 [D loss: (0.704)(R 0.677, F 0.731)] [D acc: (0.492)(0.500, 0.484)] [G loss: 0.736] [G acc: 0.047]\n",
      "193 [D loss: (0.687)(R 0.699, F 0.674)] [D acc: (0.578)(0.328, 0.828)] [G loss: 0.719] [G acc: 0.094]\n",
      "194 [D loss: (0.683)(R 0.674, F 0.692)] [D acc: (0.594)(0.484, 0.703)] [G loss: 0.716] [G acc: 0.141]\n",
      "195 [D loss: (0.727)(R 0.667, F 0.787)] [D acc: (0.492)(0.562, 0.422)] [G loss: 0.742] [G acc: 0.047]\n",
      "196 [D loss: (0.685)(R 0.689, F 0.682)] [D acc: (0.602)(0.422, 0.781)] [G loss: 0.717] [G acc: 0.156]\n",
      "197 [D loss: (0.690)(R 0.669, F 0.711)] [D acc: (0.523)(0.484, 0.562)] [G loss: 0.714] [G acc: 0.188]\n",
      "198 [D loss: (0.703)(R 0.691, F 0.716)] [D acc: (0.453)(0.422, 0.484)] [G loss: 0.726] [G acc: 0.141]\n",
      "199 [D loss: (0.696)(R 0.698, F 0.693)] [D acc: (0.508)(0.406, 0.609)] [G loss: 0.730] [G acc: 0.016]\n",
      "200 [D loss: (0.697)(R 0.684, F 0.710)] [D acc: (0.500)(0.547, 0.453)] [G loss: 0.735] [G acc: 0.047]\n",
      "201 [D loss: (0.679)(R 0.692, F 0.667)] [D acc: (0.656)(0.406, 0.906)] [G loss: 0.739] [G acc: 0.047]\n",
      "202 [D loss: (0.692)(R 0.676, F 0.707)] [D acc: (0.500)(0.578, 0.422)] [G loss: 0.730] [G acc: 0.094]\n",
      "203 [D loss: (0.692)(R 0.684, F 0.700)] [D acc: (0.539)(0.531, 0.547)] [G loss: 0.737] [G acc: 0.094]\n",
      "204 [D loss: (0.692)(R 0.690, F 0.693)] [D acc: (0.547)(0.453, 0.641)] [G loss: 0.734] [G acc: 0.094]\n",
      "205 [D loss: (0.688)(R 0.680, F 0.697)] [D acc: (0.523)(0.484, 0.562)] [G loss: 0.741] [G acc: 0.094]\n",
      "206 [D loss: (0.692)(R 0.683, F 0.701)] [D acc: (0.547)(0.516, 0.578)] [G loss: 0.749] [G acc: 0.031]\n",
      "207 [D loss: (0.690)(R 0.701, F 0.678)] [D acc: (0.555)(0.406, 0.703)] [G loss: 0.735] [G acc: 0.062]\n",
      "208 [D loss: (0.711)(R 0.665, F 0.756)] [D acc: (0.453)(0.562, 0.344)] [G loss: 0.730] [G acc: 0.062]\n",
      "209 [D loss: (0.683)(R 0.692, F 0.673)] [D acc: (0.594)(0.391, 0.797)] [G loss: 0.737] [G acc: 0.078]\n",
      "210 [D loss: (0.688)(R 0.691, F 0.685)] [D acc: (0.617)(0.547, 0.688)] [G loss: 0.737] [G acc: 0.078]\n",
      "211 [D loss: (0.688)(R 0.693, F 0.684)] [D acc: (0.539)(0.453, 0.625)] [G loss: 0.742] [G acc: 0.078]\n",
      "212 [D loss: (0.692)(R 0.689, F 0.694)] [D acc: (0.523)(0.469, 0.578)] [G loss: 0.748] [G acc: 0.031]\n",
      "213 [D loss: (0.695)(R 0.693, F 0.698)] [D acc: (0.492)(0.438, 0.547)] [G loss: 0.763] [G acc: 0.031]\n",
      "214 [D loss: (0.691)(R 0.719, F 0.664)] [D acc: (0.578)(0.297, 0.859)] [G loss: 0.784] [G acc: 0.016]\n",
      "215 [D loss: (0.684)(R 0.673, F 0.695)] [D acc: (0.617)(0.625, 0.609)] [G loss: 0.730] [G acc: 0.172]\n",
      "216 [D loss: (0.694)(R 0.674, F 0.715)] [D acc: (0.523)(0.641, 0.406)] [G loss: 0.726] [G acc: 0.141]\n",
      "217 [D loss: (0.694)(R 0.699, F 0.689)] [D acc: (0.516)(0.406, 0.625)] [G loss: 0.739] [G acc: 0.125]\n",
      "218 [D loss: (0.692)(R 0.696, F 0.688)] [D acc: (0.539)(0.484, 0.594)] [G loss: 0.725] [G acc: 0.172]\n",
      "219 [D loss: (0.673)(R 0.661, F 0.684)] [D acc: (0.594)(0.609, 0.578)] [G loss: 0.739] [G acc: 0.234]\n",
      "220 [D loss: (0.701)(R 0.686, F 0.717)] [D acc: (0.461)(0.516, 0.406)] [G loss: 0.749] [G acc: 0.203]\n",
      "221 [D loss: (0.628)(R 0.676, F 0.579)] [D acc: (0.750)(0.562, 0.938)] [G loss: 0.734] [G acc: 0.250]\n",
      "222 [D loss: (0.686)(R 0.644, F 0.727)] [D acc: (0.586)(0.672, 0.500)] [G loss: 0.930] [G acc: 0.062]\n",
      "223 [D loss: (0.616)(R 0.701, F 0.531)] [D acc: (0.703)(0.531, 0.875)] [G loss: 0.809] [G acc: 0.250]\n",
      "224 [D loss: (0.675)(R 0.689, F 0.661)] [D acc: (0.633)(0.594, 0.672)] [G loss: 0.914] [G acc: 0.109]\n",
      "225 [D loss: (0.841)(R 0.597, F 1.085)] [D acc: (0.422)(0.750, 0.094)] [G loss: 0.728] [G acc: 0.203]\n",
      "226 [D loss: (0.687)(R 0.671, F 0.702)] [D acc: (0.508)(0.578, 0.438)] [G loss: 0.726] [G acc: 0.203]\n",
      "227 [D loss: (0.685)(R 0.661, F 0.710)] [D acc: (0.570)(0.672, 0.469)] [G loss: 0.709] [G acc: 0.281]\n",
      "228 [D loss: (0.691)(R 0.660, F 0.722)] [D acc: (0.531)(0.641, 0.422)] [G loss: 0.727] [G acc: 0.203]\n",
      "229 [D loss: (0.687)(R 0.674, F 0.701)] [D acc: (0.586)(0.609, 0.562)] [G loss: 0.718] [G acc: 0.344]\n",
      "230 [D loss: (0.690)(R 0.666, F 0.713)] [D acc: (0.516)(0.625, 0.406)] [G loss: 0.731] [G acc: 0.156]\n",
      "231 [D loss: (0.672)(R 0.663, F 0.681)] [D acc: (0.586)(0.562, 0.609)] [G loss: 0.727] [G acc: 0.156]\n",
      "232 [D loss: (0.680)(R 0.641, F 0.719)] [D acc: (0.555)(0.625, 0.484)] [G loss: 0.725] [G acc: 0.312]\n",
      "233 [D loss: (0.691)(R 0.648, F 0.733)] [D acc: (0.484)(0.609, 0.359)] [G loss: 0.717] [G acc: 0.281]\n",
      "234 [D loss: (0.677)(R 0.644, F 0.710)] [D acc: (0.625)(0.703, 0.547)] [G loss: 0.716] [G acc: 0.344]\n",
      "235 [D loss: (0.696)(R 0.635, F 0.758)] [D acc: (0.508)(0.656, 0.359)] [G loss: 0.718] [G acc: 0.297]\n",
      "236 [D loss: (0.701)(R 0.677, F 0.725)] [D acc: (0.445)(0.516, 0.375)] [G loss: 0.724] [G acc: 0.266]\n",
      "237 [D loss: (0.685)(R 0.661, F 0.710)] [D acc: (0.578)(0.641, 0.516)] [G loss: 0.735] [G acc: 0.203]\n",
      "238 [D loss: (0.693)(R 0.666, F 0.721)] [D acc: (0.508)(0.578, 0.438)] [G loss: 0.739] [G acc: 0.172]\n",
      "239 [D loss: (0.679)(R 0.664, F 0.694)] [D acc: (0.656)(0.703, 0.609)] [G loss: 0.765] [G acc: 0.094]\n",
      "240 [D loss: (0.699)(R 0.677, F 0.721)] [D acc: (0.492)(0.531, 0.453)] [G loss: 0.728] [G acc: 0.219]\n",
      "241 [D loss: (0.700)(R 0.688, F 0.712)] [D acc: (0.500)(0.531, 0.469)] [G loss: 0.737] [G acc: 0.156]\n",
      "242 [D loss: (0.675)(R 0.662, F 0.688)] [D acc: (0.539)(0.500, 0.578)] [G loss: 0.733] [G acc: 0.219]\n",
      "243 [D loss: (0.677)(R 0.673, F 0.680)] [D acc: (0.609)(0.547, 0.672)] [G loss: 0.729] [G acc: 0.281]\n",
      "244 [D loss: (0.696)(R 0.660, F 0.733)] [D acc: (0.531)(0.641, 0.422)] [G loss: 0.747] [G acc: 0.125]\n",
      "245 [D loss: (0.681)(R 0.674, F 0.688)] [D acc: (0.539)(0.484, 0.594)] [G loss: 0.748] [G acc: 0.094]\n",
      "246 [D loss: (0.680)(R 0.646, F 0.715)] [D acc: (0.570)(0.688, 0.453)] [G loss: 0.753] [G acc: 0.141]\n",
      "247 [D loss: (0.673)(R 0.643, F 0.702)] [D acc: (0.578)(0.641, 0.516)] [G loss: 0.738] [G acc: 0.172]\n",
      "248 [D loss: (0.676)(R 0.651, F 0.701)] [D acc: (0.539)(0.625, 0.453)] [G loss: 0.741] [G acc: 0.234]\n",
      "249 [D loss: (0.677)(R 0.620, F 0.734)] [D acc: (0.555)(0.688, 0.422)] [G loss: 0.788] [G acc: 0.156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 [D loss: (0.710)(R 0.660, F 0.760)] [D acc: (0.469)(0.594, 0.344)] [G loss: 0.768] [G acc: 0.172]\n",
      "251 [D loss: (0.696)(R 0.648, F 0.745)] [D acc: (0.516)(0.609, 0.422)] [G loss: 0.759] [G acc: 0.109]\n",
      "252 [D loss: (0.676)(R 0.638, F 0.713)] [D acc: (0.555)(0.688, 0.422)] [G loss: 0.747] [G acc: 0.266]\n",
      "253 [D loss: (0.700)(R 0.645, F 0.754)] [D acc: (0.539)(0.766, 0.312)] [G loss: 0.742] [G acc: 0.188]\n",
      "254 [D loss: (0.690)(R 0.683, F 0.696)] [D acc: (0.539)(0.562, 0.516)] [G loss: 0.741] [G acc: 0.188]\n",
      "255 [D loss: (0.688)(R 0.655, F 0.721)] [D acc: (0.594)(0.719, 0.469)] [G loss: 0.727] [G acc: 0.266]\n",
      "256 [D loss: (0.701)(R 0.668, F 0.734)] [D acc: (0.461)(0.516, 0.406)] [G loss: 0.735] [G acc: 0.172]\n",
      "257 [D loss: (0.676)(R 0.660, F 0.692)] [D acc: (0.586)(0.609, 0.562)] [G loss: 0.732] [G acc: 0.281]\n",
      "258 [D loss: (0.698)(R 0.676, F 0.720)] [D acc: (0.547)(0.578, 0.516)] [G loss: 0.738] [G acc: 0.156]\n",
      "259 [D loss: (0.678)(R 0.655, F 0.701)] [D acc: (0.625)(0.703, 0.547)] [G loss: 0.743] [G acc: 0.188]\n",
      "260 [D loss: (0.680)(R 0.646, F 0.714)] [D acc: (0.562)(0.656, 0.469)] [G loss: 0.745] [G acc: 0.203]\n",
      "261 [D loss: (0.675)(R 0.658, F 0.693)] [D acc: (0.594)(0.656, 0.531)] [G loss: 0.754] [G acc: 0.156]\n",
      "262 [D loss: (0.710)(R 0.665, F 0.756)] [D acc: (0.461)(0.578, 0.344)] [G loss: 0.743] [G acc: 0.172]\n",
      "263 [D loss: (0.667)(R 0.639, F 0.695)] [D acc: (0.633)(0.688, 0.578)] [G loss: 0.736] [G acc: 0.203]\n",
      "264 [D loss: (0.684)(R 0.641, F 0.726)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.742] [G acc: 0.234]\n",
      "265 [D loss: (0.677)(R 0.650, F 0.703)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.766] [G acc: 0.141]\n",
      "266 [D loss: (0.686)(R 0.648, F 0.724)] [D acc: (0.570)(0.625, 0.516)] [G loss: 0.751] [G acc: 0.156]\n",
      "267 [D loss: (0.676)(R 0.684, F 0.667)] [D acc: (0.586)(0.484, 0.688)] [G loss: 0.757] [G acc: 0.203]\n",
      "268 [D loss: (0.676)(R 0.661, F 0.690)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.740] [G acc: 0.234]\n",
      "269 [D loss: (0.673)(R 0.636, F 0.710)] [D acc: (0.562)(0.656, 0.469)] [G loss: 0.744] [G acc: 0.266]\n",
      "270 [D loss: (0.685)(R 0.647, F 0.724)] [D acc: (0.555)(0.641, 0.469)] [G loss: 0.764] [G acc: 0.172]\n",
      "271 [D loss: (0.679)(R 0.630, F 0.728)] [D acc: (0.586)(0.703, 0.469)] [G loss: 0.765] [G acc: 0.188]\n",
      "272 [D loss: (0.692)(R 0.645, F 0.738)] [D acc: (0.531)(0.625, 0.438)] [G loss: 0.746] [G acc: 0.266]\n",
      "273 [D loss: (0.652)(R 0.652, F 0.651)] [D acc: (0.641)(0.594, 0.688)] [G loss: 0.851] [G acc: 0.125]\n",
      "274 [D loss: (0.671)(R 0.745, F 0.596)] [D acc: (0.672)(0.453, 0.891)] [G loss: 1.085] [G acc: 0.125]\n",
      "275 [D loss: (0.727)(R 0.605, F 0.848)] [D acc: (0.445)(0.703, 0.188)] [G loss: 0.732] [G acc: 0.266]\n",
      "276 [D loss: (0.660)(R 0.606, F 0.715)] [D acc: (0.664)(0.812, 0.516)] [G loss: 0.728] [G acc: 0.281]\n",
      "277 [D loss: (0.675)(R 0.578, F 0.773)] [D acc: (0.648)(0.875, 0.422)] [G loss: 0.738] [G acc: 0.328]\n",
      "278 [D loss: (0.669)(R 0.619, F 0.719)] [D acc: (0.594)(0.688, 0.500)] [G loss: 0.758] [G acc: 0.266]\n",
      "279 [D loss: (0.681)(R 0.600, F 0.761)] [D acc: (0.617)(0.766, 0.469)] [G loss: 0.770] [G acc: 0.203]\n",
      "280 [D loss: (0.682)(R 0.645, F 0.718)] [D acc: (0.594)(0.641, 0.547)] [G loss: 0.762] [G acc: 0.203]\n",
      "281 [D loss: (0.660)(R 0.599, F 0.722)] [D acc: (0.602)(0.750, 0.453)] [G loss: 0.771] [G acc: 0.188]\n",
      "282 [D loss: (0.676)(R 0.622, F 0.729)] [D acc: (0.578)(0.719, 0.438)] [G loss: 0.753] [G acc: 0.344]\n",
      "283 [D loss: (0.650)(R 0.604, F 0.697)] [D acc: (0.633)(0.734, 0.531)] [G loss: 0.776] [G acc: 0.172]\n",
      "284 [D loss: (0.666)(R 0.636, F 0.695)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.779] [G acc: 0.203]\n",
      "285 [D loss: (0.676)(R 0.647, F 0.705)] [D acc: (0.555)(0.641, 0.469)] [G loss: 0.801] [G acc: 0.094]\n",
      "286 [D loss: (0.689)(R 0.624, F 0.754)] [D acc: (0.594)(0.719, 0.469)] [G loss: 0.776] [G acc: 0.188]\n",
      "287 [D loss: (0.688)(R 0.675, F 0.700)] [D acc: (0.555)(0.594, 0.516)] [G loss: 0.770] [G acc: 0.281]\n",
      "288 [D loss: (0.682)(R 0.683, F 0.681)] [D acc: (0.555)(0.500, 0.609)] [G loss: 0.778] [G acc: 0.188]\n",
      "289 [D loss: (0.675)(R 0.657, F 0.693)] [D acc: (0.602)(0.609, 0.594)] [G loss: 0.784] [G acc: 0.125]\n",
      "290 [D loss: (0.683)(R 0.637, F 0.728)] [D acc: (0.586)(0.688, 0.484)] [G loss: 0.784] [G acc: 0.172]\n",
      "291 [D loss: (0.660)(R 0.647, F 0.674)] [D acc: (0.641)(0.609, 0.672)] [G loss: 0.770] [G acc: 0.172]\n",
      "292 [D loss: (0.661)(R 0.630, F 0.691)] [D acc: (0.609)(0.703, 0.516)] [G loss: 0.796] [G acc: 0.109]\n",
      "293 [D loss: (0.645)(R 0.620, F 0.669)] [D acc: (0.641)(0.656, 0.625)] [G loss: 0.789] [G acc: 0.188]\n",
      "294 [D loss: (0.654)(R 0.613, F 0.694)] [D acc: (0.586)(0.625, 0.547)] [G loss: 0.810] [G acc: 0.203]\n",
      "295 [D loss: (0.663)(R 0.613, F 0.714)] [D acc: (0.664)(0.734, 0.594)] [G loss: 0.928] [G acc: 0.031]\n",
      "296 [D loss: (0.712)(R 0.690, F 0.734)] [D acc: (0.539)(0.516, 0.562)] [G loss: 0.840] [G acc: 0.109]\n",
      "297 [D loss: (0.680)(R 0.618, F 0.742)] [D acc: (0.555)(0.625, 0.484)] [G loss: 0.787] [G acc: 0.188]\n",
      "298 [D loss: (0.676)(R 0.649, F 0.703)] [D acc: (0.539)(0.609, 0.469)] [G loss: 0.804] [G acc: 0.125]\n",
      "299 [D loss: (0.654)(R 0.626, F 0.683)] [D acc: (0.633)(0.625, 0.641)] [G loss: 0.792] [G acc: 0.203]\n",
      "300 [D loss: (0.684)(R 0.635, F 0.733)] [D acc: (0.562)(0.641, 0.484)] [G loss: 0.769] [G acc: 0.219]\n",
      "301 [D loss: (0.672)(R 0.648, F 0.695)] [D acc: (0.594)(0.578, 0.609)] [G loss: 0.796] [G acc: 0.156]\n",
      "302 [D loss: (0.676)(R 0.622, F 0.730)] [D acc: (0.531)(0.609, 0.453)] [G loss: 0.831] [G acc: 0.094]\n",
      "303 [D loss: (0.685)(R 0.684, F 0.686)] [D acc: (0.586)(0.594, 0.578)] [G loss: 0.791] [G acc: 0.172]\n",
      "304 [D loss: (0.675)(R 0.640, F 0.711)] [D acc: (0.578)(0.641, 0.516)] [G loss: 0.786] [G acc: 0.141]\n",
      "305 [D loss: (0.674)(R 0.645, F 0.702)] [D acc: (0.609)(0.656, 0.562)] [G loss: 0.800] [G acc: 0.172]\n",
      "306 [D loss: (0.669)(R 0.638, F 0.700)] [D acc: (0.609)(0.594, 0.625)] [G loss: 0.806] [G acc: 0.141]\n",
      "307 [D loss: (0.649)(R 0.613, F 0.686)] [D acc: (0.641)(0.688, 0.594)] [G loss: 0.851] [G acc: 0.109]\n",
      "308 [D loss: (0.676)(R 0.655, F 0.698)] [D acc: (0.594)(0.625, 0.562)] [G loss: 0.825] [G acc: 0.156]\n",
      "309 [D loss: (0.659)(R 0.636, F 0.681)] [D acc: (0.609)(0.609, 0.609)] [G loss: 0.819] [G acc: 0.109]\n",
      "310 [D loss: (0.680)(R 0.593, F 0.767)] [D acc: (0.555)(0.703, 0.406)] [G loss: 0.822] [G acc: 0.125]\n",
      "311 [D loss: (0.665)(R 0.670, F 0.659)] [D acc: (0.633)(0.594, 0.672)] [G loss: 0.836] [G acc: 0.156]\n",
      "312 [D loss: (0.666)(R 0.622, F 0.709)] [D acc: (0.586)(0.656, 0.516)] [G loss: 0.861] [G acc: 0.094]\n",
      "313 [D loss: (0.700)(R 0.700, F 0.701)] [D acc: (0.516)(0.484, 0.547)] [G loss: 0.795] [G acc: 0.156]\n",
      "314 [D loss: (0.670)(R 0.656, F 0.683)] [D acc: (0.555)(0.547, 0.562)] [G loss: 0.820] [G acc: 0.078]\n",
      "315 [D loss: (0.672)(R 0.639, F 0.706)] [D acc: (0.594)(0.594, 0.594)] [G loss: 0.844] [G acc: 0.078]\n",
      "316 [D loss: (0.642)(R 0.639, F 0.645)] [D acc: (0.672)(0.672, 0.672)] [G loss: 0.832] [G acc: 0.172]\n",
      "317 [D loss: (0.678)(R 0.647, F 0.708)] [D acc: (0.625)(0.641, 0.609)] [G loss: 0.840] [G acc: 0.141]\n",
      "318 [D loss: (0.652)(R 0.619, F 0.686)] [D acc: (0.617)(0.672, 0.562)] [G loss: 0.816] [G acc: 0.188]\n",
      "319 [D loss: (0.661)(R 0.631, F 0.691)] [D acc: (0.578)(0.609, 0.547)] [G loss: 0.849] [G acc: 0.078]\n",
      "320 [D loss: (0.650)(R 0.581, F 0.720)] [D acc: (0.625)(0.719, 0.531)] [G loss: 0.849] [G acc: 0.125]\n",
      "321 [D loss: (0.645)(R 0.617, F 0.674)] [D acc: (0.688)(0.719, 0.656)] [G loss: 0.810] [G acc: 0.188]\n",
      "322 [D loss: (0.647)(R 0.554, F 0.740)] [D acc: (0.594)(0.734, 0.453)] [G loss: 0.839] [G acc: 0.141]\n",
      "323 [D loss: (0.631)(R 0.612, F 0.651)] [D acc: (0.711)(0.688, 0.734)] [G loss: 0.835] [G acc: 0.125]\n",
      "324 [D loss: (0.699)(R 0.592, F 0.806)] [D acc: (0.586)(0.688, 0.484)] [G loss: 0.875] [G acc: 0.094]\n",
      "325 [D loss: (0.639)(R 0.562, F 0.716)] [D acc: (0.602)(0.688, 0.516)] [G loss: 0.870] [G acc: 0.125]\n",
      "326 [D loss: (0.639)(R 0.665, F 0.614)] [D acc: (0.711)(0.594, 0.828)] [G loss: 0.929] [G acc: 0.047]\n",
      "327 [D loss: (0.665)(R 0.636, F 0.693)] [D acc: (0.594)(0.594, 0.594)] [G loss: 0.906] [G acc: 0.141]\n",
      "328 [D loss: (0.648)(R 0.601, F 0.696)] [D acc: (0.633)(0.672, 0.594)] [G loss: 0.787] [G acc: 0.234]\n",
      "329 [D loss: (0.646)(R 0.614, F 0.679)] [D acc: (0.594)(0.578, 0.609)] [G loss: 0.847] [G acc: 0.172]\n",
      "330 [D loss: (0.617)(R 0.546, F 0.689)] [D acc: (0.648)(0.766, 0.531)] [G loss: 0.822] [G acc: 0.297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331 [D loss: (0.642)(R 0.538, F 0.747)] [D acc: (0.633)(0.797, 0.469)] [G loss: 0.870] [G acc: 0.219]\n",
      "332 [D loss: (0.703)(R 0.611, F 0.794)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.876] [G acc: 0.156]\n",
      "333 [D loss: (0.654)(R 0.648, F 0.660)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.884] [G acc: 0.109]\n",
      "334 [D loss: (0.643)(R 0.597, F 0.688)] [D acc: (0.656)(0.703, 0.609)] [G loss: 0.860] [G acc: 0.156]\n",
      "335 [D loss: (0.677)(R 0.581, F 0.774)] [D acc: (0.578)(0.672, 0.484)] [G loss: 0.872] [G acc: 0.203]\n",
      "336 [D loss: (0.641)(R 0.594, F 0.689)] [D acc: (0.641)(0.703, 0.578)] [G loss: 0.912] [G acc: 0.078]\n",
      "337 [D loss: (0.650)(R 0.639, F 0.660)] [D acc: (0.641)(0.609, 0.672)] [G loss: 0.958] [G acc: 0.078]\n",
      "338 [D loss: (0.636)(R 0.609, F 0.663)] [D acc: (0.648)(0.672, 0.625)] [G loss: 0.896] [G acc: 0.141]\n",
      "339 [D loss: (0.626)(R 0.608, F 0.644)] [D acc: (0.688)(0.703, 0.672)] [G loss: 0.932] [G acc: 0.141]\n",
      "340 [D loss: (0.673)(R 0.637, F 0.710)] [D acc: (0.570)(0.594, 0.547)] [G loss: 0.926] [G acc: 0.125]\n",
      "341 [D loss: (0.659)(R 0.607, F 0.712)] [D acc: (0.578)(0.625, 0.531)] [G loss: 0.913] [G acc: 0.125]\n",
      "342 [D loss: (0.599)(R 0.543, F 0.655)] [D acc: (0.711)(0.719, 0.703)] [G loss: 0.912] [G acc: 0.125]\n",
      "343 [D loss: (0.655)(R 0.563, F 0.748)] [D acc: (0.656)(0.750, 0.562)] [G loss: 0.913] [G acc: 0.172]\n",
      "344 [D loss: (0.679)(R 0.599, F 0.758)] [D acc: (0.617)(0.703, 0.531)] [G loss: 0.944] [G acc: 0.078]\n",
      "345 [D loss: (0.625)(R 0.620, F 0.631)] [D acc: (0.664)(0.641, 0.688)] [G loss: 0.930] [G acc: 0.188]\n",
      "346 [D loss: (0.665)(R 0.573, F 0.756)] [D acc: (0.617)(0.672, 0.562)] [G loss: 0.931] [G acc: 0.141]\n",
      "347 [D loss: (0.657)(R 0.618, F 0.696)] [D acc: (0.602)(0.625, 0.578)] [G loss: 0.941] [G acc: 0.125]\n",
      "348 [D loss: (0.653)(R 0.627, F 0.680)] [D acc: (0.602)(0.625, 0.578)] [G loss: 0.916] [G acc: 0.094]\n",
      "349 [D loss: (0.653)(R 0.619, F 0.688)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.897] [G acc: 0.172]\n",
      "350 [D loss: (0.671)(R 0.634, F 0.707)] [D acc: (0.578)(0.641, 0.516)] [G loss: 0.920] [G acc: 0.141]\n",
      "351 [D loss: (0.674)(R 0.636, F 0.712)] [D acc: (0.586)(0.594, 0.578)] [G loss: 0.877] [G acc: 0.125]\n",
      "352 [D loss: (0.605)(R 0.581, F 0.629)] [D acc: (0.695)(0.703, 0.688)] [G loss: 0.888] [G acc: 0.156]\n",
      "353 [D loss: (0.644)(R 0.626, F 0.661)] [D acc: (0.695)(0.719, 0.672)] [G loss: 0.878] [G acc: 0.203]\n",
      "354 [D loss: (0.657)(R 0.636, F 0.677)] [D acc: (0.555)(0.516, 0.594)] [G loss: 0.918] [G acc: 0.141]\n",
      "355 [D loss: (0.651)(R 0.630, F 0.673)] [D acc: (0.625)(0.578, 0.672)] [G loss: 0.900] [G acc: 0.109]\n",
      "356 [D loss: (0.640)(R 0.633, F 0.647)] [D acc: (0.586)(0.547, 0.625)] [G loss: 0.901] [G acc: 0.141]\n",
      "357 [D loss: (0.639)(R 0.662, F 0.616)] [D acc: (0.641)(0.547, 0.734)] [G loss: 0.860] [G acc: 0.188]\n",
      "358 [D loss: (0.611)(R 0.522, F 0.700)] [D acc: (0.695)(0.734, 0.656)] [G loss: 0.825] [G acc: 0.297]\n",
      "359 [D loss: (0.677)(R 0.594, F 0.759)] [D acc: (0.617)(0.672, 0.562)] [G loss: 0.935] [G acc: 0.094]\n",
      "360 [D loss: (0.654)(R 0.643, F 0.665)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.938] [G acc: 0.094]\n",
      "361 [D loss: (0.664)(R 0.654, F 0.675)] [D acc: (0.578)(0.578, 0.578)] [G loss: 0.893] [G acc: 0.172]\n",
      "362 [D loss: (0.637)(R 0.609, F 0.665)] [D acc: (0.688)(0.672, 0.703)] [G loss: 0.973] [G acc: 0.109]\n",
      "363 [D loss: (0.639)(R 0.620, F 0.658)] [D acc: (0.641)(0.625, 0.656)] [G loss: 0.901] [G acc: 0.156]\n",
      "364 [D loss: (0.691)(R 0.618, F 0.764)] [D acc: (0.578)(0.656, 0.500)] [G loss: 0.901] [G acc: 0.094]\n",
      "365 [D loss: (0.660)(R 0.599, F 0.722)] [D acc: (0.586)(0.625, 0.547)] [G loss: 0.924] [G acc: 0.125]\n",
      "366 [D loss: (0.641)(R 0.595, F 0.686)] [D acc: (0.680)(0.703, 0.656)] [G loss: 0.923] [G acc: 0.156]\n",
      "367 [D loss: (0.665)(R 0.602, F 0.728)] [D acc: (0.641)(0.703, 0.578)] [G loss: 0.896] [G acc: 0.156]\n",
      "368 [D loss: (0.675)(R 0.712, F 0.637)] [D acc: (0.617)(0.500, 0.734)] [G loss: 0.872] [G acc: 0.141]\n",
      "369 [D loss: (0.666)(R 0.636, F 0.696)] [D acc: (0.617)(0.625, 0.609)] [G loss: 0.891] [G acc: 0.109]\n",
      "370 [D loss: (0.658)(R 0.605, F 0.711)] [D acc: (0.594)(0.641, 0.547)] [G loss: 0.915] [G acc: 0.125]\n",
      "371 [D loss: (0.605)(R 0.574, F 0.636)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.877] [G acc: 0.203]\n",
      "372 [D loss: (0.646)(R 0.616, F 0.676)] [D acc: (0.578)(0.656, 0.500)] [G loss: 0.929] [G acc: 0.141]\n",
      "373 [D loss: (0.609)(R 0.527, F 0.690)] [D acc: (0.711)(0.750, 0.672)] [G loss: 0.932] [G acc: 0.172]\n",
      "374 [D loss: (0.609)(R 0.540, F 0.679)] [D acc: (0.664)(0.703, 0.625)] [G loss: 0.883] [G acc: 0.188]\n",
      "375 [D loss: (0.654)(R 0.608, F 0.700)] [D acc: (0.570)(0.547, 0.594)] [G loss: 0.827] [G acc: 0.281]\n",
      "376 [D loss: (0.617)(R 0.563, F 0.670)] [D acc: (0.648)(0.672, 0.625)] [G loss: 0.885] [G acc: 0.156]\n",
      "377 [D loss: (0.631)(R 0.582, F 0.679)] [D acc: (0.609)(0.641, 0.578)] [G loss: 0.862] [G acc: 0.250]\n",
      "378 [D loss: (0.685)(R 0.599, F 0.770)] [D acc: (0.555)(0.625, 0.484)] [G loss: 0.864] [G acc: 0.234]\n",
      "379 [D loss: (0.683)(R 0.652, F 0.713)] [D acc: (0.562)(0.547, 0.578)] [G loss: 0.869] [G acc: 0.234]\n",
      "380 [D loss: (0.631)(R 0.618, F 0.645)] [D acc: (0.648)(0.625, 0.672)] [G loss: 0.909] [G acc: 0.156]\n",
      "381 [D loss: (0.658)(R 0.581, F 0.735)] [D acc: (0.641)(0.672, 0.609)] [G loss: 0.900] [G acc: 0.172]\n",
      "382 [D loss: (0.637)(R 0.575, F 0.699)] [D acc: (0.625)(0.641, 0.609)] [G loss: 0.959] [G acc: 0.125]\n",
      "383 [D loss: (0.648)(R 0.596, F 0.700)] [D acc: (0.633)(0.609, 0.656)] [G loss: 0.888] [G acc: 0.156]\n",
      "384 [D loss: (0.665)(R 0.571, F 0.759)] [D acc: (0.594)(0.609, 0.578)] [G loss: 0.937] [G acc: 0.109]\n",
      "385 [D loss: (0.707)(R 0.688, F 0.727)] [D acc: (0.547)(0.500, 0.594)] [G loss: 0.874] [G acc: 0.109]\n",
      "386 [D loss: (0.653)(R 0.638, F 0.668)] [D acc: (0.633)(0.594, 0.672)] [G loss: 0.891] [G acc: 0.141]\n",
      "387 [D loss: (0.626)(R 0.595, F 0.657)] [D acc: (0.672)(0.703, 0.641)] [G loss: 0.881] [G acc: 0.125]\n",
      "388 [D loss: (0.656)(R 0.635, F 0.677)] [D acc: (0.609)(0.562, 0.656)] [G loss: 0.930] [G acc: 0.094]\n",
      "389 [D loss: (0.588)(R 0.590, F 0.586)] [D acc: (0.758)(0.734, 0.781)] [G loss: 0.962] [G acc: 0.109]\n",
      "390 [D loss: (0.637)(R 0.651, F 0.623)] [D acc: (0.641)(0.531, 0.750)] [G loss: 0.923] [G acc: 0.125]\n",
      "391 [D loss: (0.643)(R 0.590, F 0.696)] [D acc: (0.656)(0.688, 0.625)] [G loss: 0.957] [G acc: 0.141]\n",
      "392 [D loss: (0.587)(R 0.578, F 0.596)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.076] [G acc: 0.062]\n",
      "393 [D loss: (0.636)(R 0.701, F 0.572)] [D acc: (0.648)(0.500, 0.797)] [G loss: 1.065] [G acc: 0.062]\n",
      "394 [D loss: (0.680)(R 0.587, F 0.774)] [D acc: (0.578)(0.656, 0.500)] [G loss: 0.897] [G acc: 0.203]\n",
      "395 [D loss: (0.658)(R 0.599, F 0.716)] [D acc: (0.633)(0.688, 0.578)] [G loss: 0.910] [G acc: 0.203]\n",
      "396 [D loss: (0.634)(R 0.565, F 0.703)] [D acc: (0.586)(0.609, 0.562)] [G loss: 0.910] [G acc: 0.125]\n",
      "397 [D loss: (0.673)(R 0.589, F 0.757)] [D acc: (0.578)(0.703, 0.453)] [G loss: 0.953] [G acc: 0.078]\n",
      "398 [D loss: (0.634)(R 0.623, F 0.645)] [D acc: (0.641)(0.641, 0.641)] [G loss: 0.913] [G acc: 0.172]\n",
      "399 [D loss: (0.695)(R 0.704, F 0.686)] [D acc: (0.531)(0.453, 0.609)] [G loss: 0.935] [G acc: 0.141]\n",
      "400 [D loss: (0.644)(R 0.656, F 0.633)] [D acc: (0.617)(0.578, 0.656)] [G loss: 0.853] [G acc: 0.219]\n",
      "401 [D loss: (0.643)(R 0.607, F 0.679)] [D acc: (0.633)(0.609, 0.656)] [G loss: 0.890] [G acc: 0.141]\n",
      "402 [D loss: (0.646)(R 0.554, F 0.737)] [D acc: (0.586)(0.641, 0.531)] [G loss: 0.905] [G acc: 0.125]\n",
      "403 [D loss: (0.661)(R 0.630, F 0.692)] [D acc: (0.586)(0.594, 0.578)] [G loss: 0.890] [G acc: 0.203]\n",
      "404 [D loss: (0.655)(R 0.607, F 0.703)] [D acc: (0.609)(0.609, 0.609)] [G loss: 0.942] [G acc: 0.141]\n",
      "405 [D loss: (0.639)(R 0.600, F 0.678)] [D acc: (0.617)(0.703, 0.531)] [G loss: 0.893] [G acc: 0.188]\n",
      "406 [D loss: (0.644)(R 0.605, F 0.684)] [D acc: (0.586)(0.578, 0.594)] [G loss: 0.942] [G acc: 0.172]\n",
      "407 [D loss: (0.626)(R 0.625, F 0.627)] [D acc: (0.664)(0.578, 0.750)] [G loss: 0.909] [G acc: 0.203]\n",
      "408 [D loss: (0.608)(R 0.534, F 0.683)] [D acc: (0.664)(0.719, 0.609)] [G loss: 0.940] [G acc: 0.156]\n",
      "409 [D loss: (0.665)(R 0.646, F 0.685)] [D acc: (0.578)(0.578, 0.578)] [G loss: 0.912] [G acc: 0.141]\n",
      "410 [D loss: (0.648)(R 0.653, F 0.643)] [D acc: (0.672)(0.641, 0.703)] [G loss: 0.946] [G acc: 0.141]\n",
      "411 [D loss: (0.670)(R 0.612, F 0.729)] [D acc: (0.625)(0.656, 0.594)] [G loss: 0.910] [G acc: 0.141]\n",
      "412 [D loss: (0.635)(R 0.628, F 0.642)] [D acc: (0.625)(0.594, 0.656)] [G loss: 0.907] [G acc: 0.125]\n",
      "413 [D loss: (0.572)(R 0.494, F 0.649)] [D acc: (0.734)(0.812, 0.656)] [G loss: 0.997] [G acc: 0.156]\n",
      "414 [D loss: (0.643)(R 0.612, F 0.674)] [D acc: (0.648)(0.625, 0.672)] [G loss: 0.988] [G acc: 0.156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415 [D loss: (0.608)(R 0.583, F 0.632)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.996] [G acc: 0.188]\n",
      "416 [D loss: (0.606)(R 0.540, F 0.672)] [D acc: (0.664)(0.672, 0.656)] [G loss: 0.935] [G acc: 0.172]\n",
      "417 [D loss: (0.642)(R 0.612, F 0.671)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.000] [G acc: 0.156]\n",
      "418 [D loss: (0.671)(R 0.609, F 0.733)] [D acc: (0.633)(0.672, 0.594)] [G loss: 0.975] [G acc: 0.125]\n",
      "419 [D loss: (0.623)(R 0.631, F 0.614)] [D acc: (0.648)(0.594, 0.703)] [G loss: 0.996] [G acc: 0.141]\n",
      "420 [D loss: (0.595)(R 0.596, F 0.594)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.035] [G acc: 0.125]\n",
      "421 [D loss: (0.689)(R 0.700, F 0.678)] [D acc: (0.578)(0.484, 0.672)] [G loss: 0.973] [G acc: 0.141]\n",
      "422 [D loss: (0.624)(R 0.602, F 0.645)] [D acc: (0.641)(0.641, 0.641)] [G loss: 1.002] [G acc: 0.078]\n",
      "423 [D loss: (0.637)(R 0.609, F 0.665)] [D acc: (0.633)(0.594, 0.672)] [G loss: 0.926] [G acc: 0.156]\n",
      "424 [D loss: (0.707)(R 0.636, F 0.778)] [D acc: (0.547)(0.578, 0.516)] [G loss: 1.013] [G acc: 0.016]\n",
      "425 [D loss: (0.678)(R 0.688, F 0.668)] [D acc: (0.562)(0.469, 0.656)] [G loss: 0.937] [G acc: 0.125]\n",
      "426 [D loss: (0.634)(R 0.623, F 0.645)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.012] [G acc: 0.078]\n",
      "427 [D loss: (0.633)(R 0.627, F 0.639)] [D acc: (0.641)(0.547, 0.734)] [G loss: 0.914] [G acc: 0.188]\n",
      "428 [D loss: (0.618)(R 0.588, F 0.649)] [D acc: (0.664)(0.625, 0.703)] [G loss: 0.919] [G acc: 0.188]\n",
      "429 [D loss: (0.657)(R 0.546, F 0.769)] [D acc: (0.617)(0.703, 0.531)] [G loss: 0.921] [G acc: 0.203]\n",
      "430 [D loss: (0.640)(R 0.605, F 0.674)] [D acc: (0.625)(0.594, 0.656)] [G loss: 0.912] [G acc: 0.188]\n",
      "431 [D loss: (0.654)(R 0.562, F 0.745)] [D acc: (0.617)(0.672, 0.562)] [G loss: 1.033] [G acc: 0.078]\n",
      "432 [D loss: (0.649)(R 0.645, F 0.653)] [D acc: (0.609)(0.562, 0.656)] [G loss: 0.943] [G acc: 0.188]\n",
      "433 [D loss: (0.651)(R 0.634, F 0.667)] [D acc: (0.648)(0.594, 0.703)] [G loss: 0.978] [G acc: 0.109]\n",
      "434 [D loss: (0.644)(R 0.616, F 0.671)] [D acc: (0.625)(0.609, 0.641)] [G loss: 0.904] [G acc: 0.203]\n",
      "435 [D loss: (0.636)(R 0.653, F 0.620)] [D acc: (0.602)(0.500, 0.703)] [G loss: 0.902] [G acc: 0.141]\n",
      "436 [D loss: (0.640)(R 0.658, F 0.622)] [D acc: (0.625)(0.594, 0.656)] [G loss: 0.906] [G acc: 0.156]\n",
      "437 [D loss: (0.665)(R 0.536, F 0.795)] [D acc: (0.625)(0.750, 0.500)] [G loss: 0.965] [G acc: 0.094]\n",
      "438 [D loss: (0.677)(R 0.643, F 0.712)] [D acc: (0.547)(0.531, 0.562)] [G loss: 0.926] [G acc: 0.172]\n",
      "439 [D loss: (0.648)(R 0.601, F 0.695)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.881] [G acc: 0.234]\n",
      "440 [D loss: (0.636)(R 0.589, F 0.682)] [D acc: (0.625)(0.672, 0.578)] [G loss: 0.955] [G acc: 0.172]\n",
      "441 [D loss: (0.654)(R 0.670, F 0.637)] [D acc: (0.609)(0.484, 0.734)] [G loss: 0.974] [G acc: 0.094]\n",
      "442 [D loss: (0.616)(R 0.601, F 0.631)] [D acc: (0.680)(0.641, 0.719)] [G loss: 0.985] [G acc: 0.109]\n",
      "443 [D loss: (0.626)(R 0.629, F 0.623)] [D acc: (0.664)(0.625, 0.703)] [G loss: 0.923] [G acc: 0.203]\n",
      "444 [D loss: (0.634)(R 0.586, F 0.682)] [D acc: (0.664)(0.688, 0.641)] [G loss: 0.954] [G acc: 0.141]\n",
      "445 [D loss: (0.644)(R 0.654, F 0.634)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.984] [G acc: 0.078]\n",
      "446 [D loss: (0.654)(R 0.601, F 0.707)] [D acc: (0.641)(0.703, 0.578)] [G loss: 0.936] [G acc: 0.078]\n",
      "447 [D loss: (0.604)(R 0.642, F 0.567)] [D acc: (0.641)(0.500, 0.781)] [G loss: 1.007] [G acc: 0.109]\n",
      "448 [D loss: (0.623)(R 0.615, F 0.631)] [D acc: (0.664)(0.625, 0.703)] [G loss: 0.943] [G acc: 0.156]\n",
      "449 [D loss: (0.678)(R 0.573, F 0.784)] [D acc: (0.625)(0.672, 0.578)] [G loss: 0.936] [G acc: 0.141]\n",
      "450 [D loss: (0.636)(R 0.594, F 0.678)] [D acc: (0.641)(0.656, 0.625)] [G loss: 0.894] [G acc: 0.156]\n",
      "451 [D loss: (0.660)(R 0.585, F 0.734)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.033] [G acc: 0.047]\n",
      "452 [D loss: (0.631)(R 0.628, F 0.635)] [D acc: (0.633)(0.562, 0.703)] [G loss: 0.889] [G acc: 0.203]\n",
      "453 [D loss: (0.648)(R 0.554, F 0.742)] [D acc: (0.609)(0.688, 0.531)] [G loss: 0.909] [G acc: 0.125]\n",
      "454 [D loss: (0.645)(R 0.635, F 0.656)] [D acc: (0.648)(0.562, 0.734)] [G loss: 0.906] [G acc: 0.203]\n",
      "455 [D loss: (0.630)(R 0.589, F 0.671)] [D acc: (0.641)(0.688, 0.594)] [G loss: 0.954] [G acc: 0.188]\n",
      "456 [D loss: (0.648)(R 0.664, F 0.632)] [D acc: (0.594)(0.516, 0.672)] [G loss: 1.047] [G acc: 0.078]\n",
      "457 [D loss: (0.668)(R 0.609, F 0.726)] [D acc: (0.594)(0.641, 0.547)] [G loss: 0.918] [G acc: 0.141]\n",
      "458 [D loss: (0.632)(R 0.590, F 0.673)] [D acc: (0.625)(0.641, 0.609)] [G loss: 0.956] [G acc: 0.141]\n",
      "459 [D loss: (0.639)(R 0.576, F 0.702)] [D acc: (0.672)(0.672, 0.672)] [G loss: 0.949] [G acc: 0.125]\n",
      "460 [D loss: (0.627)(R 0.600, F 0.653)] [D acc: (0.656)(0.656, 0.656)] [G loss: 0.930] [G acc: 0.141]\n",
      "461 [D loss: (0.617)(R 0.632, F 0.602)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.947] [G acc: 0.188]\n",
      "462 [D loss: (0.617)(R 0.565, F 0.669)] [D acc: (0.672)(0.719, 0.625)] [G loss: 0.974] [G acc: 0.203]\n",
      "463 [D loss: (0.633)(R 0.612, F 0.654)] [D acc: (0.609)(0.609, 0.609)] [G loss: 0.917] [G acc: 0.141]\n",
      "464 [D loss: (0.655)(R 0.604, F 0.706)] [D acc: (0.641)(0.672, 0.609)] [G loss: 0.902] [G acc: 0.266]\n",
      "465 [D loss: (0.656)(R 0.623, F 0.689)] [D acc: (0.664)(0.625, 0.703)] [G loss: 0.991] [G acc: 0.094]\n",
      "466 [D loss: (0.595)(R 0.570, F 0.620)] [D acc: (0.703)(0.719, 0.688)] [G loss: 0.989] [G acc: 0.141]\n",
      "467 [D loss: (0.651)(R 0.604, F 0.697)] [D acc: (0.609)(0.625, 0.594)] [G loss: 0.924] [G acc: 0.219]\n",
      "468 [D loss: (0.654)(R 0.619, F 0.689)] [D acc: (0.617)(0.609, 0.625)] [G loss: 1.002] [G acc: 0.109]\n",
      "469 [D loss: (0.642)(R 0.584, F 0.700)] [D acc: (0.625)(0.641, 0.609)] [G loss: 1.060] [G acc: 0.109]\n",
      "470 [D loss: (0.660)(R 0.575, F 0.746)] [D acc: (0.578)(0.625, 0.531)] [G loss: 0.931] [G acc: 0.172]\n",
      "471 [D loss: (0.619)(R 0.616, F 0.621)] [D acc: (0.664)(0.562, 0.766)] [G loss: 0.980] [G acc: 0.141]\n",
      "472 [D loss: (0.635)(R 0.615, F 0.655)] [D acc: (0.648)(0.625, 0.672)] [G loss: 0.995] [G acc: 0.125]\n",
      "473 [D loss: (0.608)(R 0.579, F 0.638)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.048] [G acc: 0.094]\n",
      "474 [D loss: (0.630)(R 0.617, F 0.642)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.000] [G acc: 0.125]\n",
      "475 [D loss: (0.659)(R 0.690, F 0.627)] [D acc: (0.594)(0.469, 0.719)] [G loss: 0.918] [G acc: 0.172]\n",
      "476 [D loss: (0.619)(R 0.638, F 0.601)] [D acc: (0.641)(0.531, 0.750)] [G loss: 0.994] [G acc: 0.047]\n",
      "477 [D loss: (0.620)(R 0.589, F 0.650)] [D acc: (0.695)(0.641, 0.750)] [G loss: 0.940] [G acc: 0.141]\n",
      "478 [D loss: (0.670)(R 0.678, F 0.661)] [D acc: (0.617)(0.594, 0.641)] [G loss: 0.947] [G acc: 0.172]\n",
      "479 [D loss: (0.641)(R 0.643, F 0.638)] [D acc: (0.594)(0.609, 0.578)] [G loss: 1.013] [G acc: 0.125]\n",
      "480 [D loss: (0.643)(R 0.686, F 0.600)] [D acc: (0.602)(0.469, 0.734)] [G loss: 0.993] [G acc: 0.141]\n",
      "481 [D loss: (0.629)(R 0.557, F 0.701)] [D acc: (0.648)(0.703, 0.594)] [G loss: 1.004] [G acc: 0.109]\n",
      "482 [D loss: (0.586)(R 0.572, F 0.599)] [D acc: (0.711)(0.672, 0.750)] [G loss: 0.975] [G acc: 0.141]\n",
      "483 [D loss: (0.598)(R 0.542, F 0.654)] [D acc: (0.672)(0.672, 0.672)] [G loss: 0.995] [G acc: 0.156]\n",
      "484 [D loss: (0.650)(R 0.644, F 0.656)] [D acc: (0.625)(0.562, 0.688)] [G loss: 0.988] [G acc: 0.125]\n",
      "485 [D loss: (0.644)(R 0.597, F 0.690)] [D acc: (0.648)(0.609, 0.688)] [G loss: 0.958] [G acc: 0.125]\n",
      "486 [D loss: (0.603)(R 0.583, F 0.623)] [D acc: (0.695)(0.641, 0.750)] [G loss: 0.933] [G acc: 0.188]\n",
      "487 [D loss: (0.596)(R 0.559, F 0.632)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.010] [G acc: 0.125]\n",
      "488 [D loss: (0.601)(R 0.573, F 0.630)] [D acc: (0.609)(0.609, 0.609)] [G loss: 0.908] [G acc: 0.203]\n",
      "489 [D loss: (0.600)(R 0.531, F 0.669)] [D acc: (0.719)(0.703, 0.734)] [G loss: 0.939] [G acc: 0.172]\n",
      "490 [D loss: (0.683)(R 0.626, F 0.740)] [D acc: (0.586)(0.594, 0.578)] [G loss: 1.009] [G acc: 0.141]\n",
      "491 [D loss: (0.709)(R 0.697, F 0.720)] [D acc: (0.547)(0.484, 0.609)] [G loss: 0.934] [G acc: 0.125]\n",
      "492 [D loss: (0.601)(R 0.581, F 0.622)] [D acc: (0.695)(0.703, 0.688)] [G loss: 0.940] [G acc: 0.203]\n",
      "493 [D loss: (0.611)(R 0.564, F 0.658)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.045] [G acc: 0.109]\n",
      "494 [D loss: (0.603)(R 0.651, F 0.556)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.161] [G acc: 0.062]\n",
      "495 [D loss: (0.639)(R 0.695, F 0.584)] [D acc: (0.633)(0.516, 0.750)] [G loss: 1.034] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496 [D loss: (0.660)(R 0.596, F 0.725)] [D acc: (0.672)(0.703, 0.641)] [G loss: 0.918] [G acc: 0.203]\n",
      "497 [D loss: (0.615)(R 0.545, F 0.684)] [D acc: (0.680)(0.703, 0.656)] [G loss: 0.951] [G acc: 0.203]\n",
      "498 [D loss: (0.628)(R 0.602, F 0.654)] [D acc: (0.680)(0.656, 0.703)] [G loss: 0.937] [G acc: 0.250]\n",
      "499 [D loss: (0.685)(R 0.645, F 0.724)] [D acc: (0.570)(0.562, 0.578)] [G loss: 1.033] [G acc: 0.141]\n",
      "500 [D loss: (0.625)(R 0.591, F 0.659)] [D acc: (0.672)(0.625, 0.719)] [G loss: 0.996] [G acc: 0.188]\n",
      "501 [D loss: (0.643)(R 0.617, F 0.670)] [D acc: (0.570)(0.562, 0.578)] [G loss: 0.963] [G acc: 0.141]\n",
      "502 [D loss: (0.626)(R 0.621, F 0.632)] [D acc: (0.633)(0.594, 0.672)] [G loss: 0.943] [G acc: 0.203]\n",
      "503 [D loss: (0.610)(R 0.578, F 0.642)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.028] [G acc: 0.125]\n",
      "504 [D loss: (0.679)(R 0.612, F 0.747)] [D acc: (0.625)(0.656, 0.594)] [G loss: 0.979] [G acc: 0.125]\n",
      "505 [D loss: (0.577)(R 0.517, F 0.638)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.048] [G acc: 0.031]\n",
      "506 [D loss: (0.616)(R 0.593, F 0.639)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.021] [G acc: 0.156]\n",
      "507 [D loss: (0.656)(R 0.615, F 0.698)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.091] [G acc: 0.047]\n",
      "508 [D loss: (0.666)(R 0.648, F 0.684)] [D acc: (0.547)(0.547, 0.547)] [G loss: 0.998] [G acc: 0.141]\n",
      "509 [D loss: (0.642)(R 0.622, F 0.661)] [D acc: (0.633)(0.625, 0.641)] [G loss: 1.069] [G acc: 0.016]\n",
      "510 [D loss: (0.633)(R 0.649, F 0.617)] [D acc: (0.609)(0.562, 0.656)] [G loss: 0.972] [G acc: 0.125]\n",
      "511 [D loss: (0.634)(R 0.590, F 0.679)] [D acc: (0.609)(0.641, 0.578)] [G loss: 0.896] [G acc: 0.203]\n",
      "512 [D loss: (0.618)(R 0.599, F 0.637)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.030] [G acc: 0.078]\n",
      "513 [D loss: (0.579)(R 0.566, F 0.591)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.096] [G acc: 0.109]\n",
      "514 [D loss: (0.582)(R 0.578, F 0.586)] [D acc: (0.680)(0.672, 0.688)] [G loss: 0.908] [G acc: 0.250]\n",
      "515 [D loss: (0.663)(R 0.601, F 0.726)] [D acc: (0.602)(0.641, 0.562)] [G loss: 0.959] [G acc: 0.156]\n",
      "516 [D loss: (0.581)(R 0.519, F 0.643)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.001] [G acc: 0.188]\n",
      "517 [D loss: (0.663)(R 0.610, F 0.717)] [D acc: (0.633)(0.609, 0.656)] [G loss: 0.933] [G acc: 0.234]\n",
      "518 [D loss: (0.629)(R 0.599, F 0.659)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.076] [G acc: 0.047]\n",
      "519 [D loss: (0.656)(R 0.689, F 0.623)] [D acc: (0.617)(0.562, 0.672)] [G loss: 0.980] [G acc: 0.188]\n",
      "520 [D loss: (0.678)(R 0.558, F 0.798)] [D acc: (0.641)(0.688, 0.594)] [G loss: 0.941] [G acc: 0.219]\n",
      "521 [D loss: (0.615)(R 0.584, F 0.647)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.011] [G acc: 0.125]\n",
      "522 [D loss: (0.595)(R 0.608, F 0.583)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.037] [G acc: 0.125]\n",
      "523 [D loss: (0.680)(R 0.655, F 0.704)] [D acc: (0.594)(0.547, 0.641)] [G loss: 0.995] [G acc: 0.094]\n",
      "524 [D loss: (0.690)(R 0.628, F 0.752)] [D acc: (0.516)(0.547, 0.484)] [G loss: 0.994] [G acc: 0.094]\n",
      "525 [D loss: (0.624)(R 0.636, F 0.612)] [D acc: (0.625)(0.594, 0.656)] [G loss: 0.991] [G acc: 0.188]\n",
      "526 [D loss: (0.676)(R 0.683, F 0.669)] [D acc: (0.562)(0.484, 0.641)] [G loss: 0.958] [G acc: 0.156]\n",
      "527 [D loss: (0.659)(R 0.639, F 0.679)] [D acc: (0.617)(0.547, 0.688)] [G loss: 0.948] [G acc: 0.188]\n",
      "528 [D loss: (0.660)(R 0.682, F 0.639)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.972] [G acc: 0.141]\n",
      "529 [D loss: (0.623)(R 0.607, F 0.639)] [D acc: (0.734)(0.688, 0.781)] [G loss: 0.971] [G acc: 0.078]\n",
      "530 [D loss: (0.635)(R 0.662, F 0.608)] [D acc: (0.641)(0.562, 0.719)] [G loss: 0.996] [G acc: 0.125]\n",
      "531 [D loss: (0.660)(R 0.729, F 0.592)] [D acc: (0.656)(0.469, 0.844)] [G loss: 0.990] [G acc: 0.141]\n",
      "532 [D loss: (0.635)(R 0.543, F 0.727)] [D acc: (0.672)(0.719, 0.625)] [G loss: 0.953] [G acc: 0.094]\n",
      "533 [D loss: (0.635)(R 0.658, F 0.613)] [D acc: (0.680)(0.500, 0.859)] [G loss: 0.998] [G acc: 0.141]\n",
      "534 [D loss: (0.654)(R 0.672, F 0.637)] [D acc: (0.633)(0.562, 0.703)] [G loss: 0.918] [G acc: 0.203]\n",
      "535 [D loss: (0.595)(R 0.552, F 0.638)] [D acc: (0.680)(0.703, 0.656)] [G loss: 0.964] [G acc: 0.188]\n",
      "536 [D loss: (0.635)(R 0.608, F 0.663)] [D acc: (0.688)(0.672, 0.703)] [G loss: 0.974] [G acc: 0.156]\n",
      "537 [D loss: (0.617)(R 0.631, F 0.604)] [D acc: (0.656)(0.578, 0.734)] [G loss: 0.968] [G acc: 0.172]\n",
      "538 [D loss: (0.602)(R 0.542, F 0.662)] [D acc: (0.664)(0.688, 0.641)] [G loss: 1.041] [G acc: 0.094]\n",
      "539 [D loss: (0.679)(R 0.615, F 0.742)] [D acc: (0.641)(0.656, 0.625)] [G loss: 1.069] [G acc: 0.078]\n",
      "540 [D loss: (0.607)(R 0.598, F 0.615)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.160] [G acc: 0.062]\n",
      "541 [D loss: (0.623)(R 0.645, F 0.601)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.077] [G acc: 0.078]\n",
      "542 [D loss: (0.652)(R 0.671, F 0.634)] [D acc: (0.594)(0.531, 0.656)] [G loss: 0.994] [G acc: 0.141]\n",
      "543 [D loss: (0.664)(R 0.633, F 0.695)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.932] [G acc: 0.203]\n",
      "544 [D loss: (0.602)(R 0.561, F 0.644)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.008] [G acc: 0.141]\n",
      "545 [D loss: (0.672)(R 0.650, F 0.694)] [D acc: (0.570)(0.547, 0.594)] [G loss: 0.984] [G acc: 0.219]\n",
      "546 [D loss: (0.623)(R 0.626, F 0.619)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.047] [G acc: 0.156]\n",
      "547 [D loss: (0.642)(R 0.613, F 0.671)] [D acc: (0.594)(0.531, 0.656)] [G loss: 0.971] [G acc: 0.109]\n",
      "548 [D loss: (0.686)(R 0.596, F 0.777)] [D acc: (0.586)(0.594, 0.578)] [G loss: 0.971] [G acc: 0.156]\n",
      "549 [D loss: (0.633)(R 0.654, F 0.613)] [D acc: (0.656)(0.547, 0.766)] [G loss: 0.962] [G acc: 0.141]\n",
      "550 [D loss: (0.627)(R 0.608, F 0.647)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.037] [G acc: 0.078]\n",
      "551 [D loss: (0.622)(R 0.625, F 0.619)] [D acc: (0.664)(0.609, 0.719)] [G loss: 0.940] [G acc: 0.156]\n",
      "552 [D loss: (0.635)(R 0.625, F 0.645)] [D acc: (0.648)(0.547, 0.750)] [G loss: 1.077] [G acc: 0.062]\n",
      "553 [D loss: (0.681)(R 0.745, F 0.617)] [D acc: (0.562)(0.453, 0.672)] [G loss: 0.910] [G acc: 0.219]\n",
      "554 [D loss: (0.721)(R 0.699, F 0.743)] [D acc: (0.516)(0.484, 0.547)] [G loss: 0.909] [G acc: 0.188]\n",
      "555 [D loss: (0.605)(R 0.630, F 0.581)] [D acc: (0.703)(0.578, 0.828)] [G loss: 0.951] [G acc: 0.094]\n",
      "556 [D loss: (0.687)(R 0.586, F 0.787)] [D acc: (0.578)(0.656, 0.500)] [G loss: 0.992] [G acc: 0.078]\n",
      "557 [D loss: (0.609)(R 0.616, F 0.603)] [D acc: (0.719)(0.672, 0.766)] [G loss: 0.945] [G acc: 0.234]\n",
      "558 [D loss: (0.638)(R 0.643, F 0.633)] [D acc: (0.664)(0.609, 0.719)] [G loss: 0.943] [G acc: 0.125]\n",
      "559 [D loss: (0.640)(R 0.585, F 0.696)] [D acc: (0.680)(0.703, 0.656)] [G loss: 0.912] [G acc: 0.172]\n",
      "560 [D loss: (0.603)(R 0.612, F 0.593)] [D acc: (0.648)(0.594, 0.703)] [G loss: 0.972] [G acc: 0.172]\n",
      "561 [D loss: (0.570)(R 0.550, F 0.590)] [D acc: (0.703)(0.672, 0.734)] [G loss: 0.950] [G acc: 0.219]\n",
      "562 [D loss: (0.682)(R 0.598, F 0.766)] [D acc: (0.594)(0.609, 0.578)] [G loss: 1.005] [G acc: 0.156]\n",
      "563 [D loss: (0.614)(R 0.608, F 0.620)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.005] [G acc: 0.109]\n",
      "564 [D loss: (0.661)(R 0.638, F 0.684)] [D acc: (0.625)(0.594, 0.656)] [G loss: 0.952] [G acc: 0.141]\n",
      "565 [D loss: (0.638)(R 0.605, F 0.671)] [D acc: (0.641)(0.594, 0.688)] [G loss: 0.949] [G acc: 0.156]\n",
      "566 [D loss: (0.636)(R 0.657, F 0.615)] [D acc: (0.617)(0.500, 0.734)] [G loss: 1.072] [G acc: 0.078]\n",
      "567 [D loss: (0.674)(R 0.761, F 0.586)] [D acc: (0.609)(0.422, 0.797)] [G loss: 1.018] [G acc: 0.094]\n",
      "568 [D loss: (0.641)(R 0.599, F 0.684)] [D acc: (0.641)(0.656, 0.625)] [G loss: 0.907] [G acc: 0.188]\n",
      "569 [D loss: (0.600)(R 0.584, F 0.617)] [D acc: (0.664)(0.625, 0.703)] [G loss: 0.949] [G acc: 0.250]\n",
      "570 [D loss: (0.661)(R 0.642, F 0.681)] [D acc: (0.602)(0.547, 0.656)] [G loss: 0.937] [G acc: 0.234]\n",
      "571 [D loss: (0.654)(R 0.618, F 0.690)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.045] [G acc: 0.094]\n",
      "572 [D loss: (0.637)(R 0.675, F 0.599)] [D acc: (0.680)(0.594, 0.766)] [G loss: 0.869] [G acc: 0.266]\n",
      "573 [D loss: (0.701)(R 0.651, F 0.752)] [D acc: (0.633)(0.656, 0.609)] [G loss: 0.972] [G acc: 0.141]\n",
      "574 [D loss: (0.644)(R 0.618, F 0.669)] [D acc: (0.617)(0.609, 0.625)] [G loss: 0.921] [G acc: 0.156]\n",
      "575 [D loss: (0.618)(R 0.623, F 0.614)] [D acc: (0.609)(0.562, 0.656)] [G loss: 1.016] [G acc: 0.156]\n",
      "576 [D loss: (0.606)(R 0.580, F 0.631)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.040] [G acc: 0.094]\n",
      "577 [D loss: (0.649)(R 0.640, F 0.658)] [D acc: (0.617)(0.594, 0.641)] [G loss: 0.896] [G acc: 0.203]\n",
      "578 [D loss: (0.666)(R 0.596, F 0.736)] [D acc: (0.633)(0.672, 0.594)] [G loss: 0.945] [G acc: 0.078]\n",
      "579 [D loss: (0.644)(R 0.622, F 0.666)] [D acc: (0.688)(0.641, 0.734)] [G loss: 0.982] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580 [D loss: (0.594)(R 0.576, F 0.612)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.010] [G acc: 0.156]\n",
      "581 [D loss: (0.623)(R 0.616, F 0.630)] [D acc: (0.648)(0.609, 0.688)] [G loss: 0.982] [G acc: 0.062]\n",
      "582 [D loss: (0.608)(R 0.566, F 0.649)] [D acc: (0.688)(0.672, 0.703)] [G loss: 0.966] [G acc: 0.188]\n",
      "583 [D loss: (0.647)(R 0.636, F 0.658)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.000] [G acc: 0.141]\n",
      "584 [D loss: (0.631)(R 0.587, F 0.674)] [D acc: (0.586)(0.625, 0.547)] [G loss: 0.946] [G acc: 0.172]\n",
      "585 [D loss: (0.610)(R 0.595, F 0.624)] [D acc: (0.648)(0.609, 0.688)] [G loss: 0.898] [G acc: 0.219]\n",
      "586 [D loss: (0.661)(R 0.615, F 0.707)] [D acc: (0.609)(0.578, 0.641)] [G loss: 0.928] [G acc: 0.250]\n",
      "587 [D loss: (0.649)(R 0.638, F 0.660)] [D acc: (0.602)(0.578, 0.625)] [G loss: 0.989] [G acc: 0.203]\n",
      "588 [D loss: (0.643)(R 0.596, F 0.690)] [D acc: (0.594)(0.578, 0.609)] [G loss: 0.937] [G acc: 0.156]\n",
      "589 [D loss: (0.629)(R 0.585, F 0.673)] [D acc: (0.672)(0.672, 0.672)] [G loss: 0.969] [G acc: 0.156]\n",
      "590 [D loss: (0.617)(R 0.601, F 0.633)] [D acc: (0.648)(0.625, 0.672)] [G loss: 0.949] [G acc: 0.203]\n",
      "591 [D loss: (0.640)(R 0.623, F 0.656)] [D acc: (0.648)(0.609, 0.688)] [G loss: 0.918] [G acc: 0.203]\n",
      "592 [D loss: (0.661)(R 0.572, F 0.750)] [D acc: (0.602)(0.625, 0.578)] [G loss: 0.982] [G acc: 0.141]\n",
      "593 [D loss: (0.645)(R 0.670, F 0.619)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.001] [G acc: 0.125]\n",
      "594 [D loss: (0.596)(R 0.566, F 0.626)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.069] [G acc: 0.078]\n",
      "595 [D loss: (0.618)(R 0.611, F 0.626)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.068] [G acc: 0.156]\n",
      "596 [D loss: (0.705)(R 0.773, F 0.637)] [D acc: (0.602)(0.438, 0.766)] [G loss: 1.014] [G acc: 0.062]\n",
      "597 [D loss: (0.621)(R 0.647, F 0.595)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.918] [G acc: 0.203]\n",
      "598 [D loss: (0.578)(R 0.594, F 0.562)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.127] [G acc: 0.109]\n",
      "599 [D loss: (0.617)(R 0.638, F 0.595)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.093] [G acc: 0.078]\n",
      "600 [D loss: (0.744)(R 0.533, F 0.955)] [D acc: (0.609)(0.734, 0.484)] [G loss: 0.958] [G acc: 0.156]\n",
      "601 [D loss: (0.660)(R 0.703, F 0.617)] [D acc: (0.625)(0.531, 0.719)] [G loss: 0.903] [G acc: 0.250]\n",
      "602 [D loss: (0.651)(R 0.641, F 0.661)] [D acc: (0.617)(0.531, 0.703)] [G loss: 0.982] [G acc: 0.156]\n",
      "603 [D loss: (0.637)(R 0.680, F 0.593)] [D acc: (0.594)(0.453, 0.734)] [G loss: 1.027] [G acc: 0.141]\n",
      "604 [D loss: (0.643)(R 0.616, F 0.670)] [D acc: (0.656)(0.656, 0.656)] [G loss: 0.864] [G acc: 0.281]\n",
      "605 [D loss: (0.638)(R 0.575, F 0.701)] [D acc: (0.641)(0.641, 0.641)] [G loss: 0.987] [G acc: 0.125]\n",
      "606 [D loss: (0.623)(R 0.598, F 0.649)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.076] [G acc: 0.125]\n",
      "607 [D loss: (0.638)(R 0.651, F 0.624)] [D acc: (0.633)(0.500, 0.766)] [G loss: 1.000] [G acc: 0.203]\n",
      "608 [D loss: (0.586)(R 0.582, F 0.591)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.014] [G acc: 0.172]\n",
      "609 [D loss: (0.635)(R 0.586, F 0.684)] [D acc: (0.648)(0.688, 0.609)] [G loss: 0.983] [G acc: 0.172]\n",
      "610 [D loss: (0.588)(R 0.524, F 0.651)] [D acc: (0.742)(0.781, 0.703)] [G loss: 1.067] [G acc: 0.156]\n",
      "611 [D loss: (0.622)(R 0.677, F 0.566)] [D acc: (0.711)(0.578, 0.844)] [G loss: 0.977] [G acc: 0.172]\n",
      "612 [D loss: (0.670)(R 0.683, F 0.657)] [D acc: (0.594)(0.547, 0.641)] [G loss: 1.069] [G acc: 0.141]\n",
      "613 [D loss: (0.599)(R 0.595, F 0.603)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.097] [G acc: 0.031]\n",
      "614 [D loss: (0.698)(R 0.641, F 0.755)] [D acc: (0.562)(0.578, 0.547)] [G loss: 0.919] [G acc: 0.234]\n",
      "615 [D loss: (0.661)(R 0.675, F 0.647)] [D acc: (0.586)(0.547, 0.625)] [G loss: 0.955] [G acc: 0.141]\n",
      "616 [D loss: (0.652)(R 0.657, F 0.648)] [D acc: (0.617)(0.594, 0.641)] [G loss: 0.953] [G acc: 0.156]\n",
      "617 [D loss: (0.624)(R 0.601, F 0.648)] [D acc: (0.641)(0.578, 0.703)] [G loss: 0.998] [G acc: 0.141]\n",
      "618 [D loss: (0.655)(R 0.655, F 0.654)] [D acc: (0.586)(0.562, 0.609)] [G loss: 0.993] [G acc: 0.141]\n",
      "619 [D loss: (0.559)(R 0.582, F 0.537)] [D acc: (0.734)(0.656, 0.812)] [G loss: 0.992] [G acc: 0.219]\n",
      "620 [D loss: (0.652)(R 0.666, F 0.639)] [D acc: (0.617)(0.547, 0.688)] [G loss: 0.916] [G acc: 0.250]\n",
      "621 [D loss: (0.621)(R 0.611, F 0.632)] [D acc: (0.672)(0.609, 0.734)] [G loss: 0.944] [G acc: 0.234]\n",
      "622 [D loss: (0.605)(R 0.575, F 0.636)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.007] [G acc: 0.172]\n",
      "623 [D loss: (0.655)(R 0.596, F 0.713)] [D acc: (0.609)(0.688, 0.531)] [G loss: 0.971] [G acc: 0.219]\n",
      "624 [D loss: (0.658)(R 0.608, F 0.708)] [D acc: (0.625)(0.672, 0.578)] [G loss: 1.000] [G acc: 0.125]\n",
      "625 [D loss: (0.601)(R 0.597, F 0.605)] [D acc: (0.688)(0.625, 0.750)] [G loss: 0.994] [G acc: 0.156]\n",
      "626 [D loss: (0.623)(R 0.584, F 0.662)] [D acc: (0.609)(0.578, 0.641)] [G loss: 0.955] [G acc: 0.281]\n",
      "627 [D loss: (0.620)(R 0.644, F 0.596)] [D acc: (0.625)(0.516, 0.734)] [G loss: 0.971] [G acc: 0.219]\n",
      "628 [D loss: (0.659)(R 0.577, F 0.741)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.081] [G acc: 0.125]\n",
      "629 [D loss: (0.687)(R 0.706, F 0.668)] [D acc: (0.562)(0.531, 0.594)] [G loss: 0.957] [G acc: 0.203]\n",
      "630 [D loss: (0.585)(R 0.504, F 0.666)] [D acc: (0.688)(0.781, 0.594)] [G loss: 0.956] [G acc: 0.219]\n",
      "631 [D loss: (0.621)(R 0.576, F 0.666)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.020] [G acc: 0.156]\n",
      "632 [D loss: (0.652)(R 0.608, F 0.696)] [D acc: (0.641)(0.641, 0.641)] [G loss: 1.050] [G acc: 0.125]\n",
      "633 [D loss: (0.614)(R 0.649, F 0.579)] [D acc: (0.672)(0.594, 0.750)] [G loss: 0.959] [G acc: 0.141]\n",
      "634 [D loss: (0.696)(R 0.620, F 0.772)] [D acc: (0.641)(0.594, 0.688)] [G loss: 0.918] [G acc: 0.203]\n",
      "635 [D loss: (0.604)(R 0.645, F 0.563)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.018] [G acc: 0.094]\n",
      "636 [D loss: (0.616)(R 0.561, F 0.671)] [D acc: (0.648)(0.656, 0.641)] [G loss: 0.963] [G acc: 0.266]\n",
      "637 [D loss: (0.655)(R 0.630, F 0.680)] [D acc: (0.609)(0.578, 0.641)] [G loss: 1.065] [G acc: 0.156]\n",
      "638 [D loss: (0.591)(R 0.581, F 0.602)] [D acc: (0.680)(0.703, 0.656)] [G loss: 1.053] [G acc: 0.172]\n",
      "639 [D loss: (0.644)(R 0.633, F 0.654)] [D acc: (0.602)(0.578, 0.625)] [G loss: 0.987] [G acc: 0.250]\n",
      "640 [D loss: (0.630)(R 0.592, F 0.667)] [D acc: (0.648)(0.641, 0.656)] [G loss: 0.901] [G acc: 0.281]\n",
      "641 [D loss: (0.600)(R 0.556, F 0.644)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.923] [G acc: 0.188]\n",
      "642 [D loss: (0.650)(R 0.651, F 0.650)] [D acc: (0.617)(0.562, 0.672)] [G loss: 0.912] [G acc: 0.219]\n",
      "643 [D loss: (0.632)(R 0.564, F 0.700)] [D acc: (0.648)(0.688, 0.609)] [G loss: 0.960] [G acc: 0.188]\n",
      "644 [D loss: (0.564)(R 0.568, F 0.560)] [D acc: (0.758)(0.703, 0.812)] [G loss: 0.943] [G acc: 0.281]\n",
      "645 [D loss: (0.629)(R 0.645, F 0.613)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.016] [G acc: 0.125]\n",
      "646 [D loss: (0.625)(R 0.667, F 0.584)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.224] [G acc: 0.062]\n",
      "647 [D loss: (0.674)(R 0.758, F 0.591)] [D acc: (0.602)(0.500, 0.703)] [G loss: 1.059] [G acc: 0.156]\n",
      "648 [D loss: (0.665)(R 0.620, F 0.710)] [D acc: (0.570)(0.562, 0.578)] [G loss: 0.953] [G acc: 0.172]\n",
      "649 [D loss: (0.603)(R 0.590, F 0.617)] [D acc: (0.711)(0.656, 0.766)] [G loss: 0.958] [G acc: 0.203]\n",
      "650 [D loss: (0.641)(R 0.523, F 0.760)] [D acc: (0.664)(0.719, 0.609)] [G loss: 0.870] [G acc: 0.297]\n",
      "651 [D loss: (0.632)(R 0.625, F 0.638)] [D acc: (0.633)(0.578, 0.688)] [G loss: 0.954] [G acc: 0.188]\n",
      "652 [D loss: (0.678)(R 0.637, F 0.719)] [D acc: (0.562)(0.594, 0.531)] [G loss: 0.967] [G acc: 0.109]\n",
      "653 [D loss: (0.632)(R 0.632, F 0.633)] [D acc: (0.633)(0.531, 0.734)] [G loss: 0.934] [G acc: 0.141]\n",
      "654 [D loss: (0.645)(R 0.670, F 0.620)] [D acc: (0.617)(0.516, 0.719)] [G loss: 0.907] [G acc: 0.203]\n",
      "655 [D loss: (0.659)(R 0.667, F 0.650)] [D acc: (0.633)(0.578, 0.688)] [G loss: 0.960] [G acc: 0.141]\n",
      "656 [D loss: (0.682)(R 0.703, F 0.661)] [D acc: (0.570)(0.500, 0.641)] [G loss: 0.933] [G acc: 0.141]\n",
      "657 [D loss: (0.630)(R 0.503, F 0.758)] [D acc: (0.648)(0.750, 0.547)] [G loss: 0.960] [G acc: 0.203]\n",
      "658 [D loss: (0.561)(R 0.537, F 0.586)] [D acc: (0.695)(0.703, 0.688)] [G loss: 0.987] [G acc: 0.094]\n",
      "659 [D loss: (0.620)(R 0.561, F 0.679)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.156] [G acc: 0.047]\n",
      "660 [D loss: (0.659)(R 0.704, F 0.613)] [D acc: (0.609)(0.531, 0.688)] [G loss: 0.949] [G acc: 0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661 [D loss: (0.701)(R 0.598, F 0.804)] [D acc: (0.531)(0.609, 0.453)] [G loss: 0.923] [G acc: 0.219]\n",
      "662 [D loss: (0.673)(R 0.653, F 0.692)] [D acc: (0.586)(0.609, 0.562)] [G loss: 0.912] [G acc: 0.188]\n",
      "663 [D loss: (0.635)(R 0.637, F 0.632)] [D acc: (0.617)(0.578, 0.656)] [G loss: 0.922] [G acc: 0.250]\n",
      "664 [D loss: (0.649)(R 0.566, F 0.732)] [D acc: (0.586)(0.672, 0.500)] [G loss: 0.968] [G acc: 0.125]\n",
      "665 [D loss: (0.647)(R 0.628, F 0.665)] [D acc: (0.648)(0.609, 0.688)] [G loss: 0.979] [G acc: 0.125]\n",
      "666 [D loss: (0.644)(R 0.648, F 0.640)] [D acc: (0.617)(0.578, 0.656)] [G loss: 0.981] [G acc: 0.141]\n",
      "667 [D loss: (0.655)(R 0.661, F 0.649)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.047] [G acc: 0.188]\n",
      "668 [D loss: (0.649)(R 0.672, F 0.626)] [D acc: (0.586)(0.500, 0.672)] [G loss: 0.978] [G acc: 0.141]\n",
      "669 [D loss: (0.638)(R 0.647, F 0.629)] [D acc: (0.617)(0.547, 0.688)] [G loss: 0.955] [G acc: 0.203]\n",
      "670 [D loss: (0.663)(R 0.689, F 0.638)] [D acc: (0.570)(0.500, 0.641)] [G loss: 1.020] [G acc: 0.094]\n",
      "671 [D loss: (0.600)(R 0.621, F 0.579)] [D acc: (0.656)(0.594, 0.719)] [G loss: 0.962] [G acc: 0.188]\n",
      "672 [D loss: (0.627)(R 0.599, F 0.656)] [D acc: (0.656)(0.656, 0.656)] [G loss: 0.953] [G acc: 0.219]\n",
      "673 [D loss: (0.650)(R 0.704, F 0.596)] [D acc: (0.633)(0.484, 0.781)] [G loss: 1.000] [G acc: 0.141]\n",
      "674 [D loss: (0.656)(R 0.606, F 0.707)] [D acc: (0.609)(0.641, 0.578)] [G loss: 0.973] [G acc: 0.188]\n",
      "675 [D loss: (0.627)(R 0.619, F 0.634)] [D acc: (0.695)(0.656, 0.734)] [G loss: 0.931] [G acc: 0.188]\n",
      "676 [D loss: (0.634)(R 0.563, F 0.706)] [D acc: (0.648)(0.672, 0.625)] [G loss: 1.020] [G acc: 0.078]\n",
      "677 [D loss: (0.618)(R 0.635, F 0.601)] [D acc: (0.641)(0.516, 0.766)] [G loss: 0.982] [G acc: 0.188]\n",
      "678 [D loss: (0.645)(R 0.614, F 0.676)] [D acc: (0.633)(0.641, 0.625)] [G loss: 0.980] [G acc: 0.188]\n",
      "679 [D loss: (0.624)(R 0.621, F 0.626)] [D acc: (0.664)(0.594, 0.734)] [G loss: 0.905] [G acc: 0.281]\n",
      "680 [D loss: (0.619)(R 0.564, F 0.674)] [D acc: (0.648)(0.688, 0.609)] [G loss: 0.850] [G acc: 0.281]\n",
      "681 [D loss: (0.639)(R 0.520, F 0.759)] [D acc: (0.656)(0.734, 0.578)] [G loss: 1.136] [G acc: 0.125]\n",
      "682 [D loss: (0.655)(R 0.650, F 0.660)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.085] [G acc: 0.031]\n",
      "683 [D loss: (0.710)(R 0.702, F 0.719)] [D acc: (0.555)(0.547, 0.562)] [G loss: 0.906] [G acc: 0.250]\n",
      "684 [D loss: (0.623)(R 0.599, F 0.647)] [D acc: (0.648)(0.641, 0.656)] [G loss: 0.999] [G acc: 0.109]\n",
      "685 [D loss: (0.644)(R 0.637, F 0.650)] [D acc: (0.586)(0.562, 0.609)] [G loss: 0.944] [G acc: 0.172]\n",
      "686 [D loss: (0.634)(R 0.612, F 0.655)] [D acc: (0.672)(0.672, 0.672)] [G loss: 0.995] [G acc: 0.172]\n",
      "687 [D loss: (0.649)(R 0.623, F 0.674)] [D acc: (0.633)(0.609, 0.656)] [G loss: 0.841] [G acc: 0.250]\n",
      "688 [D loss: (0.636)(R 0.598, F 0.674)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.012] [G acc: 0.172]\n",
      "689 [D loss: (0.663)(R 0.634, F 0.693)] [D acc: (0.641)(0.609, 0.672)] [G loss: 0.889] [G acc: 0.281]\n",
      "690 [D loss: (0.637)(R 0.573, F 0.701)] [D acc: (0.672)(0.672, 0.672)] [G loss: 0.942] [G acc: 0.188]\n",
      "691 [D loss: (0.639)(R 0.586, F 0.693)] [D acc: (0.680)(0.672, 0.688)] [G loss: 0.981] [G acc: 0.109]\n",
      "692 [D loss: (0.639)(R 0.612, F 0.666)] [D acc: (0.625)(0.594, 0.656)] [G loss: 0.949] [G acc: 0.234]\n",
      "693 [D loss: (0.698)(R 0.765, F 0.631)] [D acc: (0.531)(0.453, 0.609)] [G loss: 0.922] [G acc: 0.188]\n",
      "694 [D loss: (0.642)(R 0.654, F 0.629)] [D acc: (0.602)(0.578, 0.625)] [G loss: 0.895] [G acc: 0.219]\n",
      "695 [D loss: (0.637)(R 0.650, F 0.623)] [D acc: (0.656)(0.531, 0.781)] [G loss: 0.916] [G acc: 0.188]\n",
      "696 [D loss: (0.602)(R 0.593, F 0.611)] [D acc: (0.680)(0.672, 0.688)] [G loss: 0.950] [G acc: 0.188]\n",
      "697 [D loss: (0.636)(R 0.609, F 0.664)] [D acc: (0.633)(0.609, 0.656)] [G loss: 0.965] [G acc: 0.125]\n",
      "698 [D loss: (0.605)(R 0.624, F 0.587)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.988] [G acc: 0.172]\n",
      "699 [D loss: (0.578)(R 0.495, F 0.661)] [D acc: (0.688)(0.734, 0.641)] [G loss: 1.138] [G acc: 0.109]\n",
      "700 [D loss: (0.569)(R 0.638, F 0.501)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.367] [G acc: 0.078]\n",
      "701 [D loss: (0.668)(R 0.579, F 0.757)] [D acc: (0.586)(0.625, 0.547)] [G loss: 1.023] [G acc: 0.203]\n",
      "702 [D loss: (0.655)(R 0.610, F 0.700)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.963] [G acc: 0.250]\n",
      "703 [D loss: (0.651)(R 0.673, F 0.629)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.067] [G acc: 0.141]\n",
      "704 [D loss: (0.610)(R 0.652, F 0.569)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.045] [G acc: 0.109]\n",
      "705 [D loss: (0.628)(R 0.613, F 0.644)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.015] [G acc: 0.188]\n",
      "706 [D loss: (0.659)(R 0.701, F 0.616)] [D acc: (0.625)(0.484, 0.766)] [G loss: 1.046] [G acc: 0.047]\n",
      "707 [D loss: (0.668)(R 0.661, F 0.674)] [D acc: (0.555)(0.516, 0.594)] [G loss: 1.080] [G acc: 0.141]\n",
      "708 [D loss: (0.683)(R 0.705, F 0.661)] [D acc: (0.586)(0.516, 0.656)] [G loss: 1.006] [G acc: 0.141]\n",
      "709 [D loss: (0.612)(R 0.567, F 0.657)] [D acc: (0.664)(0.672, 0.656)] [G loss: 0.910] [G acc: 0.219]\n",
      "710 [D loss: (0.659)(R 0.573, F 0.744)] [D acc: (0.641)(0.719, 0.562)] [G loss: 1.035] [G acc: 0.156]\n",
      "711 [D loss: (0.632)(R 0.666, F 0.597)] [D acc: (0.648)(0.516, 0.781)] [G loss: 0.934] [G acc: 0.188]\n",
      "712 [D loss: (0.612)(R 0.604, F 0.619)] [D acc: (0.695)(0.641, 0.750)] [G loss: 0.934] [G acc: 0.203]\n",
      "713 [D loss: (0.599)(R 0.584, F 0.614)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.004] [G acc: 0.203]\n",
      "714 [D loss: (0.643)(R 0.649, F 0.636)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.142] [G acc: 0.078]\n",
      "715 [D loss: (0.654)(R 0.723, F 0.584)] [D acc: (0.656)(0.531, 0.781)] [G loss: 1.079] [G acc: 0.125]\n",
      "716 [D loss: (0.627)(R 0.540, F 0.715)] [D acc: (0.609)(0.688, 0.531)] [G loss: 0.951] [G acc: 0.172]\n",
      "717 [D loss: (0.628)(R 0.562, F 0.694)] [D acc: (0.664)(0.734, 0.594)] [G loss: 1.106] [G acc: 0.125]\n",
      "718 [D loss: (0.625)(R 0.602, F 0.647)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.000] [G acc: 0.172]\n",
      "719 [D loss: (0.580)(R 0.526, F 0.634)] [D acc: (0.664)(0.688, 0.641)] [G loss: 1.023] [G acc: 0.250]\n",
      "720 [D loss: (0.668)(R 0.635, F 0.700)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.028] [G acc: 0.125]\n",
      "721 [D loss: (0.611)(R 0.600, F 0.622)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.103] [G acc: 0.125]\n",
      "722 [D loss: (0.592)(R 0.597, F 0.587)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.036] [G acc: 0.156]\n",
      "723 [D loss: (0.578)(R 0.556, F 0.601)] [D acc: (0.680)(0.609, 0.750)] [G loss: 0.971] [G acc: 0.156]\n",
      "724 [D loss: (0.629)(R 0.570, F 0.688)] [D acc: (0.641)(0.656, 0.625)] [G loss: 1.017] [G acc: 0.188]\n",
      "725 [D loss: (0.640)(R 0.629, F 0.651)] [D acc: (0.648)(0.594, 0.703)] [G loss: 0.995] [G acc: 0.203]\n",
      "726 [D loss: (0.669)(R 0.661, F 0.677)] [D acc: (0.602)(0.531, 0.672)] [G loss: 0.968] [G acc: 0.188]\n",
      "727 [D loss: (0.652)(R 0.647, F 0.657)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.104] [G acc: 0.094]\n",
      "728 [D loss: (0.559)(R 0.609, F 0.510)] [D acc: (0.734)(0.625, 0.844)] [G loss: 0.977] [G acc: 0.188]\n",
      "729 [D loss: (0.647)(R 0.596, F 0.698)] [D acc: (0.602)(0.578, 0.625)] [G loss: 1.009] [G acc: 0.156]\n",
      "730 [D loss: (0.621)(R 0.589, F 0.652)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.060] [G acc: 0.188]\n",
      "731 [D loss: (0.619)(R 0.636, F 0.603)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.037] [G acc: 0.203]\n",
      "732 [D loss: (0.673)(R 0.675, F 0.671)] [D acc: (0.594)(0.547, 0.641)] [G loss: 1.004] [G acc: 0.156]\n",
      "733 [D loss: (0.643)(R 0.622, F 0.664)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.017] [G acc: 0.156]\n",
      "734 [D loss: (0.664)(R 0.608, F 0.721)] [D acc: (0.586)(0.578, 0.594)] [G loss: 0.905] [G acc: 0.188]\n",
      "735 [D loss: (0.675)(R 0.632, F 0.719)] [D acc: (0.609)(0.578, 0.641)] [G loss: 1.021] [G acc: 0.203]\n",
      "736 [D loss: (0.657)(R 0.656, F 0.658)] [D acc: (0.570)(0.500, 0.641)] [G loss: 1.009] [G acc: 0.094]\n",
      "737 [D loss: (0.643)(R 0.682, F 0.603)] [D acc: (0.648)(0.531, 0.766)] [G loss: 0.965] [G acc: 0.188]\n",
      "738 [D loss: (0.671)(R 0.675, F 0.666)] [D acc: (0.602)(0.531, 0.672)] [G loss: 0.905] [G acc: 0.188]\n",
      "739 [D loss: (0.645)(R 0.648, F 0.642)] [D acc: (0.641)(0.562, 0.719)] [G loss: 0.932] [G acc: 0.234]\n",
      "740 [D loss: (0.680)(R 0.700, F 0.660)] [D acc: (0.578)(0.531, 0.625)] [G loss: 0.984] [G acc: 0.141]\n",
      "741 [D loss: (0.610)(R 0.671, F 0.550)] [D acc: (0.664)(0.469, 0.859)] [G loss: 0.902] [G acc: 0.188]\n",
      "742 [D loss: (0.638)(R 0.624, F 0.652)] [D acc: (0.656)(0.594, 0.719)] [G loss: 0.962] [G acc: 0.203]\n",
      "743 [D loss: (0.623)(R 0.586, F 0.661)] [D acc: (0.695)(0.641, 0.750)] [G loss: 0.981] [G acc: 0.156]\n",
      "744 [D loss: (0.668)(R 0.654, F 0.682)] [D acc: (0.641)(0.562, 0.719)] [G loss: 0.902] [G acc: 0.250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745 [D loss: (0.674)(R 0.617, F 0.732)] [D acc: (0.586)(0.562, 0.609)] [G loss: 0.929] [G acc: 0.219]\n",
      "746 [D loss: (0.640)(R 0.588, F 0.693)] [D acc: (0.625)(0.656, 0.594)] [G loss: 0.968] [G acc: 0.141]\n",
      "747 [D loss: (0.634)(R 0.668, F 0.600)] [D acc: (0.664)(0.547, 0.781)] [G loss: 0.982] [G acc: 0.156]\n",
      "748 [D loss: (0.650)(R 0.665, F 0.634)] [D acc: (0.672)(0.594, 0.750)] [G loss: 0.902] [G acc: 0.234]\n",
      "749 [D loss: (0.627)(R 0.579, F 0.674)] [D acc: (0.625)(0.641, 0.609)] [G loss: 0.976] [G acc: 0.156]\n",
      "750 [D loss: (0.649)(R 0.686, F 0.612)] [D acc: (0.656)(0.594, 0.719)] [G loss: 0.922] [G acc: 0.172]\n",
      "751 [D loss: (0.598)(R 0.569, F 0.626)] [D acc: (0.625)(0.609, 0.641)] [G loss: 1.052] [G acc: 0.172]\n",
      "752 [D loss: (0.636)(R 0.585, F 0.686)] [D acc: (0.711)(0.703, 0.719)] [G loss: 0.990] [G acc: 0.188]\n",
      "753 [D loss: (0.632)(R 0.592, F 0.673)] [D acc: (0.641)(0.625, 0.656)] [G loss: 0.963] [G acc: 0.203]\n",
      "754 [D loss: (0.701)(R 0.737, F 0.665)] [D acc: (0.547)(0.516, 0.578)] [G loss: 1.013] [G acc: 0.141]\n",
      "755 [D loss: (0.628)(R 0.632, F 0.624)] [D acc: (0.617)(0.562, 0.672)] [G loss: 0.995] [G acc: 0.141]\n",
      "756 [D loss: (0.650)(R 0.642, F 0.658)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.010] [G acc: 0.172]\n",
      "757 [D loss: (0.686)(R 0.725, F 0.646)] [D acc: (0.609)(0.516, 0.703)] [G loss: 0.908] [G acc: 0.156]\n",
      "758 [D loss: (0.633)(R 0.639, F 0.627)] [D acc: (0.672)(0.578, 0.766)] [G loss: 0.885] [G acc: 0.234]\n",
      "759 [D loss: (0.641)(R 0.587, F 0.696)] [D acc: (0.680)(0.688, 0.672)] [G loss: 0.981] [G acc: 0.094]\n",
      "760 [D loss: (0.621)(R 0.642, F 0.601)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.021] [G acc: 0.156]\n",
      "761 [D loss: (0.639)(R 0.672, F 0.605)] [D acc: (0.695)(0.609, 0.781)] [G loss: 0.930] [G acc: 0.219]\n",
      "762 [D loss: (0.610)(R 0.604, F 0.616)] [D acc: (0.695)(0.625, 0.766)] [G loss: 0.845] [G acc: 0.312]\n",
      "763 [D loss: (0.622)(R 0.601, F 0.642)] [D acc: (0.625)(0.609, 0.641)] [G loss: 0.991] [G acc: 0.172]\n",
      "764 [D loss: (0.629)(R 0.603, F 0.654)] [D acc: (0.625)(0.609, 0.641)] [G loss: 0.985] [G acc: 0.203]\n",
      "765 [D loss: (0.668)(R 0.619, F 0.717)] [D acc: (0.562)(0.609, 0.516)] [G loss: 0.977] [G acc: 0.156]\n",
      "766 [D loss: (0.666)(R 0.675, F 0.657)] [D acc: (0.609)(0.547, 0.672)] [G loss: 0.942] [G acc: 0.188]\n",
      "767 [D loss: (0.658)(R 0.673, F 0.643)] [D acc: (0.648)(0.578, 0.719)] [G loss: 0.992] [G acc: 0.172]\n",
      "768 [D loss: (0.617)(R 0.596, F 0.639)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.937] [G acc: 0.250]\n",
      "769 [D loss: (0.650)(R 0.685, F 0.616)] [D acc: (0.617)(0.531, 0.703)] [G loss: 0.958] [G acc: 0.203]\n",
      "770 [D loss: (0.661)(R 0.647, F 0.674)] [D acc: (0.602)(0.562, 0.641)] [G loss: 0.967] [G acc: 0.188]\n",
      "771 [D loss: (0.639)(R 0.665, F 0.612)] [D acc: (0.641)(0.516, 0.766)] [G loss: 1.003] [G acc: 0.203]\n",
      "772 [D loss: (0.618)(R 0.642, F 0.593)] [D acc: (0.680)(0.609, 0.750)] [G loss: 0.906] [G acc: 0.188]\n",
      "773 [D loss: (0.616)(R 0.589, F 0.643)] [D acc: (0.680)(0.656, 0.703)] [G loss: 0.936] [G acc: 0.250]\n",
      "774 [D loss: (0.679)(R 0.628, F 0.729)] [D acc: (0.609)(0.594, 0.625)] [G loss: 1.016] [G acc: 0.172]\n",
      "775 [D loss: (0.659)(R 0.683, F 0.635)] [D acc: (0.609)(0.547, 0.672)] [G loss: 0.973] [G acc: 0.203]\n",
      "776 [D loss: (0.650)(R 0.635, F 0.666)] [D acc: (0.641)(0.578, 0.703)] [G loss: 0.994] [G acc: 0.156]\n",
      "777 [D loss: (0.638)(R 0.640, F 0.637)] [D acc: (0.594)(0.516, 0.672)] [G loss: 0.992] [G acc: 0.156]\n",
      "778 [D loss: (0.614)(R 0.568, F 0.659)] [D acc: (0.672)(0.688, 0.656)] [G loss: 0.981] [G acc: 0.094]\n",
      "779 [D loss: (0.600)(R 0.633, F 0.568)] [D acc: (0.680)(0.547, 0.812)] [G loss: 0.959] [G acc: 0.156]\n",
      "780 [D loss: (0.657)(R 0.600, F 0.714)] [D acc: (0.648)(0.641, 0.656)] [G loss: 0.928] [G acc: 0.234]\n",
      "781 [D loss: (0.646)(R 0.632, F 0.659)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.018] [G acc: 0.172]\n",
      "782 [D loss: (0.656)(R 0.672, F 0.640)] [D acc: (0.586)(0.547, 0.625)] [G loss: 0.982] [G acc: 0.203]\n",
      "783 [D loss: (0.623)(R 0.640, F 0.605)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.020] [G acc: 0.156]\n",
      "784 [D loss: (0.608)(R 0.561, F 0.655)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.072] [G acc: 0.094]\n",
      "785 [D loss: (0.558)(R 0.577, F 0.540)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.104] [G acc: 0.125]\n",
      "786 [D loss: (0.657)(R 0.599, F 0.716)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.043] [G acc: 0.203]\n",
      "787 [D loss: (0.643)(R 0.627, F 0.659)] [D acc: (0.633)(0.625, 0.641)] [G loss: 1.031] [G acc: 0.172]\n",
      "788 [D loss: (0.613)(R 0.686, F 0.540)] [D acc: (0.688)(0.531, 0.844)] [G loss: 0.955] [G acc: 0.234]\n",
      "789 [D loss: (0.655)(R 0.631, F 0.680)] [D acc: (0.602)(0.578, 0.625)] [G loss: 1.066] [G acc: 0.125]\n",
      "790 [D loss: (0.634)(R 0.664, F 0.604)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.086] [G acc: 0.109]\n",
      "791 [D loss: (0.634)(R 0.596, F 0.673)] [D acc: (0.602)(0.562, 0.641)] [G loss: 0.976] [G acc: 0.172]\n",
      "792 [D loss: (0.611)(R 0.609, F 0.613)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.059] [G acc: 0.094]\n",
      "793 [D loss: (0.620)(R 0.602, F 0.637)] [D acc: (0.648)(0.641, 0.656)] [G loss: 0.953] [G acc: 0.234]\n",
      "794 [D loss: (0.662)(R 0.613, F 0.710)] [D acc: (0.664)(0.594, 0.734)] [G loss: 0.995] [G acc: 0.172]\n",
      "795 [D loss: (0.659)(R 0.654, F 0.665)] [D acc: (0.609)(0.516, 0.703)] [G loss: 1.036] [G acc: 0.125]\n",
      "796 [D loss: (0.673)(R 0.670, F 0.676)] [D acc: (0.562)(0.516, 0.609)] [G loss: 0.989] [G acc: 0.094]\n",
      "797 [D loss: (0.614)(R 0.616, F 0.612)] [D acc: (0.680)(0.625, 0.734)] [G loss: 0.994] [G acc: 0.109]\n",
      "798 [D loss: (0.628)(R 0.671, F 0.585)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.001] [G acc: 0.141]\n",
      "799 [D loss: (0.643)(R 0.645, F 0.642)] [D acc: (0.602)(0.547, 0.656)] [G loss: 0.916] [G acc: 0.156]\n",
      "800 [D loss: (0.605)(R 0.645, F 0.564)] [D acc: (0.672)(0.547, 0.797)] [G loss: 0.903] [G acc: 0.219]\n",
      "801 [D loss: (0.609)(R 0.581, F 0.637)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.116] [G acc: 0.078]\n",
      "802 [D loss: (0.570)(R 0.614, F 0.525)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.040] [G acc: 0.188]\n",
      "803 [D loss: (0.634)(R 0.576, F 0.692)] [D acc: (0.633)(0.594, 0.672)] [G loss: 0.975] [G acc: 0.188]\n",
      "804 [D loss: (0.631)(R 0.579, F 0.684)] [D acc: (0.625)(0.594, 0.656)] [G loss: 1.064] [G acc: 0.125]\n",
      "805 [D loss: (0.658)(R 0.752, F 0.564)] [D acc: (0.648)(0.484, 0.812)] [G loss: 0.990] [G acc: 0.141]\n",
      "806 [D loss: (0.701)(R 0.625, F 0.777)] [D acc: (0.625)(0.625, 0.625)] [G loss: 0.936] [G acc: 0.219]\n",
      "807 [D loss: (0.634)(R 0.613, F 0.655)] [D acc: (0.633)(0.578, 0.688)] [G loss: 0.864] [G acc: 0.219]\n",
      "808 [D loss: (0.569)(R 0.483, F 0.656)] [D acc: (0.711)(0.781, 0.641)] [G loss: 0.910] [G acc: 0.172]\n",
      "809 [D loss: (0.600)(R 0.558, F 0.642)] [D acc: (0.633)(0.625, 0.641)] [G loss: 0.930] [G acc: 0.203]\n",
      "810 [D loss: (0.593)(R 0.542, F 0.645)] [D acc: (0.648)(0.688, 0.609)] [G loss: 1.069] [G acc: 0.172]\n",
      "811 [D loss: (0.620)(R 0.571, F 0.668)] [D acc: (0.633)(0.672, 0.594)] [G loss: 1.024] [G acc: 0.125]\n",
      "812 [D loss: (0.587)(R 0.546, F 0.628)] [D acc: (0.664)(0.656, 0.672)] [G loss: 0.987] [G acc: 0.234]\n",
      "813 [D loss: (0.581)(R 0.547, F 0.615)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.026] [G acc: 0.156]\n",
      "814 [D loss: (0.626)(R 0.594, F 0.657)] [D acc: (0.680)(0.688, 0.672)] [G loss: 0.944] [G acc: 0.234]\n",
      "815 [D loss: (0.625)(R 0.633, F 0.618)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.254] [G acc: 0.062]\n",
      "816 [D loss: (0.648)(R 0.636, F 0.660)] [D acc: (0.602)(0.531, 0.672)] [G loss: 1.123] [G acc: 0.062]\n",
      "817 [D loss: (0.684)(R 0.745, F 0.623)] [D acc: (0.602)(0.500, 0.703)] [G loss: 0.988] [G acc: 0.141]\n",
      "818 [D loss: (0.637)(R 0.613, F 0.660)] [D acc: (0.648)(0.609, 0.688)] [G loss: 0.997] [G acc: 0.078]\n",
      "819 [D loss: (0.620)(R 0.585, F 0.656)] [D acc: (0.625)(0.641, 0.609)] [G loss: 0.989] [G acc: 0.109]\n",
      "820 [D loss: (0.665)(R 0.618, F 0.711)] [D acc: (0.609)(0.625, 0.594)] [G loss: 0.939] [G acc: 0.172]\n",
      "821 [D loss: (0.572)(R 0.518, F 0.626)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.012] [G acc: 0.172]\n",
      "822 [D loss: (0.635)(R 0.615, F 0.654)] [D acc: (0.633)(0.594, 0.672)] [G loss: 0.955] [G acc: 0.188]\n",
      "823 [D loss: (0.635)(R 0.645, F 0.624)] [D acc: (0.617)(0.547, 0.688)] [G loss: 1.084] [G acc: 0.141]\n",
      "824 [D loss: (0.602)(R 0.602, F 0.602)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.030] [G acc: 0.141]\n",
      "825 [D loss: (0.605)(R 0.568, F 0.642)] [D acc: (0.719)(0.672, 0.766)] [G loss: 0.988] [G acc: 0.219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826 [D loss: (0.562)(R 0.558, F 0.567)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.052] [G acc: 0.203]\n",
      "827 [D loss: (0.677)(R 0.645, F 0.710)] [D acc: (0.625)(0.594, 0.656)] [G loss: 0.986] [G acc: 0.141]\n",
      "828 [D loss: (0.622)(R 0.611, F 0.633)] [D acc: (0.609)(0.578, 0.641)] [G loss: 0.985] [G acc: 0.219]\n",
      "829 [D loss: (0.580)(R 0.533, F 0.627)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.077] [G acc: 0.062]\n",
      "830 [D loss: (0.656)(R 0.659, F 0.653)] [D acc: (0.602)(0.531, 0.672)] [G loss: 1.116] [G acc: 0.125]\n",
      "831 [D loss: (0.696)(R 0.656, F 0.736)] [D acc: (0.594)(0.578, 0.609)] [G loss: 1.037] [G acc: 0.141]\n",
      "832 [D loss: (0.621)(R 0.646, F 0.597)] [D acc: (0.648)(0.562, 0.734)] [G loss: 0.930] [G acc: 0.266]\n",
      "833 [D loss: (0.623)(R 0.662, F 0.583)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.006] [G acc: 0.156]\n",
      "834 [D loss: (0.636)(R 0.674, F 0.598)] [D acc: (0.617)(0.422, 0.812)] [G loss: 0.976] [G acc: 0.172]\n",
      "835 [D loss: (0.625)(R 0.595, F 0.656)] [D acc: (0.648)(0.641, 0.656)] [G loss: 0.935] [G acc: 0.188]\n",
      "836 [D loss: (0.623)(R 0.572, F 0.674)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.053] [G acc: 0.094]\n",
      "837 [D loss: (0.688)(R 0.610, F 0.766)] [D acc: (0.609)(0.625, 0.594)] [G loss: 0.985] [G acc: 0.141]\n",
      "838 [D loss: (0.607)(R 0.626, F 0.589)] [D acc: (0.648)(0.578, 0.719)] [G loss: 0.975] [G acc: 0.188]\n",
      "839 [D loss: (0.640)(R 0.579, F 0.701)] [D acc: (0.703)(0.734, 0.672)] [G loss: 1.012] [G acc: 0.109]\n",
      "840 [D loss: (0.564)(R 0.546, F 0.582)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.106] [G acc: 0.141]\n",
      "841 [D loss: (0.605)(R 0.617, F 0.592)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.051] [G acc: 0.109]\n",
      "842 [D loss: (0.647)(R 0.554, F 0.740)] [D acc: (0.609)(0.656, 0.562)] [G loss: 1.018] [G acc: 0.203]\n",
      "843 [D loss: (0.620)(R 0.649, F 0.591)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.038] [G acc: 0.125]\n",
      "844 [D loss: (0.631)(R 0.572, F 0.690)] [D acc: (0.609)(0.594, 0.625)] [G loss: 0.975] [G acc: 0.219]\n",
      "845 [D loss: (0.635)(R 0.592, F 0.678)] [D acc: (0.609)(0.625, 0.594)] [G loss: 0.986] [G acc: 0.172]\n",
      "846 [D loss: (0.599)(R 0.526, F 0.672)] [D acc: (0.625)(0.641, 0.609)] [G loss: 1.113] [G acc: 0.172]\n",
      "847 [D loss: (0.614)(R 0.575, F 0.652)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.094] [G acc: 0.078]\n",
      "848 [D loss: (0.665)(R 0.622, F 0.708)] [D acc: (0.617)(0.625, 0.609)] [G loss: 1.039] [G acc: 0.078]\n",
      "849 [D loss: (0.644)(R 0.592, F 0.696)] [D acc: (0.625)(0.656, 0.594)] [G loss: 1.044] [G acc: 0.156]\n",
      "850 [D loss: (0.635)(R 0.659, F 0.611)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.156] [G acc: 0.094]\n",
      "851 [D loss: (0.630)(R 0.716, F 0.543)] [D acc: (0.664)(0.516, 0.812)] [G loss: 1.066] [G acc: 0.172]\n",
      "852 [D loss: (0.637)(R 0.591, F 0.683)] [D acc: (0.594)(0.609, 0.578)] [G loss: 1.104] [G acc: 0.125]\n",
      "853 [D loss: (0.637)(R 0.645, F 0.629)] [D acc: (0.602)(0.531, 0.672)] [G loss: 1.014] [G acc: 0.125]\n",
      "854 [D loss: (0.619)(R 0.659, F 0.579)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.062] [G acc: 0.172]\n",
      "855 [D loss: (0.611)(R 0.593, F 0.628)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.009] [G acc: 0.109]\n",
      "856 [D loss: (0.572)(R 0.584, F 0.561)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.088] [G acc: 0.125]\n",
      "857 [D loss: (0.592)(R 0.629, F 0.554)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.025] [G acc: 0.203]\n",
      "858 [D loss: (0.591)(R 0.566, F 0.615)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.015] [G acc: 0.250]\n",
      "859 [D loss: (0.632)(R 0.604, F 0.660)] [D acc: (0.609)(0.641, 0.578)] [G loss: 1.010] [G acc: 0.172]\n",
      "860 [D loss: (0.608)(R 0.614, F 0.602)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.229] [G acc: 0.109]\n",
      "861 [D loss: (0.596)(R 0.565, F 0.627)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.041] [G acc: 0.188]\n",
      "862 [D loss: (0.617)(R 0.668, F 0.567)] [D acc: (0.641)(0.562, 0.719)] [G loss: 1.232] [G acc: 0.094]\n",
      "863 [D loss: (0.608)(R 0.584, F 0.633)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.083] [G acc: 0.141]\n",
      "864 [D loss: (0.592)(R 0.569, F 0.614)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.146] [G acc: 0.109]\n",
      "865 [D loss: (0.625)(R 0.613, F 0.636)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.187] [G acc: 0.172]\n",
      "866 [D loss: (0.595)(R 0.586, F 0.604)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.160] [G acc: 0.109]\n",
      "867 [D loss: (0.612)(R 0.530, F 0.694)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.164] [G acc: 0.188]\n",
      "868 [D loss: (0.604)(R 0.637, F 0.572)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.043] [G acc: 0.156]\n",
      "869 [D loss: (0.572)(R 0.580, F 0.565)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.036] [G acc: 0.250]\n",
      "870 [D loss: (0.626)(R 0.673, F 0.579)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.210] [G acc: 0.094]\n",
      "871 [D loss: (0.612)(R 0.632, F 0.591)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.050] [G acc: 0.125]\n",
      "872 [D loss: (0.600)(R 0.602, F 0.598)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.020] [G acc: 0.219]\n",
      "873 [D loss: (0.699)(R 0.533, F 0.865)] [D acc: (0.617)(0.703, 0.531)] [G loss: 1.080] [G acc: 0.125]\n",
      "874 [D loss: (0.570)(R 0.588, F 0.553)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.024] [G acc: 0.188]\n",
      "875 [D loss: (0.636)(R 0.595, F 0.677)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.072] [G acc: 0.172]\n",
      "876 [D loss: (0.639)(R 0.665, F 0.613)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.059] [G acc: 0.188]\n",
      "877 [D loss: (0.638)(R 0.660, F 0.615)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.042] [G acc: 0.203]\n",
      "878 [D loss: (0.634)(R 0.583, F 0.685)] [D acc: (0.633)(0.625, 0.641)] [G loss: 1.013] [G acc: 0.172]\n",
      "879 [D loss: (0.618)(R 0.601, F 0.635)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.151] [G acc: 0.094]\n",
      "880 [D loss: (0.574)(R 0.535, F 0.612)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.002] [G acc: 0.219]\n",
      "881 [D loss: (0.633)(R 0.641, F 0.625)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.146] [G acc: 0.188]\n",
      "882 [D loss: (0.595)(R 0.603, F 0.586)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.107] [G acc: 0.172]\n",
      "883 [D loss: (0.620)(R 0.547, F 0.692)] [D acc: (0.625)(0.672, 0.578)] [G loss: 1.033] [G acc: 0.172]\n",
      "884 [D loss: (0.589)(R 0.624, F 0.554)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.067] [G acc: 0.156]\n",
      "885 [D loss: (0.584)(R 0.602, F 0.566)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.030] [G acc: 0.156]\n",
      "886 [D loss: (0.632)(R 0.568, F 0.696)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.138] [G acc: 0.141]\n",
      "887 [D loss: (0.605)(R 0.631, F 0.579)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.138] [G acc: 0.203]\n",
      "888 [D loss: (0.596)(R 0.592, F 0.600)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.118] [G acc: 0.188]\n",
      "889 [D loss: (0.607)(R 0.618, F 0.596)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.153] [G acc: 0.125]\n",
      "890 [D loss: (0.625)(R 0.593, F 0.657)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.045] [G acc: 0.188]\n",
      "891 [D loss: (0.656)(R 0.663, F 0.650)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.126] [G acc: 0.156]\n",
      "892 [D loss: (0.619)(R 0.580, F 0.658)] [D acc: (0.656)(0.656, 0.656)] [G loss: 1.035] [G acc: 0.156]\n",
      "893 [D loss: (0.596)(R 0.572, F 0.620)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.197] [G acc: 0.094]\n",
      "894 [D loss: (0.628)(R 0.637, F 0.620)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.158] [G acc: 0.094]\n",
      "895 [D loss: (0.563)(R 0.599, F 0.527)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.113] [G acc: 0.062]\n",
      "896 [D loss: (0.594)(R 0.588, F 0.600)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.043] [G acc: 0.234]\n",
      "897 [D loss: (0.529)(R 0.514, F 0.544)] [D acc: (0.734)(0.734, 0.734)] [G loss: 0.994] [G acc: 0.312]\n",
      "898 [D loss: (0.671)(R 0.607, F 0.736)] [D acc: (0.586)(0.594, 0.578)] [G loss: 1.134] [G acc: 0.125]\n",
      "899 [D loss: (0.585)(R 0.532, F 0.638)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.109] [G acc: 0.109]\n",
      "900 [D loss: (0.650)(R 0.621, F 0.679)] [D acc: (0.609)(0.625, 0.594)] [G loss: 1.047] [G acc: 0.219]\n",
      "901 [D loss: (0.667)(R 0.648, F 0.687)] [D acc: (0.594)(0.547, 0.641)] [G loss: 1.093] [G acc: 0.125]\n",
      "902 [D loss: (0.562)(R 0.553, F 0.570)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.092] [G acc: 0.188]\n",
      "903 [D loss: (0.652)(R 0.678, F 0.625)] [D acc: (0.578)(0.484, 0.672)] [G loss: 1.042] [G acc: 0.172]\n",
      "904 [D loss: (0.651)(R 0.592, F 0.711)] [D acc: (0.594)(0.594, 0.594)] [G loss: 1.031] [G acc: 0.141]\n",
      "905 [D loss: (0.630)(R 0.645, F 0.614)] [D acc: (0.625)(0.594, 0.656)] [G loss: 1.036] [G acc: 0.156]\n",
      "906 [D loss: (0.629)(R 0.631, F 0.627)] [D acc: (0.648)(0.625, 0.672)] [G loss: 0.989] [G acc: 0.219]\n",
      "907 [D loss: (0.611)(R 0.648, F 0.574)] [D acc: (0.641)(0.562, 0.719)] [G loss: 0.998] [G acc: 0.141]\n",
      "908 [D loss: (0.614)(R 0.601, F 0.628)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.121] [G acc: 0.156]\n",
      "909 [D loss: (0.642)(R 0.681, F 0.602)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.017] [G acc: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910 [D loss: (0.595)(R 0.662, F 0.528)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.065] [G acc: 0.172]\n",
      "911 [D loss: (0.608)(R 0.583, F 0.633)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.082] [G acc: 0.188]\n",
      "912 [D loss: (0.582)(R 0.563, F 0.600)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.088] [G acc: 0.125]\n",
      "913 [D loss: (0.597)(R 0.632, F 0.562)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.131] [G acc: 0.125]\n",
      "914 [D loss: (0.585)(R 0.591, F 0.578)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.164] [G acc: 0.125]\n",
      "915 [D loss: (0.605)(R 0.537, F 0.672)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.096] [G acc: 0.203]\n",
      "916 [D loss: (0.672)(R 0.647, F 0.697)] [D acc: (0.641)(0.562, 0.719)] [G loss: 1.150] [G acc: 0.141]\n",
      "917 [D loss: (0.603)(R 0.572, F 0.633)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.093] [G acc: 0.094]\n",
      "918 [D loss: (0.710)(R 0.695, F 0.726)] [D acc: (0.500)(0.484, 0.516)] [G loss: 1.055] [G acc: 0.125]\n",
      "919 [D loss: (0.581)(R 0.563, F 0.598)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.031] [G acc: 0.188]\n",
      "920 [D loss: (0.658)(R 0.631, F 0.686)] [D acc: (0.602)(0.562, 0.641)] [G loss: 0.994] [G acc: 0.203]\n",
      "921 [D loss: (0.641)(R 0.639, F 0.642)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.027] [G acc: 0.172]\n",
      "922 [D loss: (0.605)(R 0.624, F 0.587)] [D acc: (0.625)(0.531, 0.719)] [G loss: 0.984] [G acc: 0.141]\n",
      "923 [D loss: (0.642)(R 0.594, F 0.689)] [D acc: (0.633)(0.609, 0.656)] [G loss: 0.963] [G acc: 0.172]\n",
      "924 [D loss: (0.603)(R 0.618, F 0.588)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.105] [G acc: 0.094]\n",
      "925 [D loss: (0.572)(R 0.548, F 0.595)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.044] [G acc: 0.156]\n",
      "926 [D loss: (0.615)(R 0.574, F 0.656)] [D acc: (0.688)(0.656, 0.719)] [G loss: 0.994] [G acc: 0.234]\n",
      "927 [D loss: (0.650)(R 0.640, F 0.661)] [D acc: (0.602)(0.516, 0.688)] [G loss: 1.131] [G acc: 0.188]\n",
      "928 [D loss: (0.684)(R 0.685, F 0.683)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.105] [G acc: 0.094]\n",
      "929 [D loss: (0.649)(R 0.636, F 0.662)] [D acc: (0.617)(0.578, 0.656)] [G loss: 1.008] [G acc: 0.156]\n",
      "930 [D loss: (0.548)(R 0.476, F 0.621)] [D acc: (0.703)(0.734, 0.672)] [G loss: 1.032] [G acc: 0.125]\n",
      "931 [D loss: (0.592)(R 0.609, F 0.576)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.016] [G acc: 0.219]\n",
      "932 [D loss: (0.611)(R 0.503, F 0.719)] [D acc: (0.656)(0.672, 0.641)] [G loss: 1.087] [G acc: 0.125]\n",
      "933 [D loss: (0.603)(R 0.629, F 0.577)] [D acc: (0.641)(0.547, 0.734)] [G loss: 0.997] [G acc: 0.156]\n",
      "934 [D loss: (0.596)(R 0.584, F 0.607)] [D acc: (0.625)(0.609, 0.641)] [G loss: 1.040] [G acc: 0.188]\n",
      "935 [D loss: (0.670)(R 0.601, F 0.738)] [D acc: (0.625)(0.547, 0.703)] [G loss: 1.094] [G acc: 0.172]\n",
      "936 [D loss: (0.607)(R 0.591, F 0.622)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.241] [G acc: 0.156]\n",
      "937 [D loss: (0.629)(R 0.711, F 0.548)] [D acc: (0.633)(0.453, 0.812)] [G loss: 1.148] [G acc: 0.141]\n",
      "938 [D loss: (0.720)(R 0.736, F 0.704)] [D acc: (0.508)(0.469, 0.547)] [G loss: 1.001] [G acc: 0.203]\n",
      "939 [D loss: (0.705)(R 0.716, F 0.694)] [D acc: (0.539)(0.484, 0.594)] [G loss: 0.971] [G acc: 0.219]\n",
      "940 [D loss: (0.576)(R 0.547, F 0.605)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.055] [G acc: 0.125]\n",
      "941 [D loss: (0.691)(R 0.660, F 0.723)] [D acc: (0.531)(0.516, 0.547)] [G loss: 1.003] [G acc: 0.188]\n",
      "942 [D loss: (0.552)(R 0.535, F 0.570)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.065] [G acc: 0.203]\n",
      "943 [D loss: (0.599)(R 0.570, F 0.628)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.091] [G acc: 0.094]\n",
      "944 [D loss: (0.659)(R 0.700, F 0.617)] [D acc: (0.617)(0.484, 0.750)] [G loss: 0.970] [G acc: 0.156]\n",
      "945 [D loss: (0.608)(R 0.559, F 0.657)] [D acc: (0.625)(0.656, 0.594)] [G loss: 1.008] [G acc: 0.188]\n",
      "946 [D loss: (0.606)(R 0.595, F 0.616)] [D acc: (0.617)(0.562, 0.672)] [G loss: 0.959] [G acc: 0.203]\n",
      "947 [D loss: (0.613)(R 0.531, F 0.696)] [D acc: (0.680)(0.734, 0.625)] [G loss: 0.940] [G acc: 0.234]\n",
      "948 [D loss: (0.602)(R 0.523, F 0.682)] [D acc: (0.680)(0.766, 0.594)] [G loss: 1.047] [G acc: 0.125]\n",
      "949 [D loss: (0.621)(R 0.626, F 0.616)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.021] [G acc: 0.266]\n",
      "950 [D loss: (0.569)(R 0.534, F 0.605)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.215] [G acc: 0.125]\n",
      "951 [D loss: (0.704)(R 0.770, F 0.637)] [D acc: (0.602)(0.484, 0.719)] [G loss: 0.984] [G acc: 0.156]\n",
      "952 [D loss: (0.633)(R 0.678, F 0.589)] [D acc: (0.617)(0.484, 0.750)] [G loss: 1.075] [G acc: 0.125]\n",
      "953 [D loss: (0.662)(R 0.696, F 0.629)] [D acc: (0.609)(0.547, 0.672)] [G loss: 0.965] [G acc: 0.156]\n",
      "954 [D loss: (0.618)(R 0.615, F 0.620)] [D acc: (0.664)(0.516, 0.812)] [G loss: 1.031] [G acc: 0.094]\n",
      "955 [D loss: (0.621)(R 0.651, F 0.592)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.080] [G acc: 0.062]\n",
      "956 [D loss: (0.594)(R 0.541, F 0.648)] [D acc: (0.656)(0.719, 0.594)] [G loss: 1.050] [G acc: 0.156]\n",
      "957 [D loss: (0.598)(R 0.614, F 0.582)] [D acc: (0.672)(0.562, 0.781)] [G loss: 0.963] [G acc: 0.266]\n",
      "958 [D loss: (0.634)(R 0.642, F 0.626)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.056] [G acc: 0.141]\n",
      "959 [D loss: (0.629)(R 0.648, F 0.609)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.050] [G acc: 0.141]\n",
      "960 [D loss: (0.613)(R 0.614, F 0.613)] [D acc: (0.664)(0.609, 0.719)] [G loss: 0.998] [G acc: 0.156]\n",
      "961 [D loss: (0.612)(R 0.615, F 0.609)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.115] [G acc: 0.156]\n",
      "962 [D loss: (0.593)(R 0.586, F 0.600)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.166] [G acc: 0.125]\n",
      "963 [D loss: (0.612)(R 0.630, F 0.594)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.151] [G acc: 0.062]\n",
      "964 [D loss: (0.587)(R 0.516, F 0.658)] [D acc: (0.664)(0.688, 0.641)] [G loss: 1.111] [G acc: 0.172]\n",
      "965 [D loss: (0.676)(R 0.648, F 0.704)] [D acc: (0.602)(0.547, 0.656)] [G loss: 1.079] [G acc: 0.094]\n",
      "966 [D loss: (0.613)(R 0.622, F 0.604)] [D acc: (0.609)(0.562, 0.656)] [G loss: 1.023] [G acc: 0.188]\n",
      "967 [D loss: (0.678)(R 0.641, F 0.715)] [D acc: (0.617)(0.625, 0.609)] [G loss: 1.063] [G acc: 0.094]\n",
      "968 [D loss: (0.613)(R 0.669, F 0.557)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.154] [G acc: 0.078]\n",
      "969 [D loss: (0.583)(R 0.563, F 0.602)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.035] [G acc: 0.094]\n",
      "970 [D loss: (0.575)(R 0.576, F 0.575)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.045] [G acc: 0.203]\n",
      "971 [D loss: (0.641)(R 0.644, F 0.638)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.065] [G acc: 0.141]\n",
      "972 [D loss: (0.676)(R 0.668, F 0.684)] [D acc: (0.586)(0.531, 0.641)] [G loss: 1.061] [G acc: 0.234]\n",
      "973 [D loss: (0.628)(R 0.629, F 0.627)] [D acc: (0.625)(0.641, 0.609)] [G loss: 1.047] [G acc: 0.156]\n",
      "974 [D loss: (0.613)(R 0.567, F 0.660)] [D acc: (0.672)(0.688, 0.656)] [G loss: 1.022] [G acc: 0.203]\n",
      "975 [D loss: (0.594)(R 0.556, F 0.632)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.019] [G acc: 0.203]\n",
      "976 [D loss: (0.674)(R 0.677, F 0.671)] [D acc: (0.633)(0.609, 0.656)] [G loss: 1.092] [G acc: 0.125]\n",
      "977 [D loss: (0.656)(R 0.653, F 0.660)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.138] [G acc: 0.047]\n",
      "978 [D loss: (0.662)(R 0.709, F 0.616)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.001] [G acc: 0.172]\n",
      "979 [D loss: (0.603)(R 0.590, F 0.617)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.043] [G acc: 0.125]\n",
      "980 [D loss: (0.645)(R 0.655, F 0.635)] [D acc: (0.617)(0.578, 0.656)] [G loss: 1.075] [G acc: 0.109]\n",
      "981 [D loss: (0.590)(R 0.638, F 0.543)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.051] [G acc: 0.141]\n",
      "982 [D loss: (0.657)(R 0.626, F 0.688)] [D acc: (0.602)(0.594, 0.609)] [G loss: 1.087] [G acc: 0.125]\n",
      "983 [D loss: (0.573)(R 0.553, F 0.593)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.097] [G acc: 0.141]\n",
      "984 [D loss: (0.651)(R 0.676, F 0.625)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.192] [G acc: 0.125]\n",
      "985 [D loss: (0.626)(R 0.620, F 0.632)] [D acc: (0.633)(0.516, 0.750)] [G loss: 1.056] [G acc: 0.156]\n",
      "986 [D loss: (0.618)(R 0.638, F 0.598)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.108] [G acc: 0.125]\n",
      "987 [D loss: (0.612)(R 0.581, F 0.643)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.077] [G acc: 0.125]\n",
      "988 [D loss: (0.623)(R 0.687, F 0.559)] [D acc: (0.672)(0.531, 0.812)] [G loss: 1.078] [G acc: 0.094]\n",
      "989 [D loss: (0.585)(R 0.571, F 0.600)] [D acc: (0.672)(0.609, 0.734)] [G loss: 0.981] [G acc: 0.156]\n",
      "990 [D loss: (0.569)(R 0.491, F 0.647)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.160] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "991 [D loss: (0.579)(R 0.593, F 0.565)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.215] [G acc: 0.109]\n",
      "992 [D loss: (0.606)(R 0.563, F 0.650)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.198] [G acc: 0.125]\n",
      "993 [D loss: (0.586)(R 0.626, F 0.545)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.098] [G acc: 0.188]\n",
      "994 [D loss: (0.633)(R 0.616, F 0.651)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.319] [G acc: 0.109]\n",
      "995 [D loss: (0.567)(R 0.643, F 0.491)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.210] [G acc: 0.062]\n",
      "996 [D loss: (0.617)(R 0.535, F 0.698)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.007] [G acc: 0.281]\n",
      "997 [D loss: (0.670)(R 0.714, F 0.626)] [D acc: (0.602)(0.562, 0.641)] [G loss: 0.988] [G acc: 0.250]\n",
      "998 [D loss: (0.577)(R 0.479, F 0.675)] [D acc: (0.719)(0.781, 0.656)] [G loss: 1.005] [G acc: 0.172]\n",
      "999 [D loss: (0.627)(R 0.653, F 0.601)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.046] [G acc: 0.141]\n",
      "1000 [D loss: (0.631)(R 0.617, F 0.645)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.069] [G acc: 0.203]\n",
      "1001 [D loss: (0.597)(R 0.569, F 0.626)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.069] [G acc: 0.203]\n",
      "1002 [D loss: (0.593)(R 0.599, F 0.587)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.114] [G acc: 0.125]\n",
      "1003 [D loss: (0.612)(R 0.625, F 0.600)] [D acc: (0.617)(0.547, 0.688)] [G loss: 1.193] [G acc: 0.141]\n",
      "1004 [D loss: (0.624)(R 0.676, F 0.573)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.078] [G acc: 0.219]\n",
      "1005 [D loss: (0.651)(R 0.610, F 0.691)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.067] [G acc: 0.078]\n",
      "1006 [D loss: (0.623)(R 0.570, F 0.676)] [D acc: (0.664)(0.656, 0.672)] [G loss: 0.964] [G acc: 0.219]\n",
      "1007 [D loss: (0.623)(R 0.579, F 0.667)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.150] [G acc: 0.141]\n",
      "1008 [D loss: (0.607)(R 0.645, F 0.569)] [D acc: (0.695)(0.594, 0.797)] [G loss: 0.991] [G acc: 0.219]\n",
      "1009 [D loss: (0.580)(R 0.507, F 0.652)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.179] [G acc: 0.141]\n",
      "1010 [D loss: (0.594)(R 0.581, F 0.607)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.069] [G acc: 0.172]\n",
      "1011 [D loss: (0.607)(R 0.625, F 0.588)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.097] [G acc: 0.125]\n",
      "1012 [D loss: (0.623)(R 0.539, F 0.706)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.005] [G acc: 0.172]\n",
      "1013 [D loss: (0.618)(R 0.643, F 0.594)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.081] [G acc: 0.156]\n",
      "1014 [D loss: (0.631)(R 0.635, F 0.628)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.085] [G acc: 0.125]\n",
      "1015 [D loss: (0.597)(R 0.595, F 0.598)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.104] [G acc: 0.156]\n",
      "1016 [D loss: (0.628)(R 0.673, F 0.583)] [D acc: (0.625)(0.531, 0.719)] [G loss: 0.987] [G acc: 0.172]\n",
      "1017 [D loss: (0.556)(R 0.568, F 0.544)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.120] [G acc: 0.156]\n",
      "1018 [D loss: (0.584)(R 0.594, F 0.574)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.058] [G acc: 0.156]\n",
      "1019 [D loss: (0.580)(R 0.486, F 0.674)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.131] [G acc: 0.109]\n",
      "1020 [D loss: (0.540)(R 0.514, F 0.567)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.096] [G acc: 0.094]\n",
      "1021 [D loss: (0.593)(R 0.516, F 0.670)] [D acc: (0.641)(0.672, 0.609)] [G loss: 1.117] [G acc: 0.172]\n",
      "1022 [D loss: (0.564)(R 0.557, F 0.570)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.124] [G acc: 0.125]\n",
      "1023 [D loss: (0.601)(R 0.630, F 0.571)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.117] [G acc: 0.094]\n",
      "1024 [D loss: (0.598)(R 0.541, F 0.656)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.141] [G acc: 0.203]\n",
      "1025 [D loss: (0.575)(R 0.550, F 0.601)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.096] [G acc: 0.219]\n",
      "1026 [D loss: (0.648)(R 0.648, F 0.648)] [D acc: (0.625)(0.594, 0.656)] [G loss: 1.152] [G acc: 0.188]\n",
      "1027 [D loss: (0.615)(R 0.678, F 0.551)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.077] [G acc: 0.172]\n",
      "1028 [D loss: (0.642)(R 0.554, F 0.731)] [D acc: (0.641)(0.641, 0.641)] [G loss: 1.185] [G acc: 0.109]\n",
      "1029 [D loss: (0.597)(R 0.671, F 0.524)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.010] [G acc: 0.188]\n",
      "1030 [D loss: (0.579)(R 0.559, F 0.599)] [D acc: (0.711)(0.703, 0.719)] [G loss: 0.995] [G acc: 0.172]\n",
      "1031 [D loss: (0.567)(R 0.566, F 0.568)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.094] [G acc: 0.156]\n",
      "1032 [D loss: (0.566)(R 0.559, F 0.574)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.126] [G acc: 0.188]\n",
      "1033 [D loss: (0.577)(R 0.582, F 0.572)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.204] [G acc: 0.125]\n",
      "1034 [D loss: (0.623)(R 0.610, F 0.636)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.121] [G acc: 0.188]\n",
      "1035 [D loss: (0.639)(R 0.621, F 0.658)] [D acc: (0.609)(0.594, 0.625)] [G loss: 1.132] [G acc: 0.219]\n",
      "1036 [D loss: (0.570)(R 0.573, F 0.567)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.057] [G acc: 0.188]\n",
      "1037 [D loss: (0.582)(R 0.501, F 0.663)] [D acc: (0.656)(0.719, 0.594)] [G loss: 1.078] [G acc: 0.203]\n",
      "1038 [D loss: (0.652)(R 0.590, F 0.713)] [D acc: (0.594)(0.594, 0.594)] [G loss: 1.171] [G acc: 0.203]\n",
      "1039 [D loss: (0.648)(R 0.678, F 0.618)] [D acc: (0.602)(0.500, 0.703)] [G loss: 1.229] [G acc: 0.078]\n",
      "1040 [D loss: (0.618)(R 0.665, F 0.570)] [D acc: (0.617)(0.547, 0.688)] [G loss: 1.099] [G acc: 0.062]\n",
      "1041 [D loss: (0.539)(R 0.532, F 0.546)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.138] [G acc: 0.062]\n",
      "1042 [D loss: (0.568)(R 0.590, F 0.546)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.160] [G acc: 0.141]\n",
      "1043 [D loss: (0.645)(R 0.596, F 0.694)] [D acc: (0.617)(0.641, 0.594)] [G loss: 1.162] [G acc: 0.141]\n",
      "1044 [D loss: (0.613)(R 0.584, F 0.641)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.126] [G acc: 0.125]\n",
      "1045 [D loss: (0.588)(R 0.646, F 0.530)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.105] [G acc: 0.141]\n",
      "1046 [D loss: (0.689)(R 0.623, F 0.756)] [D acc: (0.586)(0.625, 0.547)] [G loss: 1.119] [G acc: 0.125]\n",
      "1047 [D loss: (0.597)(R 0.623, F 0.572)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.115] [G acc: 0.172]\n",
      "1048 [D loss: (0.609)(R 0.599, F 0.619)] [D acc: (0.633)(0.609, 0.656)] [G loss: 1.147] [G acc: 0.094]\n",
      "1049 [D loss: (0.667)(R 0.669, F 0.666)] [D acc: (0.602)(0.547, 0.656)] [G loss: 1.023] [G acc: 0.141]\n",
      "1050 [D loss: (0.613)(R 0.572, F 0.655)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.084] [G acc: 0.109]\n",
      "1051 [D loss: (0.558)(R 0.624, F 0.491)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.057] [G acc: 0.172]\n",
      "1052 [D loss: (0.602)(R 0.577, F 0.628)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.164] [G acc: 0.125]\n",
      "1053 [D loss: (0.645)(R 0.626, F 0.665)] [D acc: (0.625)(0.641, 0.609)] [G loss: 1.190] [G acc: 0.141]\n",
      "1054 [D loss: (0.597)(R 0.617, F 0.577)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.137] [G acc: 0.172]\n",
      "1055 [D loss: (0.611)(R 0.617, F 0.604)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.114] [G acc: 0.125]\n",
      "1056 [D loss: (0.573)(R 0.591, F 0.555)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.098] [G acc: 0.062]\n",
      "1057 [D loss: (0.639)(R 0.598, F 0.679)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.056] [G acc: 0.203]\n",
      "1058 [D loss: (0.669)(R 0.694, F 0.645)] [D acc: (0.578)(0.531, 0.625)] [G loss: 1.119] [G acc: 0.062]\n",
      "1059 [D loss: (0.607)(R 0.579, F 0.635)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.106] [G acc: 0.141]\n",
      "1060 [D loss: (0.564)(R 0.575, F 0.553)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.097] [G acc: 0.078]\n",
      "1061 [D loss: (0.625)(R 0.679, F 0.571)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.088] [G acc: 0.109]\n",
      "1062 [D loss: (0.618)(R 0.618, F 0.619)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.246] [G acc: 0.141]\n",
      "1063 [D loss: (0.554)(R 0.525, F 0.582)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.179] [G acc: 0.125]\n",
      "1064 [D loss: (0.612)(R 0.606, F 0.618)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.108] [G acc: 0.188]\n",
      "1065 [D loss: (0.556)(R 0.556, F 0.555)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.076] [G acc: 0.141]\n",
      "1066 [D loss: (0.687)(R 0.611, F 0.763)] [D acc: (0.625)(0.609, 0.641)] [G loss: 1.156] [G acc: 0.141]\n",
      "1067 [D loss: (0.639)(R 0.678, F 0.600)] [D acc: (0.617)(0.547, 0.688)] [G loss: 1.121] [G acc: 0.141]\n",
      "1068 [D loss: (0.595)(R 0.608, F 0.582)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.067] [G acc: 0.172]\n",
      "1069 [D loss: (0.702)(R 0.631, F 0.773)] [D acc: (0.578)(0.594, 0.562)] [G loss: 1.174] [G acc: 0.125]\n",
      "1070 [D loss: (0.643)(R 0.726, F 0.560)] [D acc: (0.633)(0.469, 0.797)] [G loss: 1.026] [G acc: 0.234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071 [D loss: (0.603)(R 0.641, F 0.566)] [D acc: (0.648)(0.516, 0.781)] [G loss: 1.024] [G acc: 0.219]\n",
      "1072 [D loss: (0.574)(R 0.578, F 0.570)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.038] [G acc: 0.141]\n",
      "1073 [D loss: (0.591)(R 0.630, F 0.552)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.084] [G acc: 0.141]\n",
      "1074 [D loss: (0.618)(R 0.559, F 0.678)] [D acc: (0.641)(0.656, 0.625)] [G loss: 1.030] [G acc: 0.188]\n",
      "1075 [D loss: (0.656)(R 0.720, F 0.592)] [D acc: (0.641)(0.531, 0.750)] [G loss: 0.963] [G acc: 0.219]\n",
      "1076 [D loss: (0.693)(R 0.633, F 0.754)] [D acc: (0.594)(0.594, 0.594)] [G loss: 1.104] [G acc: 0.094]\n",
      "1077 [D loss: (0.644)(R 0.651, F 0.636)] [D acc: (0.633)(0.562, 0.703)] [G loss: 1.042] [G acc: 0.141]\n",
      "1078 [D loss: (0.598)(R 0.610, F 0.585)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.013] [G acc: 0.188]\n",
      "1079 [D loss: (0.553)(R 0.589, F 0.517)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.080] [G acc: 0.125]\n",
      "1080 [D loss: (0.623)(R 0.548, F 0.699)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.106] [G acc: 0.125]\n",
      "1081 [D loss: (0.607)(R 0.600, F 0.615)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.085] [G acc: 0.125]\n",
      "1082 [D loss: (0.638)(R 0.599, F 0.677)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.074] [G acc: 0.141]\n",
      "1083 [D loss: (0.573)(R 0.565, F 0.580)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.039] [G acc: 0.109]\n",
      "1084 [D loss: (0.642)(R 0.651, F 0.634)] [D acc: (0.633)(0.547, 0.719)] [G loss: 1.071] [G acc: 0.156]\n",
      "1085 [D loss: (0.575)(R 0.599, F 0.551)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.124] [G acc: 0.172]\n",
      "1086 [D loss: (0.646)(R 0.606, F 0.686)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.075] [G acc: 0.172]\n",
      "1087 [D loss: (0.580)(R 0.582, F 0.579)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.118] [G acc: 0.156]\n",
      "1088 [D loss: (0.577)(R 0.619, F 0.535)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.053] [G acc: 0.172]\n",
      "1089 [D loss: (0.683)(R 0.660, F 0.706)] [D acc: (0.578)(0.547, 0.609)] [G loss: 1.039] [G acc: 0.172]\n",
      "1090 [D loss: (0.596)(R 0.613, F 0.579)] [D acc: (0.688)(0.609, 0.766)] [G loss: 0.999] [G acc: 0.203]\n",
      "1091 [D loss: (0.583)(R 0.585, F 0.582)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.142] [G acc: 0.109]\n",
      "1092 [D loss: (0.600)(R 0.599, F 0.601)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.089] [G acc: 0.156]\n",
      "1093 [D loss: (0.565)(R 0.587, F 0.543)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.068] [G acc: 0.219]\n",
      "1094 [D loss: (0.570)(R 0.549, F 0.590)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.056] [G acc: 0.188]\n",
      "1095 [D loss: (0.665)(R 0.614, F 0.717)] [D acc: (0.617)(0.656, 0.578)] [G loss: 1.235] [G acc: 0.156]\n",
      "1096 [D loss: (0.582)(R 0.650, F 0.514)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.156] [G acc: 0.172]\n",
      "1097 [D loss: (0.626)(R 0.712, F 0.541)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.157] [G acc: 0.141]\n",
      "1098 [D loss: (0.660)(R 0.576, F 0.743)] [D acc: (0.656)(0.734, 0.578)] [G loss: 1.143] [G acc: 0.125]\n",
      "1099 [D loss: (0.594)(R 0.600, F 0.589)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.075] [G acc: 0.203]\n",
      "1100 [D loss: (0.620)(R 0.666, F 0.574)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.105] [G acc: 0.125]\n",
      "1101 [D loss: (0.596)(R 0.603, F 0.590)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.309] [G acc: 0.125]\n",
      "1102 [D loss: (0.549)(R 0.505, F 0.593)] [D acc: (0.789)(0.828, 0.750)] [G loss: 1.202] [G acc: 0.141]\n",
      "1103 [D loss: (0.559)(R 0.567, F 0.550)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.216] [G acc: 0.094]\n",
      "1104 [D loss: (0.654)(R 0.648, F 0.660)] [D acc: (0.602)(0.547, 0.656)] [G loss: 1.095] [G acc: 0.125]\n",
      "1105 [D loss: (0.535)(R 0.513, F 0.557)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.195] [G acc: 0.109]\n",
      "1106 [D loss: (0.688)(R 0.673, F 0.702)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.179] [G acc: 0.141]\n",
      "1107 [D loss: (0.587)(R 0.542, F 0.633)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.101] [G acc: 0.219]\n",
      "1108 [D loss: (0.584)(R 0.553, F 0.614)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.071] [G acc: 0.172]\n",
      "1109 [D loss: (0.646)(R 0.635, F 0.656)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.091] [G acc: 0.141]\n",
      "1110 [D loss: (0.594)(R 0.621, F 0.567)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.120] [G acc: 0.125]\n",
      "1111 [D loss: (0.632)(R 0.639, F 0.625)] [D acc: (0.633)(0.594, 0.672)] [G loss: 0.994] [G acc: 0.172]\n",
      "1112 [D loss: (0.678)(R 0.599, F 0.756)] [D acc: (0.609)(0.562, 0.656)] [G loss: 1.070] [G acc: 0.172]\n",
      "1113 [D loss: (0.572)(R 0.562, F 0.581)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.041] [G acc: 0.203]\n",
      "1114 [D loss: (0.603)(R 0.612, F 0.594)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.151] [G acc: 0.156]\n",
      "1115 [D loss: (0.635)(R 0.656, F 0.614)] [D acc: (0.594)(0.484, 0.703)] [G loss: 1.082] [G acc: 0.172]\n",
      "1116 [D loss: (0.627)(R 0.659, F 0.594)] [D acc: (0.602)(0.547, 0.656)] [G loss: 1.025] [G acc: 0.156]\n",
      "1117 [D loss: (0.668)(R 0.552, F 0.783)] [D acc: (0.633)(0.688, 0.578)] [G loss: 1.109] [G acc: 0.188]\n",
      "1118 [D loss: (0.626)(R 0.675, F 0.577)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.079] [G acc: 0.109]\n",
      "1119 [D loss: (0.617)(R 0.635, F 0.598)] [D acc: (0.625)(0.547, 0.703)] [G loss: 1.075] [G acc: 0.172]\n",
      "1120 [D loss: (0.564)(R 0.549, F 0.579)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.072] [G acc: 0.094]\n",
      "1121 [D loss: (0.617)(R 0.669, F 0.564)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.043] [G acc: 0.219]\n",
      "1122 [D loss: (0.603)(R 0.588, F 0.617)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.218] [G acc: 0.125]\n",
      "1123 [D loss: (0.620)(R 0.589, F 0.650)] [D acc: (0.633)(0.656, 0.609)] [G loss: 1.135] [G acc: 0.125]\n",
      "1124 [D loss: (0.627)(R 0.621, F 0.633)] [D acc: (0.617)(0.531, 0.703)] [G loss: 1.062] [G acc: 0.219]\n",
      "1125 [D loss: (0.618)(R 0.630, F 0.606)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.084] [G acc: 0.141]\n",
      "1126 [D loss: (0.546)(R 0.528, F 0.563)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.129] [G acc: 0.109]\n",
      "1127 [D loss: (0.564)(R 0.539, F 0.588)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.117] [G acc: 0.156]\n",
      "1128 [D loss: (0.621)(R 0.641, F 0.601)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.235] [G acc: 0.078]\n",
      "1129 [D loss: (0.620)(R 0.616, F 0.624)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.066] [G acc: 0.141]\n",
      "1130 [D loss: (0.584)(R 0.564, F 0.604)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.141] [G acc: 0.094]\n",
      "1131 [D loss: (0.582)(R 0.556, F 0.607)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.109] [G acc: 0.141]\n",
      "1132 [D loss: (0.579)(R 0.552, F 0.606)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.130] [G acc: 0.203]\n",
      "1133 [D loss: (0.622)(R 0.678, F 0.566)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.207] [G acc: 0.109]\n",
      "1134 [D loss: (0.535)(R 0.536, F 0.534)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.107] [G acc: 0.188]\n",
      "1135 [D loss: (0.654)(R 0.633, F 0.674)] [D acc: (0.602)(0.594, 0.609)] [G loss: 1.382] [G acc: 0.094]\n",
      "1136 [D loss: (0.646)(R 0.719, F 0.573)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.134] [G acc: 0.141]\n",
      "1137 [D loss: (0.594)(R 0.581, F 0.608)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.038] [G acc: 0.094]\n",
      "1138 [D loss: (0.594)(R 0.563, F 0.624)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.162] [G acc: 0.141]\n",
      "1139 [D loss: (0.592)(R 0.542, F 0.642)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.294] [G acc: 0.078]\n",
      "1140 [D loss: (0.574)(R 0.511, F 0.638)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.229] [G acc: 0.109]\n",
      "1141 [D loss: (0.545)(R 0.462, F 0.628)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.194] [G acc: 0.172]\n",
      "1142 [D loss: (0.659)(R 0.705, F 0.612)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.101] [G acc: 0.172]\n",
      "1143 [D loss: (0.561)(R 0.522, F 0.601)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.197] [G acc: 0.094]\n",
      "1144 [D loss: (0.624)(R 0.591, F 0.657)] [D acc: (0.656)(0.672, 0.641)] [G loss: 1.190] [G acc: 0.156]\n",
      "1145 [D loss: (0.586)(R 0.614, F 0.558)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.151] [G acc: 0.125]\n",
      "1146 [D loss: (0.637)(R 0.604, F 0.671)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.157] [G acc: 0.156]\n",
      "1147 [D loss: (0.580)(R 0.631, F 0.529)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.155] [G acc: 0.172]\n",
      "1148 [D loss: (0.596)(R 0.574, F 0.618)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.176] [G acc: 0.141]\n",
      "1149 [D loss: (0.577)(R 0.568, F 0.586)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.177] [G acc: 0.141]\n",
      "1150 [D loss: (0.594)(R 0.558, F 0.630)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.095] [G acc: 0.156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151 [D loss: (0.561)(R 0.612, F 0.509)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.186] [G acc: 0.141]\n",
      "1152 [D loss: (0.564)(R 0.564, F 0.565)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.242] [G acc: 0.125]\n",
      "1153 [D loss: (0.601)(R 0.573, F 0.629)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.235] [G acc: 0.109]\n",
      "1154 [D loss: (0.697)(R 0.640, F 0.755)] [D acc: (0.609)(0.609, 0.609)] [G loss: 1.138] [G acc: 0.172]\n",
      "1155 [D loss: (0.607)(R 0.621, F 0.594)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.051] [G acc: 0.172]\n",
      "1156 [D loss: (0.612)(R 0.624, F 0.600)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.107] [G acc: 0.094]\n",
      "1157 [D loss: (0.603)(R 0.570, F 0.636)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.030] [G acc: 0.266]\n",
      "1158 [D loss: (0.662)(R 0.609, F 0.715)] [D acc: (0.625)(0.594, 0.656)] [G loss: 1.096] [G acc: 0.203]\n",
      "1159 [D loss: (0.550)(R 0.567, F 0.534)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.098] [G acc: 0.141]\n",
      "1160 [D loss: (0.680)(R 0.645, F 0.715)] [D acc: (0.602)(0.531, 0.672)] [G loss: 0.997] [G acc: 0.219]\n",
      "1161 [D loss: (0.604)(R 0.635, F 0.573)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.143] [G acc: 0.188]\n",
      "1162 [D loss: (0.565)(R 0.530, F 0.601)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.204] [G acc: 0.141]\n",
      "1163 [D loss: (0.586)(R 0.589, F 0.584)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.126] [G acc: 0.141]\n",
      "1164 [D loss: (0.647)(R 0.601, F 0.693)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.035] [G acc: 0.172]\n",
      "1165 [D loss: (0.543)(R 0.547, F 0.539)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.109] [G acc: 0.141]\n",
      "1166 [D loss: (0.525)(R 0.518, F 0.532)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.172] [G acc: 0.172]\n",
      "1167 [D loss: (0.548)(R 0.510, F 0.586)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.263] [G acc: 0.078]\n",
      "1168 [D loss: (0.544)(R 0.506, F 0.582)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.215] [G acc: 0.125]\n",
      "1169 [D loss: (0.553)(R 0.545, F 0.561)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.073] [G acc: 0.203]\n",
      "1170 [D loss: (0.550)(R 0.513, F 0.587)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.228] [G acc: 0.188]\n",
      "1171 [D loss: (0.582)(R 0.578, F 0.586)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.151] [G acc: 0.172]\n",
      "1172 [D loss: (0.608)(R 0.621, F 0.595)] [D acc: (0.633)(0.547, 0.719)] [G loss: 1.175] [G acc: 0.078]\n",
      "1173 [D loss: (0.696)(R 0.787, F 0.606)] [D acc: (0.531)(0.406, 0.656)] [G loss: 1.142] [G acc: 0.109]\n",
      "1174 [D loss: (0.605)(R 0.602, F 0.609)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.125] [G acc: 0.156]\n",
      "1175 [D loss: (0.593)(R 0.570, F 0.616)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.127] [G acc: 0.188]\n",
      "1176 [D loss: (0.553)(R 0.552, F 0.554)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.173] [G acc: 0.156]\n",
      "1177 [D loss: (0.605)(R 0.549, F 0.661)] [D acc: (0.633)(0.641, 0.625)] [G loss: 1.059] [G acc: 0.094]\n",
      "1178 [D loss: (0.518)(R 0.469, F 0.567)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.229] [G acc: 0.094]\n",
      "1179 [D loss: (0.624)(R 0.620, F 0.629)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.232] [G acc: 0.109]\n",
      "1180 [D loss: (0.632)(R 0.595, F 0.669)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.237] [G acc: 0.062]\n",
      "1181 [D loss: (0.606)(R 0.694, F 0.517)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.212] [G acc: 0.047]\n",
      "1182 [D loss: (0.565)(R 0.590, F 0.539)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.294] [G acc: 0.047]\n",
      "1183 [D loss: (0.612)(R 0.585, F 0.639)] [D acc: (0.617)(0.641, 0.594)] [G loss: 1.158] [G acc: 0.078]\n",
      "1184 [D loss: (0.613)(R 0.630, F 0.596)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.193] [G acc: 0.062]\n",
      "1185 [D loss: (0.616)(R 0.632, F 0.600)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.050] [G acc: 0.203]\n",
      "1186 [D loss: (0.624)(R 0.625, F 0.623)] [D acc: (0.633)(0.562, 0.703)] [G loss: 1.057] [G acc: 0.219]\n",
      "1187 [D loss: (0.546)(R 0.499, F 0.594)] [D acc: (0.734)(0.766, 0.703)] [G loss: 1.109] [G acc: 0.203]\n",
      "1188 [D loss: (0.548)(R 0.511, F 0.585)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.182] [G acc: 0.125]\n",
      "1189 [D loss: (0.564)(R 0.587, F 0.541)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.108] [G acc: 0.141]\n",
      "1190 [D loss: (0.605)(R 0.574, F 0.637)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.220] [G acc: 0.141]\n",
      "1191 [D loss: (0.595)(R 0.579, F 0.610)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.239] [G acc: 0.078]\n",
      "1192 [D loss: (0.586)(R 0.557, F 0.615)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.226] [G acc: 0.094]\n",
      "1193 [D loss: (0.663)(R 0.649, F 0.677)] [D acc: (0.609)(0.625, 0.594)] [G loss: 1.151] [G acc: 0.125]\n",
      "1194 [D loss: (0.687)(R 0.753, F 0.620)] [D acc: (0.586)(0.469, 0.703)] [G loss: 1.100] [G acc: 0.109]\n",
      "1195 [D loss: (0.597)(R 0.671, F 0.523)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.098] [G acc: 0.109]\n",
      "1196 [D loss: (0.601)(R 0.665, F 0.536)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.208] [G acc: 0.125]\n",
      "1197 [D loss: (0.572)(R 0.550, F 0.594)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.134] [G acc: 0.156]\n",
      "1198 [D loss: (0.591)(R 0.613, F 0.570)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.098] [G acc: 0.062]\n",
      "1199 [D loss: (0.602)(R 0.603, F 0.601)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.091] [G acc: 0.141]\n",
      "1200 [D loss: (0.632)(R 0.593, F 0.672)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.233] [G acc: 0.078]\n",
      "1201 [D loss: (0.545)(R 0.587, F 0.503)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.219] [G acc: 0.125]\n",
      "1202 [D loss: (0.596)(R 0.560, F 0.631)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.170] [G acc: 0.094]\n",
      "1203 [D loss: (0.521)(R 0.509, F 0.533)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.049] [G acc: 0.219]\n",
      "1204 [D loss: (0.475)(R 0.458, F 0.492)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.174] [G acc: 0.188]\n",
      "1205 [D loss: (0.566)(R 0.413, F 0.719)] [D acc: (0.727)(0.781, 0.672)] [G loss: 1.339] [G acc: 0.125]\n",
      "1206 [D loss: (0.676)(R 0.739, F 0.613)] [D acc: (0.578)(0.453, 0.703)] [G loss: 1.174] [G acc: 0.125]\n",
      "1207 [D loss: (0.608)(R 0.561, F 0.654)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.312] [G acc: 0.078]\n",
      "1208 [D loss: (0.603)(R 0.515, F 0.691)] [D acc: (0.672)(0.719, 0.625)] [G loss: 1.105] [G acc: 0.156]\n",
      "1209 [D loss: (0.530)(R 0.504, F 0.555)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.286] [G acc: 0.078]\n",
      "1210 [D loss: (0.604)(R 0.647, F 0.560)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.230] [G acc: 0.109]\n",
      "1211 [D loss: (0.574)(R 0.593, F 0.555)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.240] [G acc: 0.094]\n",
      "1212 [D loss: (0.597)(R 0.606, F 0.588)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.264] [G acc: 0.094]\n",
      "1213 [D loss: (0.620)(R 0.653, F 0.587)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.127] [G acc: 0.078]\n",
      "1214 [D loss: (0.597)(R 0.594, F 0.599)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.183] [G acc: 0.062]\n",
      "1215 [D loss: (0.526)(R 0.496, F 0.555)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.258] [G acc: 0.125]\n",
      "1216 [D loss: (0.632)(R 0.641, F 0.622)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.192] [G acc: 0.172]\n",
      "1217 [D loss: (0.639)(R 0.669, F 0.609)] [D acc: (0.617)(0.531, 0.703)] [G loss: 1.157] [G acc: 0.062]\n",
      "1218 [D loss: (0.610)(R 0.643, F 0.577)] [D acc: (0.633)(0.516, 0.750)] [G loss: 1.095] [G acc: 0.172]\n",
      "1219 [D loss: (0.565)(R 0.609, F 0.521)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.196] [G acc: 0.141]\n",
      "1220 [D loss: (0.566)(R 0.552, F 0.581)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.099] [G acc: 0.156]\n",
      "1221 [D loss: (0.489)(R 0.437, F 0.542)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.230] [G acc: 0.141]\n",
      "1222 [D loss: (0.603)(R 0.533, F 0.673)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.252] [G acc: 0.109]\n",
      "1223 [D loss: (0.528)(R 0.565, F 0.490)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.180] [G acc: 0.094]\n",
      "1224 [D loss: (0.641)(R 0.548, F 0.734)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.239] [G acc: 0.078]\n",
      "1225 [D loss: (0.590)(R 0.652, F 0.528)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.092] [G acc: 0.172]\n",
      "1226 [D loss: (0.561)(R 0.542, F 0.580)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.247] [G acc: 0.078]\n",
      "1227 [D loss: (0.588)(R 0.592, F 0.584)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.179] [G acc: 0.125]\n",
      "1228 [D loss: (0.516)(R 0.488, F 0.543)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.203] [G acc: 0.109]\n",
      "1229 [D loss: (0.560)(R 0.572, F 0.547)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.160] [G acc: 0.156]\n",
      "1230 [D loss: (0.647)(R 0.652, F 0.643)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.168] [G acc: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1231 [D loss: (0.566)(R 0.540, F 0.591)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.283] [G acc: 0.031]\n",
      "1232 [D loss: (0.574)(R 0.503, F 0.645)] [D acc: (0.688)(0.766, 0.609)] [G loss: 1.269] [G acc: 0.078]\n",
      "1233 [D loss: (0.649)(R 0.709, F 0.589)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.172] [G acc: 0.141]\n",
      "1234 [D loss: (0.666)(R 0.597, F 0.735)] [D acc: (0.633)(0.625, 0.641)] [G loss: 1.220] [G acc: 0.109]\n",
      "1235 [D loss: (0.655)(R 0.719, F 0.591)] [D acc: (0.633)(0.516, 0.750)] [G loss: 1.087] [G acc: 0.078]\n",
      "1236 [D loss: (0.606)(R 0.660, F 0.552)] [D acc: (0.633)(0.484, 0.781)] [G loss: 1.013] [G acc: 0.109]\n",
      "1237 [D loss: (0.585)(R 0.656, F 0.514)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.173] [G acc: 0.094]\n",
      "1238 [D loss: (0.658)(R 0.578, F 0.738)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.205] [G acc: 0.156]\n",
      "1239 [D loss: (0.566)(R 0.561, F 0.571)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.274] [G acc: 0.125]\n",
      "1240 [D loss: (0.535)(R 0.546, F 0.525)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.257] [G acc: 0.125]\n",
      "1241 [D loss: (0.579)(R 0.584, F 0.574)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.218] [G acc: 0.109]\n",
      "1242 [D loss: (0.575)(R 0.581, F 0.569)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.202] [G acc: 0.109]\n",
      "1243 [D loss: (0.491)(R 0.473, F 0.509)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.223] [G acc: 0.109]\n",
      "1244 [D loss: (0.637)(R 0.604, F 0.670)] [D acc: (0.656)(0.672, 0.641)] [G loss: 1.236] [G acc: 0.109]\n",
      "1245 [D loss: (0.595)(R 0.643, F 0.548)] [D acc: (0.617)(0.484, 0.750)] [G loss: 1.079] [G acc: 0.156]\n",
      "1246 [D loss: (0.587)(R 0.632, F 0.542)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.144] [G acc: 0.141]\n",
      "1247 [D loss: (0.582)(R 0.570, F 0.593)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.281] [G acc: 0.125]\n",
      "1248 [D loss: (0.601)(R 0.614, F 0.588)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.160] [G acc: 0.125]\n",
      "1249 [D loss: (0.613)(R 0.567, F 0.658)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.404] [G acc: 0.078]\n",
      "1250 [D loss: (0.591)(R 0.609, F 0.573)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.227] [G acc: 0.094]\n",
      "1251 [D loss: (0.592)(R 0.607, F 0.578)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.117] [G acc: 0.125]\n",
      "1252 [D loss: (0.531)(R 0.534, F 0.528)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.175] [G acc: 0.109]\n",
      "1253 [D loss: (0.623)(R 0.527, F 0.719)] [D acc: (0.648)(0.672, 0.625)] [G loss: 1.221] [G acc: 0.141]\n",
      "1254 [D loss: (0.578)(R 0.669, F 0.487)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.196] [G acc: 0.156]\n",
      "1255 [D loss: (0.585)(R 0.618, F 0.551)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.087] [G acc: 0.141]\n",
      "1256 [D loss: (0.573)(R 0.535, F 0.612)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.153] [G acc: 0.094]\n",
      "1257 [D loss: (0.672)(R 0.734, F 0.609)] [D acc: (0.578)(0.438, 0.719)] [G loss: 1.130] [G acc: 0.156]\n",
      "1258 [D loss: (0.588)(R 0.582, F 0.594)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.050] [G acc: 0.250]\n",
      "1259 [D loss: (0.583)(R 0.575, F 0.591)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.166] [G acc: 0.188]\n",
      "1260 [D loss: (0.580)(R 0.559, F 0.601)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.257] [G acc: 0.141]\n",
      "1261 [D loss: (0.662)(R 0.614, F 0.709)] [D acc: (0.617)(0.562, 0.672)] [G loss: 1.093] [G acc: 0.094]\n",
      "1262 [D loss: (0.572)(R 0.607, F 0.537)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.063] [G acc: 0.141]\n",
      "1263 [D loss: (0.556)(R 0.490, F 0.623)] [D acc: (0.711)(0.750, 0.672)] [G loss: 1.111] [G acc: 0.156]\n",
      "1264 [D loss: (0.626)(R 0.631, F 0.621)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.121] [G acc: 0.172]\n",
      "1265 [D loss: (0.564)(R 0.596, F 0.532)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.164] [G acc: 0.156]\n",
      "1266 [D loss: (0.585)(R 0.588, F 0.582)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.247] [G acc: 0.156]\n",
      "1267 [D loss: (0.665)(R 0.643, F 0.686)] [D acc: (0.609)(0.531, 0.688)] [G loss: 1.213] [G acc: 0.047]\n",
      "1268 [D loss: (0.603)(R 0.681, F 0.524)] [D acc: (0.680)(0.484, 0.875)] [G loss: 1.055] [G acc: 0.125]\n",
      "1269 [D loss: (0.566)(R 0.506, F 0.625)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.169] [G acc: 0.062]\n",
      "1270 [D loss: (0.561)(R 0.488, F 0.635)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.249] [G acc: 0.109]\n",
      "1271 [D loss: (0.558)(R 0.525, F 0.590)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.332] [G acc: 0.047]\n",
      "1272 [D loss: (0.567)(R 0.646, F 0.488)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.211] [G acc: 0.047]\n",
      "1273 [D loss: (0.578)(R 0.594, F 0.562)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.206] [G acc: 0.109]\n",
      "1274 [D loss: (0.612)(R 0.561, F 0.663)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.150] [G acc: 0.141]\n",
      "1275 [D loss: (0.601)(R 0.629, F 0.574)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.074] [G acc: 0.250]\n",
      "1276 [D loss: (0.553)(R 0.577, F 0.528)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.143] [G acc: 0.188]\n",
      "1277 [D loss: (0.520)(R 0.500, F 0.540)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.275] [G acc: 0.234]\n",
      "1278 [D loss: (0.542)(R 0.467, F 0.617)] [D acc: (0.766)(0.781, 0.750)] [G loss: 1.264] [G acc: 0.156]\n",
      "1279 [D loss: (0.539)(R 0.422, F 0.656)] [D acc: (0.789)(0.844, 0.734)] [G loss: 1.213] [G acc: 0.156]\n",
      "1280 [D loss: (0.612)(R 0.703, F 0.521)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.238] [G acc: 0.094]\n",
      "1281 [D loss: (0.634)(R 0.592, F 0.675)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.169] [G acc: 0.094]\n",
      "1282 [D loss: (0.601)(R 0.667, F 0.535)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.221] [G acc: 0.156]\n",
      "1283 [D loss: (0.532)(R 0.548, F 0.517)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.228] [G acc: 0.141]\n",
      "1284 [D loss: (0.566)(R 0.502, F 0.631)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.613] [G acc: 0.062]\n",
      "1285 [D loss: (0.655)(R 0.707, F 0.602)] [D acc: (0.648)(0.531, 0.766)] [G loss: 1.328] [G acc: 0.062]\n",
      "1286 [D loss: (0.623)(R 0.617, F 0.628)] [D acc: (0.656)(0.656, 0.656)] [G loss: 1.310] [G acc: 0.047]\n",
      "1287 [D loss: (0.566)(R 0.601, F 0.530)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.137] [G acc: 0.172]\n",
      "1288 [D loss: (0.569)(R 0.576, F 0.561)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.141] [G acc: 0.156]\n",
      "1289 [D loss: (0.515)(R 0.493, F 0.538)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.205] [G acc: 0.125]\n",
      "1290 [D loss: (0.587)(R 0.567, F 0.606)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.229] [G acc: 0.188]\n",
      "1291 [D loss: (0.610)(R 0.586, F 0.633)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.233] [G acc: 0.094]\n",
      "1292 [D loss: (0.628)(R 0.585, F 0.672)] [D acc: (0.617)(0.609, 0.625)] [G loss: 1.384] [G acc: 0.078]\n",
      "1293 [D loss: (0.603)(R 0.657, F 0.550)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.214] [G acc: 0.094]\n",
      "1294 [D loss: (0.597)(R 0.618, F 0.577)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.170] [G acc: 0.156]\n",
      "1295 [D loss: (0.569)(R 0.485, F 0.653)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.082] [G acc: 0.203]\n",
      "1296 [D loss: (0.535)(R 0.569, F 0.501)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.111] [G acc: 0.172]\n",
      "1297 [D loss: (0.537)(R 0.503, F 0.571)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.181] [G acc: 0.109]\n",
      "1298 [D loss: (0.585)(R 0.508, F 0.663)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.410] [G acc: 0.094]\n",
      "1299 [D loss: (0.564)(R 0.592, F 0.535)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.325] [G acc: 0.062]\n",
      "1300 [D loss: (0.492)(R 0.468, F 0.515)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.358] [G acc: 0.125]\n",
      "1301 [D loss: (0.533)(R 0.461, F 0.606)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.406] [G acc: 0.156]\n",
      "1302 [D loss: (0.568)(R 0.622, F 0.514)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.316] [G acc: 0.078]\n",
      "1303 [D loss: (0.533)(R 0.564, F 0.501)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.261] [G acc: 0.109]\n",
      "1304 [D loss: (0.565)(R 0.459, F 0.672)] [D acc: (0.703)(0.781, 0.625)] [G loss: 1.331] [G acc: 0.141]\n",
      "1305 [D loss: (0.535)(R 0.545, F 0.525)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.268] [G acc: 0.156]\n",
      "1306 [D loss: (0.551)(R 0.481, F 0.620)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.302] [G acc: 0.125]\n",
      "1307 [D loss: (0.561)(R 0.512, F 0.610)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.357] [G acc: 0.078]\n",
      "1308 [D loss: (0.553)(R 0.571, F 0.534)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.254] [G acc: 0.125]\n",
      "1309 [D loss: (0.569)(R 0.545, F 0.592)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.475] [G acc: 0.109]\n",
      "1310 [D loss: (0.472)(R 0.517, F 0.427)] [D acc: (0.812)(0.703, 0.922)] [G loss: 1.400] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311 [D loss: (0.540)(R 0.582, F 0.497)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.412] [G acc: 0.047]\n",
      "1312 [D loss: (0.552)(R 0.490, F 0.615)] [D acc: (0.680)(0.719, 0.641)] [G loss: 1.377] [G acc: 0.078]\n",
      "1313 [D loss: (0.520)(R 0.516, F 0.525)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.389] [G acc: 0.109]\n",
      "1314 [D loss: (0.555)(R 0.517, F 0.594)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.351] [G acc: 0.141]\n",
      "1315 [D loss: (0.578)(R 0.632, F 0.524)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.286] [G acc: 0.172]\n",
      "1316 [D loss: (0.574)(R 0.569, F 0.578)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.267] [G acc: 0.141]\n",
      "1317 [D loss: (0.618)(R 0.634, F 0.603)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.149] [G acc: 0.172]\n",
      "1318 [D loss: (0.560)(R 0.651, F 0.468)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.246] [G acc: 0.125]\n",
      "1319 [D loss: (0.540)(R 0.549, F 0.532)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.202] [G acc: 0.156]\n",
      "1320 [D loss: (0.625)(R 0.550, F 0.700)] [D acc: (0.617)(0.641, 0.594)] [G loss: 1.109] [G acc: 0.141]\n",
      "1321 [D loss: (0.507)(R 0.520, F 0.494)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.355] [G acc: 0.125]\n",
      "1322 [D loss: (0.683)(R 0.711, F 0.655)] [D acc: (0.633)(0.531, 0.734)] [G loss: 1.160] [G acc: 0.125]\n",
      "1323 [D loss: (0.607)(R 0.671, F 0.544)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.282] [G acc: 0.078]\n",
      "1324 [D loss: (0.627)(R 0.650, F 0.605)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.171] [G acc: 0.125]\n",
      "1325 [D loss: (0.597)(R 0.557, F 0.638)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.168] [G acc: 0.203]\n",
      "1326 [D loss: (0.579)(R 0.594, F 0.565)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.236] [G acc: 0.141]\n",
      "1327 [D loss: (0.615)(R 0.712, F 0.519)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.126] [G acc: 0.109]\n",
      "1328 [D loss: (0.501)(R 0.465, F 0.538)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.228] [G acc: 0.109]\n",
      "1329 [D loss: (0.584)(R 0.481, F 0.687)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.402] [G acc: 0.047]\n",
      "1330 [D loss: (0.542)(R 0.570, F 0.514)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.272] [G acc: 0.078]\n",
      "1331 [D loss: (0.603)(R 0.534, F 0.671)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.317] [G acc: 0.016]\n",
      "1332 [D loss: (0.527)(R 0.596, F 0.458)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.366] [G acc: 0.062]\n",
      "1333 [D loss: (0.563)(R 0.626, F 0.501)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.333] [G acc: 0.078]\n",
      "1334 [D loss: (0.672)(R 0.502, F 0.843)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.470] [G acc: 0.062]\n",
      "1335 [D loss: (0.585)(R 0.662, F 0.507)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.263] [G acc: 0.188]\n",
      "1336 [D loss: (0.529)(R 0.534, F 0.523)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.219] [G acc: 0.094]\n",
      "1337 [D loss: (0.617)(R 0.667, F 0.567)] [D acc: (0.641)(0.562, 0.719)] [G loss: 1.264] [G acc: 0.094]\n",
      "1338 [D loss: (0.559)(R 0.596, F 0.522)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.289] [G acc: 0.141]\n",
      "1339 [D loss: (0.625)(R 0.704, F 0.546)] [D acc: (0.641)(0.516, 0.766)] [G loss: 1.351] [G acc: 0.078]\n",
      "1340 [D loss: (0.585)(R 0.588, F 0.582)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.255] [G acc: 0.078]\n",
      "1341 [D loss: (0.668)(R 0.607, F 0.729)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.148] [G acc: 0.125]\n",
      "1342 [D loss: (0.561)(R 0.680, F 0.441)] [D acc: (0.680)(0.500, 0.859)] [G loss: 1.113] [G acc: 0.156]\n",
      "1343 [D loss: (0.619)(R 0.526, F 0.711)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.226] [G acc: 0.094]\n",
      "1344 [D loss: (0.516)(R 0.554, F 0.479)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.231] [G acc: 0.172]\n",
      "1345 [D loss: (0.541)(R 0.502, F 0.580)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.295] [G acc: 0.109]\n",
      "1346 [D loss: (0.540)(R 0.581, F 0.498)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.195] [G acc: 0.172]\n",
      "1347 [D loss: (0.597)(R 0.610, F 0.584)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.187] [G acc: 0.188]\n",
      "1348 [D loss: (0.692)(R 0.627, F 0.757)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.397] [G acc: 0.016]\n",
      "1349 [D loss: (0.533)(R 0.535, F 0.531)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.254] [G acc: 0.078]\n",
      "1350 [D loss: (0.500)(R 0.475, F 0.525)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.379] [G acc: 0.141]\n",
      "1351 [D loss: (0.604)(R 0.532, F 0.676)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.504] [G acc: 0.047]\n",
      "1352 [D loss: (0.639)(R 0.710, F 0.567)] [D acc: (0.617)(0.562, 0.672)] [G loss: 1.233] [G acc: 0.109]\n",
      "1353 [D loss: (0.511)(R 0.526, F 0.495)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.193] [G acc: 0.172]\n",
      "1354 [D loss: (0.486)(R 0.455, F 0.518)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.318] [G acc: 0.203]\n",
      "1355 [D loss: (0.572)(R 0.521, F 0.623)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.255] [G acc: 0.172]\n",
      "1356 [D loss: (0.644)(R 0.523, F 0.765)] [D acc: (0.664)(0.750, 0.578)] [G loss: 1.128] [G acc: 0.219]\n",
      "1357 [D loss: (0.576)(R 0.603, F 0.550)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.306] [G acc: 0.078]\n",
      "1358 [D loss: (0.605)(R 0.593, F 0.617)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.216] [G acc: 0.188]\n",
      "1359 [D loss: (0.663)(R 0.706, F 0.621)] [D acc: (0.648)(0.531, 0.766)] [G loss: 1.284] [G acc: 0.094]\n",
      "1360 [D loss: (0.644)(R 0.740, F 0.548)] [D acc: (0.648)(0.516, 0.781)] [G loss: 1.256] [G acc: 0.141]\n",
      "1361 [D loss: (0.557)(R 0.523, F 0.591)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.182] [G acc: 0.125]\n",
      "1362 [D loss: (0.589)(R 0.622, F 0.557)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.279] [G acc: 0.109]\n",
      "1363 [D loss: (0.560)(R 0.538, F 0.583)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.348] [G acc: 0.125]\n",
      "1364 [D loss: (0.627)(R 0.699, F 0.555)] [D acc: (0.633)(0.516, 0.750)] [G loss: 1.286] [G acc: 0.109]\n",
      "1365 [D loss: (0.573)(R 0.463, F 0.684)] [D acc: (0.664)(0.719, 0.609)] [G loss: 1.286] [G acc: 0.031]\n",
      "1366 [D loss: (0.619)(R 0.653, F 0.585)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.184] [G acc: 0.109]\n",
      "1367 [D loss: (0.574)(R 0.550, F 0.598)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.099] [G acc: 0.234]\n",
      "1368 [D loss: (0.578)(R 0.530, F 0.625)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.275] [G acc: 0.125]\n",
      "1369 [D loss: (0.521)(R 0.537, F 0.505)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.227] [G acc: 0.125]\n",
      "1370 [D loss: (0.541)(R 0.592, F 0.491)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.142] [G acc: 0.141]\n",
      "1371 [D loss: (0.488)(R 0.434, F 0.543)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.298] [G acc: 0.125]\n",
      "1372 [D loss: (0.592)(R 0.548, F 0.637)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.303] [G acc: 0.078]\n",
      "1373 [D loss: (0.595)(R 0.647, F 0.543)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.132] [G acc: 0.188]\n",
      "1374 [D loss: (0.595)(R 0.572, F 0.619)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.062] [G acc: 0.172]\n",
      "1375 [D loss: (0.670)(R 0.761, F 0.579)] [D acc: (0.633)(0.484, 0.781)] [G loss: 1.217] [G acc: 0.078]\n",
      "1376 [D loss: (0.572)(R 0.515, F 0.628)] [D acc: (0.680)(0.703, 0.656)] [G loss: 1.108] [G acc: 0.125]\n",
      "1377 [D loss: (0.557)(R 0.646, F 0.468)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.210] [G acc: 0.109]\n",
      "1378 [D loss: (0.553)(R 0.572, F 0.533)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.264] [G acc: 0.078]\n",
      "1379 [D loss: (0.569)(R 0.530, F 0.608)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.202] [G acc: 0.141]\n",
      "1380 [D loss: (0.648)(R 0.599, F 0.697)] [D acc: (0.594)(0.625, 0.562)] [G loss: 1.240] [G acc: 0.156]\n",
      "1381 [D loss: (0.580)(R 0.667, F 0.492)] [D acc: (0.727)(0.562, 0.891)] [G loss: 1.153] [G acc: 0.219]\n",
      "1382 [D loss: (0.586)(R 0.590, F 0.583)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.171] [G acc: 0.109]\n",
      "1383 [D loss: (0.692)(R 0.715, F 0.670)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.104] [G acc: 0.172]\n",
      "1384 [D loss: (0.608)(R 0.556, F 0.660)] [D acc: (0.656)(0.656, 0.656)] [G loss: 1.131] [G acc: 0.109]\n",
      "1385 [D loss: (0.524)(R 0.543, F 0.505)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.296] [G acc: 0.078]\n",
      "1386 [D loss: (0.573)(R 0.451, F 0.695)] [D acc: (0.711)(0.750, 0.672)] [G loss: 1.228] [G acc: 0.172]\n",
      "1387 [D loss: (0.537)(R 0.599, F 0.476)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.155] [G acc: 0.141]\n",
      "1388 [D loss: (0.559)(R 0.570, F 0.549)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.285] [G acc: 0.125]\n",
      "1389 [D loss: (0.595)(R 0.590, F 0.600)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.185] [G acc: 0.141]\n",
      "1390 [D loss: (0.537)(R 0.511, F 0.563)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.290] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1391 [D loss: (0.550)(R 0.456, F 0.645)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.321] [G acc: 0.156]\n",
      "1392 [D loss: (0.494)(R 0.516, F 0.472)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.361] [G acc: 0.078]\n",
      "1393 [D loss: (0.599)(R 0.587, F 0.610)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.274] [G acc: 0.156]\n",
      "1394 [D loss: (0.648)(R 0.750, F 0.546)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.139] [G acc: 0.172]\n",
      "1395 [D loss: (0.591)(R 0.642, F 0.541)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.183] [G acc: 0.125]\n",
      "1396 [D loss: (0.589)(R 0.601, F 0.577)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.300] [G acc: 0.125]\n",
      "1397 [D loss: (0.586)(R 0.612, F 0.560)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.353] [G acc: 0.141]\n",
      "1398 [D loss: (0.660)(R 0.630, F 0.689)] [D acc: (0.609)(0.562, 0.656)] [G loss: 1.320] [G acc: 0.078]\n",
      "1399 [D loss: (0.558)(R 0.593, F 0.523)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.269] [G acc: 0.172]\n",
      "1400 [D loss: (0.606)(R 0.592, F 0.620)] [D acc: (0.617)(0.625, 0.609)] [G loss: 1.194] [G acc: 0.188]\n",
      "1401 [D loss: (0.498)(R 0.496, F 0.501)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.127] [G acc: 0.203]\n",
      "1402 [D loss: (0.616)(R 0.615, F 0.616)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.310] [G acc: 0.109]\n",
      "1403 [D loss: (0.567)(R 0.584, F 0.549)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.471] [G acc: 0.094]\n",
      "1404 [D loss: (0.567)(R 0.589, F 0.546)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.165] [G acc: 0.156]\n",
      "1405 [D loss: (0.597)(R 0.679, F 0.516)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.103] [G acc: 0.188]\n",
      "1406 [D loss: (0.573)(R 0.487, F 0.658)] [D acc: (0.664)(0.688, 0.641)] [G loss: 1.246] [G acc: 0.125]\n",
      "1407 [D loss: (0.523)(R 0.523, F 0.523)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.356] [G acc: 0.125]\n",
      "1408 [D loss: (0.534)(R 0.552, F 0.515)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.255] [G acc: 0.172]\n",
      "1409 [D loss: (0.586)(R 0.604, F 0.567)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.194] [G acc: 0.141]\n",
      "1410 [D loss: (0.584)(R 0.501, F 0.668)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.251] [G acc: 0.109]\n",
      "1411 [D loss: (0.664)(R 0.716, F 0.613)] [D acc: (0.602)(0.469, 0.734)] [G loss: 1.300] [G acc: 0.047]\n",
      "1412 [D loss: (0.560)(R 0.607, F 0.513)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.182] [G acc: 0.125]\n",
      "1413 [D loss: (0.565)(R 0.591, F 0.540)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.317] [G acc: 0.141]\n",
      "1414 [D loss: (0.594)(R 0.579, F 0.609)] [D acc: (0.656)(0.656, 0.656)] [G loss: 1.155] [G acc: 0.188]\n",
      "1415 [D loss: (0.574)(R 0.615, F 0.533)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.181] [G acc: 0.172]\n",
      "1416 [D loss: (0.621)(R 0.578, F 0.665)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.229] [G acc: 0.062]\n",
      "1417 [D loss: (0.631)(R 0.624, F 0.637)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.149] [G acc: 0.188]\n",
      "1418 [D loss: (0.579)(R 0.598, F 0.561)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.150] [G acc: 0.141]\n",
      "1419 [D loss: (0.620)(R 0.598, F 0.643)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.263] [G acc: 0.156]\n",
      "1420 [D loss: (0.610)(R 0.647, F 0.572)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.306] [G acc: 0.109]\n",
      "1421 [D loss: (0.592)(R 0.600, F 0.583)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.268] [G acc: 0.109]\n",
      "1422 [D loss: (0.573)(R 0.572, F 0.574)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.169] [G acc: 0.125]\n",
      "1423 [D loss: (0.605)(R 0.610, F 0.600)] [D acc: (0.617)(0.562, 0.672)] [G loss: 1.243] [G acc: 0.109]\n",
      "1424 [D loss: (0.548)(R 0.563, F 0.533)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.213] [G acc: 0.141]\n",
      "1425 [D loss: (0.566)(R 0.592, F 0.540)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.161] [G acc: 0.172]\n",
      "1426 [D loss: (0.554)(R 0.455, F 0.653)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.196] [G acc: 0.172]\n",
      "1427 [D loss: (0.526)(R 0.505, F 0.546)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.211] [G acc: 0.109]\n",
      "1428 [D loss: (0.604)(R 0.589, F 0.620)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.170] [G acc: 0.141]\n",
      "1429 [D loss: (0.672)(R 0.567, F 0.778)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.238] [G acc: 0.078]\n",
      "1430 [D loss: (0.529)(R 0.564, F 0.494)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.195] [G acc: 0.125]\n",
      "1431 [D loss: (0.566)(R 0.646, F 0.486)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.025] [G acc: 0.266]\n",
      "1432 [D loss: (0.578)(R 0.618, F 0.539)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.090] [G acc: 0.172]\n",
      "1433 [D loss: (0.558)(R 0.386, F 0.730)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.229] [G acc: 0.141]\n",
      "1434 [D loss: (0.592)(R 0.619, F 0.566)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.167] [G acc: 0.172]\n",
      "1435 [D loss: (0.568)(R 0.525, F 0.612)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.208] [G acc: 0.188]\n",
      "1436 [D loss: (0.582)(R 0.526, F 0.637)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.152] [G acc: 0.125]\n",
      "1437 [D loss: (0.582)(R 0.548, F 0.617)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.188] [G acc: 0.094]\n",
      "1438 [D loss: (0.462)(R 0.441, F 0.483)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.349] [G acc: 0.125]\n",
      "1439 [D loss: (0.504)(R 0.536, F 0.471)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.271] [G acc: 0.109]\n",
      "1440 [D loss: (0.537)(R 0.489, F 0.585)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.113] [G acc: 0.125]\n",
      "1441 [D loss: (0.514)(R 0.528, F 0.501)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.488] [G acc: 0.125]\n",
      "1442 [D loss: (0.488)(R 0.510, F 0.467)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.392] [G acc: 0.141]\n",
      "1443 [D loss: (0.550)(R 0.434, F 0.666)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.346] [G acc: 0.125]\n",
      "1444 [D loss: (0.645)(R 0.637, F 0.653)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.287] [G acc: 0.141]\n",
      "1445 [D loss: (0.682)(R 0.726, F 0.639)] [D acc: (0.602)(0.531, 0.672)] [G loss: 1.205] [G acc: 0.188]\n",
      "1446 [D loss: (0.635)(R 0.616, F 0.655)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.257] [G acc: 0.125]\n",
      "1447 [D loss: (0.575)(R 0.512, F 0.637)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.250] [G acc: 0.125]\n",
      "1448 [D loss: (0.570)(R 0.554, F 0.585)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.212] [G acc: 0.141]\n",
      "1449 [D loss: (0.601)(R 0.603, F 0.599)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.240] [G acc: 0.109]\n",
      "1450 [D loss: (0.627)(R 0.653, F 0.602)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.136] [G acc: 0.172]\n",
      "1451 [D loss: (0.522)(R 0.503, F 0.541)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.161] [G acc: 0.109]\n",
      "1452 [D loss: (0.626)(R 0.674, F 0.578)] [D acc: (0.633)(0.500, 0.766)] [G loss: 1.248] [G acc: 0.125]\n",
      "1453 [D loss: (0.601)(R 0.675, F 0.527)] [D acc: (0.633)(0.516, 0.750)] [G loss: 1.129] [G acc: 0.078]\n",
      "1454 [D loss: (0.601)(R 0.614, F 0.587)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.105] [G acc: 0.125]\n",
      "1455 [D loss: (0.552)(R 0.533, F 0.571)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.242] [G acc: 0.141]\n",
      "1456 [D loss: (0.530)(R 0.513, F 0.547)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.137] [G acc: 0.141]\n",
      "1457 [D loss: (0.632)(R 0.624, F 0.640)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.085] [G acc: 0.156]\n",
      "1458 [D loss: (0.573)(R 0.577, F 0.570)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.309] [G acc: 0.109]\n",
      "1459 [D loss: (0.526)(R 0.533, F 0.518)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.241] [G acc: 0.109]\n",
      "1460 [D loss: (0.500)(R 0.463, F 0.536)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.251] [G acc: 0.094]\n",
      "1461 [D loss: (0.547)(R 0.513, F 0.582)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.336] [G acc: 0.031]\n",
      "1462 [D loss: (0.598)(R 0.560, F 0.635)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.312] [G acc: 0.094]\n",
      "1463 [D loss: (0.577)(R 0.624, F 0.530)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.243] [G acc: 0.141]\n",
      "1464 [D loss: (0.619)(R 0.683, F 0.556)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.247] [G acc: 0.125]\n",
      "1465 [D loss: (0.609)(R 0.589, F 0.628)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.271] [G acc: 0.078]\n",
      "1466 [D loss: (0.580)(R 0.562, F 0.599)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.205] [G acc: 0.109]\n",
      "1467 [D loss: (0.541)(R 0.599, F 0.484)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.191] [G acc: 0.156]\n",
      "1468 [D loss: (0.574)(R 0.498, F 0.649)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.303] [G acc: 0.078]\n",
      "1469 [D loss: (0.572)(R 0.637, F 0.507)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.128] [G acc: 0.172]\n",
      "1470 [D loss: (0.601)(R 0.632, F 0.571)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.268] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1471 [D loss: (0.514)(R 0.549, F 0.479)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.193] [G acc: 0.156]\n",
      "1472 [D loss: (0.450)(R 0.478, F 0.422)] [D acc: (0.852)(0.766, 0.938)] [G loss: 1.322] [G acc: 0.172]\n",
      "1473 [D loss: (0.581)(R 0.393, F 0.768)] [D acc: (0.703)(0.797, 0.609)] [G loss: 1.277] [G acc: 0.094]\n",
      "1474 [D loss: (0.569)(R 0.656, F 0.482)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.324] [G acc: 0.047]\n",
      "1475 [D loss: (0.554)(R 0.493, F 0.614)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.291] [G acc: 0.094]\n",
      "1476 [D loss: (0.642)(R 0.781, F 0.503)] [D acc: (0.602)(0.438, 0.766)] [G loss: 1.251] [G acc: 0.062]\n",
      "1477 [D loss: (0.608)(R 0.599, F 0.616)] [D acc: (0.633)(0.562, 0.703)] [G loss: 1.275] [G acc: 0.094]\n",
      "1478 [D loss: (0.584)(R 0.680, F 0.489)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.385] [G acc: 0.062]\n",
      "1479 [D loss: (0.571)(R 0.594, F 0.548)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.292] [G acc: 0.078]\n",
      "1480 [D loss: (0.510)(R 0.529, F 0.490)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.244] [G acc: 0.203]\n",
      "1481 [D loss: (0.529)(R 0.485, F 0.572)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.274] [G acc: 0.188]\n",
      "1482 [D loss: (0.556)(R 0.636, F 0.477)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.317] [G acc: 0.141]\n",
      "1483 [D loss: (0.517)(R 0.455, F 0.578)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.239] [G acc: 0.172]\n",
      "1484 [D loss: (0.640)(R 0.571, F 0.709)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.178] [G acc: 0.141]\n",
      "1485 [D loss: (0.611)(R 0.616, F 0.605)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.242] [G acc: 0.141]\n",
      "1486 [D loss: (0.579)(R 0.491, F 0.666)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.246] [G acc: 0.062]\n",
      "1487 [D loss: (0.637)(R 0.688, F 0.587)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.207] [G acc: 0.094]\n",
      "1488 [D loss: (0.569)(R 0.593, F 0.546)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.212] [G acc: 0.141]\n",
      "1489 [D loss: (0.583)(R 0.617, F 0.549)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.288] [G acc: 0.031]\n",
      "1490 [D loss: (0.581)(R 0.577, F 0.585)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.225] [G acc: 0.078]\n",
      "1491 [D loss: (0.595)(R 0.676, F 0.515)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.134] [G acc: 0.172]\n",
      "1492 [D loss: (0.628)(R 0.626, F 0.630)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.124] [G acc: 0.172]\n",
      "1493 [D loss: (0.554)(R 0.558, F 0.549)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.226] [G acc: 0.078]\n",
      "1494 [D loss: (0.600)(R 0.661, F 0.539)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.200] [G acc: 0.125]\n",
      "1495 [D loss: (0.605)(R 0.601, F 0.609)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.284] [G acc: 0.156]\n",
      "1496 [D loss: (0.612)(R 0.621, F 0.603)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.255] [G acc: 0.172]\n",
      "1497 [D loss: (0.636)(R 0.596, F 0.677)] [D acc: (0.625)(0.609, 0.641)] [G loss: 1.149] [G acc: 0.172]\n",
      "1498 [D loss: (0.500)(R 0.495, F 0.505)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.236] [G acc: 0.094]\n",
      "1499 [D loss: (0.599)(R 0.581, F 0.617)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.357] [G acc: 0.078]\n",
      "1500 [D loss: (0.532)(R 0.523, F 0.541)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.246] [G acc: 0.141]\n",
      "1501 [D loss: (0.506)(R 0.501, F 0.511)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.344] [G acc: 0.109]\n",
      "1502 [D loss: (0.584)(R 0.620, F 0.547)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.200] [G acc: 0.109]\n",
      "1503 [D loss: (0.548)(R 0.499, F 0.597)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.240] [G acc: 0.125]\n",
      "1504 [D loss: (0.614)(R 0.642, F 0.585)] [D acc: (0.617)(0.484, 0.750)] [G loss: 1.156] [G acc: 0.188]\n",
      "1505 [D loss: (0.573)(R 0.471, F 0.675)] [D acc: (0.766)(0.781, 0.750)] [G loss: 1.278] [G acc: 0.109]\n",
      "1506 [D loss: (0.627)(R 0.696, F 0.558)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.103] [G acc: 0.156]\n",
      "1507 [D loss: (0.632)(R 0.610, F 0.654)] [D acc: (0.625)(0.609, 0.641)] [G loss: 1.058] [G acc: 0.141]\n",
      "1508 [D loss: (0.561)(R 0.511, F 0.611)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.150] [G acc: 0.172]\n",
      "1509 [D loss: (0.570)(R 0.564, F 0.575)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.228] [G acc: 0.047]\n",
      "1510 [D loss: (0.591)(R 0.595, F 0.587)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.187] [G acc: 0.156]\n",
      "1511 [D loss: (0.681)(R 0.632, F 0.730)] [D acc: (0.609)(0.562, 0.656)] [G loss: 1.257] [G acc: 0.125]\n",
      "1512 [D loss: (0.579)(R 0.690, F 0.468)] [D acc: (0.648)(0.453, 0.844)] [G loss: 1.056] [G acc: 0.156]\n",
      "1513 [D loss: (0.560)(R 0.534, F 0.585)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.194] [G acc: 0.109]\n",
      "1514 [D loss: (0.616)(R 0.683, F 0.549)] [D acc: (0.633)(0.547, 0.719)] [G loss: 1.049] [G acc: 0.266]\n",
      "1515 [D loss: (0.557)(R 0.474, F 0.640)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.144] [G acc: 0.109]\n",
      "1516 [D loss: (0.635)(R 0.662, F 0.609)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.140] [G acc: 0.172]\n",
      "1517 [D loss: (0.589)(R 0.613, F 0.566)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.249] [G acc: 0.094]\n",
      "1518 [D loss: (0.571)(R 0.594, F 0.549)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.218] [G acc: 0.172]\n",
      "1519 [D loss: (0.561)(R 0.523, F 0.598)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.088] [G acc: 0.188]\n",
      "1520 [D loss: (0.599)(R 0.634, F 0.563)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.222] [G acc: 0.188]\n",
      "1521 [D loss: (0.519)(R 0.547, F 0.491)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.251] [G acc: 0.125]\n",
      "1522 [D loss: (0.583)(R 0.471, F 0.695)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.262] [G acc: 0.078]\n",
      "1523 [D loss: (0.570)(R 0.613, F 0.528)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.186] [G acc: 0.078]\n",
      "1524 [D loss: (0.560)(R 0.540, F 0.580)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.179] [G acc: 0.078]\n",
      "1525 [D loss: (0.519)(R 0.491, F 0.548)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.170] [G acc: 0.156]\n",
      "1526 [D loss: (0.542)(R 0.459, F 0.625)] [D acc: (0.734)(0.766, 0.703)] [G loss: 1.432] [G acc: 0.109]\n",
      "1527 [D loss: (0.603)(R 0.687, F 0.519)] [D acc: (0.664)(0.516, 0.812)] [G loss: 1.291] [G acc: 0.062]\n",
      "1528 [D loss: (0.496)(R 0.519, F 0.473)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.236] [G acc: 0.109]\n",
      "1529 [D loss: (0.484)(R 0.434, F 0.534)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.414] [G acc: 0.062]\n",
      "1530 [D loss: (0.562)(R 0.578, F 0.545)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.401] [G acc: 0.094]\n",
      "1531 [D loss: (0.485)(R 0.462, F 0.507)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.277] [G acc: 0.141]\n",
      "1532 [D loss: (0.564)(R 0.559, F 0.569)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.258] [G acc: 0.125]\n",
      "1533 [D loss: (0.529)(R 0.527, F 0.531)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.239] [G acc: 0.109]\n",
      "1534 [D loss: (0.551)(R 0.625, F 0.478)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.320] [G acc: 0.109]\n",
      "1535 [D loss: (0.579)(R 0.443, F 0.715)] [D acc: (0.711)(0.766, 0.656)] [G loss: 1.385] [G acc: 0.109]\n",
      "1536 [D loss: (0.562)(R 0.643, F 0.480)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.504] [G acc: 0.078]\n",
      "1537 [D loss: (0.627)(R 0.642, F 0.611)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.488] [G acc: 0.078]\n",
      "1538 [D loss: (0.470)(R 0.479, F 0.462)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.523] [G acc: 0.094]\n",
      "1539 [D loss: (0.559)(R 0.536, F 0.583)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.377] [G acc: 0.156]\n",
      "1540 [D loss: (0.587)(R 0.670, F 0.503)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.339] [G acc: 0.078]\n",
      "1541 [D loss: (0.498)(R 0.508, F 0.487)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.203] [G acc: 0.188]\n",
      "1542 [D loss: (0.575)(R 0.619, F 0.531)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.190] [G acc: 0.234]\n",
      "1543 [D loss: (0.471)(R 0.405, F 0.538)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.355] [G acc: 0.141]\n",
      "1544 [D loss: (0.685)(R 0.599, F 0.770)] [D acc: (0.609)(0.625, 0.594)] [G loss: 1.354] [G acc: 0.109]\n",
      "1545 [D loss: (0.554)(R 0.551, F 0.558)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.284] [G acc: 0.156]\n",
      "1546 [D loss: (0.568)(R 0.565, F 0.571)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.463] [G acc: 0.047]\n",
      "1547 [D loss: (0.626)(R 0.694, F 0.559)] [D acc: (0.625)(0.469, 0.781)] [G loss: 1.201] [G acc: 0.125]\n",
      "1548 [D loss: (0.578)(R 0.558, F 0.599)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.275] [G acc: 0.109]\n",
      "1549 [D loss: (0.535)(R 0.537, F 0.533)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.140] [G acc: 0.203]\n",
      "1550 [D loss: (0.474)(R 0.521, F 0.426)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.172] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1551 [D loss: (0.437)(R 0.351, F 0.524)] [D acc: (0.758)(0.812, 0.703)] [G loss: 1.314] [G acc: 0.172]\n",
      "1552 [D loss: (0.621)(R 0.651, F 0.591)] [D acc: (0.664)(0.547, 0.781)] [G loss: 1.382] [G acc: 0.109]\n",
      "1553 [D loss: (0.570)(R 0.537, F 0.603)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.408] [G acc: 0.078]\n",
      "1554 [D loss: (0.634)(R 0.630, F 0.637)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.333] [G acc: 0.047]\n",
      "1555 [D loss: (0.590)(R 0.707, F 0.472)] [D acc: (0.672)(0.500, 0.844)] [G loss: 1.259] [G acc: 0.109]\n",
      "1556 [D loss: (0.500)(R 0.511, F 0.490)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.264] [G acc: 0.172]\n",
      "1557 [D loss: (0.509)(R 0.447, F 0.570)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.361] [G acc: 0.188]\n",
      "1558 [D loss: (0.640)(R 0.641, F 0.639)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.360] [G acc: 0.062]\n",
      "1559 [D loss: (0.528)(R 0.607, F 0.448)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.218] [G acc: 0.141]\n",
      "1560 [D loss: (0.655)(R 0.671, F 0.639)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.137] [G acc: 0.172]\n",
      "1561 [D loss: (0.501)(R 0.548, F 0.454)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.171] [G acc: 0.156]\n",
      "1562 [D loss: (0.528)(R 0.464, F 0.591)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.308] [G acc: 0.109]\n",
      "1563 [D loss: (0.612)(R 0.561, F 0.662)] [D acc: (0.656)(0.672, 0.641)] [G loss: 1.389] [G acc: 0.109]\n",
      "1564 [D loss: (0.667)(R 0.752, F 0.582)] [D acc: (0.695)(0.531, 0.859)] [G loss: 1.295] [G acc: 0.047]\n",
      "1565 [D loss: (0.538)(R 0.559, F 0.516)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.290] [G acc: 0.109]\n",
      "1566 [D loss: (0.517)(R 0.504, F 0.529)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.227] [G acc: 0.188]\n",
      "1567 [D loss: (0.584)(R 0.557, F 0.611)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.362] [G acc: 0.094]\n",
      "1568 [D loss: (0.669)(R 0.511, F 0.826)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.291] [G acc: 0.109]\n",
      "1569 [D loss: (0.511)(R 0.542, F 0.481)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.239] [G acc: 0.078]\n",
      "1570 [D loss: (0.534)(R 0.585, F 0.483)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.316] [G acc: 0.141]\n",
      "1571 [D loss: (0.550)(R 0.525, F 0.575)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.180] [G acc: 0.141]\n",
      "1572 [D loss: (0.598)(R 0.591, F 0.604)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.191] [G acc: 0.172]\n",
      "1573 [D loss: (0.585)(R 0.553, F 0.617)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.261] [G acc: 0.156]\n",
      "1574 [D loss: (0.631)(R 0.726, F 0.536)] [D acc: (0.641)(0.484, 0.797)] [G loss: 1.277] [G acc: 0.156]\n",
      "1575 [D loss: (0.560)(R 0.517, F 0.603)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.139] [G acc: 0.172]\n",
      "1576 [D loss: (0.542)(R 0.576, F 0.509)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.265] [G acc: 0.109]\n",
      "1577 [D loss: (0.563)(R 0.504, F 0.622)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.198] [G acc: 0.109]\n",
      "1578 [D loss: (0.604)(R 0.668, F 0.540)] [D acc: (0.656)(0.531, 0.781)] [G loss: 1.105] [G acc: 0.109]\n",
      "1579 [D loss: (0.635)(R 0.622, F 0.649)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.217] [G acc: 0.078]\n",
      "1580 [D loss: (0.543)(R 0.520, F 0.566)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.242] [G acc: 0.109]\n",
      "1581 [D loss: (0.579)(R 0.529, F 0.628)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.297] [G acc: 0.031]\n",
      "1582 [D loss: (0.621)(R 0.651, F 0.591)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.181] [G acc: 0.109]\n",
      "1583 [D loss: (0.587)(R 0.626, F 0.549)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.149] [G acc: 0.172]\n",
      "1584 [D loss: (0.526)(R 0.481, F 0.571)] [D acc: (0.766)(0.781, 0.750)] [G loss: 1.184] [G acc: 0.156]\n",
      "1585 [D loss: (0.527)(R 0.503, F 0.551)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.214] [G acc: 0.094]\n",
      "1586 [D loss: (0.594)(R 0.528, F 0.659)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.323] [G acc: 0.062]\n",
      "1587 [D loss: (0.541)(R 0.606, F 0.475)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.277] [G acc: 0.141]\n",
      "1588 [D loss: (0.608)(R 0.483, F 0.732)] [D acc: (0.688)(0.719, 0.656)] [G loss: 1.387] [G acc: 0.141]\n",
      "1589 [D loss: (0.512)(R 0.533, F 0.490)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.331] [G acc: 0.062]\n",
      "1590 [D loss: (0.602)(R 0.609, F 0.596)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.272] [G acc: 0.172]\n",
      "1591 [D loss: (0.565)(R 0.578, F 0.552)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.337] [G acc: 0.062]\n",
      "1592 [D loss: (0.662)(R 0.737, F 0.586)] [D acc: (0.633)(0.500, 0.766)] [G loss: 1.404] [G acc: 0.031]\n",
      "1593 [D loss: (0.660)(R 0.783, F 0.537)] [D acc: (0.594)(0.422, 0.766)] [G loss: 1.222] [G acc: 0.109]\n",
      "1594 [D loss: (0.551)(R 0.600, F 0.502)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.345] [G acc: 0.125]\n",
      "1595 [D loss: (0.547)(R 0.504, F 0.589)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.255] [G acc: 0.125]\n",
      "1596 [D loss: (0.539)(R 0.500, F 0.579)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.254] [G acc: 0.078]\n",
      "1597 [D loss: (0.620)(R 0.669, F 0.570)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.179] [G acc: 0.094]\n",
      "1598 [D loss: (0.549)(R 0.540, F 0.558)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.169] [G acc: 0.188]\n",
      "1599 [D loss: (0.563)(R 0.550, F 0.576)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.201] [G acc: 0.125]\n",
      "1600 [D loss: (0.612)(R 0.615, F 0.608)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.216] [G acc: 0.141]\n",
      "1601 [D loss: (0.491)(R 0.517, F 0.464)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.432] [G acc: 0.078]\n",
      "1602 [D loss: (0.546)(R 0.525, F 0.566)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.276] [G acc: 0.156]\n",
      "1603 [D loss: (0.513)(R 0.579, F 0.447)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.340] [G acc: 0.078]\n",
      "1604 [D loss: (0.549)(R 0.530, F 0.568)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.340] [G acc: 0.125]\n",
      "1605 [D loss: (0.566)(R 0.515, F 0.616)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.308] [G acc: 0.141]\n",
      "1606 [D loss: (0.576)(R 0.487, F 0.664)] [D acc: (0.695)(0.766, 0.625)] [G loss: 1.321] [G acc: 0.031]\n",
      "1607 [D loss: (0.591)(R 0.636, F 0.545)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.274] [G acc: 0.094]\n",
      "1608 [D loss: (0.572)(R 0.541, F 0.602)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.290] [G acc: 0.125]\n",
      "1609 [D loss: (0.559)(R 0.552, F 0.566)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.264] [G acc: 0.109]\n",
      "1610 [D loss: (0.579)(R 0.670, F 0.488)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.250] [G acc: 0.094]\n",
      "1611 [D loss: (0.550)(R 0.514, F 0.587)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.243] [G acc: 0.062]\n",
      "1612 [D loss: (0.573)(R 0.567, F 0.579)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.422] [G acc: 0.078]\n",
      "1613 [D loss: (0.624)(R 0.743, F 0.505)] [D acc: (0.656)(0.484, 0.828)] [G loss: 1.415] [G acc: 0.125]\n",
      "1614 [D loss: (0.520)(R 0.506, F 0.534)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.113] [G acc: 0.234]\n",
      "1615 [D loss: (0.546)(R 0.475, F 0.616)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.150] [G acc: 0.156]\n",
      "1616 [D loss: (0.563)(R 0.649, F 0.477)] [D acc: (0.648)(0.547, 0.750)] [G loss: 1.123] [G acc: 0.141]\n",
      "1617 [D loss: (0.636)(R 0.609, F 0.663)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.190] [G acc: 0.094]\n",
      "1618 [D loss: (0.595)(R 0.654, F 0.536)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.206] [G acc: 0.156]\n",
      "1619 [D loss: (0.500)(R 0.483, F 0.518)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.352] [G acc: 0.078]\n",
      "1620 [D loss: (0.573)(R 0.552, F 0.594)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.203] [G acc: 0.172]\n",
      "1621 [D loss: (0.640)(R 0.711, F 0.568)] [D acc: (0.617)(0.516, 0.719)] [G loss: 1.248] [G acc: 0.156]\n",
      "1622 [D loss: (0.540)(R 0.583, F 0.498)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.189] [G acc: 0.172]\n",
      "1623 [D loss: (0.636)(R 0.697, F 0.574)] [D acc: (0.609)(0.531, 0.688)] [G loss: 1.296] [G acc: 0.078]\n",
      "1624 [D loss: (0.487)(R 0.485, F 0.489)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.300] [G acc: 0.078]\n",
      "1625 [D loss: (0.544)(R 0.441, F 0.648)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.361] [G acc: 0.062]\n",
      "1626 [D loss: (0.570)(R 0.574, F 0.566)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.361] [G acc: 0.109]\n",
      "1627 [D loss: (0.646)(R 0.609, F 0.684)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.368] [G acc: 0.078]\n",
      "1628 [D loss: (0.592)(R 0.634, F 0.549)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.228] [G acc: 0.141]\n",
      "1629 [D loss: (0.557)(R 0.579, F 0.536)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.377] [G acc: 0.125]\n",
      "1630 [D loss: (0.532)(R 0.429, F 0.635)] [D acc: (0.742)(0.797, 0.688)] [G loss: 1.342] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1631 [D loss: (0.515)(R 0.536, F 0.494)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.343] [G acc: 0.094]\n",
      "1632 [D loss: (0.684)(R 0.645, F 0.723)] [D acc: (0.617)(0.594, 0.641)] [G loss: 1.265] [G acc: 0.109]\n",
      "1633 [D loss: (0.626)(R 0.689, F 0.563)] [D acc: (0.609)(0.516, 0.703)] [G loss: 1.126] [G acc: 0.172]\n",
      "1634 [D loss: (0.597)(R 0.618, F 0.575)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.043] [G acc: 0.203]\n",
      "1635 [D loss: (0.590)(R 0.596, F 0.584)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.169] [G acc: 0.094]\n",
      "1636 [D loss: (0.558)(R 0.515, F 0.601)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.231] [G acc: 0.094]\n",
      "1637 [D loss: (0.586)(R 0.536, F 0.636)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.233] [G acc: 0.094]\n",
      "1638 [D loss: (0.624)(R 0.616, F 0.632)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.154] [G acc: 0.109]\n",
      "1639 [D loss: (0.618)(R 0.650, F 0.587)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.257] [G acc: 0.062]\n",
      "1640 [D loss: (0.496)(R 0.511, F 0.481)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.214] [G acc: 0.125]\n",
      "1641 [D loss: (0.637)(R 0.581, F 0.692)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.121] [G acc: 0.141]\n",
      "1642 [D loss: (0.574)(R 0.576, F 0.573)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.134] [G acc: 0.125]\n",
      "1643 [D loss: (0.503)(R 0.452, F 0.554)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.327] [G acc: 0.125]\n",
      "1644 [D loss: (0.561)(R 0.511, F 0.610)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.219] [G acc: 0.188]\n",
      "1645 [D loss: (0.630)(R 0.634, F 0.627)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.238] [G acc: 0.125]\n",
      "1646 [D loss: (0.666)(R 0.747, F 0.586)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.032] [G acc: 0.188]\n",
      "1647 [D loss: (0.499)(R 0.521, F 0.476)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.327] [G acc: 0.188]\n",
      "1648 [D loss: (0.536)(R 0.458, F 0.613)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.322] [G acc: 0.094]\n",
      "1649 [D loss: (0.534)(R 0.595, F 0.472)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.224] [G acc: 0.234]\n",
      "1650 [D loss: (0.671)(R 0.553, F 0.789)] [D acc: (0.672)(0.688, 0.656)] [G loss: 1.304] [G acc: 0.062]\n",
      "1651 [D loss: (0.625)(R 0.677, F 0.573)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.219] [G acc: 0.047]\n",
      "1652 [D loss: (0.533)(R 0.558, F 0.508)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.220] [G acc: 0.156]\n",
      "1653 [D loss: (0.543)(R 0.538, F 0.548)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.297] [G acc: 0.109]\n",
      "1654 [D loss: (0.600)(R 0.570, F 0.629)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.150] [G acc: 0.125]\n",
      "1655 [D loss: (0.683)(R 0.734, F 0.631)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.242] [G acc: 0.094]\n",
      "1656 [D loss: (0.601)(R 0.575, F 0.627)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.161] [G acc: 0.156]\n",
      "1657 [D loss: (0.549)(R 0.566, F 0.533)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.299] [G acc: 0.125]\n",
      "1658 [D loss: (0.543)(R 0.566, F 0.521)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.256] [G acc: 0.188]\n",
      "1659 [D loss: (0.511)(R 0.507, F 0.515)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.276] [G acc: 0.156]\n",
      "1660 [D loss: (0.542)(R 0.483, F 0.600)] [D acc: (0.750)(0.781, 0.719)] [G loss: 1.252] [G acc: 0.062]\n",
      "1661 [D loss: (0.640)(R 0.676, F 0.605)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.327] [G acc: 0.062]\n",
      "1662 [D loss: (0.660)(R 0.797, F 0.523)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.324] [G acc: 0.062]\n",
      "1663 [D loss: (0.596)(R 0.587, F 0.606)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.148] [G acc: 0.156]\n",
      "1664 [D loss: (0.554)(R 0.557, F 0.551)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.225] [G acc: 0.125]\n",
      "1665 [D loss: (0.559)(R 0.578, F 0.540)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.159] [G acc: 0.156]\n",
      "1666 [D loss: (0.532)(R 0.519, F 0.546)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.284] [G acc: 0.141]\n",
      "1667 [D loss: (0.563)(R 0.572, F 0.553)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.309] [G acc: 0.062]\n",
      "1668 [D loss: (0.656)(R 0.631, F 0.681)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.314] [G acc: 0.047]\n",
      "1669 [D loss: (0.584)(R 0.523, F 0.645)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.433] [G acc: 0.078]\n",
      "1670 [D loss: (0.513)(R 0.528, F 0.498)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.235] [G acc: 0.109]\n",
      "1671 [D loss: (0.618)(R 0.673, F 0.564)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.177] [G acc: 0.109]\n",
      "1672 [D loss: (0.604)(R 0.686, F 0.522)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.268] [G acc: 0.141]\n",
      "1673 [D loss: (0.671)(R 0.636, F 0.706)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.110] [G acc: 0.047]\n",
      "1674 [D loss: (0.601)(R 0.597, F 0.605)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.134] [G acc: 0.203]\n",
      "1675 [D loss: (0.510)(R 0.497, F 0.522)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.234] [G acc: 0.109]\n",
      "1676 [D loss: (0.583)(R 0.590, F 0.576)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.193] [G acc: 0.172]\n",
      "1677 [D loss: (0.481)(R 0.442, F 0.520)] [D acc: (0.789)(0.797, 0.781)] [G loss: 1.312] [G acc: 0.141]\n",
      "1678 [D loss: (0.533)(R 0.542, F 0.524)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.448] [G acc: 0.062]\n",
      "1679 [D loss: (0.540)(R 0.579, F 0.501)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.320] [G acc: 0.094]\n",
      "1680 [D loss: (0.553)(R 0.551, F 0.555)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.372] [G acc: 0.125]\n",
      "1681 [D loss: (0.596)(R 0.545, F 0.647)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.284] [G acc: 0.125]\n",
      "1682 [D loss: (0.494)(R 0.459, F 0.528)] [D acc: (0.742)(0.781, 0.703)] [G loss: 1.391] [G acc: 0.156]\n",
      "1683 [D loss: (0.647)(R 0.617, F 0.678)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.227] [G acc: 0.125]\n",
      "1684 [D loss: (0.598)(R 0.656, F 0.540)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.127] [G acc: 0.234]\n",
      "1685 [D loss: (0.533)(R 0.569, F 0.497)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.154] [G acc: 0.188]\n",
      "1686 [D loss: (0.563)(R 0.572, F 0.553)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.300] [G acc: 0.094]\n",
      "1687 [D loss: (0.561)(R 0.495, F 0.627)] [D acc: (0.680)(0.688, 0.672)] [G loss: 1.340] [G acc: 0.125]\n",
      "1688 [D loss: (0.617)(R 0.577, F 0.657)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.082] [G acc: 0.156]\n",
      "1689 [D loss: (0.522)(R 0.558, F 0.486)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.257] [G acc: 0.125]\n",
      "1690 [D loss: (0.660)(R 0.704, F 0.616)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.211] [G acc: 0.109]\n",
      "1691 [D loss: (0.573)(R 0.579, F 0.568)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.226] [G acc: 0.141]\n",
      "1692 [D loss: (0.590)(R 0.521, F 0.659)] [D acc: (0.703)(0.734, 0.672)] [G loss: 1.252] [G acc: 0.094]\n",
      "1693 [D loss: (0.601)(R 0.648, F 0.554)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.249] [G acc: 0.094]\n",
      "1694 [D loss: (0.578)(R 0.599, F 0.558)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.098] [G acc: 0.188]\n",
      "1695 [D loss: (0.596)(R 0.540, F 0.652)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.279] [G acc: 0.062]\n",
      "1696 [D loss: (0.507)(R 0.469, F 0.544)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.621] [G acc: 0.031]\n",
      "1697 [D loss: (0.598)(R 0.657, F 0.538)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.159] [G acc: 0.125]\n",
      "1698 [D loss: (0.552)(R 0.577, F 0.528)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.493] [G acc: 0.094]\n",
      "1699 [D loss: (0.554)(R 0.545, F 0.563)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.407] [G acc: 0.094]\n",
      "1700 [D loss: (0.656)(R 0.706, F 0.607)] [D acc: (0.602)(0.516, 0.688)] [G loss: 1.140] [G acc: 0.141]\n",
      "1701 [D loss: (0.574)(R 0.644, F 0.505)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.215] [G acc: 0.156]\n",
      "1702 [D loss: (0.591)(R 0.547, F 0.636)] [D acc: (0.664)(0.734, 0.594)] [G loss: 1.238] [G acc: 0.141]\n",
      "1703 [D loss: (0.556)(R 0.593, F 0.519)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.172] [G acc: 0.141]\n",
      "1704 [D loss: (0.559)(R 0.548, F 0.570)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.290] [G acc: 0.188]\n",
      "1705 [D loss: (0.520)(R 0.531, F 0.510)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.299] [G acc: 0.203]\n",
      "1706 [D loss: (0.553)(R 0.568, F 0.537)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.290] [G acc: 0.156]\n",
      "1707 [D loss: (0.515)(R 0.548, F 0.483)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.277] [G acc: 0.125]\n",
      "1708 [D loss: (0.551)(R 0.551, F 0.550)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.203] [G acc: 0.141]\n",
      "1709 [D loss: (0.596)(R 0.583, F 0.608)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.311] [G acc: 0.109]\n",
      "1710 [D loss: (0.518)(R 0.524, F 0.513)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.210] [G acc: 0.266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1711 [D loss: (0.609)(R 0.535, F 0.683)] [D acc: (0.648)(0.703, 0.594)] [G loss: 1.378] [G acc: 0.109]\n",
      "1712 [D loss: (0.581)(R 0.622, F 0.541)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.320] [G acc: 0.141]\n",
      "1713 [D loss: (0.567)(R 0.631, F 0.503)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.345] [G acc: 0.109]\n",
      "1714 [D loss: (0.493)(R 0.522, F 0.465)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.339] [G acc: 0.094]\n",
      "1715 [D loss: (0.557)(R 0.536, F 0.578)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.385] [G acc: 0.078]\n",
      "1716 [D loss: (0.554)(R 0.587, F 0.521)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.439] [G acc: 0.109]\n",
      "1717 [D loss: (0.657)(R 0.668, F 0.646)] [D acc: (0.586)(0.547, 0.625)] [G loss: 1.362] [G acc: 0.078]\n",
      "1718 [D loss: (0.546)(R 0.611, F 0.481)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.245] [G acc: 0.109]\n",
      "1719 [D loss: (0.661)(R 0.660, F 0.662)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.222] [G acc: 0.094]\n",
      "1720 [D loss: (0.557)(R 0.532, F 0.582)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.171] [G acc: 0.219]\n",
      "1721 [D loss: (0.563)(R 0.586, F 0.540)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.147] [G acc: 0.188]\n",
      "1722 [D loss: (0.616)(R 0.533, F 0.698)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.315] [G acc: 0.141]\n",
      "1723 [D loss: (0.572)(R 0.595, F 0.548)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.225] [G acc: 0.219]\n",
      "1724 [D loss: (0.653)(R 0.622, F 0.684)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.227] [G acc: 0.141]\n",
      "1725 [D loss: (0.583)(R 0.577, F 0.589)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.227] [G acc: 0.109]\n",
      "1726 [D loss: (0.583)(R 0.606, F 0.561)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.194] [G acc: 0.109]\n",
      "1727 [D loss: (0.560)(R 0.629, F 0.491)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.244] [G acc: 0.078]\n",
      "1728 [D loss: (0.585)(R 0.579, F 0.592)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.387] [G acc: 0.047]\n",
      "1729 [D loss: (0.601)(R 0.771, F 0.430)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.203] [G acc: 0.188]\n",
      "1730 [D loss: (0.552)(R 0.524, F 0.580)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.187] [G acc: 0.156]\n",
      "1731 [D loss: (0.555)(R 0.556, F 0.554)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.211] [G acc: 0.219]\n",
      "1732 [D loss: (0.588)(R 0.558, F 0.618)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.257] [G acc: 0.141]\n",
      "1733 [D loss: (0.604)(R 0.515, F 0.692)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.250] [G acc: 0.156]\n",
      "1734 [D loss: (0.482)(R 0.518, F 0.447)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.419] [G acc: 0.031]\n",
      "1735 [D loss: (0.632)(R 0.478, F 0.786)] [D acc: (0.703)(0.750, 0.656)] [G loss: 1.324] [G acc: 0.062]\n",
      "1736 [D loss: (0.615)(R 0.734, F 0.496)] [D acc: (0.594)(0.453, 0.734)] [G loss: 1.402] [G acc: 0.109]\n",
      "1737 [D loss: (0.593)(R 0.612, F 0.575)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.312] [G acc: 0.094]\n",
      "1738 [D loss: (0.512)(R 0.553, F 0.470)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.189] [G acc: 0.188]\n",
      "1739 [D loss: (0.544)(R 0.457, F 0.631)] [D acc: (0.703)(0.766, 0.641)] [G loss: 1.311] [G acc: 0.109]\n",
      "1740 [D loss: (0.626)(R 0.757, F 0.494)] [D acc: (0.680)(0.516, 0.844)] [G loss: 1.234] [G acc: 0.156]\n",
      "1741 [D loss: (0.562)(R 0.562, F 0.562)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.267] [G acc: 0.156]\n",
      "1742 [D loss: (0.647)(R 0.503, F 0.792)] [D acc: (0.602)(0.672, 0.531)] [G loss: 1.300] [G acc: 0.094]\n",
      "1743 [D loss: (0.551)(R 0.632, F 0.471)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.184] [G acc: 0.141]\n",
      "1744 [D loss: (0.506)(R 0.491, F 0.521)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.293] [G acc: 0.156]\n",
      "1745 [D loss: (0.570)(R 0.610, F 0.529)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.173] [G acc: 0.156]\n",
      "1746 [D loss: (0.523)(R 0.488, F 0.557)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.297] [G acc: 0.156]\n",
      "1747 [D loss: (0.616)(R 0.708, F 0.523)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.297] [G acc: 0.078]\n",
      "1748 [D loss: (0.655)(R 0.630, F 0.680)] [D acc: (0.617)(0.578, 0.656)] [G loss: 1.232] [G acc: 0.156]\n",
      "1749 [D loss: (0.556)(R 0.618, F 0.493)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.437] [G acc: 0.094]\n",
      "1750 [D loss: (0.634)(R 0.610, F 0.658)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.282] [G acc: 0.094]\n",
      "1751 [D loss: (0.566)(R 0.524, F 0.608)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.376] [G acc: 0.031]\n",
      "1752 [D loss: (0.619)(R 0.695, F 0.543)] [D acc: (0.609)(0.516, 0.703)] [G loss: 1.303] [G acc: 0.094]\n",
      "1753 [D loss: (0.583)(R 0.590, F 0.575)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.334] [G acc: 0.078]\n",
      "1754 [D loss: (0.506)(R 0.496, F 0.516)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.190] [G acc: 0.203]\n",
      "1755 [D loss: (0.575)(R 0.556, F 0.595)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.188] [G acc: 0.125]\n",
      "1756 [D loss: (0.576)(R 0.556, F 0.595)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.284] [G acc: 0.156]\n",
      "1757 [D loss: (0.536)(R 0.530, F 0.541)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.332] [G acc: 0.078]\n",
      "1758 [D loss: (0.593)(R 0.629, F 0.556)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.329] [G acc: 0.156]\n",
      "1759 [D loss: (0.581)(R 0.636, F 0.526)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.362] [G acc: 0.156]\n",
      "1760 [D loss: (0.524)(R 0.570, F 0.477)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.260] [G acc: 0.047]\n",
      "1761 [D loss: (0.588)(R 0.569, F 0.606)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.341] [G acc: 0.125]\n",
      "1762 [D loss: (0.504)(R 0.537, F 0.470)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.214] [G acc: 0.172]\n",
      "1763 [D loss: (0.464)(R 0.366, F 0.563)] [D acc: (0.781)(0.828, 0.734)] [G loss: 1.424] [G acc: 0.094]\n",
      "1764 [D loss: (0.548)(R 0.517, F 0.578)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.326] [G acc: 0.141]\n",
      "1765 [D loss: (0.592)(R 0.596, F 0.588)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.328] [G acc: 0.094]\n",
      "1766 [D loss: (0.540)(R 0.546, F 0.534)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.399] [G acc: 0.141]\n",
      "1767 [D loss: (0.571)(R 0.525, F 0.617)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.283] [G acc: 0.188]\n",
      "1768 [D loss: (0.553)(R 0.513, F 0.593)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.225] [G acc: 0.203]\n",
      "1769 [D loss: (0.598)(R 0.579, F 0.618)] [D acc: (0.641)(0.656, 0.625)] [G loss: 1.262] [G acc: 0.109]\n",
      "1770 [D loss: (0.510)(R 0.581, F 0.439)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.282] [G acc: 0.094]\n",
      "1771 [D loss: (0.493)(R 0.451, F 0.534)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.392] [G acc: 0.125]\n",
      "1772 [D loss: (0.554)(R 0.522, F 0.586)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.380] [G acc: 0.062]\n",
      "1773 [D loss: (0.608)(R 0.567, F 0.649)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.353] [G acc: 0.094]\n",
      "1774 [D loss: (0.599)(R 0.666, F 0.532)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.233] [G acc: 0.109]\n",
      "1775 [D loss: (0.611)(R 0.593, F 0.628)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.259] [G acc: 0.125]\n",
      "1776 [D loss: (0.588)(R 0.662, F 0.515)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.227] [G acc: 0.219]\n",
      "1777 [D loss: (0.551)(R 0.540, F 0.563)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.108] [G acc: 0.141]\n",
      "1778 [D loss: (0.618)(R 0.666, F 0.570)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.239] [G acc: 0.219]\n",
      "1779 [D loss: (0.587)(R 0.612, F 0.563)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.285] [G acc: 0.094]\n",
      "1780 [D loss: (0.548)(R 0.517, F 0.580)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.229] [G acc: 0.141]\n",
      "1781 [D loss: (0.589)(R 0.614, F 0.564)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.264] [G acc: 0.125]\n",
      "1782 [D loss: (0.546)(R 0.594, F 0.498)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.271] [G acc: 0.062]\n",
      "1783 [D loss: (0.631)(R 0.705, F 0.558)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.210] [G acc: 0.141]\n",
      "1784 [D loss: (0.532)(R 0.554, F 0.510)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.260] [G acc: 0.156]\n",
      "1785 [D loss: (0.565)(R 0.571, F 0.559)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.242] [G acc: 0.172]\n",
      "1786 [D loss: (0.526)(R 0.583, F 0.468)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.162] [G acc: 0.250]\n",
      "1787 [D loss: (0.662)(R 0.674, F 0.650)] [D acc: (0.625)(0.641, 0.609)] [G loss: 1.258] [G acc: 0.172]\n",
      "1788 [D loss: (0.642)(R 0.541, F 0.742)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.220] [G acc: 0.156]\n",
      "1789 [D loss: (0.545)(R 0.659, F 0.431)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.217] [G acc: 0.172]\n",
      "1790 [D loss: (0.509)(R 0.428, F 0.591)] [D acc: (0.758)(0.797, 0.719)] [G loss: 1.322] [G acc: 0.156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791 [D loss: (0.579)(R 0.580, F 0.578)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.281] [G acc: 0.156]\n",
      "1792 [D loss: (0.687)(R 0.673, F 0.700)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.212] [G acc: 0.141]\n",
      "1793 [D loss: (0.608)(R 0.630, F 0.587)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.278] [G acc: 0.125]\n",
      "1794 [D loss: (0.498)(R 0.497, F 0.499)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.360] [G acc: 0.062]\n",
      "1795 [D loss: (0.505)(R 0.491, F 0.519)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.364] [G acc: 0.094]\n",
      "1796 [D loss: (0.592)(R 0.524, F 0.660)] [D acc: (0.680)(0.703, 0.656)] [G loss: 1.275] [G acc: 0.109]\n",
      "1797 [D loss: (0.585)(R 0.625, F 0.546)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.339] [G acc: 0.062]\n",
      "1798 [D loss: (0.550)(R 0.634, F 0.465)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.260] [G acc: 0.125]\n",
      "1799 [D loss: (0.578)(R 0.563, F 0.593)] [D acc: (0.680)(0.688, 0.672)] [G loss: 1.234] [G acc: 0.172]\n",
      "1800 [D loss: (0.520)(R 0.469, F 0.571)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.262] [G acc: 0.109]\n",
      "1801 [D loss: (0.526)(R 0.497, F 0.556)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.314] [G acc: 0.109]\n",
      "1802 [D loss: (0.607)(R 0.502, F 0.713)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.437] [G acc: 0.141]\n",
      "1803 [D loss: (0.540)(R 0.436, F 0.644)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.370] [G acc: 0.109]\n",
      "1804 [D loss: (0.539)(R 0.556, F 0.521)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.341] [G acc: 0.141]\n",
      "1805 [D loss: (0.577)(R 0.625, F 0.529)] [D acc: (0.648)(0.547, 0.750)] [G loss: 1.278] [G acc: 0.125]\n",
      "1806 [D loss: (0.537)(R 0.459, F 0.616)] [D acc: (0.734)(0.766, 0.703)] [G loss: 1.304] [G acc: 0.141]\n",
      "1807 [D loss: (0.563)(R 0.587, F 0.540)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.312] [G acc: 0.141]\n",
      "1808 [D loss: (0.499)(R 0.547, F 0.451)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.270] [G acc: 0.188]\n",
      "1809 [D loss: (0.523)(R 0.495, F 0.552)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.306] [G acc: 0.156]\n",
      "1810 [D loss: (0.504)(R 0.488, F 0.519)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.300] [G acc: 0.156]\n",
      "1811 [D loss: (0.544)(R 0.562, F 0.526)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.300] [G acc: 0.188]\n",
      "1812 [D loss: (0.650)(R 0.570, F 0.730)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.395] [G acc: 0.141]\n",
      "1813 [D loss: (0.593)(R 0.627, F 0.559)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.185] [G acc: 0.172]\n",
      "1814 [D loss: (0.600)(R 0.608, F 0.592)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.304] [G acc: 0.094]\n",
      "1815 [D loss: (0.540)(R 0.592, F 0.487)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.369] [G acc: 0.125]\n",
      "1816 [D loss: (0.535)(R 0.562, F 0.508)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.192] [G acc: 0.125]\n",
      "1817 [D loss: (0.622)(R 0.553, F 0.691)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.312] [G acc: 0.109]\n",
      "1818 [D loss: (0.663)(R 0.786, F 0.541)] [D acc: (0.617)(0.453, 0.781)] [G loss: 1.194] [G acc: 0.094]\n",
      "1819 [D loss: (0.603)(R 0.645, F 0.560)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.167] [G acc: 0.156]\n",
      "1820 [D loss: (0.592)(R 0.579, F 0.605)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.238] [G acc: 0.094]\n",
      "1821 [D loss: (0.568)(R 0.526, F 0.611)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.188] [G acc: 0.172]\n",
      "1822 [D loss: (0.581)(R 0.549, F 0.613)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.210] [G acc: 0.109]\n",
      "1823 [D loss: (0.504)(R 0.529, F 0.478)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.244] [G acc: 0.172]\n",
      "1824 [D loss: (0.576)(R 0.533, F 0.618)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.435] [G acc: 0.141]\n",
      "1825 [D loss: (0.555)(R 0.544, F 0.566)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.242] [G acc: 0.078]\n",
      "1826 [D loss: (0.572)(R 0.521, F 0.623)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.489] [G acc: 0.094]\n",
      "1827 [D loss: (0.486)(R 0.511, F 0.461)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.424] [G acc: 0.109]\n",
      "1828 [D loss: (0.455)(R 0.433, F 0.476)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.265] [G acc: 0.094]\n",
      "1829 [D loss: (0.579)(R 0.604, F 0.554)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.314] [G acc: 0.109]\n",
      "1830 [D loss: (0.536)(R 0.554, F 0.517)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.403] [G acc: 0.125]\n",
      "1831 [D loss: (0.521)(R 0.524, F 0.518)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.366] [G acc: 0.078]\n",
      "1832 [D loss: (0.515)(R 0.453, F 0.576)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.404] [G acc: 0.062]\n",
      "1833 [D loss: (0.667)(R 0.647, F 0.688)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.304] [G acc: 0.125]\n",
      "1834 [D loss: (0.590)(R 0.641, F 0.538)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.498] [G acc: 0.047]\n",
      "1835 [D loss: (0.706)(R 0.706, F 0.706)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.292] [G acc: 0.094]\n",
      "1836 [D loss: (0.657)(R 0.807, F 0.507)] [D acc: (0.641)(0.484, 0.797)] [G loss: 1.291] [G acc: 0.062]\n",
      "1837 [D loss: (0.553)(R 0.502, F 0.604)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.292] [G acc: 0.078]\n",
      "1838 [D loss: (0.571)(R 0.559, F 0.582)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.377] [G acc: 0.094]\n",
      "1839 [D loss: (0.531)(R 0.650, F 0.413)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.285] [G acc: 0.125]\n",
      "1840 [D loss: (0.551)(R 0.576, F 0.526)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.262] [G acc: 0.172]\n",
      "1841 [D loss: (0.541)(R 0.538, F 0.544)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.308] [G acc: 0.078]\n",
      "1842 [D loss: (0.510)(R 0.493, F 0.526)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.287] [G acc: 0.141]\n",
      "1843 [D loss: (0.628)(R 0.700, F 0.556)] [D acc: (0.625)(0.531, 0.719)] [G loss: 1.207] [G acc: 0.109]\n",
      "1844 [D loss: (0.566)(R 0.640, F 0.492)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.094] [G acc: 0.203]\n",
      "1845 [D loss: (0.616)(R 0.490, F 0.742)] [D acc: (0.688)(0.719, 0.656)] [G loss: 1.256] [G acc: 0.109]\n",
      "1846 [D loss: (0.570)(R 0.672, F 0.469)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.230] [G acc: 0.125]\n",
      "1847 [D loss: (0.584)(R 0.598, F 0.571)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.287] [G acc: 0.109]\n",
      "1848 [D loss: (0.541)(R 0.619, F 0.462)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.367] [G acc: 0.156]\n",
      "1849 [D loss: (0.586)(R 0.535, F 0.637)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.337] [G acc: 0.141]\n",
      "1850 [D loss: (0.506)(R 0.567, F 0.445)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.303] [G acc: 0.141]\n",
      "1851 [D loss: (0.590)(R 0.591, F 0.590)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.302] [G acc: 0.141]\n",
      "1852 [D loss: (0.532)(R 0.552, F 0.513)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.138] [G acc: 0.188]\n",
      "1853 [D loss: (0.604)(R 0.514, F 0.695)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.227] [G acc: 0.188]\n",
      "1854 [D loss: (0.555)(R 0.593, F 0.518)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.443] [G acc: 0.109]\n",
      "1855 [D loss: (0.615)(R 0.617, F 0.612)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.302] [G acc: 0.078]\n",
      "1856 [D loss: (0.601)(R 0.567, F 0.635)] [D acc: (0.656)(0.672, 0.641)] [G loss: 1.223] [G acc: 0.109]\n",
      "1857 [D loss: (0.601)(R 0.629, F 0.572)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.238] [G acc: 0.125]\n",
      "1858 [D loss: (0.609)(R 0.585, F 0.633)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.161] [G acc: 0.156]\n",
      "1859 [D loss: (0.612)(R 0.632, F 0.591)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.193] [G acc: 0.109]\n",
      "1860 [D loss: (0.557)(R 0.562, F 0.551)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.119] [G acc: 0.219]\n",
      "1861 [D loss: (0.589)(R 0.544, F 0.633)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.244] [G acc: 0.094]\n",
      "1862 [D loss: (0.583)(R 0.574, F 0.592)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.245] [G acc: 0.109]\n",
      "1863 [D loss: (0.518)(R 0.537, F 0.499)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.208] [G acc: 0.234]\n",
      "1864 [D loss: (0.467)(R 0.425, F 0.510)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.346] [G acc: 0.125]\n",
      "1865 [D loss: (0.522)(R 0.477, F 0.568)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.304] [G acc: 0.109]\n",
      "1866 [D loss: (0.525)(R 0.515, F 0.535)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.398] [G acc: 0.094]\n",
      "1867 [D loss: (0.516)(R 0.521, F 0.511)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.335] [G acc: 0.062]\n",
      "1868 [D loss: (0.488)(R 0.509, F 0.467)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.503] [G acc: 0.094]\n",
      "1869 [D loss: (0.622)(R 0.528, F 0.715)] [D acc: (0.641)(0.656, 0.625)] [G loss: 1.318] [G acc: 0.031]\n",
      "1870 [D loss: (0.551)(R 0.630, F 0.473)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.340] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1871 [D loss: (0.618)(R 0.629, F 0.608)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.262] [G acc: 0.109]\n",
      "1872 [D loss: (0.585)(R 0.579, F 0.591)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.440] [G acc: 0.062]\n",
      "1873 [D loss: (0.615)(R 0.637, F 0.592)] [D acc: (0.625)(0.531, 0.719)] [G loss: 1.187] [G acc: 0.109]\n",
      "1874 [D loss: (0.505)(R 0.468, F 0.541)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.328] [G acc: 0.094]\n",
      "1875 [D loss: (0.520)(R 0.460, F 0.579)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.263] [G acc: 0.156]\n",
      "1876 [D loss: (0.621)(R 0.737, F 0.504)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.378] [G acc: 0.078]\n",
      "1877 [D loss: (0.527)(R 0.476, F 0.577)] [D acc: (0.773)(0.812, 0.734)] [G loss: 1.319] [G acc: 0.125]\n",
      "1878 [D loss: (0.542)(R 0.487, F 0.597)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.333] [G acc: 0.156]\n",
      "1879 [D loss: (0.586)(R 0.629, F 0.543)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.173] [G acc: 0.203]\n",
      "1880 [D loss: (0.592)(R 0.558, F 0.627)] [D acc: (0.688)(0.719, 0.656)] [G loss: 1.336] [G acc: 0.125]\n",
      "1881 [D loss: (0.523)(R 0.585, F 0.462)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.199] [G acc: 0.156]\n",
      "1882 [D loss: (0.546)(R 0.502, F 0.590)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.211] [G acc: 0.188]\n",
      "1883 [D loss: (0.590)(R 0.685, F 0.495)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.365] [G acc: 0.094]\n",
      "1884 [D loss: (0.504)(R 0.486, F 0.521)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.388] [G acc: 0.219]\n",
      "1885 [D loss: (0.617)(R 0.600, F 0.634)] [D acc: (0.680)(0.688, 0.672)] [G loss: 1.389] [G acc: 0.109]\n",
      "1886 [D loss: (0.657)(R 0.659, F 0.655)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.353] [G acc: 0.141]\n",
      "1887 [D loss: (0.556)(R 0.543, F 0.570)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.372] [G acc: 0.141]\n",
      "1888 [D loss: (0.514)(R 0.578, F 0.450)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.349] [G acc: 0.172]\n",
      "1889 [D loss: (0.469)(R 0.447, F 0.491)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.392] [G acc: 0.125]\n",
      "1890 [D loss: (0.474)(R 0.515, F 0.434)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.430] [G acc: 0.188]\n",
      "1891 [D loss: (0.453)(R 0.389, F 0.518)] [D acc: (0.805)(0.828, 0.781)] [G loss: 1.604] [G acc: 0.094]\n",
      "1892 [D loss: (0.531)(R 0.555, F 0.508)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.472] [G acc: 0.125]\n",
      "1893 [D loss: (0.593)(R 0.528, F 0.658)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.346] [G acc: 0.172]\n",
      "1894 [D loss: (0.540)(R 0.572, F 0.507)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.386] [G acc: 0.141]\n",
      "1895 [D loss: (0.559)(R 0.688, F 0.430)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.319] [G acc: 0.109]\n",
      "1896 [D loss: (0.624)(R 0.607, F 0.641)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.285] [G acc: 0.125]\n",
      "1897 [D loss: (0.516)(R 0.529, F 0.502)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.160] [G acc: 0.219]\n",
      "1898 [D loss: (0.606)(R 0.627, F 0.585)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.406] [G acc: 0.078]\n",
      "1899 [D loss: (0.535)(R 0.566, F 0.504)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.288] [G acc: 0.094]\n",
      "1900 [D loss: (0.601)(R 0.605, F 0.597)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.254] [G acc: 0.109]\n",
      "1901 [D loss: (0.518)(R 0.557, F 0.479)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.309] [G acc: 0.094]\n",
      "1902 [D loss: (0.507)(R 0.459, F 0.555)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.385] [G acc: 0.141]\n",
      "1903 [D loss: (0.575)(R 0.585, F 0.564)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.416] [G acc: 0.125]\n",
      "1904 [D loss: (0.569)(R 0.598, F 0.539)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.227] [G acc: 0.141]\n",
      "1905 [D loss: (0.551)(R 0.514, F 0.589)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.466] [G acc: 0.047]\n",
      "1906 [D loss: (0.543)(R 0.519, F 0.568)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.375] [G acc: 0.156]\n",
      "1907 [D loss: (0.571)(R 0.603, F 0.539)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.335] [G acc: 0.125]\n",
      "1908 [D loss: (0.557)(R 0.593, F 0.522)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.346] [G acc: 0.125]\n",
      "1909 [D loss: (0.538)(R 0.553, F 0.522)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.301] [G acc: 0.141]\n",
      "1910 [D loss: (0.574)(R 0.560, F 0.589)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.433] [G acc: 0.078]\n",
      "1911 [D loss: (0.573)(R 0.641, F 0.505)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.298] [G acc: 0.109]\n",
      "1912 [D loss: (0.504)(R 0.484, F 0.524)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.413] [G acc: 0.094]\n",
      "1913 [D loss: (0.495)(R 0.486, F 0.504)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.393] [G acc: 0.203]\n",
      "1914 [D loss: (0.604)(R 0.625, F 0.583)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.279] [G acc: 0.078]\n",
      "1915 [D loss: (0.615)(R 0.568, F 0.662)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.321] [G acc: 0.141]\n",
      "1916 [D loss: (0.636)(R 0.633, F 0.639)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.215] [G acc: 0.094]\n",
      "1917 [D loss: (0.576)(R 0.525, F 0.626)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.365] [G acc: 0.125]\n",
      "1918 [D loss: (0.542)(R 0.591, F 0.493)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.362] [G acc: 0.109]\n",
      "1919 [D loss: (0.622)(R 0.619, F 0.625)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.309] [G acc: 0.141]\n",
      "1920 [D loss: (0.541)(R 0.471, F 0.612)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.396] [G acc: 0.125]\n",
      "1921 [D loss: (0.595)(R 0.510, F 0.679)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.320] [G acc: 0.156]\n",
      "1922 [D loss: (0.553)(R 0.658, F 0.448)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.313] [G acc: 0.141]\n",
      "1923 [D loss: (0.577)(R 0.637, F 0.517)] [D acc: (0.641)(0.562, 0.719)] [G loss: 1.292] [G acc: 0.094]\n",
      "1924 [D loss: (0.630)(R 0.678, F 0.582)] [D acc: (0.641)(0.562, 0.719)] [G loss: 1.303] [G acc: 0.109]\n",
      "1925 [D loss: (0.610)(R 0.684, F 0.535)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.312] [G acc: 0.109]\n",
      "1926 [D loss: (0.642)(R 0.633, F 0.651)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.366] [G acc: 0.109]\n",
      "1927 [D loss: (0.547)(R 0.584, F 0.511)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.225] [G acc: 0.188]\n",
      "1928 [D loss: (0.567)(R 0.501, F 0.632)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.588] [G acc: 0.047]\n",
      "1929 [D loss: (0.575)(R 0.614, F 0.536)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.315] [G acc: 0.094]\n",
      "1930 [D loss: (0.556)(R 0.557, F 0.556)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.232] [G acc: 0.156]\n",
      "1931 [D loss: (0.594)(R 0.639, F 0.549)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.371] [G acc: 0.109]\n",
      "1932 [D loss: (0.573)(R 0.569, F 0.577)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.363] [G acc: 0.125]\n",
      "1933 [D loss: (0.536)(R 0.466, F 0.606)] [D acc: (0.672)(0.719, 0.625)] [G loss: 1.185] [G acc: 0.219]\n",
      "1934 [D loss: (0.525)(R 0.572, F 0.478)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.313] [G acc: 0.109]\n",
      "1935 [D loss: (0.535)(R 0.473, F 0.598)] [D acc: (0.734)(0.781, 0.688)] [G loss: 1.272] [G acc: 0.141]\n",
      "1936 [D loss: (0.592)(R 0.621, F 0.562)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.299] [G acc: 0.156]\n",
      "1937 [D loss: (0.574)(R 0.621, F 0.528)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.158] [G acc: 0.203]\n",
      "1938 [D loss: (0.620)(R 0.634, F 0.607)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.195] [G acc: 0.188]\n",
      "1939 [D loss: (0.563)(R 0.521, F 0.604)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.259] [G acc: 0.156]\n",
      "1940 [D loss: (0.538)(R 0.558, F 0.517)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.122] [G acc: 0.188]\n",
      "1941 [D loss: (0.545)(R 0.489, F 0.601)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.350] [G acc: 0.141]\n",
      "1942 [D loss: (0.474)(R 0.453, F 0.495)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.276] [G acc: 0.141]\n",
      "1943 [D loss: (0.598)(R 0.493, F 0.704)] [D acc: (0.680)(0.734, 0.625)] [G loss: 1.288] [G acc: 0.172]\n",
      "1944 [D loss: (0.628)(R 0.655, F 0.601)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.162] [G acc: 0.156]\n",
      "1945 [D loss: (0.533)(R 0.595, F 0.470)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.352] [G acc: 0.156]\n",
      "1946 [D loss: (0.579)(R 0.552, F 0.606)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.204] [G acc: 0.141]\n",
      "1947 [D loss: (0.536)(R 0.544, F 0.528)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.262] [G acc: 0.109]\n",
      "1948 [D loss: (0.576)(R 0.633, F 0.518)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.178] [G acc: 0.203]\n",
      "1949 [D loss: (0.643)(R 0.639, F 0.648)] [D acc: (0.664)(0.547, 0.781)] [G loss: 1.261] [G acc: 0.109]\n",
      "1950 [D loss: (0.520)(R 0.518, F 0.521)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.250] [G acc: 0.156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951 [D loss: (0.564)(R 0.603, F 0.524)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.232] [G acc: 0.188]\n",
      "1952 [D loss: (0.560)(R 0.534, F 0.586)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.245] [G acc: 0.141]\n",
      "1953 [D loss: (0.663)(R 0.675, F 0.652)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.245] [G acc: 0.141]\n",
      "1954 [D loss: (0.585)(R 0.643, F 0.527)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.278] [G acc: 0.156]\n",
      "1955 [D loss: (0.641)(R 0.595, F 0.687)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.273] [G acc: 0.094]\n",
      "1956 [D loss: (0.587)(R 0.649, F 0.525)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.368] [G acc: 0.109]\n",
      "1957 [D loss: (0.661)(R 0.666, F 0.657)] [D acc: (0.594)(0.547, 0.641)] [G loss: 1.319] [G acc: 0.109]\n",
      "1958 [D loss: (0.525)(R 0.533, F 0.516)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.192] [G acc: 0.266]\n",
      "1959 [D loss: (0.612)(R 0.636, F 0.588)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.178] [G acc: 0.172]\n",
      "1960 [D loss: (0.534)(R 0.499, F 0.568)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.331] [G acc: 0.109]\n",
      "1961 [D loss: (0.580)(R 0.624, F 0.536)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.293] [G acc: 0.156]\n",
      "1962 [D loss: (0.539)(R 0.585, F 0.494)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.352] [G acc: 0.156]\n",
      "1963 [D loss: (0.622)(R 0.647, F 0.596)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.093] [G acc: 0.172]\n",
      "1964 [D loss: (0.550)(R 0.513, F 0.587)] [D acc: (0.703)(0.750, 0.656)] [G loss: 1.247] [G acc: 0.156]\n",
      "1965 [D loss: (0.624)(R 0.624, F 0.624)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.122] [G acc: 0.125]\n",
      "1966 [D loss: (0.550)(R 0.553, F 0.546)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.112] [G acc: 0.156]\n",
      "1967 [D loss: (0.533)(R 0.539, F 0.527)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.236] [G acc: 0.078]\n",
      "1968 [D loss: (0.566)(R 0.580, F 0.552)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.188] [G acc: 0.203]\n",
      "1969 [D loss: (0.605)(R 0.514, F 0.695)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.105] [G acc: 0.125]\n",
      "1970 [D loss: (0.615)(R 0.669, F 0.562)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.293] [G acc: 0.094]\n",
      "1971 [D loss: (0.616)(R 0.605, F 0.628)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.145] [G acc: 0.156]\n",
      "1972 [D loss: (0.528)(R 0.501, F 0.554)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.226] [G acc: 0.141]\n",
      "1973 [D loss: (0.575)(R 0.610, F 0.541)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.261] [G acc: 0.141]\n",
      "1974 [D loss: (0.516)(R 0.492, F 0.540)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.302] [G acc: 0.109]\n",
      "1975 [D loss: (0.612)(R 0.578, F 0.647)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.239] [G acc: 0.172]\n",
      "1976 [D loss: (0.720)(R 0.751, F 0.689)] [D acc: (0.586)(0.500, 0.672)] [G loss: 1.154] [G acc: 0.188]\n",
      "1977 [D loss: (0.574)(R 0.644, F 0.504)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.178] [G acc: 0.125]\n",
      "1978 [D loss: (0.489)(R 0.490, F 0.489)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.289] [G acc: 0.156]\n",
      "1979 [D loss: (0.636)(R 0.600, F 0.672)] [D acc: (0.656)(0.656, 0.656)] [G loss: 1.282] [G acc: 0.109]\n",
      "1980 [D loss: (0.663)(R 0.660, F 0.666)] [D acc: (0.609)(0.547, 0.672)] [G loss: 1.290] [G acc: 0.078]\n",
      "1981 [D loss: (0.551)(R 0.552, F 0.551)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.230] [G acc: 0.062]\n",
      "1982 [D loss: (0.579)(R 0.570, F 0.588)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.189] [G acc: 0.141]\n",
      "1983 [D loss: (0.638)(R 0.660, F 0.615)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.333] [G acc: 0.062]\n",
      "1984 [D loss: (0.557)(R 0.600, F 0.514)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.255] [G acc: 0.172]\n",
      "1985 [D loss: (0.557)(R 0.595, F 0.520)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.262] [G acc: 0.125]\n",
      "1986 [D loss: (0.603)(R 0.618, F 0.588)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.278] [G acc: 0.172]\n",
      "1987 [D loss: (0.527)(R 0.517, F 0.537)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.164] [G acc: 0.172]\n",
      "1988 [D loss: (0.605)(R 0.545, F 0.665)] [D acc: (0.695)(0.750, 0.641)] [G loss: 1.269] [G acc: 0.141]\n",
      "1989 [D loss: (0.558)(R 0.594, F 0.522)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.124] [G acc: 0.156]\n",
      "1990 [D loss: (0.551)(R 0.548, F 0.554)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.192] [G acc: 0.188]\n",
      "1991 [D loss: (0.539)(R 0.552, F 0.525)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.191] [G acc: 0.219]\n",
      "1992 [D loss: (0.638)(R 0.600, F 0.677)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.232] [G acc: 0.078]\n",
      "1993 [D loss: (0.568)(R 0.517, F 0.619)] [D acc: (0.688)(0.719, 0.656)] [G loss: 1.448] [G acc: 0.094]\n",
      "1994 [D loss: (0.640)(R 0.757, F 0.523)] [D acc: (0.664)(0.516, 0.812)] [G loss: 1.211] [G acc: 0.125]\n",
      "1995 [D loss: (0.557)(R 0.549, F 0.565)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.259] [G acc: 0.109]\n",
      "1996 [D loss: (0.555)(R 0.502, F 0.608)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.154] [G acc: 0.156]\n",
      "1997 [D loss: (0.481)(R 0.479, F 0.483)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.231] [G acc: 0.188]\n",
      "1998 [D loss: (0.626)(R 0.690, F 0.563)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.197] [G acc: 0.156]\n",
      "1999 [D loss: (0.567)(R 0.633, F 0.501)] [D acc: (0.664)(0.516, 0.812)] [G loss: 1.353] [G acc: 0.078]\n",
      "2000 [D loss: (0.499)(R 0.480, F 0.518)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.365] [G acc: 0.125]\n",
      "2001 [D loss: (0.488)(R 0.387, F 0.588)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.436] [G acc: 0.109]\n",
      "2002 [D loss: (0.587)(R 0.496, F 0.677)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.374] [G acc: 0.062]\n",
      "2003 [D loss: (0.556)(R 0.628, F 0.484)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.385] [G acc: 0.125]\n",
      "2004 [D loss: (0.574)(R 0.608, F 0.541)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.359] [G acc: 0.109]\n",
      "2005 [D loss: (0.604)(R 0.570, F 0.637)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.351] [G acc: 0.094]\n",
      "2006 [D loss: (0.592)(R 0.676, F 0.508)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.355] [G acc: 0.078]\n",
      "2007 [D loss: (0.610)(R 0.609, F 0.610)] [D acc: (0.633)(0.609, 0.656)] [G loss: 1.240] [G acc: 0.047]\n",
      "2008 [D loss: (0.597)(R 0.578, F 0.615)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.335] [G acc: 0.078]\n",
      "2009 [D loss: (0.508)(R 0.543, F 0.472)] [D acc: (0.789)(0.672, 0.906)] [G loss: 1.229] [G acc: 0.219]\n",
      "2010 [D loss: (0.608)(R 0.628, F 0.588)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.229] [G acc: 0.172]\n",
      "2011 [D loss: (0.585)(R 0.600, F 0.569)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.273] [G acc: 0.109]\n",
      "2012 [D loss: (0.567)(R 0.645, F 0.489)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.317] [G acc: 0.141]\n",
      "2013 [D loss: (0.593)(R 0.532, F 0.654)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.225] [G acc: 0.188]\n",
      "2014 [D loss: (0.536)(R 0.531, F 0.541)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.416] [G acc: 0.062]\n",
      "2015 [D loss: (0.577)(R 0.695, F 0.459)] [D acc: (0.672)(0.484, 0.859)] [G loss: 1.348] [G acc: 0.141]\n",
      "2016 [D loss: (0.619)(R 0.673, F 0.565)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.176] [G acc: 0.078]\n",
      "2017 [D loss: (0.476)(R 0.493, F 0.459)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.202] [G acc: 0.156]\n",
      "2018 [D loss: (0.596)(R 0.542, F 0.649)] [D acc: (0.602)(0.578, 0.625)] [G loss: 1.212] [G acc: 0.203]\n",
      "2019 [D loss: (0.632)(R 0.611, F 0.652)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.576] [G acc: 0.062]\n",
      "2020 [D loss: (0.592)(R 0.696, F 0.488)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.531] [G acc: 0.047]\n",
      "2021 [D loss: (0.583)(R 0.559, F 0.606)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.124] [G acc: 0.172]\n",
      "2022 [D loss: (0.572)(R 0.542, F 0.603)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.253] [G acc: 0.094]\n",
      "2023 [D loss: (0.623)(R 0.638, F 0.607)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.400] [G acc: 0.109]\n",
      "2024 [D loss: (0.582)(R 0.522, F 0.642)] [D acc: (0.734)(0.766, 0.703)] [G loss: 1.193] [G acc: 0.188]\n",
      "2025 [D loss: (0.550)(R 0.549, F 0.551)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.307] [G acc: 0.094]\n",
      "2026 [D loss: (0.485)(R 0.430, F 0.540)] [D acc: (0.789)(0.797, 0.781)] [G loss: 1.384] [G acc: 0.109]\n",
      "2027 [D loss: (0.655)(R 0.751, F 0.560)] [D acc: (0.602)(0.484, 0.719)] [G loss: 1.261] [G acc: 0.141]\n",
      "2028 [D loss: (0.588)(R 0.689, F 0.486)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.168] [G acc: 0.156]\n",
      "2029 [D loss: (0.476)(R 0.442, F 0.511)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.262] [G acc: 0.172]\n",
      "2030 [D loss: (0.591)(R 0.563, F 0.619)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.161] [G acc: 0.203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2031 [D loss: (0.608)(R 0.619, F 0.598)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.261] [G acc: 0.094]\n",
      "2032 [D loss: (0.512)(R 0.565, F 0.459)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.212] [G acc: 0.172]\n",
      "2033 [D loss: (0.540)(R 0.506, F 0.574)] [D acc: (0.703)(0.734, 0.672)] [G loss: 1.298] [G acc: 0.188]\n",
      "2034 [D loss: (0.566)(R 0.583, F 0.549)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.252] [G acc: 0.188]\n",
      "2035 [D loss: (0.558)(R 0.471, F 0.644)] [D acc: (0.734)(0.781, 0.688)] [G loss: 1.203] [G acc: 0.172]\n",
      "2036 [D loss: (0.604)(R 0.529, F 0.679)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.259] [G acc: 0.250]\n",
      "2037 [D loss: (0.618)(R 0.643, F 0.593)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.145] [G acc: 0.219]\n",
      "2038 [D loss: (0.458)(R 0.444, F 0.472)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.336] [G acc: 0.141]\n",
      "2039 [D loss: (0.591)(R 0.547, F 0.635)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.441] [G acc: 0.141]\n",
      "2040 [D loss: (0.487)(R 0.523, F 0.451)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.398] [G acc: 0.094]\n",
      "2041 [D loss: (0.552)(R 0.464, F 0.640)] [D acc: (0.672)(0.734, 0.609)] [G loss: 1.350] [G acc: 0.094]\n",
      "2042 [D loss: (0.508)(R 0.484, F 0.532)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.436] [G acc: 0.062]\n",
      "2043 [D loss: (0.541)(R 0.552, F 0.530)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.440] [G acc: 0.125]\n",
      "2044 [D loss: (0.495)(R 0.498, F 0.493)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.504] [G acc: 0.094]\n",
      "2045 [D loss: (0.576)(R 0.646, F 0.507)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.482] [G acc: 0.109]\n",
      "2046 [D loss: (0.648)(R 0.665, F 0.632)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.263] [G acc: 0.156]\n",
      "2047 [D loss: (0.493)(R 0.518, F 0.469)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.296] [G acc: 0.109]\n",
      "2048 [D loss: (0.574)(R 0.548, F 0.599)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.362] [G acc: 0.109]\n",
      "2049 [D loss: (0.630)(R 0.715, F 0.546)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.179] [G acc: 0.203]\n",
      "2050 [D loss: (0.496)(R 0.549, F 0.443)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.353] [G acc: 0.078]\n",
      "2051 [D loss: (0.543)(R 0.567, F 0.519)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.235] [G acc: 0.219]\n",
      "2052 [D loss: (0.594)(R 0.643, F 0.546)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.242] [G acc: 0.156]\n",
      "2053 [D loss: (0.679)(R 0.607, F 0.751)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.264] [G acc: 0.156]\n",
      "2054 [D loss: (0.550)(R 0.577, F 0.522)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.284] [G acc: 0.125]\n",
      "2055 [D loss: (0.562)(R 0.568, F 0.555)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.302] [G acc: 0.109]\n",
      "2056 [D loss: (0.590)(R 0.636, F 0.543)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.247] [G acc: 0.094]\n",
      "2057 [D loss: (0.528)(R 0.532, F 0.524)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.353] [G acc: 0.188]\n",
      "2058 [D loss: (0.661)(R 0.756, F 0.566)] [D acc: (0.648)(0.547, 0.750)] [G loss: 1.324] [G acc: 0.188]\n",
      "2059 [D loss: (0.575)(R 0.636, F 0.514)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.353] [G acc: 0.078]\n",
      "2060 [D loss: (0.543)(R 0.528, F 0.558)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.157] [G acc: 0.219]\n",
      "2061 [D loss: (0.516)(R 0.524, F 0.508)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.337] [G acc: 0.125]\n",
      "2062 [D loss: (0.681)(R 0.740, F 0.621)] [D acc: (0.586)(0.500, 0.672)] [G loss: 1.132] [G acc: 0.172]\n",
      "2063 [D loss: (0.543)(R 0.545, F 0.541)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.304] [G acc: 0.203]\n",
      "2064 [D loss: (0.519)(R 0.521, F 0.516)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.204] [G acc: 0.188]\n",
      "2065 [D loss: (0.484)(R 0.462, F 0.505)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.537] [G acc: 0.094]\n",
      "2066 [D loss: (0.604)(R 0.617, F 0.591)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.360] [G acc: 0.109]\n",
      "2067 [D loss: (0.568)(R 0.623, F 0.513)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.331] [G acc: 0.141]\n",
      "2068 [D loss: (0.616)(R 0.595, F 0.636)] [D acc: (0.633)(0.609, 0.656)] [G loss: 1.281] [G acc: 0.141]\n",
      "2069 [D loss: (0.561)(R 0.469, F 0.653)] [D acc: (0.703)(0.734, 0.672)] [G loss: 1.283] [G acc: 0.219]\n",
      "2070 [D loss: (0.535)(R 0.624, F 0.446)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.287] [G acc: 0.125]\n",
      "2071 [D loss: (0.565)(R 0.481, F 0.648)] [D acc: (0.742)(0.781, 0.703)] [G loss: 1.265] [G acc: 0.172]\n",
      "2072 [D loss: (0.539)(R 0.544, F 0.533)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.368] [G acc: 0.141]\n",
      "2073 [D loss: (0.490)(R 0.480, F 0.500)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.237] [G acc: 0.219]\n",
      "2074 [D loss: (0.584)(R 0.548, F 0.620)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.320] [G acc: 0.125]\n",
      "2075 [D loss: (0.605)(R 0.558, F 0.652)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.210] [G acc: 0.188]\n",
      "2076 [D loss: (0.576)(R 0.616, F 0.536)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.376] [G acc: 0.125]\n",
      "2077 [D loss: (0.522)(R 0.511, F 0.532)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.494] [G acc: 0.062]\n",
      "2078 [D loss: (0.556)(R 0.580, F 0.532)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.318] [G acc: 0.172]\n",
      "2079 [D loss: (0.509)(R 0.404, F 0.613)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.396] [G acc: 0.062]\n",
      "2080 [D loss: (0.569)(R 0.629, F 0.509)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.315] [G acc: 0.172]\n",
      "2081 [D loss: (0.606)(R 0.538, F 0.674)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.239] [G acc: 0.172]\n",
      "2082 [D loss: (0.577)(R 0.577, F 0.576)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.451] [G acc: 0.062]\n",
      "2083 [D loss: (0.503)(R 0.528, F 0.479)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.348] [G acc: 0.094]\n",
      "2084 [D loss: (0.566)(R 0.528, F 0.603)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.521] [G acc: 0.031]\n",
      "2085 [D loss: (0.560)(R 0.575, F 0.545)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.291] [G acc: 0.172]\n",
      "2086 [D loss: (0.540)(R 0.530, F 0.549)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.372] [G acc: 0.125]\n",
      "2087 [D loss: (0.516)(R 0.588, F 0.444)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.220] [G acc: 0.141]\n",
      "2088 [D loss: (0.576)(R 0.646, F 0.506)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.378] [G acc: 0.062]\n",
      "2089 [D loss: (0.646)(R 0.603, F 0.688)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.217] [G acc: 0.094]\n",
      "2090 [D loss: (0.525)(R 0.559, F 0.491)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.314] [G acc: 0.062]\n",
      "2091 [D loss: (0.470)(R 0.474, F 0.466)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.421] [G acc: 0.109]\n",
      "2092 [D loss: (0.529)(R 0.549, F 0.508)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.295] [G acc: 0.125]\n",
      "2093 [D loss: (0.555)(R 0.549, F 0.560)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.400] [G acc: 0.156]\n",
      "2094 [D loss: (0.617)(R 0.601, F 0.633)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.389] [G acc: 0.141]\n",
      "2095 [D loss: (0.639)(R 0.633, F 0.645)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.199] [G acc: 0.172]\n",
      "2096 [D loss: (0.504)(R 0.583, F 0.425)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.278] [G acc: 0.172]\n",
      "2097 [D loss: (0.487)(R 0.514, F 0.460)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.337] [G acc: 0.188]\n",
      "2098 [D loss: (0.534)(R 0.488, F 0.580)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.470] [G acc: 0.109]\n",
      "2099 [D loss: (0.497)(R 0.470, F 0.524)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.531] [G acc: 0.109]\n",
      "2100 [D loss: (0.456)(R 0.504, F 0.408)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.394] [G acc: 0.109]\n",
      "2101 [D loss: (0.592)(R 0.494, F 0.690)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.260] [G acc: 0.188]\n",
      "2102 [D loss: (0.561)(R 0.602, F 0.520)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.511] [G acc: 0.141]\n",
      "2103 [D loss: (0.562)(R 0.627, F 0.496)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.424] [G acc: 0.141]\n",
      "2104 [D loss: (0.481)(R 0.452, F 0.511)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.417] [G acc: 0.125]\n",
      "2105 [D loss: (0.477)(R 0.499, F 0.454)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.580] [G acc: 0.094]\n",
      "2106 [D loss: (0.655)(R 0.655, F 0.655)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.319] [G acc: 0.094]\n",
      "2107 [D loss: (0.570)(R 0.516, F 0.624)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.629] [G acc: 0.062]\n",
      "2108 [D loss: (0.514)(R 0.454, F 0.573)] [D acc: (0.758)(0.812, 0.703)] [G loss: 1.454] [G acc: 0.125]\n",
      "2109 [D loss: (0.626)(R 0.662, F 0.590)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.356] [G acc: 0.125]\n",
      "2110 [D loss: (0.546)(R 0.595, F 0.496)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.351] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2111 [D loss: (0.612)(R 0.638, F 0.586)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.183] [G acc: 0.203]\n",
      "2112 [D loss: (0.645)(R 0.693, F 0.596)] [D acc: (0.648)(0.547, 0.750)] [G loss: 1.410] [G acc: 0.141]\n",
      "2113 [D loss: (0.590)(R 0.705, F 0.475)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.158] [G acc: 0.188]\n",
      "2114 [D loss: (0.556)(R 0.546, F 0.566)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.234] [G acc: 0.203]\n",
      "2115 [D loss: (0.506)(R 0.512, F 0.500)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.214] [G acc: 0.141]\n",
      "2116 [D loss: (0.525)(R 0.586, F 0.464)] [D acc: (0.734)(0.578, 0.891)] [G loss: 1.197] [G acc: 0.219]\n",
      "2117 [D loss: (0.570)(R 0.489, F 0.651)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.369] [G acc: 0.109]\n",
      "2118 [D loss: (0.586)(R 0.618, F 0.554)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.310] [G acc: 0.078]\n",
      "2119 [D loss: (0.581)(R 0.610, F 0.553)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.255] [G acc: 0.156]\n",
      "2120 [D loss: (0.498)(R 0.525, F 0.470)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.434] [G acc: 0.109]\n",
      "2121 [D loss: (0.571)(R 0.606, F 0.536)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.304] [G acc: 0.125]\n",
      "2122 [D loss: (0.563)(R 0.526, F 0.600)] [D acc: (0.672)(0.688, 0.656)] [G loss: 1.360] [G acc: 0.141]\n",
      "2123 [D loss: (0.620)(R 0.592, F 0.647)] [D acc: (0.656)(0.656, 0.656)] [G loss: 1.310] [G acc: 0.094]\n",
      "2124 [D loss: (0.621)(R 0.633, F 0.609)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.191] [G acc: 0.172]\n",
      "2125 [D loss: (0.576)(R 0.588, F 0.564)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.258] [G acc: 0.188]\n",
      "2126 [D loss: (0.521)(R 0.535, F 0.508)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.275] [G acc: 0.156]\n",
      "2127 [D loss: (0.581)(R 0.611, F 0.550)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.198] [G acc: 0.094]\n",
      "2128 [D loss: (0.572)(R 0.556, F 0.588)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.209] [G acc: 0.109]\n",
      "2129 [D loss: (0.543)(R 0.578, F 0.509)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.317] [G acc: 0.156]\n",
      "2130 [D loss: (0.592)(R 0.620, F 0.564)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.305] [G acc: 0.094]\n",
      "2131 [D loss: (0.532)(R 0.560, F 0.505)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.474] [G acc: 0.125]\n",
      "2132 [D loss: (0.481)(R 0.468, F 0.493)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.286] [G acc: 0.109]\n",
      "2133 [D loss: (0.546)(R 0.539, F 0.554)] [D acc: (0.680)(0.688, 0.672)] [G loss: 1.344] [G acc: 0.172]\n",
      "2134 [D loss: (0.513)(R 0.524, F 0.502)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.403] [G acc: 0.078]\n",
      "2135 [D loss: (0.523)(R 0.459, F 0.587)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.346] [G acc: 0.125]\n",
      "2136 [D loss: (0.636)(R 0.720, F 0.551)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.293] [G acc: 0.156]\n",
      "2137 [D loss: (0.500)(R 0.520, F 0.479)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.434] [G acc: 0.062]\n",
      "2138 [D loss: (0.537)(R 0.574, F 0.500)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.372] [G acc: 0.141]\n",
      "2139 [D loss: (0.572)(R 0.607, F 0.538)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.285] [G acc: 0.125]\n",
      "2140 [D loss: (0.532)(R 0.557, F 0.507)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.361] [G acc: 0.109]\n",
      "2141 [D loss: (0.615)(R 0.515, F 0.714)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.232] [G acc: 0.188]\n",
      "2142 [D loss: (0.545)(R 0.546, F 0.544)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.355] [G acc: 0.109]\n",
      "2143 [D loss: (0.512)(R 0.499, F 0.525)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.493] [G acc: 0.016]\n",
      "2144 [D loss: (0.499)(R 0.495, F 0.503)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.438] [G acc: 0.109]\n",
      "2145 [D loss: (0.618)(R 0.654, F 0.582)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.353] [G acc: 0.141]\n",
      "2146 [D loss: (0.584)(R 0.583, F 0.585)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.346] [G acc: 0.156]\n",
      "2147 [D loss: (0.558)(R 0.600, F 0.516)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.309] [G acc: 0.141]\n",
      "2148 [D loss: (0.608)(R 0.635, F 0.582)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.200] [G acc: 0.156]\n",
      "2149 [D loss: (0.563)(R 0.535, F 0.592)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.411] [G acc: 0.094]\n",
      "2150 [D loss: (0.717)(R 0.863, F 0.572)] [D acc: (0.570)(0.422, 0.719)] [G loss: 1.170] [G acc: 0.141]\n",
      "2151 [D loss: (0.573)(R 0.561, F 0.585)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.366] [G acc: 0.125]\n",
      "2152 [D loss: (0.596)(R 0.668, F 0.525)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.256] [G acc: 0.109]\n",
      "2153 [D loss: (0.573)(R 0.587, F 0.560)] [D acc: (0.680)(0.688, 0.672)] [G loss: 1.371] [G acc: 0.078]\n",
      "2154 [D loss: (0.539)(R 0.529, F 0.549)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.330] [G acc: 0.062]\n",
      "2155 [D loss: (0.672)(R 0.600, F 0.744)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.345] [G acc: 0.109]\n",
      "2156 [D loss: (0.636)(R 0.744, F 0.529)] [D acc: (0.602)(0.438, 0.766)] [G loss: 1.224] [G acc: 0.141]\n",
      "2157 [D loss: (0.524)(R 0.530, F 0.518)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.005] [G acc: 0.234]\n",
      "2158 [D loss: (0.495)(R 0.474, F 0.516)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.249] [G acc: 0.125]\n",
      "2159 [D loss: (0.552)(R 0.469, F 0.634)] [D acc: (0.734)(0.766, 0.703)] [G loss: 1.243] [G acc: 0.125]\n",
      "2160 [D loss: (0.602)(R 0.568, F 0.635)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.191] [G acc: 0.172]\n",
      "2161 [D loss: (0.520)(R 0.503, F 0.537)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.390] [G acc: 0.094]\n",
      "2162 [D loss: (0.605)(R 0.651, F 0.559)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.368] [G acc: 0.125]\n",
      "2163 [D loss: (0.536)(R 0.537, F 0.535)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.188] [G acc: 0.172]\n",
      "2164 [D loss: (0.665)(R 0.656, F 0.675)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.158] [G acc: 0.156]\n",
      "2165 [D loss: (0.568)(R 0.608, F 0.529)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.267] [G acc: 0.094]\n",
      "2166 [D loss: (0.551)(R 0.622, F 0.479)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.190] [G acc: 0.156]\n",
      "2167 [D loss: (0.569)(R 0.634, F 0.504)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.233] [G acc: 0.188]\n",
      "2168 [D loss: (0.480)(R 0.472, F 0.489)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.402] [G acc: 0.094]\n",
      "2169 [D loss: (0.642)(R 0.544, F 0.740)] [D acc: (0.609)(0.641, 0.578)] [G loss: 1.359] [G acc: 0.094]\n",
      "2170 [D loss: (0.598)(R 0.683, F 0.512)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.348] [G acc: 0.062]\n",
      "2171 [D loss: (0.556)(R 0.598, F 0.513)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.290] [G acc: 0.109]\n",
      "2172 [D loss: (0.571)(R 0.511, F 0.632)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.339] [G acc: 0.062]\n",
      "2173 [D loss: (0.669)(R 0.581, F 0.757)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.202] [G acc: 0.078]\n",
      "2174 [D loss: (0.567)(R 0.691, F 0.444)] [D acc: (0.703)(0.531, 0.875)] [G loss: 1.288] [G acc: 0.156]\n",
      "2175 [D loss: (0.575)(R 0.642, F 0.507)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.274] [G acc: 0.125]\n",
      "2176 [D loss: (0.575)(R 0.538, F 0.611)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.274] [G acc: 0.078]\n",
      "2177 [D loss: (0.543)(R 0.569, F 0.517)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.215] [G acc: 0.078]\n",
      "2178 [D loss: (0.604)(R 0.579, F 0.629)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.157] [G acc: 0.062]\n",
      "2179 [D loss: (0.545)(R 0.588, F 0.502)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.314] [G acc: 0.016]\n",
      "2180 [D loss: (0.524)(R 0.454, F 0.594)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.278] [G acc: 0.172]\n",
      "2181 [D loss: (0.550)(R 0.556, F 0.544)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.317] [G acc: 0.109]\n",
      "2182 [D loss: (0.584)(R 0.608, F 0.559)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.230] [G acc: 0.094]\n",
      "2183 [D loss: (0.562)(R 0.540, F 0.583)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.292] [G acc: 0.141]\n",
      "2184 [D loss: (0.589)(R 0.634, F 0.544)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.306] [G acc: 0.125]\n",
      "2185 [D loss: (0.550)(R 0.481, F 0.620)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.300] [G acc: 0.188]\n",
      "2186 [D loss: (0.635)(R 0.634, F 0.635)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.213] [G acc: 0.109]\n",
      "2187 [D loss: (0.600)(R 0.641, F 0.559)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.225] [G acc: 0.156]\n",
      "2188 [D loss: (0.553)(R 0.590, F 0.516)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.357] [G acc: 0.156]\n",
      "2189 [D loss: (0.612)(R 0.591, F 0.632)] [D acc: (0.641)(0.641, 0.641)] [G loss: 1.264] [G acc: 0.156]\n",
      "2190 [D loss: (0.615)(R 0.571, F 0.659)] [D acc: (0.680)(0.703, 0.656)] [G loss: 1.298] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2191 [D loss: (0.528)(R 0.571, F 0.486)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.293] [G acc: 0.094]\n",
      "2192 [D loss: (0.586)(R 0.599, F 0.573)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.243] [G acc: 0.094]\n",
      "2193 [D loss: (0.597)(R 0.525, F 0.669)] [D acc: (0.664)(0.703, 0.625)] [G loss: 1.276] [G acc: 0.078]\n",
      "2194 [D loss: (0.529)(R 0.525, F 0.534)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.254] [G acc: 0.094]\n",
      "2195 [D loss: (0.542)(R 0.539, F 0.544)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.463] [G acc: 0.078]\n",
      "2196 [D loss: (0.510)(R 0.547, F 0.473)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.246] [G acc: 0.156]\n",
      "2197 [D loss: (0.662)(R 0.660, F 0.664)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.191] [G acc: 0.188]\n",
      "2198 [D loss: (0.570)(R 0.570, F 0.570)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.205] [G acc: 0.156]\n",
      "2199 [D loss: (0.509)(R 0.478, F 0.539)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.333] [G acc: 0.109]\n",
      "2200 [D loss: (0.585)(R 0.511, F 0.660)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.429] [G acc: 0.078]\n",
      "2201 [D loss: (0.593)(R 0.715, F 0.471)] [D acc: (0.703)(0.547, 0.859)] [G loss: 1.168] [G acc: 0.125]\n",
      "2202 [D loss: (0.591)(R 0.604, F 0.578)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.329] [G acc: 0.094]\n",
      "2203 [D loss: (0.529)(R 0.496, F 0.562)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.267] [G acc: 0.141]\n",
      "2204 [D loss: (0.500)(R 0.483, F 0.517)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.296] [G acc: 0.156]\n",
      "2205 [D loss: (0.579)(R 0.458, F 0.700)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.300] [G acc: 0.141]\n",
      "2206 [D loss: (0.562)(R 0.586, F 0.539)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.224] [G acc: 0.094]\n",
      "2207 [D loss: (0.513)(R 0.477, F 0.550)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.332] [G acc: 0.078]\n",
      "2208 [D loss: (0.495)(R 0.498, F 0.491)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.344] [G acc: 0.141]\n",
      "2209 [D loss: (0.608)(R 0.589, F 0.627)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.210] [G acc: 0.109]\n",
      "2210 [D loss: (0.654)(R 0.785, F 0.522)] [D acc: (0.609)(0.453, 0.766)] [G loss: 1.243] [G acc: 0.125]\n",
      "2211 [D loss: (0.595)(R 0.609, F 0.580)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.124] [G acc: 0.219]\n",
      "2212 [D loss: (0.526)(R 0.468, F 0.584)] [D acc: (0.703)(0.734, 0.672)] [G loss: 1.297] [G acc: 0.109]\n",
      "2213 [D loss: (0.618)(R 0.649, F 0.587)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.282] [G acc: 0.078]\n",
      "2214 [D loss: (0.533)(R 0.580, F 0.486)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.230] [G acc: 0.094]\n",
      "2215 [D loss: (0.503)(R 0.490, F 0.515)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.264] [G acc: 0.109]\n",
      "2216 [D loss: (0.597)(R 0.545, F 0.650)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.294] [G acc: 0.094]\n",
      "2217 [D loss: (0.530)(R 0.549, F 0.512)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.320] [G acc: 0.109]\n",
      "2218 [D loss: (0.580)(R 0.540, F 0.619)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.504] [G acc: 0.047]\n",
      "2219 [D loss: (0.487)(R 0.552, F 0.422)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.527] [G acc: 0.109]\n",
      "2220 [D loss: (0.654)(R 0.679, F 0.628)] [D acc: (0.586)(0.531, 0.641)] [G loss: 1.219] [G acc: 0.109]\n",
      "2221 [D loss: (0.541)(R 0.552, F 0.529)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.241] [G acc: 0.078]\n",
      "2222 [D loss: (0.637)(R 0.596, F 0.679)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.221] [G acc: 0.141]\n",
      "2223 [D loss: (0.595)(R 0.734, F 0.455)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.219] [G acc: 0.203]\n",
      "2224 [D loss: (0.542)(R 0.570, F 0.515)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.220] [G acc: 0.109]\n",
      "2225 [D loss: (0.604)(R 0.600, F 0.608)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.183] [G acc: 0.156]\n",
      "2226 [D loss: (0.612)(R 0.521, F 0.702)] [D acc: (0.633)(0.672, 0.594)] [G loss: 1.343] [G acc: 0.094]\n",
      "2227 [D loss: (0.565)(R 0.622, F 0.508)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.172] [G acc: 0.141]\n",
      "2228 [D loss: (0.625)(R 0.558, F 0.693)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.276] [G acc: 0.125]\n",
      "2229 [D loss: (0.638)(R 0.678, F 0.597)] [D acc: (0.617)(0.547, 0.688)] [G loss: 1.166] [G acc: 0.188]\n",
      "2230 [D loss: (0.482)(R 0.474, F 0.490)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.392] [G acc: 0.125]\n",
      "2231 [D loss: (0.580)(R 0.532, F 0.628)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.215] [G acc: 0.141]\n",
      "2232 [D loss: (0.549)(R 0.538, F 0.560)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.357] [G acc: 0.078]\n",
      "2233 [D loss: (0.616)(R 0.675, F 0.557)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.170] [G acc: 0.125]\n",
      "2234 [D loss: (0.555)(R 0.584, F 0.526)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.229] [G acc: 0.141]\n",
      "2235 [D loss: (0.609)(R 0.541, F 0.678)] [D acc: (0.633)(0.641, 0.625)] [G loss: 1.216] [G acc: 0.094]\n",
      "2236 [D loss: (0.668)(R 0.683, F 0.654)] [D acc: (0.602)(0.531, 0.672)] [G loss: 1.237] [G acc: 0.109]\n",
      "2237 [D loss: (0.530)(R 0.525, F 0.536)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.259] [G acc: 0.125]\n",
      "2238 [D loss: (0.611)(R 0.572, F 0.650)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.144] [G acc: 0.188]\n",
      "2239 [D loss: (0.499)(R 0.509, F 0.489)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.194] [G acc: 0.141]\n",
      "2240 [D loss: (0.567)(R 0.588, F 0.547)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.338] [G acc: 0.078]\n",
      "2241 [D loss: (0.528)(R 0.547, F 0.508)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.314] [G acc: 0.109]\n",
      "2242 [D loss: (0.492)(R 0.515, F 0.469)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.417] [G acc: 0.109]\n",
      "2243 [D loss: (0.607)(R 0.474, F 0.740)] [D acc: (0.719)(0.797, 0.641)] [G loss: 1.136] [G acc: 0.141]\n",
      "2244 [D loss: (0.606)(R 0.575, F 0.637)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.318] [G acc: 0.141]\n",
      "2245 [D loss: (0.517)(R 0.527, F 0.507)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.298] [G acc: 0.125]\n",
      "2246 [D loss: (0.552)(R 0.579, F 0.526)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.363] [G acc: 0.125]\n",
      "2247 [D loss: (0.540)(R 0.511, F 0.569)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.355] [G acc: 0.141]\n",
      "2248 [D loss: (0.466)(R 0.457, F 0.475)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.595] [G acc: 0.094]\n",
      "2249 [D loss: (0.507)(R 0.576, F 0.438)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.310] [G acc: 0.109]\n",
      "2250 [D loss: (0.579)(R 0.551, F 0.607)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.486] [G acc: 0.078]\n",
      "2251 [D loss: (0.537)(R 0.574, F 0.500)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.392] [G acc: 0.109]\n",
      "2252 [D loss: (0.524)(R 0.505, F 0.544)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.298] [G acc: 0.156]\n",
      "2253 [D loss: (0.589)(R 0.593, F 0.586)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.313] [G acc: 0.094]\n",
      "2254 [D loss: (0.600)(R 0.652, F 0.548)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.473] [G acc: 0.078]\n",
      "2255 [D loss: (0.589)(R 0.529, F 0.649)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.189] [G acc: 0.172]\n",
      "2256 [D loss: (0.588)(R 0.610, F 0.565)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.330] [G acc: 0.078]\n",
      "2257 [D loss: (0.566)(R 0.630, F 0.503)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.278] [G acc: 0.141]\n",
      "2258 [D loss: (0.618)(R 0.582, F 0.653)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.281] [G acc: 0.125]\n",
      "2259 [D loss: (0.518)(R 0.485, F 0.551)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.275] [G acc: 0.172]\n",
      "2260 [D loss: (0.584)(R 0.611, F 0.558)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.303] [G acc: 0.094]\n",
      "2261 [D loss: (0.567)(R 0.606, F 0.528)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.331] [G acc: 0.109]\n",
      "2262 [D loss: (0.567)(R 0.564, F 0.570)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.251] [G acc: 0.156]\n",
      "2263 [D loss: (0.540)(R 0.582, F 0.498)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.262] [G acc: 0.188]\n",
      "2264 [D loss: (0.511)(R 0.499, F 0.523)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.387] [G acc: 0.156]\n",
      "2265 [D loss: (0.609)(R 0.608, F 0.610)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.451] [G acc: 0.078]\n",
      "2266 [D loss: (0.565)(R 0.594, F 0.536)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.269] [G acc: 0.125]\n",
      "2267 [D loss: (0.532)(R 0.531, F 0.533)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.280] [G acc: 0.156]\n",
      "2268 [D loss: (0.577)(R 0.539, F 0.614)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.409] [G acc: 0.094]\n",
      "2269 [D loss: (0.519)(R 0.491, F 0.546)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.329] [G acc: 0.125]\n",
      "2270 [D loss: (0.589)(R 0.557, F 0.620)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.420] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2271 [D loss: (0.566)(R 0.641, F 0.491)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.098] [G acc: 0.203]\n",
      "2272 [D loss: (0.566)(R 0.544, F 0.588)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.266] [G acc: 0.125]\n",
      "2273 [D loss: (0.595)(R 0.559, F 0.632)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.331] [G acc: 0.141]\n",
      "2274 [D loss: (0.524)(R 0.521, F 0.527)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.390] [G acc: 0.188]\n",
      "2275 [D loss: (0.631)(R 0.613, F 0.649)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.327] [G acc: 0.094]\n",
      "2276 [D loss: (0.515)(R 0.583, F 0.448)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.343] [G acc: 0.188]\n",
      "2277 [D loss: (0.532)(R 0.548, F 0.515)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.258] [G acc: 0.156]\n",
      "2278 [D loss: (0.554)(R 0.525, F 0.583)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.404] [G acc: 0.062]\n",
      "2279 [D loss: (0.546)(R 0.624, F 0.468)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.348] [G acc: 0.078]\n",
      "2280 [D loss: (0.512)(R 0.525, F 0.498)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.169] [G acc: 0.188]\n",
      "2281 [D loss: (0.625)(R 0.719, F 0.531)] [D acc: (0.641)(0.500, 0.781)] [G loss: 1.172] [G acc: 0.109]\n",
      "2282 [D loss: (0.588)(R 0.598, F 0.577)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.093] [G acc: 0.188]\n",
      "2283 [D loss: (0.486)(R 0.484, F 0.488)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.265] [G acc: 0.141]\n",
      "2284 [D loss: (0.653)(R 0.639, F 0.666)] [D acc: (0.594)(0.531, 0.656)] [G loss: 1.275] [G acc: 0.078]\n",
      "2285 [D loss: (0.551)(R 0.583, F 0.520)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.160] [G acc: 0.203]\n",
      "2286 [D loss: (0.551)(R 0.503, F 0.600)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.349] [G acc: 0.156]\n",
      "2287 [D loss: (0.581)(R 0.588, F 0.574)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.315] [G acc: 0.094]\n",
      "2288 [D loss: (0.550)(R 0.541, F 0.559)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.423] [G acc: 0.125]\n",
      "2289 [D loss: (0.588)(R 0.611, F 0.565)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.385] [G acc: 0.047]\n",
      "2290 [D loss: (0.583)(R 0.544, F 0.622)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.298] [G acc: 0.078]\n",
      "2291 [D loss: (0.551)(R 0.649, F 0.452)] [D acc: (0.672)(0.516, 0.828)] [G loss: 1.313] [G acc: 0.078]\n",
      "2292 [D loss: (0.685)(R 0.683, F 0.688)] [D acc: (0.609)(0.562, 0.656)] [G loss: 1.199] [G acc: 0.141]\n",
      "2293 [D loss: (0.498)(R 0.540, F 0.457)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.219] [G acc: 0.125]\n",
      "2294 [D loss: (0.562)(R 0.615, F 0.508)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.379] [G acc: 0.094]\n",
      "2295 [D loss: (0.573)(R 0.549, F 0.597)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.286] [G acc: 0.141]\n",
      "2296 [D loss: (0.646)(R 0.683, F 0.608)] [D acc: (0.672)(0.531, 0.812)] [G loss: 1.337] [G acc: 0.062]\n",
      "2297 [D loss: (0.517)(R 0.560, F 0.473)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.241] [G acc: 0.156]\n",
      "2298 [D loss: (0.595)(R 0.463, F 0.728)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.364] [G acc: 0.141]\n",
      "2299 [D loss: (0.559)(R 0.661, F 0.457)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.247] [G acc: 0.109]\n",
      "2300 [D loss: (0.538)(R 0.555, F 0.520)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.282] [G acc: 0.125]\n",
      "2301 [D loss: (0.585)(R 0.584, F 0.587)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.359] [G acc: 0.062]\n",
      "2302 [D loss: (0.526)(R 0.555, F 0.496)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.398] [G acc: 0.141]\n",
      "2303 [D loss: (0.560)(R 0.522, F 0.598)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.224] [G acc: 0.188]\n",
      "2304 [D loss: (0.540)(R 0.522, F 0.558)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.365] [G acc: 0.125]\n",
      "2305 [D loss: (0.586)(R 0.595, F 0.577)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.215] [G acc: 0.188]\n",
      "2306 [D loss: (0.607)(R 0.587, F 0.627)] [D acc: (0.641)(0.641, 0.641)] [G loss: 1.344] [G acc: 0.062]\n",
      "2307 [D loss: (0.608)(R 0.666, F 0.550)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.330] [G acc: 0.078]\n",
      "2308 [D loss: (0.580)(R 0.596, F 0.563)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.267] [G acc: 0.109]\n",
      "2309 [D loss: (0.547)(R 0.564, F 0.531)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.423] [G acc: 0.078]\n",
      "2310 [D loss: (0.629)(R 0.661, F 0.597)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.361] [G acc: 0.094]\n",
      "2311 [D loss: (0.528)(R 0.534, F 0.522)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.279] [G acc: 0.047]\n",
      "2312 [D loss: (0.556)(R 0.522, F 0.589)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.300] [G acc: 0.141]\n",
      "2313 [D loss: (0.544)(R 0.498, F 0.590)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.368] [G acc: 0.094]\n",
      "2314 [D loss: (0.542)(R 0.572, F 0.512)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.253] [G acc: 0.156]\n",
      "2315 [D loss: (0.530)(R 0.529, F 0.531)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.266] [G acc: 0.141]\n",
      "2316 [D loss: (0.543)(R 0.521, F 0.564)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.290] [G acc: 0.094]\n",
      "2317 [D loss: (0.544)(R 0.539, F 0.549)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.389] [G acc: 0.078]\n",
      "2318 [D loss: (0.535)(R 0.476, F 0.594)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.402] [G acc: 0.047]\n",
      "2319 [D loss: (0.597)(R 0.591, F 0.603)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.443] [G acc: 0.047]\n",
      "2320 [D loss: (0.551)(R 0.627, F 0.475)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.160] [G acc: 0.125]\n",
      "2321 [D loss: (0.523)(R 0.558, F 0.487)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.206] [G acc: 0.109]\n",
      "2322 [D loss: (0.507)(R 0.487, F 0.527)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.490] [G acc: 0.016]\n",
      "2323 [D loss: (0.547)(R 0.563, F 0.532)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.427] [G acc: 0.094]\n",
      "2324 [D loss: (0.672)(R 0.664, F 0.680)] [D acc: (0.625)(0.609, 0.641)] [G loss: 1.431] [G acc: 0.094]\n",
      "2325 [D loss: (0.644)(R 0.741, F 0.547)] [D acc: (0.664)(0.516, 0.812)] [G loss: 1.257] [G acc: 0.125]\n",
      "2326 [D loss: (0.604)(R 0.700, F 0.509)] [D acc: (0.656)(0.531, 0.781)] [G loss: 1.139] [G acc: 0.141]\n",
      "2327 [D loss: (0.537)(R 0.590, F 0.485)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.152] [G acc: 0.188]\n",
      "2328 [D loss: (0.567)(R 0.560, F 0.573)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.338] [G acc: 0.062]\n",
      "2329 [D loss: (0.535)(R 0.565, F 0.506)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.320] [G acc: 0.094]\n",
      "2330 [D loss: (0.487)(R 0.554, F 0.421)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.345] [G acc: 0.062]\n",
      "2331 [D loss: (0.549)(R 0.456, F 0.643)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.330] [G acc: 0.125]\n",
      "2332 [D loss: (0.628)(R 0.556, F 0.700)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.253] [G acc: 0.109]\n",
      "2333 [D loss: (0.573)(R 0.587, F 0.560)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.411] [G acc: 0.047]\n",
      "2334 [D loss: (0.495)(R 0.488, F 0.502)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.311] [G acc: 0.156]\n",
      "2335 [D loss: (0.602)(R 0.499, F 0.705)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.365] [G acc: 0.094]\n",
      "2336 [D loss: (0.543)(R 0.518, F 0.568)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.265] [G acc: 0.078]\n",
      "2337 [D loss: (0.600)(R 0.614, F 0.587)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.171] [G acc: 0.141]\n",
      "2338 [D loss: (0.519)(R 0.561, F 0.477)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.193] [G acc: 0.188]\n",
      "2339 [D loss: (0.538)(R 0.446, F 0.630)] [D acc: (0.773)(0.797, 0.750)] [G loss: 1.227] [G acc: 0.141]\n",
      "2340 [D loss: (0.705)(R 0.761, F 0.650)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.235] [G acc: 0.094]\n",
      "2341 [D loss: (0.568)(R 0.603, F 0.534)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.273] [G acc: 0.125]\n",
      "2342 [D loss: (0.640)(R 0.591, F 0.688)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.296] [G acc: 0.109]\n",
      "2343 [D loss: (0.626)(R 0.622, F 0.629)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.262] [G acc: 0.031]\n",
      "2344 [D loss: (0.515)(R 0.567, F 0.463)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.203] [G acc: 0.125]\n",
      "2345 [D loss: (0.506)(R 0.439, F 0.572)] [D acc: (0.766)(0.812, 0.719)] [G loss: 1.389] [G acc: 0.062]\n",
      "2346 [D loss: (0.650)(R 0.660, F 0.640)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.274] [G acc: 0.125]\n",
      "2347 [D loss: (0.550)(R 0.615, F 0.485)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.263] [G acc: 0.094]\n",
      "2348 [D loss: (0.527)(R 0.620, F 0.434)] [D acc: (0.719)(0.547, 0.891)] [G loss: 1.402] [G acc: 0.125]\n",
      "2349 [D loss: (0.674)(R 0.653, F 0.696)] [D acc: (0.609)(0.547, 0.672)] [G loss: 1.138] [G acc: 0.156]\n",
      "2350 [D loss: (0.555)(R 0.600, F 0.510)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.048] [G acc: 0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2351 [D loss: (0.529)(R 0.497, F 0.562)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.143] [G acc: 0.203]\n",
      "2352 [D loss: (0.548)(R 0.548, F 0.549)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.339] [G acc: 0.156]\n",
      "2353 [D loss: (0.553)(R 0.533, F 0.572)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.354] [G acc: 0.141]\n",
      "2354 [D loss: (0.621)(R 0.598, F 0.644)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.300] [G acc: 0.109]\n",
      "2355 [D loss: (0.548)(R 0.584, F 0.511)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.290] [G acc: 0.062]\n",
      "2356 [D loss: (0.550)(R 0.607, F 0.493)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.368] [G acc: 0.047]\n",
      "2357 [D loss: (0.554)(R 0.538, F 0.569)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.359] [G acc: 0.125]\n",
      "2358 [D loss: (0.508)(R 0.502, F 0.514)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.352] [G acc: 0.094]\n",
      "2359 [D loss: (0.507)(R 0.487, F 0.526)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.388] [G acc: 0.078]\n",
      "2360 [D loss: (0.573)(R 0.674, F 0.472)] [D acc: (0.672)(0.516, 0.828)] [G loss: 1.458] [G acc: 0.078]\n",
      "2361 [D loss: (0.570)(R 0.527, F 0.613)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.213] [G acc: 0.156]\n",
      "2362 [D loss: (0.612)(R 0.584, F 0.639)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.302] [G acc: 0.109]\n",
      "2363 [D loss: (0.516)(R 0.601, F 0.432)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.297] [G acc: 0.109]\n",
      "2364 [D loss: (0.616)(R 0.592, F 0.641)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.209] [G acc: 0.125]\n",
      "2365 [D loss: (0.514)(R 0.512, F 0.517)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.321] [G acc: 0.078]\n",
      "2366 [D loss: (0.580)(R 0.565, F 0.596)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.312] [G acc: 0.078]\n",
      "2367 [D loss: (0.666)(R 0.647, F 0.686)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.376] [G acc: 0.078]\n",
      "2368 [D loss: (0.491)(R 0.510, F 0.472)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.221] [G acc: 0.172]\n",
      "2369 [D loss: (0.561)(R 0.485, F 0.637)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.308] [G acc: 0.125]\n",
      "2370 [D loss: (0.530)(R 0.563, F 0.497)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.366] [G acc: 0.094]\n",
      "2371 [D loss: (0.496)(R 0.521, F 0.470)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.395] [G acc: 0.094]\n",
      "2372 [D loss: (0.643)(R 0.628, F 0.658)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.292] [G acc: 0.078]\n",
      "2373 [D loss: (0.568)(R 0.600, F 0.536)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.402] [G acc: 0.109]\n",
      "2374 [D loss: (0.524)(R 0.588, F 0.460)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.320] [G acc: 0.188]\n",
      "2375 [D loss: (0.594)(R 0.728, F 0.460)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.216] [G acc: 0.141]\n",
      "2376 [D loss: (0.484)(R 0.527, F 0.441)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.278] [G acc: 0.172]\n",
      "2377 [D loss: (0.609)(R 0.513, F 0.705)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.244] [G acc: 0.109]\n",
      "2378 [D loss: (0.564)(R 0.658, F 0.471)] [D acc: (0.742)(0.562, 0.922)] [G loss: 1.378] [G acc: 0.031]\n",
      "2379 [D loss: (0.518)(R 0.575, F 0.460)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.234] [G acc: 0.078]\n",
      "2380 [D loss: (0.596)(R 0.544, F 0.648)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.295] [G acc: 0.078]\n",
      "2381 [D loss: (0.601)(R 0.664, F 0.538)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.454] [G acc: 0.078]\n",
      "2382 [D loss: (0.595)(R 0.619, F 0.570)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.280] [G acc: 0.078]\n",
      "2383 [D loss: (0.522)(R 0.593, F 0.452)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.284] [G acc: 0.141]\n",
      "2384 [D loss: (0.536)(R 0.436, F 0.636)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.400] [G acc: 0.109]\n",
      "2385 [D loss: (0.527)(R 0.572, F 0.483)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.338] [G acc: 0.141]\n",
      "2386 [D loss: (0.638)(R 0.640, F 0.636)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.410] [G acc: 0.078]\n",
      "2387 [D loss: (0.516)(R 0.562, F 0.470)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.394] [G acc: 0.062]\n",
      "2388 [D loss: (0.671)(R 0.524, F 0.818)] [D acc: (0.633)(0.641, 0.625)] [G loss: 1.359] [G acc: 0.125]\n",
      "2389 [D loss: (0.506)(R 0.546, F 0.465)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.381] [G acc: 0.094]\n",
      "2390 [D loss: (0.543)(R 0.510, F 0.576)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.354] [G acc: 0.141]\n",
      "2391 [D loss: (0.489)(R 0.489, F 0.489)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.342] [G acc: 0.141]\n",
      "2392 [D loss: (0.551)(R 0.508, F 0.595)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.410] [G acc: 0.078]\n",
      "2393 [D loss: (0.553)(R 0.559, F 0.547)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.338] [G acc: 0.094]\n",
      "2394 [D loss: (0.591)(R 0.586, F 0.595)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.341] [G acc: 0.094]\n",
      "2395 [D loss: (0.590)(R 0.658, F 0.522)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.369] [G acc: 0.125]\n",
      "2396 [D loss: (0.532)(R 0.507, F 0.556)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.441] [G acc: 0.094]\n",
      "2397 [D loss: (0.571)(R 0.643, F 0.499)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.277] [G acc: 0.156]\n",
      "2398 [D loss: (0.564)(R 0.536, F 0.591)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.220] [G acc: 0.109]\n",
      "2399 [D loss: (0.540)(R 0.543, F 0.537)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.335] [G acc: 0.109]\n",
      "2400 [D loss: (0.664)(R 0.723, F 0.604)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.362] [G acc: 0.078]\n",
      "2401 [D loss: (0.584)(R 0.646, F 0.523)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.132] [G acc: 0.203]\n",
      "2402 [D loss: (0.540)(R 0.499, F 0.581)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.293] [G acc: 0.031]\n",
      "2403 [D loss: (0.564)(R 0.507, F 0.621)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.296] [G acc: 0.141]\n",
      "2404 [D loss: (0.541)(R 0.526, F 0.557)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.231] [G acc: 0.125]\n",
      "2405 [D loss: (0.539)(R 0.603, F 0.474)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.346] [G acc: 0.141]\n",
      "2406 [D loss: (0.522)(R 0.515, F 0.529)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.345] [G acc: 0.109]\n",
      "2407 [D loss: (0.474)(R 0.447, F 0.501)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.319] [G acc: 0.156]\n",
      "2408 [D loss: (0.504)(R 0.412, F 0.597)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.415] [G acc: 0.109]\n",
      "2409 [D loss: (0.531)(R 0.529, F 0.532)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.426] [G acc: 0.109]\n",
      "2410 [D loss: (0.552)(R 0.603, F 0.500)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.353] [G acc: 0.109]\n",
      "2411 [D loss: (0.532)(R 0.572, F 0.493)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.193] [G acc: 0.125]\n",
      "2412 [D loss: (0.574)(R 0.543, F 0.604)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.184] [G acc: 0.125]\n",
      "2413 [D loss: (0.503)(R 0.530, F 0.475)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.471] [G acc: 0.094]\n",
      "2414 [D loss: (0.537)(R 0.512, F 0.563)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.262] [G acc: 0.156]\n",
      "2415 [D loss: (0.608)(R 0.516, F 0.700)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.432] [G acc: 0.031]\n",
      "2416 [D loss: (0.674)(R 0.829, F 0.518)] [D acc: (0.625)(0.469, 0.781)] [G loss: 1.247] [G acc: 0.109]\n",
      "2417 [D loss: (0.597)(R 0.689, F 0.505)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.245] [G acc: 0.078]\n",
      "2418 [D loss: (0.488)(R 0.458, F 0.519)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.269] [G acc: 0.047]\n",
      "2419 [D loss: (0.531)(R 0.555, F 0.506)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.440] [G acc: 0.125]\n",
      "2420 [D loss: (0.502)(R 0.476, F 0.528)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.283] [G acc: 0.141]\n",
      "2421 [D loss: (0.558)(R 0.541, F 0.576)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.349] [G acc: 0.094]\n",
      "2422 [D loss: (0.521)(R 0.569, F 0.474)] [D acc: (0.734)(0.578, 0.891)] [G loss: 1.351] [G acc: 0.078]\n",
      "2423 [D loss: (0.518)(R 0.477, F 0.560)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.317] [G acc: 0.031]\n",
      "2424 [D loss: (0.523)(R 0.597, F 0.448)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.386] [G acc: 0.109]\n",
      "2425 [D loss: (0.534)(R 0.493, F 0.576)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.371] [G acc: 0.109]\n",
      "2426 [D loss: (0.622)(R 0.563, F 0.681)] [D acc: (0.633)(0.609, 0.656)] [G loss: 1.400] [G acc: 0.078]\n",
      "2427 [D loss: (0.511)(R 0.570, F 0.452)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.428] [G acc: 0.109]\n",
      "2428 [D loss: (0.464)(R 0.518, F 0.409)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.353] [G acc: 0.109]\n",
      "2429 [D loss: (0.572)(R 0.615, F 0.530)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.301] [G acc: 0.172]\n",
      "2430 [D loss: (0.537)(R 0.435, F 0.639)] [D acc: (0.719)(0.781, 0.656)] [G loss: 1.268] [G acc: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431 [D loss: (0.569)(R 0.610, F 0.527)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.307] [G acc: 0.078]\n",
      "2432 [D loss: (0.495)(R 0.568, F 0.423)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.236] [G acc: 0.188]\n",
      "2433 [D loss: (0.553)(R 0.456, F 0.650)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.417] [G acc: 0.078]\n",
      "2434 [D loss: (0.547)(R 0.602, F 0.491)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.389] [G acc: 0.172]\n",
      "2435 [D loss: (0.581)(R 0.600, F 0.562)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.396] [G acc: 0.125]\n",
      "2436 [D loss: (0.581)(R 0.639, F 0.524)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.204] [G acc: 0.141]\n",
      "2437 [D loss: (0.587)(R 0.602, F 0.571)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.246] [G acc: 0.172]\n",
      "2438 [D loss: (0.540)(R 0.497, F 0.584)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.340] [G acc: 0.203]\n",
      "2439 [D loss: (0.492)(R 0.518, F 0.466)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.419] [G acc: 0.094]\n",
      "2440 [D loss: (0.563)(R 0.510, F 0.615)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.213] [G acc: 0.219]\n",
      "2441 [D loss: (0.522)(R 0.525, F 0.520)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.408] [G acc: 0.156]\n",
      "2442 [D loss: (0.478)(R 0.513, F 0.443)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.442] [G acc: 0.078]\n",
      "2443 [D loss: (0.584)(R 0.665, F 0.503)] [D acc: (0.695)(0.547, 0.844)] [G loss: 1.244] [G acc: 0.109]\n",
      "2444 [D loss: (0.535)(R 0.514, F 0.557)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.246] [G acc: 0.125]\n",
      "2445 [D loss: (0.559)(R 0.547, F 0.571)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.157] [G acc: 0.141]\n",
      "2446 [D loss: (0.507)(R 0.473, F 0.542)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.389] [G acc: 0.125]\n",
      "2447 [D loss: (0.506)(R 0.572, F 0.440)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.524] [G acc: 0.062]\n",
      "2448 [D loss: (0.522)(R 0.502, F 0.543)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.430] [G acc: 0.094]\n",
      "2449 [D loss: (0.511)(R 0.537, F 0.484)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.538] [G acc: 0.109]\n",
      "2450 [D loss: (0.590)(R 0.557, F 0.624)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.547] [G acc: 0.078]\n",
      "2451 [D loss: (0.577)(R 0.640, F 0.514)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.279] [G acc: 0.172]\n",
      "2452 [D loss: (0.576)(R 0.652, F 0.500)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.299] [G acc: 0.109]\n",
      "2453 [D loss: (0.617)(R 0.497, F 0.736)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.475] [G acc: 0.094]\n",
      "2454 [D loss: (0.506)(R 0.503, F 0.509)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.365] [G acc: 0.094]\n",
      "2455 [D loss: (0.498)(R 0.513, F 0.483)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.382] [G acc: 0.094]\n",
      "2456 [D loss: (0.561)(R 0.499, F 0.623)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.315] [G acc: 0.125]\n",
      "2457 [D loss: (0.526)(R 0.506, F 0.545)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.337] [G acc: 0.094]\n",
      "2458 [D loss: (0.601)(R 0.639, F 0.564)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.488] [G acc: 0.062]\n",
      "2459 [D loss: (0.574)(R 0.666, F 0.481)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.288] [G acc: 0.203]\n",
      "2460 [D loss: (0.523)(R 0.547, F 0.499)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.310] [G acc: 0.109]\n",
      "2461 [D loss: (0.590)(R 0.729, F 0.451)] [D acc: (0.672)(0.484, 0.859)] [G loss: 1.221] [G acc: 0.141]\n",
      "2462 [D loss: (0.602)(R 0.629, F 0.574)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.155] [G acc: 0.109]\n",
      "2463 [D loss: (0.534)(R 0.575, F 0.493)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.157] [G acc: 0.188]\n",
      "2464 [D loss: (0.521)(R 0.530, F 0.512)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.366] [G acc: 0.094]\n",
      "2465 [D loss: (0.685)(R 0.540, F 0.829)] [D acc: (0.727)(0.766, 0.688)] [G loss: 1.436] [G acc: 0.016]\n",
      "2466 [D loss: (0.527)(R 0.570, F 0.483)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.327] [G acc: 0.125]\n",
      "2467 [D loss: (0.580)(R 0.660, F 0.499)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.285] [G acc: 0.109]\n",
      "2468 [D loss: (0.511)(R 0.528, F 0.495)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.277] [G acc: 0.109]\n",
      "2469 [D loss: (0.522)(R 0.508, F 0.536)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.246] [G acc: 0.109]\n",
      "2470 [D loss: (0.557)(R 0.582, F 0.532)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.201] [G acc: 0.125]\n",
      "2471 [D loss: (0.517)(R 0.471, F 0.563)] [D acc: (0.734)(0.766, 0.703)] [G loss: 1.365] [G acc: 0.109]\n",
      "2472 [D loss: (0.558)(R 0.574, F 0.543)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.227] [G acc: 0.172]\n",
      "2473 [D loss: (0.529)(R 0.516, F 0.542)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.258] [G acc: 0.188]\n",
      "2474 [D loss: (0.604)(R 0.611, F 0.598)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.204] [G acc: 0.188]\n",
      "2475 [D loss: (0.627)(R 0.616, F 0.639)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.384] [G acc: 0.078]\n",
      "2476 [D loss: (0.499)(R 0.461, F 0.538)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.259] [G acc: 0.125]\n",
      "2477 [D loss: (0.641)(R 0.653, F 0.629)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.286] [G acc: 0.172]\n",
      "2478 [D loss: (0.500)(R 0.573, F 0.427)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.461] [G acc: 0.047]\n",
      "2479 [D loss: (0.526)(R 0.501, F 0.552)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.494] [G acc: 0.078]\n",
      "2480 [D loss: (0.581)(R 0.692, F 0.470)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.431] [G acc: 0.109]\n",
      "2481 [D loss: (0.486)(R 0.498, F 0.473)] [D acc: (0.797)(0.781, 0.812)] [G loss: 1.331] [G acc: 0.094]\n",
      "2482 [D loss: (0.646)(R 0.495, F 0.798)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.194] [G acc: 0.188]\n",
      "2483 [D loss: (0.535)(R 0.579, F 0.492)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.368] [G acc: 0.156]\n",
      "2484 [D loss: (0.550)(R 0.618, F 0.483)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.382] [G acc: 0.109]\n",
      "2485 [D loss: (0.523)(R 0.579, F 0.466)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.446] [G acc: 0.094]\n",
      "2486 [D loss: (0.524)(R 0.468, F 0.579)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.465] [G acc: 0.062]\n",
      "2487 [D loss: (0.510)(R 0.551, F 0.469)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.394] [G acc: 0.141]\n",
      "2488 [D loss: (0.601)(R 0.586, F 0.615)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.527] [G acc: 0.109]\n",
      "2489 [D loss: (0.457)(R 0.455, F 0.459)] [D acc: (0.797)(0.781, 0.812)] [G loss: 1.471] [G acc: 0.156]\n",
      "2490 [D loss: (0.594)(R 0.670, F 0.518)] [D acc: (0.672)(0.531, 0.812)] [G loss: 1.291] [G acc: 0.172]\n",
      "2491 [D loss: (0.523)(R 0.474, F 0.573)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.378] [G acc: 0.156]\n",
      "2492 [D loss: (0.552)(R 0.554, F 0.550)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.375] [G acc: 0.141]\n",
      "2493 [D loss: (0.612)(R 0.647, F 0.577)] [D acc: (0.625)(0.531, 0.719)] [G loss: 1.384] [G acc: 0.062]\n",
      "2494 [D loss: (0.516)(R 0.489, F 0.544)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.561] [G acc: 0.078]\n",
      "2495 [D loss: (0.590)(R 0.631, F 0.549)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.301] [G acc: 0.109]\n",
      "2496 [D loss: (0.591)(R 0.543, F 0.639)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.334] [G acc: 0.172]\n",
      "2497 [D loss: (0.602)(R 0.510, F 0.695)] [D acc: (0.680)(0.703, 0.656)] [G loss: 1.386] [G acc: 0.078]\n",
      "2498 [D loss: (0.602)(R 0.651, F 0.553)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.257] [G acc: 0.156]\n",
      "2499 [D loss: (0.561)(R 0.630, F 0.493)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.210] [G acc: 0.172]\n",
      "2500 [D loss: (0.542)(R 0.519, F 0.565)] [D acc: (0.672)(0.688, 0.656)] [G loss: 1.361] [G acc: 0.172]\n",
      "2501 [D loss: (0.618)(R 0.597, F 0.638)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.350] [G acc: 0.125]\n",
      "2502 [D loss: (0.541)(R 0.519, F 0.563)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.291] [G acc: 0.047]\n",
      "2503 [D loss: (0.542)(R 0.600, F 0.483)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.322] [G acc: 0.094]\n",
      "2504 [D loss: (0.515)(R 0.512, F 0.519)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.213] [G acc: 0.172]\n",
      "2505 [D loss: (0.578)(R 0.654, F 0.502)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.398] [G acc: 0.062]\n",
      "2506 [D loss: (0.564)(R 0.595, F 0.534)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.308] [G acc: 0.125]\n",
      "2507 [D loss: (0.557)(R 0.512, F 0.601)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.408] [G acc: 0.031]\n",
      "2508 [D loss: (0.494)(R 0.525, F 0.463)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.413] [G acc: 0.141]\n",
      "2509 [D loss: (0.533)(R 0.483, F 0.584)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.538] [G acc: 0.047]\n",
      "2510 [D loss: (0.571)(R 0.600, F 0.542)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.368] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2511 [D loss: (0.507)(R 0.613, F 0.400)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.408] [G acc: 0.078]\n",
      "2512 [D loss: (0.609)(R 0.615, F 0.603)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.314] [G acc: 0.141]\n",
      "2513 [D loss: (0.545)(R 0.604, F 0.485)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.451] [G acc: 0.109]\n",
      "2514 [D loss: (0.535)(R 0.583, F 0.487)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.482] [G acc: 0.156]\n",
      "2515 [D loss: (0.543)(R 0.545, F 0.541)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.331] [G acc: 0.141]\n",
      "2516 [D loss: (0.424)(R 0.401, F 0.447)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.508] [G acc: 0.156]\n",
      "2517 [D loss: (0.565)(R 0.597, F 0.534)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.379] [G acc: 0.125]\n",
      "2518 [D loss: (0.565)(R 0.558, F 0.573)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.368] [G acc: 0.125]\n",
      "2519 [D loss: (0.643)(R 0.763, F 0.524)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.422] [G acc: 0.078]\n",
      "2520 [D loss: (0.566)(R 0.634, F 0.497)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.340] [G acc: 0.078]\n",
      "2521 [D loss: (0.608)(R 0.611, F 0.606)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.367] [G acc: 0.078]\n",
      "2522 [D loss: (0.549)(R 0.600, F 0.498)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.270] [G acc: 0.125]\n",
      "2523 [D loss: (0.510)(R 0.514, F 0.506)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.333] [G acc: 0.125]\n",
      "2524 [D loss: (0.633)(R 0.564, F 0.701)] [D acc: (0.633)(0.625, 0.641)] [G loss: 1.383] [G acc: 0.094]\n",
      "2525 [D loss: (0.538)(R 0.521, F 0.555)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.311] [G acc: 0.172]\n",
      "2526 [D loss: (0.507)(R 0.505, F 0.510)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.397] [G acc: 0.062]\n",
      "2527 [D loss: (0.468)(R 0.439, F 0.497)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.413] [G acc: 0.141]\n",
      "2528 [D loss: (0.485)(R 0.503, F 0.467)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.368] [G acc: 0.125]\n",
      "2529 [D loss: (0.488)(R 0.442, F 0.534)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.422] [G acc: 0.109]\n",
      "2530 [D loss: (0.598)(R 0.628, F 0.568)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.411] [G acc: 0.062]\n",
      "2531 [D loss: (0.529)(R 0.518, F 0.540)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.258] [G acc: 0.141]\n",
      "2532 [D loss: (0.520)(R 0.523, F 0.517)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.344] [G acc: 0.094]\n",
      "2533 [D loss: (0.549)(R 0.510, F 0.587)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.402] [G acc: 0.109]\n",
      "2534 [D loss: (0.605)(R 0.594, F 0.616)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.286] [G acc: 0.141]\n",
      "2535 [D loss: (0.542)(R 0.551, F 0.534)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.402] [G acc: 0.125]\n",
      "2536 [D loss: (0.482)(R 0.465, F 0.500)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.418] [G acc: 0.047]\n",
      "2537 [D loss: (0.556)(R 0.520, F 0.592)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.402] [G acc: 0.109]\n",
      "2538 [D loss: (0.562)(R 0.577, F 0.547)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.319] [G acc: 0.125]\n",
      "2539 [D loss: (0.551)(R 0.553, F 0.549)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.321] [G acc: 0.062]\n",
      "2540 [D loss: (0.550)(R 0.577, F 0.523)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.391] [G acc: 0.078]\n",
      "2541 [D loss: (0.608)(R 0.581, F 0.636)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.244] [G acc: 0.062]\n",
      "2542 [D loss: (0.566)(R 0.591, F 0.540)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.402] [G acc: 0.047]\n",
      "2543 [D loss: (0.535)(R 0.549, F 0.522)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.352] [G acc: 0.094]\n",
      "2544 [D loss: (0.546)(R 0.713, F 0.378)] [D acc: (0.742)(0.562, 0.922)] [G loss: 1.354] [G acc: 0.141]\n",
      "2545 [D loss: (0.554)(R 0.530, F 0.578)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.365] [G acc: 0.109]\n",
      "2546 [D loss: (0.509)(R 0.461, F 0.557)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.349] [G acc: 0.109]\n",
      "2547 [D loss: (0.500)(R 0.500, F 0.500)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.370] [G acc: 0.062]\n",
      "2548 [D loss: (0.639)(R 0.551, F 0.727)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.329] [G acc: 0.141]\n",
      "2549 [D loss: (0.559)(R 0.603, F 0.515)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.359] [G acc: 0.078]\n",
      "2550 [D loss: (0.434)(R 0.413, F 0.454)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.269] [G acc: 0.172]\n",
      "2551 [D loss: (0.520)(R 0.552, F 0.489)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.340] [G acc: 0.094]\n",
      "2552 [D loss: (0.449)(R 0.414, F 0.485)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.575] [G acc: 0.047]\n",
      "2553 [D loss: (0.612)(R 0.605, F 0.619)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.370] [G acc: 0.078]\n",
      "2554 [D loss: (0.535)(R 0.489, F 0.582)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.518] [G acc: 0.094]\n",
      "2555 [D loss: (0.531)(R 0.618, F 0.444)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.414] [G acc: 0.125]\n",
      "2556 [D loss: (0.532)(R 0.584, F 0.479)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.323] [G acc: 0.125]\n",
      "2557 [D loss: (0.517)(R 0.562, F 0.473)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.452] [G acc: 0.125]\n",
      "2558 [D loss: (0.538)(R 0.536, F 0.540)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.358] [G acc: 0.094]\n",
      "2559 [D loss: (0.544)(R 0.513, F 0.574)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.524] [G acc: 0.078]\n",
      "2560 [D loss: (0.474)(R 0.566, F 0.381)] [D acc: (0.758)(0.594, 0.922)] [G loss: 1.512] [G acc: 0.078]\n",
      "2561 [D loss: (0.464)(R 0.489, F 0.438)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.328] [G acc: 0.172]\n",
      "2562 [D loss: (0.556)(R 0.545, F 0.567)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.364] [G acc: 0.125]\n",
      "2563 [D loss: (0.457)(R 0.434, F 0.479)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.324] [G acc: 0.156]\n",
      "2564 [D loss: (0.536)(R 0.437, F 0.635)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.371] [G acc: 0.062]\n",
      "2565 [D loss: (0.577)(R 0.658, F 0.496)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.436] [G acc: 0.141]\n",
      "2566 [D loss: (0.609)(R 0.557, F 0.661)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.378] [G acc: 0.078]\n",
      "2567 [D loss: (0.563)(R 0.658, F 0.469)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.359] [G acc: 0.172]\n",
      "2568 [D loss: (0.460)(R 0.503, F 0.417)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.651] [G acc: 0.062]\n",
      "2569 [D loss: (0.506)(R 0.406, F 0.606)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.550] [G acc: 0.094]\n",
      "2570 [D loss: (0.570)(R 0.597, F 0.542)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.354] [G acc: 0.109]\n",
      "2571 [D loss: (0.564)(R 0.654, F 0.475)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.472] [G acc: 0.047]\n",
      "2572 [D loss: (0.575)(R 0.670, F 0.480)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.507] [G acc: 0.109]\n",
      "2573 [D loss: (0.555)(R 0.596, F 0.513)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.349] [G acc: 0.094]\n",
      "2574 [D loss: (0.567)(R 0.623, F 0.510)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.524] [G acc: 0.078]\n",
      "2575 [D loss: (0.599)(R 0.687, F 0.512)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.394] [G acc: 0.125]\n",
      "2576 [D loss: (0.681)(R 0.657, F 0.704)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.470] [G acc: 0.109]\n",
      "2577 [D loss: (0.581)(R 0.607, F 0.556)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.274] [G acc: 0.078]\n",
      "2578 [D loss: (0.536)(R 0.540, F 0.531)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.304] [G acc: 0.172]\n",
      "2579 [D loss: (0.571)(R 0.550, F 0.593)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.337] [G acc: 0.078]\n",
      "2580 [D loss: (0.558)(R 0.628, F 0.488)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.184] [G acc: 0.203]\n",
      "2581 [D loss: (0.555)(R 0.438, F 0.671)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.318] [G acc: 0.047]\n",
      "2582 [D loss: (0.527)(R 0.615, F 0.439)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.436] [G acc: 0.094]\n",
      "2583 [D loss: (0.464)(R 0.447, F 0.481)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.283] [G acc: 0.172]\n",
      "2584 [D loss: (0.580)(R 0.615, F 0.546)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.290] [G acc: 0.234]\n",
      "2585 [D loss: (0.479)(R 0.486, F 0.472)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.405] [G acc: 0.094]\n",
      "2586 [D loss: (0.583)(R 0.581, F 0.585)] [D acc: (0.617)(0.562, 0.672)] [G loss: 1.427] [G acc: 0.141]\n",
      "2587 [D loss: (0.549)(R 0.553, F 0.546)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.208] [G acc: 0.141]\n",
      "2588 [D loss: (0.572)(R 0.630, F 0.514)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.492] [G acc: 0.062]\n",
      "2589 [D loss: (0.542)(R 0.539, F 0.544)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.288] [G acc: 0.141]\n",
      "2590 [D loss: (0.491)(R 0.503, F 0.478)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.392] [G acc: 0.031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2591 [D loss: (0.434)(R 0.426, F 0.442)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.529] [G acc: 0.078]\n",
      "2592 [D loss: (0.578)(R 0.633, F 0.524)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.438] [G acc: 0.094]\n",
      "2593 [D loss: (0.563)(R 0.470, F 0.656)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.402] [G acc: 0.062]\n",
      "2594 [D loss: (0.503)(R 0.609, F 0.398)] [D acc: (0.758)(0.609, 0.906)] [G loss: 1.360] [G acc: 0.062]\n",
      "2595 [D loss: (0.503)(R 0.577, F 0.429)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.462] [G acc: 0.141]\n",
      "2596 [D loss: (0.523)(R 0.521, F 0.525)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.527] [G acc: 0.031]\n",
      "2597 [D loss: (0.486)(R 0.483, F 0.489)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.600] [G acc: 0.109]\n",
      "2598 [D loss: (0.492)(R 0.465, F 0.518)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.656] [G acc: 0.062]\n",
      "2599 [D loss: (0.619)(R 0.595, F 0.643)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.275] [G acc: 0.078]\n",
      "2600 [D loss: (0.585)(R 0.696, F 0.474)] [D acc: (0.656)(0.516, 0.797)] [G loss: 1.326] [G acc: 0.125]\n",
      "2601 [D loss: (0.634)(R 0.522, F 0.746)] [D acc: (0.680)(0.688, 0.672)] [G loss: 1.353] [G acc: 0.141]\n",
      "2602 [D loss: (0.485)(R 0.531, F 0.438)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.423] [G acc: 0.141]\n",
      "2603 [D loss: (0.551)(R 0.647, F 0.455)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.411] [G acc: 0.188]\n",
      "2604 [D loss: (0.514)(R 0.416, F 0.611)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.544] [G acc: 0.078]\n",
      "2605 [D loss: (0.581)(R 0.610, F 0.552)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.525] [G acc: 0.125]\n",
      "2606 [D loss: (0.611)(R 0.678, F 0.544)] [D acc: (0.602)(0.500, 0.703)] [G loss: 1.432] [G acc: 0.078]\n",
      "2607 [D loss: (0.490)(R 0.474, F 0.507)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.277] [G acc: 0.141]\n",
      "2608 [D loss: (0.562)(R 0.640, F 0.484)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.365] [G acc: 0.109]\n",
      "2609 [D loss: (0.517)(R 0.625, F 0.408)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.287] [G acc: 0.141]\n",
      "2610 [D loss: (0.563)(R 0.556, F 0.569)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.222] [G acc: 0.109]\n",
      "2611 [D loss: (0.490)(R 0.478, F 0.502)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.261] [G acc: 0.156]\n",
      "2612 [D loss: (0.519)(R 0.561, F 0.477)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.432] [G acc: 0.109]\n",
      "2613 [D loss: (0.586)(R 0.500, F 0.672)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.355] [G acc: 0.125]\n",
      "2614 [D loss: (0.581)(R 0.674, F 0.489)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.273] [G acc: 0.141]\n",
      "2615 [D loss: (0.518)(R 0.483, F 0.553)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.223] [G acc: 0.172]\n",
      "2616 [D loss: (0.417)(R 0.295, F 0.539)] [D acc: (0.828)(0.859, 0.797)] [G loss: 1.359] [G acc: 0.109]\n",
      "2617 [D loss: (0.476)(R 0.547, F 0.405)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.483] [G acc: 0.125]\n",
      "2618 [D loss: (0.453)(R 0.452, F 0.455)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.507] [G acc: 0.078]\n",
      "2619 [D loss: (0.543)(R 0.439, F 0.647)] [D acc: (0.797)(0.797, 0.797)] [G loss: 1.563] [G acc: 0.047]\n",
      "2620 [D loss: (0.602)(R 0.694, F 0.511)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.460] [G acc: 0.125]\n",
      "2621 [D loss: (0.591)(R 0.572, F 0.611)] [D acc: (0.625)(0.609, 0.641)] [G loss: 1.399] [G acc: 0.094]\n",
      "2622 [D loss: (0.682)(R 0.826, F 0.538)] [D acc: (0.594)(0.484, 0.703)] [G loss: 1.372] [G acc: 0.141]\n",
      "2623 [D loss: (0.534)(R 0.485, F 0.584)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.390] [G acc: 0.094]\n",
      "2624 [D loss: (0.549)(R 0.578, F 0.520)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.330] [G acc: 0.109]\n",
      "2625 [D loss: (0.597)(R 0.629, F 0.566)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.448] [G acc: 0.094]\n",
      "2626 [D loss: (0.480)(R 0.479, F 0.480)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.557] [G acc: 0.047]\n",
      "2627 [D loss: (0.481)(R 0.521, F 0.441)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.438] [G acc: 0.078]\n",
      "2628 [D loss: (0.547)(R 0.482, F 0.612)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.433] [G acc: 0.031]\n",
      "2629 [D loss: (0.537)(R 0.515, F 0.558)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.440] [G acc: 0.078]\n",
      "2630 [D loss: (0.497)(R 0.543, F 0.451)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.450] [G acc: 0.109]\n",
      "2631 [D loss: (0.474)(R 0.534, F 0.414)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.412] [G acc: 0.109]\n",
      "2632 [D loss: (0.554)(R 0.538, F 0.570)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.395] [G acc: 0.078]\n",
      "2633 [D loss: (0.560)(R 0.578, F 0.542)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.394] [G acc: 0.125]\n",
      "2634 [D loss: (0.599)(R 0.610, F 0.587)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.590] [G acc: 0.062]\n",
      "2635 [D loss: (0.652)(R 0.710, F 0.593)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.488] [G acc: 0.078]\n",
      "2636 [D loss: (0.456)(R 0.449, F 0.462)] [D acc: (0.812)(0.734, 0.891)] [G loss: 1.449] [G acc: 0.047]\n",
      "2637 [D loss: (0.581)(R 0.548, F 0.615)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.280] [G acc: 0.125]\n",
      "2638 [D loss: (0.521)(R 0.549, F 0.494)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.414] [G acc: 0.094]\n",
      "2639 [D loss: (0.546)(R 0.585, F 0.507)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.412] [G acc: 0.062]\n",
      "2640 [D loss: (0.565)(R 0.560, F 0.569)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.391] [G acc: 0.078]\n",
      "2641 [D loss: (0.511)(R 0.491, F 0.532)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.325] [G acc: 0.078]\n",
      "2642 [D loss: (0.502)(R 0.536, F 0.467)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.424] [G acc: 0.109]\n",
      "2643 [D loss: (0.585)(R 0.590, F 0.580)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.324] [G acc: 0.125]\n",
      "2644 [D loss: (0.544)(R 0.646, F 0.441)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.356] [G acc: 0.172]\n",
      "2645 [D loss: (0.573)(R 0.566, F 0.580)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.375] [G acc: 0.078]\n",
      "2646 [D loss: (0.561)(R 0.596, F 0.526)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.166] [G acc: 0.156]\n",
      "2647 [D loss: (0.560)(R 0.552, F 0.569)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.375] [G acc: 0.172]\n",
      "2648 [D loss: (0.517)(R 0.515, F 0.519)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.271] [G acc: 0.156]\n",
      "2649 [D loss: (0.588)(R 0.623, F 0.553)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.362] [G acc: 0.234]\n",
      "2650 [D loss: (0.575)(R 0.571, F 0.578)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.318] [G acc: 0.094]\n",
      "2651 [D loss: (0.565)(R 0.598, F 0.532)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.416] [G acc: 0.109]\n",
      "2652 [D loss: (0.528)(R 0.575, F 0.481)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.418] [G acc: 0.125]\n",
      "2653 [D loss: (0.603)(R 0.694, F 0.513)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.202] [G acc: 0.250]\n",
      "2654 [D loss: (0.529)(R 0.477, F 0.580)] [D acc: (0.781)(0.797, 0.766)] [G loss: 1.433] [G acc: 0.062]\n",
      "2655 [D loss: (0.553)(R 0.584, F 0.523)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.324] [G acc: 0.094]\n",
      "2656 [D loss: (0.583)(R 0.574, F 0.593)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.247] [G acc: 0.125]\n",
      "2657 [D loss: (0.609)(R 0.639, F 0.579)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.283] [G acc: 0.109]\n",
      "2658 [D loss: (0.480)(R 0.492, F 0.467)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.233] [G acc: 0.156]\n",
      "2659 [D loss: (0.502)(R 0.501, F 0.503)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.394] [G acc: 0.125]\n",
      "2660 [D loss: (0.497)(R 0.481, F 0.513)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.396] [G acc: 0.078]\n",
      "2661 [D loss: (0.506)(R 0.462, F 0.550)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.276] [G acc: 0.172]\n",
      "2662 [D loss: (0.570)(R 0.649, F 0.491)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.405] [G acc: 0.078]\n",
      "2663 [D loss: (0.543)(R 0.618, F 0.468)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.274] [G acc: 0.094]\n",
      "2664 [D loss: (0.557)(R 0.563, F 0.552)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.292] [G acc: 0.141]\n",
      "2665 [D loss: (0.503)(R 0.510, F 0.496)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.337] [G acc: 0.156]\n",
      "2666 [D loss: (0.548)(R 0.550, F 0.547)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.326] [G acc: 0.188]\n",
      "2667 [D loss: (0.611)(R 0.651, F 0.571)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.477] [G acc: 0.016]\n",
      "2668 [D loss: (0.555)(R 0.535, F 0.574)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.379] [G acc: 0.094]\n",
      "2669 [D loss: (0.579)(R 0.531, F 0.627)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.403] [G acc: 0.047]\n",
      "2670 [D loss: (0.542)(R 0.590, F 0.494)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.257] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2671 [D loss: (0.581)(R 0.585, F 0.577)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.397] [G acc: 0.047]\n",
      "2672 [D loss: (0.575)(R 0.683, F 0.468)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.302] [G acc: 0.109]\n",
      "2673 [D loss: (0.532)(R 0.511, F 0.552)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.335] [G acc: 0.141]\n",
      "2674 [D loss: (0.564)(R 0.483, F 0.645)] [D acc: (0.719)(0.781, 0.656)] [G loss: 1.402] [G acc: 0.125]\n",
      "2675 [D loss: (0.569)(R 0.653, F 0.485)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.412] [G acc: 0.016]\n",
      "2676 [D loss: (0.493)(R 0.451, F 0.536)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.267] [G acc: 0.125]\n",
      "2677 [D loss: (0.535)(R 0.582, F 0.488)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.331] [G acc: 0.125]\n",
      "2678 [D loss: (0.564)(R 0.590, F 0.537)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.376] [G acc: 0.125]\n",
      "2679 [D loss: (0.604)(R 0.670, F 0.538)] [D acc: (0.656)(0.531, 0.781)] [G loss: 1.213] [G acc: 0.141]\n",
      "2680 [D loss: (0.573)(R 0.556, F 0.590)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.271] [G acc: 0.156]\n",
      "2681 [D loss: (0.569)(R 0.599, F 0.539)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.314] [G acc: 0.141]\n",
      "2682 [D loss: (0.585)(R 0.538, F 0.632)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.361] [G acc: 0.094]\n",
      "2683 [D loss: (0.523)(R 0.559, F 0.486)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.396] [G acc: 0.062]\n",
      "2684 [D loss: (0.568)(R 0.594, F 0.543)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.358] [G acc: 0.078]\n",
      "2685 [D loss: (0.539)(R 0.567, F 0.511)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.153] [G acc: 0.172]\n",
      "2686 [D loss: (0.597)(R 0.522, F 0.671)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.338] [G acc: 0.078]\n",
      "2687 [D loss: (0.499)(R 0.533, F 0.464)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.391] [G acc: 0.062]\n",
      "2688 [D loss: (0.475)(R 0.478, F 0.472)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.183] [G acc: 0.219]\n",
      "2689 [D loss: (0.604)(R 0.532, F 0.676)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.493] [G acc: 0.062]\n",
      "2690 [D loss: (0.584)(R 0.648, F 0.521)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.304] [G acc: 0.109]\n",
      "2691 [D loss: (0.570)(R 0.630, F 0.509)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.343] [G acc: 0.094]\n",
      "2692 [D loss: (0.584)(R 0.665, F 0.504)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.355] [G acc: 0.094]\n",
      "2693 [D loss: (0.533)(R 0.513, F 0.553)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.305] [G acc: 0.125]\n",
      "2694 [D loss: (0.622)(R 0.647, F 0.597)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.286] [G acc: 0.188]\n",
      "2695 [D loss: (0.538)(R 0.596, F 0.479)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.240] [G acc: 0.172]\n",
      "2696 [D loss: (0.496)(R 0.441, F 0.550)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.272] [G acc: 0.172]\n",
      "2697 [D loss: (0.629)(R 0.660, F 0.598)] [D acc: (0.609)(0.562, 0.656)] [G loss: 1.354] [G acc: 0.109]\n",
      "2698 [D loss: (0.599)(R 0.573, F 0.625)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.449] [G acc: 0.094]\n",
      "2699 [D loss: (0.492)(R 0.536, F 0.449)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.492] [G acc: 0.078]\n",
      "2700 [D loss: (0.571)(R 0.542, F 0.599)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.397] [G acc: 0.125]\n",
      "2701 [D loss: (0.550)(R 0.649, F 0.452)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.382] [G acc: 0.141]\n",
      "2702 [D loss: (0.467)(R 0.469, F 0.465)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.381] [G acc: 0.125]\n",
      "2703 [D loss: (0.582)(R 0.505, F 0.658)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.423] [G acc: 0.078]\n",
      "2704 [D loss: (0.633)(R 0.767, F 0.499)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.452] [G acc: 0.094]\n",
      "2705 [D loss: (0.541)(R 0.492, F 0.589)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.366] [G acc: 0.125]\n",
      "2706 [D loss: (0.525)(R 0.567, F 0.483)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.394] [G acc: 0.062]\n",
      "2707 [D loss: (0.572)(R 0.635, F 0.509)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.322] [G acc: 0.172]\n",
      "2708 [D loss: (0.516)(R 0.482, F 0.551)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.226] [G acc: 0.141]\n",
      "2709 [D loss: (0.535)(R 0.515, F 0.555)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.330] [G acc: 0.156]\n",
      "2710 [D loss: (0.537)(R 0.515, F 0.558)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.408] [G acc: 0.062]\n",
      "2711 [D loss: (0.591)(R 0.562, F 0.620)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.311] [G acc: 0.109]\n",
      "2712 [D loss: (0.585)(R 0.610, F 0.561)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.520] [G acc: 0.062]\n",
      "2713 [D loss: (0.509)(R 0.595, F 0.424)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.594] [G acc: 0.078]\n",
      "2714 [D loss: (0.575)(R 0.617, F 0.533)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.400] [G acc: 0.109]\n",
      "2715 [D loss: (0.576)(R 0.603, F 0.549)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.321] [G acc: 0.078]\n",
      "2716 [D loss: (0.442)(R 0.428, F 0.456)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.453] [G acc: 0.125]\n",
      "2717 [D loss: (0.445)(R 0.457, F 0.434)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.440] [G acc: 0.109]\n",
      "2718 [D loss: (0.570)(R 0.484, F 0.656)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.495] [G acc: 0.094]\n",
      "2719 [D loss: (0.583)(R 0.682, F 0.485)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.407] [G acc: 0.125]\n",
      "2720 [D loss: (0.537)(R 0.595, F 0.478)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.361] [G acc: 0.125]\n",
      "2721 [D loss: (0.519)(R 0.588, F 0.450)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.435] [G acc: 0.109]\n",
      "2722 [D loss: (0.586)(R 0.592, F 0.581)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.341] [G acc: 0.125]\n",
      "2723 [D loss: (0.536)(R 0.522, F 0.550)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.326] [G acc: 0.094]\n",
      "2724 [D loss: (0.513)(R 0.493, F 0.533)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.338] [G acc: 0.125]\n",
      "2725 [D loss: (0.595)(R 0.626, F 0.563)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.219] [G acc: 0.188]\n",
      "2726 [D loss: (0.559)(R 0.563, F 0.555)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.341] [G acc: 0.156]\n",
      "2727 [D loss: (0.528)(R 0.646, F 0.410)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.342] [G acc: 0.094]\n",
      "2728 [D loss: (0.540)(R 0.585, F 0.495)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.368] [G acc: 0.141]\n",
      "2729 [D loss: (0.549)(R 0.555, F 0.543)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.392] [G acc: 0.078]\n",
      "2730 [D loss: (0.550)(R 0.647, F 0.453)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.459] [G acc: 0.078]\n",
      "2731 [D loss: (0.572)(R 0.522, F 0.623)] [D acc: (0.633)(0.625, 0.641)] [G loss: 1.469] [G acc: 0.078]\n",
      "2732 [D loss: (0.533)(R 0.576, F 0.490)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.310] [G acc: 0.125]\n",
      "2733 [D loss: (0.574)(R 0.498, F 0.650)] [D acc: (0.703)(0.781, 0.625)] [G loss: 1.398] [G acc: 0.141]\n",
      "2734 [D loss: (0.593)(R 0.622, F 0.563)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.302] [G acc: 0.109]\n",
      "2735 [D loss: (0.593)(R 0.577, F 0.610)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.376] [G acc: 0.062]\n",
      "2736 [D loss: (0.623)(R 0.616, F 0.631)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.249] [G acc: 0.125]\n",
      "2737 [D loss: (0.488)(R 0.462, F 0.515)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.281] [G acc: 0.172]\n",
      "2738 [D loss: (0.503)(R 0.414, F 0.592)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.350] [G acc: 0.141]\n",
      "2739 [D loss: (0.554)(R 0.592, F 0.517)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.440] [G acc: 0.062]\n",
      "2740 [D loss: (0.611)(R 0.656, F 0.566)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.398] [G acc: 0.078]\n",
      "2741 [D loss: (0.567)(R 0.496, F 0.639)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.450] [G acc: 0.062]\n",
      "2742 [D loss: (0.566)(R 0.583, F 0.549)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.269] [G acc: 0.156]\n",
      "2743 [D loss: (0.555)(R 0.650, F 0.460)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.349] [G acc: 0.109]\n",
      "2744 [D loss: (0.514)(R 0.536, F 0.492)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.296] [G acc: 0.156]\n",
      "2745 [D loss: (0.537)(R 0.540, F 0.535)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.226] [G acc: 0.156]\n",
      "2746 [D loss: (0.550)(R 0.507, F 0.593)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.281] [G acc: 0.172]\n",
      "2747 [D loss: (0.528)(R 0.535, F 0.520)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.282] [G acc: 0.094]\n",
      "2748 [D loss: (0.503)(R 0.542, F 0.464)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.211] [G acc: 0.125]\n",
      "2749 [D loss: (0.550)(R 0.575, F 0.524)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.415] [G acc: 0.094]\n",
      "2750 [D loss: (0.494)(R 0.512, F 0.477)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.452] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2751 [D loss: (0.582)(R 0.581, F 0.582)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.475] [G acc: 0.094]\n",
      "2752 [D loss: (0.494)(R 0.505, F 0.483)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.318] [G acc: 0.156]\n",
      "2753 [D loss: (0.489)(R 0.416, F 0.561)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.490] [G acc: 0.109]\n",
      "2754 [D loss: (0.583)(R 0.598, F 0.568)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.478] [G acc: 0.078]\n",
      "2755 [D loss: (0.636)(R 0.666, F 0.605)] [D acc: (0.664)(0.547, 0.781)] [G loss: 1.357] [G acc: 0.047]\n",
      "2756 [D loss: (0.538)(R 0.585, F 0.492)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.318] [G acc: 0.031]\n",
      "2757 [D loss: (0.574)(R 0.595, F 0.552)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.429] [G acc: 0.125]\n",
      "2758 [D loss: (0.522)(R 0.519, F 0.525)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.360] [G acc: 0.109]\n",
      "2759 [D loss: (0.536)(R 0.575, F 0.497)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.341] [G acc: 0.156]\n",
      "2760 [D loss: (0.576)(R 0.534, F 0.619)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.437] [G acc: 0.062]\n",
      "2761 [D loss: (0.576)(R 0.630, F 0.521)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.496] [G acc: 0.078]\n",
      "2762 [D loss: (0.505)(R 0.575, F 0.435)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.425] [G acc: 0.125]\n",
      "2763 [D loss: (0.625)(R 0.762, F 0.488)] [D acc: (0.672)(0.531, 0.812)] [G loss: 1.406] [G acc: 0.047]\n",
      "2764 [D loss: (0.485)(R 0.420, F 0.550)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.225] [G acc: 0.125]\n",
      "2765 [D loss: (0.525)(R 0.455, F 0.595)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.344] [G acc: 0.109]\n",
      "2766 [D loss: (0.554)(R 0.575, F 0.533)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.374] [G acc: 0.062]\n",
      "2767 [D loss: (0.516)(R 0.429, F 0.603)] [D acc: (0.820)(0.797, 0.844)] [G loss: 1.387] [G acc: 0.016]\n",
      "2768 [D loss: (0.642)(R 0.655, F 0.628)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.397] [G acc: 0.125]\n",
      "2769 [D loss: (0.473)(R 0.559, F 0.387)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.376] [G acc: 0.094]\n",
      "2770 [D loss: (0.492)(R 0.455, F 0.529)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.374] [G acc: 0.078]\n",
      "2771 [D loss: (0.469)(R 0.449, F 0.490)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.608] [G acc: 0.062]\n",
      "2772 [D loss: (0.552)(R 0.554, F 0.549)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.474] [G acc: 0.078]\n",
      "2773 [D loss: (0.491)(R 0.523, F 0.459)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.509] [G acc: 0.125]\n",
      "2774 [D loss: (0.503)(R 0.497, F 0.510)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.461] [G acc: 0.109]\n",
      "2775 [D loss: (0.581)(R 0.524, F 0.637)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.157] [G acc: 0.156]\n",
      "2776 [D loss: (0.489)(R 0.547, F 0.432)] [D acc: (0.773)(0.641, 0.906)] [G loss: 1.557] [G acc: 0.031]\n",
      "2777 [D loss: (0.643)(R 0.716, F 0.570)] [D acc: (0.617)(0.531, 0.703)] [G loss: 1.234] [G acc: 0.141]\n",
      "2778 [D loss: (0.554)(R 0.610, F 0.499)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.396] [G acc: 0.062]\n",
      "2779 [D loss: (0.538)(R 0.477, F 0.600)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.397] [G acc: 0.109]\n",
      "2780 [D loss: (0.558)(R 0.654, F 0.462)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.280] [G acc: 0.125]\n",
      "2781 [D loss: (0.471)(R 0.509, F 0.434)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.303] [G acc: 0.078]\n",
      "2782 [D loss: (0.587)(R 0.532, F 0.642)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.303] [G acc: 0.125]\n",
      "2783 [D loss: (0.530)(R 0.515, F 0.544)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.640] [G acc: 0.094]\n",
      "2784 [D loss: (0.478)(R 0.491, F 0.466)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.497] [G acc: 0.031]\n",
      "2785 [D loss: (0.587)(R 0.554, F 0.620)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.533] [G acc: 0.188]\n",
      "2786 [D loss: (0.562)(R 0.660, F 0.465)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.474] [G acc: 0.141]\n",
      "2787 [D loss: (0.644)(R 0.739, F 0.549)] [D acc: (0.641)(0.516, 0.766)] [G loss: 1.219] [G acc: 0.078]\n",
      "2788 [D loss: (0.589)(R 0.539, F 0.639)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.399] [G acc: 0.047]\n",
      "2789 [D loss: (0.516)(R 0.629, F 0.403)] [D acc: (0.789)(0.625, 0.953)] [G loss: 1.325] [G acc: 0.109]\n",
      "2790 [D loss: (0.471)(R 0.452, F 0.489)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.426] [G acc: 0.078]\n",
      "2791 [D loss: (0.505)(R 0.522, F 0.487)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.286] [G acc: 0.125]\n",
      "2792 [D loss: (0.518)(R 0.557, F 0.479)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.274] [G acc: 0.172]\n",
      "2793 [D loss: (0.486)(R 0.537, F 0.435)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.262] [G acc: 0.203]\n",
      "2794 [D loss: (0.510)(R 0.454, F 0.566)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.528] [G acc: 0.062]\n",
      "2795 [D loss: (0.588)(R 0.660, F 0.517)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.528] [G acc: 0.078]\n",
      "2796 [D loss: (0.595)(R 0.415, F 0.775)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.468] [G acc: 0.078]\n",
      "2797 [D loss: (0.583)(R 0.673, F 0.493)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.387] [G acc: 0.094]\n",
      "2798 [D loss: (0.588)(R 0.633, F 0.543)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.454] [G acc: 0.062]\n",
      "2799 [D loss: (0.568)(R 0.644, F 0.493)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.388] [G acc: 0.109]\n",
      "2800 [D loss: (0.557)(R 0.603, F 0.510)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.343] [G acc: 0.141]\n",
      "2801 [D loss: (0.611)(R 0.541, F 0.680)] [D acc: (0.664)(0.703, 0.625)] [G loss: 1.375] [G acc: 0.125]\n",
      "2802 [D loss: (0.556)(R 0.623, F 0.488)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.272] [G acc: 0.125]\n",
      "2803 [D loss: (0.627)(R 0.594, F 0.661)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.510] [G acc: 0.062]\n",
      "2804 [D loss: (0.542)(R 0.611, F 0.473)] [D acc: (0.711)(0.531, 0.891)] [G loss: 1.270] [G acc: 0.125]\n",
      "2805 [D loss: (0.589)(R 0.410, F 0.769)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.333] [G acc: 0.078]\n",
      "2806 [D loss: (0.567)(R 0.661, F 0.473)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.243] [G acc: 0.078]\n",
      "2807 [D loss: (0.611)(R 0.681, F 0.541)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.335] [G acc: 0.141]\n",
      "2808 [D loss: (0.493)(R 0.463, F 0.523)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.296] [G acc: 0.188]\n",
      "2809 [D loss: (0.629)(R 0.630, F 0.627)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.377] [G acc: 0.016]\n",
      "2810 [D loss: (0.509)(R 0.589, F 0.429)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.322] [G acc: 0.125]\n",
      "2811 [D loss: (0.545)(R 0.593, F 0.498)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.342] [G acc: 0.141]\n",
      "2812 [D loss: (0.545)(R 0.515, F 0.574)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.332] [G acc: 0.047]\n",
      "2813 [D loss: (0.551)(R 0.590, F 0.512)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.182] [G acc: 0.125]\n",
      "2814 [D loss: (0.497)(R 0.497, F 0.497)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.511] [G acc: 0.141]\n",
      "2815 [D loss: (0.519)(R 0.541, F 0.497)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.557] [G acc: 0.047]\n",
      "2816 [D loss: (0.518)(R 0.539, F 0.498)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.462] [G acc: 0.078]\n",
      "2817 [D loss: (0.543)(R 0.625, F 0.461)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.332] [G acc: 0.109]\n",
      "2818 [D loss: (0.596)(R 0.519, F 0.672)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.428] [G acc: 0.031]\n",
      "2819 [D loss: (0.521)(R 0.598, F 0.444)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.449] [G acc: 0.078]\n",
      "2820 [D loss: (0.570)(R 0.649, F 0.491)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.338] [G acc: 0.062]\n",
      "2821 [D loss: (0.544)(R 0.412, F 0.677)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.374] [G acc: 0.094]\n",
      "2822 [D loss: (0.556)(R 0.579, F 0.533)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.414] [G acc: 0.094]\n",
      "2823 [D loss: (0.585)(R 0.570, F 0.600)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.421] [G acc: 0.062]\n",
      "2824 [D loss: (0.555)(R 0.672, F 0.439)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.388] [G acc: 0.078]\n",
      "2825 [D loss: (0.533)(R 0.575, F 0.492)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.506] [G acc: 0.125]\n",
      "2826 [D loss: (0.493)(R 0.486, F 0.499)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.583] [G acc: 0.094]\n",
      "2827 [D loss: (0.493)(R 0.479, F 0.508)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.453] [G acc: 0.109]\n",
      "2828 [D loss: (0.540)(R 0.601, F 0.478)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.380] [G acc: 0.094]\n",
      "2829 [D loss: (0.599)(R 0.535, F 0.662)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.323] [G acc: 0.141]\n",
      "2830 [D loss: (0.475)(R 0.539, F 0.411)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.415] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831 [D loss: (0.551)(R 0.506, F 0.596)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.348] [G acc: 0.094]\n",
      "2832 [D loss: (0.498)(R 0.502, F 0.494)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.302] [G acc: 0.203]\n",
      "2833 [D loss: (0.557)(R 0.550, F 0.565)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.334] [G acc: 0.156]\n",
      "2834 [D loss: (0.512)(R 0.551, F 0.473)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.411] [G acc: 0.156]\n",
      "2835 [D loss: (0.479)(R 0.491, F 0.467)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.381] [G acc: 0.203]\n",
      "2836 [D loss: (0.622)(R 0.486, F 0.759)] [D acc: (0.680)(0.734, 0.625)] [G loss: 1.449] [G acc: 0.141]\n",
      "2837 [D loss: (0.613)(R 0.625, F 0.601)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.329] [G acc: 0.141]\n",
      "2838 [D loss: (0.623)(R 0.689, F 0.557)] [D acc: (0.633)(0.562, 0.703)] [G loss: 1.366] [G acc: 0.062]\n",
      "2839 [D loss: (0.620)(R 0.706, F 0.533)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.394] [G acc: 0.094]\n",
      "2840 [D loss: (0.491)(R 0.500, F 0.482)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.500] [G acc: 0.047]\n",
      "2841 [D loss: (0.447)(R 0.426, F 0.468)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.394] [G acc: 0.031]\n",
      "2842 [D loss: (0.634)(R 0.645, F 0.622)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.488] [G acc: 0.078]\n",
      "2843 [D loss: (0.586)(R 0.715, F 0.457)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.242] [G acc: 0.172]\n",
      "2844 [D loss: (0.490)(R 0.533, F 0.446)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.283] [G acc: 0.094]\n",
      "2845 [D loss: (0.531)(R 0.583, F 0.479)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.364] [G acc: 0.094]\n",
      "2846 [D loss: (0.532)(R 0.450, F 0.613)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.374] [G acc: 0.094]\n",
      "2847 [D loss: (0.511)(R 0.573, F 0.449)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.282] [G acc: 0.125]\n",
      "2848 [D loss: (0.526)(R 0.515, F 0.538)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.457] [G acc: 0.094]\n",
      "2849 [D loss: (0.527)(R 0.480, F 0.574)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.289] [G acc: 0.109]\n",
      "2850 [D loss: (0.480)(R 0.493, F 0.468)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.490] [G acc: 0.141]\n",
      "2851 [D loss: (0.489)(R 0.484, F 0.495)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.448] [G acc: 0.078]\n",
      "2852 [D loss: (0.533)(R 0.596, F 0.470)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.170] [G acc: 0.250]\n",
      "2853 [D loss: (0.622)(R 0.505, F 0.739)] [D acc: (0.680)(0.703, 0.656)] [G loss: 1.254] [G acc: 0.062]\n",
      "2854 [D loss: (0.578)(R 0.695, F 0.460)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.236] [G acc: 0.172]\n",
      "2855 [D loss: (0.531)(R 0.562, F 0.500)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.369] [G acc: 0.094]\n",
      "2856 [D loss: (0.553)(R 0.562, F 0.543)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.363] [G acc: 0.125]\n",
      "2857 [D loss: (0.500)(R 0.505, F 0.495)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.311] [G acc: 0.062]\n",
      "2858 [D loss: (0.559)(R 0.568, F 0.550)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.334] [G acc: 0.062]\n",
      "2859 [D loss: (0.604)(R 0.616, F 0.593)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.485] [G acc: 0.062]\n",
      "2860 [D loss: (0.527)(R 0.660, F 0.394)] [D acc: (0.742)(0.562, 0.922)] [G loss: 1.163] [G acc: 0.219]\n",
      "2861 [D loss: (0.648)(R 0.574, F 0.722)] [D acc: (0.633)(0.672, 0.594)] [G loss: 1.286] [G acc: 0.109]\n",
      "2862 [D loss: (0.592)(R 0.670, F 0.514)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.234] [G acc: 0.172]\n",
      "2863 [D loss: (0.573)(R 0.623, F 0.522)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.440] [G acc: 0.078]\n",
      "2864 [D loss: (0.611)(R 0.599, F 0.622)] [D acc: (0.617)(0.594, 0.641)] [G loss: 1.192] [G acc: 0.141]\n",
      "2865 [D loss: (0.550)(R 0.542, F 0.559)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.218] [G acc: 0.125]\n",
      "2866 [D loss: (0.546)(R 0.567, F 0.526)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.266] [G acc: 0.109]\n",
      "2867 [D loss: (0.414)(R 0.443, F 0.385)] [D acc: (0.828)(0.766, 0.891)] [G loss: 1.397] [G acc: 0.125]\n",
      "2868 [D loss: (0.518)(R 0.439, F 0.597)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.387] [G acc: 0.094]\n",
      "2869 [D loss: (0.546)(R 0.510, F 0.582)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.250] [G acc: 0.141]\n",
      "2870 [D loss: (0.583)(R 0.604, F 0.562)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.376] [G acc: 0.109]\n",
      "2871 [D loss: (0.533)(R 0.630, F 0.436)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.300] [G acc: 0.109]\n",
      "2872 [D loss: (0.563)(R 0.594, F 0.532)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.362] [G acc: 0.094]\n",
      "2873 [D loss: (0.503)(R 0.516, F 0.490)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.341] [G acc: 0.172]\n",
      "2874 [D loss: (0.517)(R 0.517, F 0.516)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.373] [G acc: 0.109]\n",
      "2875 [D loss: (0.639)(R 0.654, F 0.624)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.323] [G acc: 0.109]\n",
      "2876 [D loss: (0.652)(R 0.691, F 0.614)] [D acc: (0.633)(0.516, 0.750)] [G loss: 1.399] [G acc: 0.094]\n",
      "2877 [D loss: (0.449)(R 0.460, F 0.438)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.279] [G acc: 0.188]\n",
      "2878 [D loss: (0.625)(R 0.537, F 0.712)] [D acc: (0.672)(0.688, 0.656)] [G loss: 1.605] [G acc: 0.047]\n",
      "2879 [D loss: (0.563)(R 0.556, F 0.569)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.288] [G acc: 0.172]\n",
      "2880 [D loss: (0.537)(R 0.582, F 0.492)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.241] [G acc: 0.125]\n",
      "2881 [D loss: (0.471)(R 0.503, F 0.439)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.462] [G acc: 0.109]\n",
      "2882 [D loss: (0.543)(R 0.586, F 0.501)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.432] [G acc: 0.047]\n",
      "2883 [D loss: (0.481)(R 0.445, F 0.516)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.353] [G acc: 0.078]\n",
      "2884 [D loss: (0.537)(R 0.504, F 0.571)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.441] [G acc: 0.078]\n",
      "2885 [D loss: (0.517)(R 0.558, F 0.476)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.301] [G acc: 0.125]\n",
      "2886 [D loss: (0.663)(R 0.706, F 0.620)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.387] [G acc: 0.062]\n",
      "2887 [D loss: (0.565)(R 0.626, F 0.503)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.470] [G acc: 0.078]\n",
      "2888 [D loss: (0.500)(R 0.460, F 0.539)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.490] [G acc: 0.078]\n",
      "2889 [D loss: (0.532)(R 0.588, F 0.476)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.379] [G acc: 0.062]\n",
      "2890 [D loss: (0.583)(R 0.610, F 0.556)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.262] [G acc: 0.109]\n",
      "2891 [D loss: (0.506)(R 0.553, F 0.460)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.402] [G acc: 0.078]\n",
      "2892 [D loss: (0.525)(R 0.480, F 0.571)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.385] [G acc: 0.172]\n",
      "2893 [D loss: (0.493)(R 0.494, F 0.492)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.425] [G acc: 0.078]\n",
      "2894 [D loss: (0.614)(R 0.710, F 0.517)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.378] [G acc: 0.062]\n",
      "2895 [D loss: (0.556)(R 0.484, F 0.628)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.372] [G acc: 0.094]\n",
      "2896 [D loss: (0.559)(R 0.661, F 0.458)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.316] [G acc: 0.031]\n",
      "2897 [D loss: (0.498)(R 0.528, F 0.468)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.331] [G acc: 0.031]\n",
      "2898 [D loss: (0.425)(R 0.431, F 0.419)] [D acc: (0.820)(0.734, 0.906)] [G loss: 1.430] [G acc: 0.094]\n",
      "2899 [D loss: (0.567)(R 0.603, F 0.531)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.432] [G acc: 0.094]\n",
      "2900 [D loss: (0.534)(R 0.578, F 0.489)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.356] [G acc: 0.078]\n",
      "2901 [D loss: (0.540)(R 0.449, F 0.631)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.246] [G acc: 0.125]\n",
      "2902 [D loss: (0.585)(R 0.580, F 0.589)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.381] [G acc: 0.047]\n",
      "2903 [D loss: (0.595)(R 0.693, F 0.497)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.277] [G acc: 0.156]\n",
      "2904 [D loss: (0.469)(R 0.484, F 0.455)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.498] [G acc: 0.125]\n",
      "2905 [D loss: (0.639)(R 0.522, F 0.755)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.480] [G acc: 0.109]\n",
      "2906 [D loss: (0.582)(R 0.615, F 0.548)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.392] [G acc: 0.062]\n",
      "2907 [D loss: (0.542)(R 0.635, F 0.449)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.394] [G acc: 0.047]\n",
      "2908 [D loss: (0.515)(R 0.483, F 0.547)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.375] [G acc: 0.141]\n",
      "2909 [D loss: (0.451)(R 0.391, F 0.511)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.548] [G acc: 0.047]\n",
      "2910 [D loss: (0.490)(R 0.504, F 0.475)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.314] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2911 [D loss: (0.490)(R 0.460, F 0.520)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.481] [G acc: 0.109]\n",
      "2912 [D loss: (0.606)(R 0.547, F 0.666)] [D acc: (0.633)(0.609, 0.656)] [G loss: 1.436] [G acc: 0.062]\n",
      "2913 [D loss: (0.599)(R 0.702, F 0.496)] [D acc: (0.656)(0.531, 0.781)] [G loss: 1.225] [G acc: 0.125]\n",
      "2914 [D loss: (0.526)(R 0.458, F 0.595)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.302] [G acc: 0.141]\n",
      "2915 [D loss: (0.567)(R 0.589, F 0.546)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.379] [G acc: 0.109]\n",
      "2916 [D loss: (0.553)(R 0.594, F 0.513)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.211] [G acc: 0.203]\n",
      "2917 [D loss: (0.522)(R 0.537, F 0.507)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.409] [G acc: 0.078]\n",
      "2918 [D loss: (0.593)(R 0.585, F 0.601)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.344] [G acc: 0.156]\n",
      "2919 [D loss: (0.463)(R 0.474, F 0.452)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.463] [G acc: 0.078]\n",
      "2920 [D loss: (0.546)(R 0.562, F 0.531)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.445] [G acc: 0.188]\n",
      "2921 [D loss: (0.596)(R 0.575, F 0.617)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.220] [G acc: 0.141]\n",
      "2922 [D loss: (0.608)(R 0.534, F 0.681)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.336] [G acc: 0.109]\n",
      "2923 [D loss: (0.598)(R 0.596, F 0.601)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.181] [G acc: 0.141]\n",
      "2924 [D loss: (0.518)(R 0.521, F 0.515)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.483] [G acc: 0.078]\n",
      "2925 [D loss: (0.612)(R 0.588, F 0.637)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.428] [G acc: 0.016]\n",
      "2926 [D loss: (0.577)(R 0.603, F 0.551)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.347] [G acc: 0.031]\n",
      "2927 [D loss: (0.516)(R 0.633, F 0.399)] [D acc: (0.719)(0.516, 0.922)] [G loss: 1.306] [G acc: 0.062]\n",
      "2928 [D loss: (0.598)(R 0.672, F 0.524)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.271] [G acc: 0.141]\n",
      "2929 [D loss: (0.571)(R 0.497, F 0.645)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.403] [G acc: 0.094]\n",
      "2930 [D loss: (0.523)(R 0.583, F 0.463)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.328] [G acc: 0.078]\n",
      "2931 [D loss: (0.535)(R 0.484, F 0.586)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.373] [G acc: 0.062]\n",
      "2932 [D loss: (0.550)(R 0.601, F 0.499)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.434] [G acc: 0.016]\n",
      "2933 [D loss: (0.523)(R 0.606, F 0.439)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.356] [G acc: 0.203]\n",
      "2934 [D loss: (0.521)(R 0.489, F 0.553)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.370] [G acc: 0.141]\n",
      "2935 [D loss: (0.563)(R 0.618, F 0.508)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.394] [G acc: 0.062]\n",
      "2936 [D loss: (0.536)(R 0.498, F 0.574)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.387] [G acc: 0.125]\n",
      "2937 [D loss: (0.515)(R 0.493, F 0.536)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.432] [G acc: 0.109]\n",
      "2938 [D loss: (0.568)(R 0.614, F 0.522)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.460] [G acc: 0.078]\n",
      "2939 [D loss: (0.551)(R 0.609, F 0.492)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.491] [G acc: 0.031]\n",
      "2940 [D loss: (0.432)(R 0.368, F 0.496)] [D acc: (0.805)(0.812, 0.797)] [G loss: 1.410] [G acc: 0.000]\n",
      "2941 [D loss: (0.637)(R 0.796, F 0.478)] [D acc: (0.641)(0.453, 0.828)] [G loss: 1.347] [G acc: 0.125]\n",
      "2942 [D loss: (0.568)(R 0.584, F 0.552)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.258] [G acc: 0.172]\n",
      "2943 [D loss: (0.586)(R 0.676, F 0.496)] [D acc: (0.672)(0.531, 0.812)] [G loss: 1.246] [G acc: 0.125]\n",
      "2944 [D loss: (0.519)(R 0.455, F 0.583)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.435] [G acc: 0.062]\n",
      "2945 [D loss: (0.531)(R 0.550, F 0.512)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.251] [G acc: 0.094]\n",
      "2946 [D loss: (0.509)(R 0.606, F 0.413)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.439] [G acc: 0.109]\n",
      "2947 [D loss: (0.523)(R 0.497, F 0.548)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.266] [G acc: 0.156]\n",
      "2948 [D loss: (0.533)(R 0.568, F 0.497)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.341] [G acc: 0.125]\n",
      "2949 [D loss: (0.558)(R 0.543, F 0.573)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.308] [G acc: 0.109]\n",
      "2950 [D loss: (0.538)(R 0.579, F 0.497)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.455] [G acc: 0.062]\n",
      "2951 [D loss: (0.527)(R 0.465, F 0.589)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.310] [G acc: 0.078]\n",
      "2952 [D loss: (0.507)(R 0.556, F 0.458)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.491] [G acc: 0.078]\n",
      "2953 [D loss: (0.572)(R 0.472, F 0.673)] [D acc: (0.695)(0.734, 0.656)] [G loss: 1.453] [G acc: 0.109]\n",
      "2954 [D loss: (0.518)(R 0.513, F 0.524)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.575] [G acc: 0.047]\n",
      "2955 [D loss: (0.460)(R 0.509, F 0.411)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.532] [G acc: 0.141]\n",
      "2956 [D loss: (0.541)(R 0.573, F 0.509)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.516] [G acc: 0.078]\n",
      "2957 [D loss: (0.492)(R 0.490, F 0.494)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.464] [G acc: 0.078]\n",
      "2958 [D loss: (0.548)(R 0.521, F 0.576)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.497] [G acc: 0.062]\n",
      "2959 [D loss: (0.595)(R 0.716, F 0.474)] [D acc: (0.672)(0.531, 0.812)] [G loss: 1.607] [G acc: 0.078]\n",
      "2960 [D loss: (0.548)(R 0.565, F 0.531)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.314] [G acc: 0.031]\n",
      "2961 [D loss: (0.571)(R 0.612, F 0.529)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.344] [G acc: 0.125]\n",
      "2962 [D loss: (0.577)(R 0.581, F 0.574)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.366] [G acc: 0.141]\n",
      "2963 [D loss: (0.538)(R 0.416, F 0.660)] [D acc: (0.727)(0.766, 0.688)] [G loss: 1.369] [G acc: 0.125]\n",
      "2964 [D loss: (0.545)(R 0.568, F 0.522)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.338] [G acc: 0.141]\n",
      "2965 [D loss: (0.425)(R 0.445, F 0.406)] [D acc: (0.812)(0.734, 0.891)] [G loss: 1.489] [G acc: 0.125]\n",
      "2966 [D loss: (0.590)(R 0.625, F 0.555)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.417] [G acc: 0.031]\n",
      "2967 [D loss: (0.646)(R 0.717, F 0.576)] [D acc: (0.641)(0.469, 0.812)] [G loss: 1.185] [G acc: 0.203]\n",
      "2968 [D loss: (0.535)(R 0.554, F 0.516)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.401] [G acc: 0.109]\n",
      "2969 [D loss: (0.560)(R 0.530, F 0.590)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.323] [G acc: 0.062]\n",
      "2970 [D loss: (0.565)(R 0.606, F 0.524)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.310] [G acc: 0.203]\n",
      "2971 [D loss: (0.495)(R 0.498, F 0.492)] [D acc: (0.812)(0.734, 0.891)] [G loss: 1.373] [G acc: 0.062]\n",
      "2972 [D loss: (0.476)(R 0.434, F 0.519)] [D acc: (0.812)(0.844, 0.781)] [G loss: 1.414] [G acc: 0.141]\n",
      "2973 [D loss: (0.483)(R 0.474, F 0.492)] [D acc: (0.789)(0.797, 0.781)] [G loss: 1.543] [G acc: 0.094]\n",
      "2974 [D loss: (0.506)(R 0.527, F 0.484)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.448] [G acc: 0.109]\n",
      "2975 [D loss: (0.693)(R 0.715, F 0.671)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.675] [G acc: 0.047]\n",
      "2976 [D loss: (0.589)(R 0.729, F 0.449)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.349] [G acc: 0.109]\n",
      "2977 [D loss: (0.507)(R 0.483, F 0.532)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.337] [G acc: 0.141]\n",
      "2978 [D loss: (0.622)(R 0.674, F 0.570)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.166] [G acc: 0.250]\n",
      "2979 [D loss: (0.529)(R 0.528, F 0.530)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.314] [G acc: 0.141]\n",
      "2980 [D loss: (0.557)(R 0.559, F 0.555)] [D acc: (0.680)(0.688, 0.672)] [G loss: 1.509] [G acc: 0.031]\n",
      "2981 [D loss: (0.530)(R 0.511, F 0.548)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.415] [G acc: 0.109]\n",
      "2982 [D loss: (0.518)(R 0.608, F 0.427)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.438] [G acc: 0.188]\n",
      "2983 [D loss: (0.548)(R 0.529, F 0.567)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.426] [G acc: 0.078]\n",
      "2984 [D loss: (0.509)(R 0.553, F 0.465)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.333] [G acc: 0.109]\n",
      "2985 [D loss: (0.546)(R 0.501, F 0.591)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.456] [G acc: 0.094]\n",
      "2986 [D loss: (0.487)(R 0.528, F 0.445)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.432] [G acc: 0.125]\n",
      "2987 [D loss: (0.512)(R 0.579, F 0.445)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.469] [G acc: 0.062]\n",
      "2988 [D loss: (0.534)(R 0.570, F 0.498)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.432] [G acc: 0.109]\n",
      "2989 [D loss: (0.524)(R 0.516, F 0.532)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.331] [G acc: 0.172]\n",
      "2990 [D loss: (0.536)(R 0.543, F 0.529)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.564] [G acc: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2991 [D loss: (0.513)(R 0.553, F 0.473)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.535] [G acc: 0.109]\n",
      "2992 [D loss: (0.571)(R 0.564, F 0.579)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.386] [G acc: 0.156]\n",
      "2993 [D loss: (0.619)(R 0.557, F 0.681)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.527] [G acc: 0.094]\n",
      "2994 [D loss: (0.579)(R 0.662, F 0.495)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.413] [G acc: 0.094]\n",
      "2995 [D loss: (0.532)(R 0.603, F 0.461)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.416] [G acc: 0.141]\n",
      "2996 [D loss: (0.457)(R 0.461, F 0.454)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.475] [G acc: 0.094]\n",
      "2997 [D loss: (0.551)(R 0.559, F 0.542)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.501] [G acc: 0.094]\n",
      "2998 [D loss: (0.529)(R 0.532, F 0.526)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.378] [G acc: 0.141]\n",
      "2999 [D loss: (0.590)(R 0.674, F 0.507)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.317] [G acc: 0.109]\n",
      "3000 [D loss: (0.519)(R 0.501, F 0.537)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.389] [G acc: 0.172]\n",
      "3001 [D loss: (0.596)(R 0.685, F 0.507)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.417] [G acc: 0.141]\n",
      "3002 [D loss: (0.587)(R 0.609, F 0.565)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.301] [G acc: 0.219]\n",
      "3003 [D loss: (0.588)(R 0.564, F 0.612)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.383] [G acc: 0.141]\n",
      "3004 [D loss: (0.624)(R 0.677, F 0.570)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.355] [G acc: 0.094]\n",
      "3005 [D loss: (0.530)(R 0.575, F 0.486)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.286] [G acc: 0.109]\n",
      "3006 [D loss: (0.509)(R 0.506, F 0.512)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.282] [G acc: 0.156]\n",
      "3007 [D loss: (0.535)(R 0.486, F 0.584)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.276] [G acc: 0.156]\n",
      "3008 [D loss: (0.531)(R 0.451, F 0.612)] [D acc: (0.758)(0.797, 0.719)] [G loss: 1.478] [G acc: 0.031]\n",
      "3009 [D loss: (0.597)(R 0.544, F 0.651)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.307] [G acc: 0.109]\n",
      "3010 [D loss: (0.560)(R 0.661, F 0.459)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.550] [G acc: 0.031]\n",
      "3011 [D loss: (0.554)(R 0.583, F 0.526)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.369] [G acc: 0.094]\n",
      "3012 [D loss: (0.506)(R 0.506, F 0.505)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.613] [G acc: 0.031]\n",
      "3013 [D loss: (0.526)(R 0.606, F 0.446)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.384] [G acc: 0.078]\n",
      "3014 [D loss: (0.546)(R 0.500, F 0.592)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.401] [G acc: 0.062]\n",
      "3015 [D loss: (0.628)(R 0.777, F 0.478)] [D acc: (0.664)(0.500, 0.828)] [G loss: 1.247] [G acc: 0.141]\n",
      "3016 [D loss: (0.473)(R 0.491, F 0.455)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.334] [G acc: 0.109]\n",
      "3017 [D loss: (0.578)(R 0.605, F 0.550)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.264] [G acc: 0.094]\n",
      "3018 [D loss: (0.512)(R 0.475, F 0.548)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.375] [G acc: 0.078]\n",
      "3019 [D loss: (0.565)(R 0.602, F 0.528)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.414] [G acc: 0.156]\n",
      "3020 [D loss: (0.529)(R 0.538, F 0.520)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.538] [G acc: 0.078]\n",
      "3021 [D loss: (0.580)(R 0.628, F 0.533)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.419] [G acc: 0.078]\n",
      "3022 [D loss: (0.511)(R 0.495, F 0.527)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.302] [G acc: 0.109]\n",
      "3023 [D loss: (0.585)(R 0.599, F 0.572)] [D acc: (0.648)(0.656, 0.641)] [G loss: 1.399] [G acc: 0.047]\n",
      "3024 [D loss: (0.524)(R 0.516, F 0.532)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.445] [G acc: 0.062]\n",
      "3025 [D loss: (0.552)(R 0.465, F 0.639)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.395] [G acc: 0.094]\n",
      "3026 [D loss: (0.574)(R 0.671, F 0.477)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.405] [G acc: 0.109]\n",
      "3027 [D loss: (0.525)(R 0.564, F 0.486)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.366] [G acc: 0.156]\n",
      "3028 [D loss: (0.528)(R 0.514, F 0.541)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.527] [G acc: 0.141]\n",
      "3029 [D loss: (0.544)(R 0.516, F 0.572)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.450] [G acc: 0.078]\n",
      "3030 [D loss: (0.552)(R 0.537, F 0.567)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.482] [G acc: 0.078]\n",
      "3031 [D loss: (0.494)(R 0.566, F 0.422)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.454] [G acc: 0.031]\n",
      "3032 [D loss: (0.612)(R 0.493, F 0.732)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.494] [G acc: 0.125]\n",
      "3033 [D loss: (0.494)(R 0.562, F 0.426)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.410] [G acc: 0.141]\n",
      "3034 [D loss: (0.530)(R 0.590, F 0.469)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.448] [G acc: 0.094]\n",
      "3035 [D loss: (0.529)(R 0.541, F 0.518)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.439] [G acc: 0.109]\n",
      "3036 [D loss: (0.615)(R 0.673, F 0.556)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.463] [G acc: 0.078]\n",
      "3037 [D loss: (0.520)(R 0.434, F 0.606)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.362] [G acc: 0.156]\n",
      "3038 [D loss: (0.503)(R 0.564, F 0.442)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.524] [G acc: 0.062]\n",
      "3039 [D loss: (0.524)(R 0.563, F 0.485)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.434] [G acc: 0.125]\n",
      "3040 [D loss: (0.532)(R 0.590, F 0.474)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.533] [G acc: 0.094]\n",
      "3041 [D loss: (0.639)(R 0.605, F 0.673)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.345] [G acc: 0.094]\n",
      "3042 [D loss: (0.574)(R 0.595, F 0.553)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.403] [G acc: 0.094]\n",
      "3043 [D loss: (0.513)(R 0.535, F 0.492)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.350] [G acc: 0.094]\n",
      "3044 [D loss: (0.599)(R 0.539, F 0.660)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.400] [G acc: 0.109]\n",
      "3045 [D loss: (0.539)(R 0.644, F 0.435)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.361] [G acc: 0.141]\n",
      "3046 [D loss: (0.511)(R 0.512, F 0.511)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.304] [G acc: 0.156]\n",
      "3047 [D loss: (0.433)(R 0.386, F 0.481)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.471] [G acc: 0.125]\n",
      "3048 [D loss: (0.617)(R 0.677, F 0.556)] [D acc: (0.641)(0.562, 0.719)] [G loss: 1.285] [G acc: 0.109]\n",
      "3049 [D loss: (0.476)(R 0.503, F 0.450)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.531] [G acc: 0.109]\n",
      "3050 [D loss: (0.540)(R 0.519, F 0.561)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.450] [G acc: 0.156]\n",
      "3051 [D loss: (0.475)(R 0.455, F 0.495)] [D acc: (0.805)(0.750, 0.859)] [G loss: 1.391] [G acc: 0.172]\n",
      "3052 [D loss: (0.675)(R 0.710, F 0.640)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.307] [G acc: 0.188]\n",
      "3053 [D loss: (0.518)(R 0.433, F 0.602)] [D acc: (0.695)(0.766, 0.625)] [G loss: 1.519] [G acc: 0.078]\n",
      "3054 [D loss: (0.519)(R 0.502, F 0.535)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.440] [G acc: 0.125]\n",
      "3055 [D loss: (0.614)(R 0.679, F 0.549)] [D acc: (0.633)(0.641, 0.625)] [G loss: 1.401] [G acc: 0.141]\n",
      "3056 [D loss: (0.543)(R 0.541, F 0.545)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.504] [G acc: 0.078]\n",
      "3057 [D loss: (0.600)(R 0.712, F 0.488)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.260] [G acc: 0.172]\n",
      "3058 [D loss: (0.511)(R 0.484, F 0.538)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.452] [G acc: 0.172]\n",
      "3059 [D loss: (0.478)(R 0.508, F 0.448)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.490] [G acc: 0.125]\n",
      "3060 [D loss: (0.624)(R 0.523, F 0.726)] [D acc: (0.641)(0.703, 0.578)] [G loss: 1.485] [G acc: 0.031]\n",
      "3061 [D loss: (0.590)(R 0.666, F 0.513)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.325] [G acc: 0.094]\n",
      "3062 [D loss: (0.655)(R 0.702, F 0.608)] [D acc: (0.633)(0.547, 0.719)] [G loss: 1.239] [G acc: 0.172]\n",
      "3063 [D loss: (0.605)(R 0.692, F 0.518)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.337] [G acc: 0.125]\n",
      "3064 [D loss: (0.546)(R 0.524, F 0.568)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.293] [G acc: 0.062]\n",
      "3065 [D loss: (0.568)(R 0.605, F 0.531)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.226] [G acc: 0.188]\n",
      "3066 [D loss: (0.568)(R 0.529, F 0.607)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.369] [G acc: 0.125]\n",
      "3067 [D loss: (0.601)(R 0.569, F 0.633)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.286] [G acc: 0.141]\n",
      "3068 [D loss: (0.497)(R 0.537, F 0.456)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.378] [G acc: 0.109]\n",
      "3069 [D loss: (0.574)(R 0.586, F 0.563)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.351] [G acc: 0.125]\n",
      "3070 [D loss: (0.518)(R 0.480, F 0.557)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.268] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3071 [D loss: (0.717)(R 0.658, F 0.776)] [D acc: (0.609)(0.562, 0.656)] [G loss: 1.338] [G acc: 0.000]\n",
      "3072 [D loss: (0.660)(R 0.876, F 0.443)] [D acc: (0.625)(0.406, 0.844)] [G loss: 1.406] [G acc: 0.078]\n",
      "3073 [D loss: (0.514)(R 0.541, F 0.487)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.217] [G acc: 0.141]\n",
      "3074 [D loss: (0.602)(R 0.587, F 0.616)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.153] [G acc: 0.219]\n",
      "3075 [D loss: (0.630)(R 0.587, F 0.673)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.278] [G acc: 0.141]\n",
      "3076 [D loss: (0.524)(R 0.582, F 0.466)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.270] [G acc: 0.094]\n",
      "3077 [D loss: (0.561)(R 0.544, F 0.577)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.158] [G acc: 0.188]\n",
      "3078 [D loss: (0.507)(R 0.577, F 0.438)] [D acc: (0.734)(0.562, 0.906)] [G loss: 1.262] [G acc: 0.156]\n",
      "3079 [D loss: (0.579)(R 0.502, F 0.656)] [D acc: (0.656)(0.672, 0.641)] [G loss: 1.366] [G acc: 0.078]\n",
      "3080 [D loss: (0.496)(R 0.486, F 0.506)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.439] [G acc: 0.078]\n",
      "3081 [D loss: (0.479)(R 0.500, F 0.458)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.248] [G acc: 0.094]\n",
      "3082 [D loss: (0.602)(R 0.563, F 0.641)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.320] [G acc: 0.125]\n",
      "3083 [D loss: (0.570)(R 0.626, F 0.513)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.339] [G acc: 0.109]\n",
      "3084 [D loss: (0.479)(R 0.500, F 0.458)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.400] [G acc: 0.094]\n",
      "3085 [D loss: (0.517)(R 0.579, F 0.456)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.235] [G acc: 0.156]\n",
      "3086 [D loss: (0.565)(R 0.430, F 0.701)] [D acc: (0.703)(0.750, 0.656)] [G loss: 1.376] [G acc: 0.062]\n",
      "3087 [D loss: (0.458)(R 0.503, F 0.413)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.350] [G acc: 0.156]\n",
      "3088 [D loss: (0.537)(R 0.559, F 0.515)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.487] [G acc: 0.094]\n",
      "3089 [D loss: (0.537)(R 0.520, F 0.554)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.379] [G acc: 0.109]\n",
      "3090 [D loss: (0.554)(R 0.610, F 0.498)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.317] [G acc: 0.125]\n",
      "3091 [D loss: (0.550)(R 0.479, F 0.622)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.270] [G acc: 0.156]\n",
      "3092 [D loss: (0.578)(R 0.568, F 0.588)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.336] [G acc: 0.094]\n",
      "3093 [D loss: (0.492)(R 0.454, F 0.529)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.427] [G acc: 0.062]\n",
      "3094 [D loss: (0.605)(R 0.676, F 0.534)] [D acc: (0.664)(0.547, 0.781)] [G loss: 1.416] [G acc: 0.109]\n",
      "3095 [D loss: (0.611)(R 0.627, F 0.595)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.323] [G acc: 0.125]\n",
      "3096 [D loss: (0.507)(R 0.522, F 0.493)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.382] [G acc: 0.062]\n",
      "3097 [D loss: (0.526)(R 0.619, F 0.434)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.519] [G acc: 0.109]\n",
      "3098 [D loss: (0.615)(R 0.605, F 0.625)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.375] [G acc: 0.094]\n",
      "3099 [D loss: (0.519)(R 0.513, F 0.526)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.368] [G acc: 0.109]\n",
      "3100 [D loss: (0.603)(R 0.613, F 0.593)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.339] [G acc: 0.047]\n",
      "3101 [D loss: (0.571)(R 0.596, F 0.546)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.193] [G acc: 0.188]\n",
      "3102 [D loss: (0.488)(R 0.531, F 0.445)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.299] [G acc: 0.156]\n",
      "3103 [D loss: (0.577)(R 0.599, F 0.555)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.213] [G acc: 0.156]\n",
      "3104 [D loss: (0.472)(R 0.448, F 0.496)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.257] [G acc: 0.188]\n",
      "3105 [D loss: (0.510)(R 0.458, F 0.562)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.433] [G acc: 0.094]\n",
      "3106 [D loss: (0.588)(R 0.628, F 0.547)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.280] [G acc: 0.156]\n",
      "3107 [D loss: (0.533)(R 0.618, F 0.448)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.464] [G acc: 0.125]\n",
      "3108 [D loss: (0.510)(R 0.574, F 0.445)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.313] [G acc: 0.078]\n",
      "3109 [D loss: (0.578)(R 0.536, F 0.620)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.336] [G acc: 0.078]\n",
      "3110 [D loss: (0.621)(R 0.587, F 0.655)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.343] [G acc: 0.062]\n",
      "3111 [D loss: (0.537)(R 0.568, F 0.505)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.219] [G acc: 0.125]\n",
      "3112 [D loss: (0.498)(R 0.479, F 0.517)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.246] [G acc: 0.156]\n",
      "3113 [D loss: (0.597)(R 0.625, F 0.568)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.194] [G acc: 0.203]\n",
      "3114 [D loss: (0.520)(R 0.513, F 0.528)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.497] [G acc: 0.047]\n",
      "3115 [D loss: (0.552)(R 0.637, F 0.468)] [D acc: (0.703)(0.547, 0.859)] [G loss: 1.441] [G acc: 0.156]\n",
      "3116 [D loss: (0.538)(R 0.524, F 0.553)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.227] [G acc: 0.156]\n",
      "3117 [D loss: (0.475)(R 0.491, F 0.460)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.221] [G acc: 0.250]\n",
      "3118 [D loss: (0.543)(R 0.586, F 0.500)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.329] [G acc: 0.031]\n",
      "3119 [D loss: (0.765)(R 0.479, F 1.052)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.286] [G acc: 0.062]\n",
      "3120 [D loss: (0.572)(R 0.713, F 0.432)] [D acc: (0.734)(0.578, 0.891)] [G loss: 1.379] [G acc: 0.031]\n",
      "3121 [D loss: (0.572)(R 0.657, F 0.486)] [D acc: (0.656)(0.516, 0.797)] [G loss: 1.333] [G acc: 0.141]\n",
      "3122 [D loss: (0.526)(R 0.539, F 0.513)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.343] [G acc: 0.078]\n",
      "3123 [D loss: (0.515)(R 0.485, F 0.544)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.326] [G acc: 0.141]\n",
      "3124 [D loss: (0.489)(R 0.517, F 0.462)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.315] [G acc: 0.125]\n",
      "3125 [D loss: (0.561)(R 0.536, F 0.586)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.440] [G acc: 0.047]\n",
      "3126 [D loss: (0.537)(R 0.606, F 0.468)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.386] [G acc: 0.188]\n",
      "3127 [D loss: (0.573)(R 0.529, F 0.617)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.250] [G acc: 0.125]\n",
      "3128 [D loss: (0.612)(R 0.647, F 0.578)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.399] [G acc: 0.047]\n",
      "3129 [D loss: (0.549)(R 0.599, F 0.500)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.301] [G acc: 0.078]\n",
      "3130 [D loss: (0.553)(R 0.546, F 0.561)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.277] [G acc: 0.047]\n",
      "3131 [D loss: (0.499)(R 0.401, F 0.598)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.432] [G acc: 0.078]\n",
      "3132 [D loss: (0.534)(R 0.531, F 0.538)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.265] [G acc: 0.109]\n",
      "3133 [D loss: (0.488)(R 0.489, F 0.488)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.317] [G acc: 0.062]\n",
      "3134 [D loss: (0.599)(R 0.522, F 0.675)] [D acc: (0.656)(0.672, 0.641)] [G loss: 1.304] [G acc: 0.125]\n",
      "3135 [D loss: (0.532)(R 0.543, F 0.520)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.373] [G acc: 0.094]\n",
      "3136 [D loss: (0.640)(R 0.553, F 0.727)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.447] [G acc: 0.031]\n",
      "3137 [D loss: (0.503)(R 0.588, F 0.419)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.338] [G acc: 0.109]\n",
      "3138 [D loss: (0.590)(R 0.614, F 0.566)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.322] [G acc: 0.094]\n",
      "3139 [D loss: (0.546)(R 0.609, F 0.484)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.198] [G acc: 0.094]\n",
      "3140 [D loss: (0.514)(R 0.550, F 0.478)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.188] [G acc: 0.156]\n",
      "3141 [D loss: (0.571)(R 0.588, F 0.554)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.381] [G acc: 0.062]\n",
      "3142 [D loss: (0.581)(R 0.509, F 0.653)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.401] [G acc: 0.047]\n",
      "3143 [D loss: (0.557)(R 0.605, F 0.509)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.304] [G acc: 0.094]\n",
      "3144 [D loss: (0.536)(R 0.609, F 0.463)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.291] [G acc: 0.203]\n",
      "3145 [D loss: (0.462)(R 0.368, F 0.557)] [D acc: (0.789)(0.828, 0.750)] [G loss: 1.403] [G acc: 0.125]\n",
      "3146 [D loss: (0.551)(R 0.495, F 0.606)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.386] [G acc: 0.094]\n",
      "3147 [D loss: (0.575)(R 0.640, F 0.510)] [D acc: (0.633)(0.531, 0.734)] [G loss: 1.397] [G acc: 0.156]\n",
      "3148 [D loss: (0.579)(R 0.647, F 0.510)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.427] [G acc: 0.094]\n",
      "3149 [D loss: (0.481)(R 0.468, F 0.494)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.408] [G acc: 0.109]\n",
      "3150 [D loss: (0.488)(R 0.538, F 0.437)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.315] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3151 [D loss: (0.586)(R 0.554, F 0.618)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.449] [G acc: 0.094]\n",
      "3152 [D loss: (0.518)(R 0.588, F 0.448)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.393] [G acc: 0.062]\n",
      "3153 [D loss: (0.494)(R 0.446, F 0.542)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.355] [G acc: 0.094]\n",
      "3154 [D loss: (0.526)(R 0.571, F 0.482)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.441] [G acc: 0.109]\n",
      "3155 [D loss: (0.489)(R 0.469, F 0.509)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.498] [G acc: 0.141]\n",
      "3156 [D loss: (0.458)(R 0.433, F 0.484)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.362] [G acc: 0.203]\n",
      "3157 [D loss: (0.485)(R 0.552, F 0.417)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.423] [G acc: 0.094]\n",
      "3158 [D loss: (0.527)(R 0.525, F 0.528)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.457] [G acc: 0.094]\n",
      "3159 [D loss: (0.570)(R 0.646, F 0.494)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.385] [G acc: 0.047]\n",
      "3160 [D loss: (0.610)(R 0.678, F 0.543)] [D acc: (0.633)(0.484, 0.781)] [G loss: 1.154] [G acc: 0.219]\n",
      "3161 [D loss: (0.610)(R 0.632, F 0.588)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.253] [G acc: 0.109]\n",
      "3162 [D loss: (0.481)(R 0.494, F 0.467)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.363] [G acc: 0.125]\n",
      "3163 [D loss: (0.517)(R 0.541, F 0.493)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.339] [G acc: 0.109]\n",
      "3164 [D loss: (0.527)(R 0.535, F 0.518)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.391] [G acc: 0.094]\n",
      "3165 [D loss: (0.588)(R 0.549, F 0.627)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.228] [G acc: 0.094]\n",
      "3166 [D loss: (0.491)(R 0.534, F 0.449)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.389] [G acc: 0.047]\n",
      "3167 [D loss: (0.505)(R 0.568, F 0.442)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.448] [G acc: 0.094]\n",
      "3168 [D loss: (0.554)(R 0.528, F 0.580)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.436] [G acc: 0.078]\n",
      "3169 [D loss: (0.587)(R 0.526, F 0.648)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.392] [G acc: 0.094]\n",
      "3170 [D loss: (0.564)(R 0.611, F 0.517)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.201] [G acc: 0.188]\n",
      "3171 [D loss: (0.453)(R 0.429, F 0.477)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.285] [G acc: 0.078]\n",
      "3172 [D loss: (0.595)(R 0.615, F 0.575)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.462] [G acc: 0.125]\n",
      "3173 [D loss: (0.548)(R 0.505, F 0.592)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.321] [G acc: 0.141]\n",
      "3174 [D loss: (0.495)(R 0.545, F 0.445)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.328] [G acc: 0.141]\n",
      "3175 [D loss: (0.574)(R 0.619, F 0.530)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.380] [G acc: 0.125]\n",
      "3176 [D loss: (0.525)(R 0.526, F 0.524)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.549] [G acc: 0.078]\n",
      "3177 [D loss: (0.460)(R 0.540, F 0.379)] [D acc: (0.797)(0.672, 0.922)] [G loss: 1.389] [G acc: 0.109]\n",
      "3178 [D loss: (0.454)(R 0.466, F 0.441)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.492] [G acc: 0.094]\n",
      "3179 [D loss: (0.550)(R 0.592, F 0.508)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.447] [G acc: 0.109]\n",
      "3180 [D loss: (0.510)(R 0.469, F 0.550)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.316] [G acc: 0.125]\n",
      "3181 [D loss: (0.523)(R 0.498, F 0.547)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.429] [G acc: 0.094]\n",
      "3182 [D loss: (0.510)(R 0.573, F 0.447)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.385] [G acc: 0.109]\n",
      "3183 [D loss: (0.549)(R 0.513, F 0.584)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.416] [G acc: 0.031]\n",
      "3184 [D loss: (0.627)(R 0.716, F 0.537)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.211] [G acc: 0.188]\n",
      "3185 [D loss: (0.505)(R 0.479, F 0.531)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.381] [G acc: 0.156]\n",
      "3186 [D loss: (0.490)(R 0.389, F 0.590)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.407] [G acc: 0.156]\n",
      "3187 [D loss: (0.533)(R 0.488, F 0.577)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.425] [G acc: 0.094]\n",
      "3188 [D loss: (0.463)(R 0.465, F 0.462)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.474] [G acc: 0.109]\n",
      "3189 [D loss: (0.516)(R 0.419, F 0.613)] [D acc: (0.797)(0.781, 0.812)] [G loss: 1.539] [G acc: 0.031]\n",
      "3190 [D loss: (0.581)(R 0.633, F 0.528)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.486] [G acc: 0.094]\n",
      "3191 [D loss: (0.451)(R 0.475, F 0.427)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.598] [G acc: 0.047]\n",
      "3192 [D loss: (0.526)(R 0.462, F 0.589)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.421] [G acc: 0.141]\n",
      "3193 [D loss: (0.686)(R 0.821, F 0.551)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.417] [G acc: 0.094]\n",
      "3194 [D loss: (0.577)(R 0.494, F 0.659)] [D acc: (0.648)(0.688, 0.609)] [G loss: 1.506] [G acc: 0.047]\n",
      "3195 [D loss: (0.504)(R 0.597, F 0.412)] [D acc: (0.750)(0.594, 0.906)] [G loss: 1.356] [G acc: 0.109]\n",
      "3196 [D loss: (0.531)(R 0.624, F 0.437)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.320] [G acc: 0.125]\n",
      "3197 [D loss: (0.677)(R 0.689, F 0.666)] [D acc: (0.609)(0.547, 0.672)] [G loss: 1.392] [G acc: 0.016]\n",
      "3198 [D loss: (0.560)(R 0.631, F 0.489)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.202] [G acc: 0.219]\n",
      "3199 [D loss: (0.549)(R 0.599, F 0.500)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.468] [G acc: 0.016]\n",
      "3200 [D loss: (0.563)(R 0.608, F 0.518)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.413] [G acc: 0.078]\n",
      "3201 [D loss: (0.563)(R 0.551, F 0.575)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.213] [G acc: 0.188]\n",
      "3202 [D loss: (0.560)(R 0.618, F 0.502)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.295] [G acc: 0.094]\n",
      "3203 [D loss: (0.573)(R 0.581, F 0.566)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.308] [G acc: 0.078]\n",
      "3204 [D loss: (0.462)(R 0.478, F 0.446)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.255] [G acc: 0.188]\n",
      "3205 [D loss: (0.512)(R 0.512, F 0.511)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.345] [G acc: 0.109]\n",
      "3206 [D loss: (0.539)(R 0.529, F 0.548)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.325] [G acc: 0.109]\n",
      "3207 [D loss: (0.564)(R 0.435, F 0.692)] [D acc: (0.688)(0.719, 0.656)] [G loss: 1.343] [G acc: 0.109]\n",
      "3208 [D loss: (0.568)(R 0.582, F 0.554)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.400] [G acc: 0.094]\n",
      "3209 [D loss: (0.439)(R 0.444, F 0.434)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.379] [G acc: 0.141]\n",
      "3210 [D loss: (0.640)(R 0.560, F 0.720)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.399] [G acc: 0.125]\n",
      "3211 [D loss: (0.565)(R 0.648, F 0.482)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.332] [G acc: 0.062]\n",
      "3212 [D loss: (0.432)(R 0.462, F 0.402)] [D acc: (0.812)(0.719, 0.906)] [G loss: 1.463] [G acc: 0.141]\n",
      "3213 [D loss: (0.440)(R 0.355, F 0.525)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.605] [G acc: 0.031]\n",
      "3214 [D loss: (0.567)(R 0.694, F 0.440)] [D acc: (0.680)(0.516, 0.844)] [G loss: 1.461] [G acc: 0.094]\n",
      "3215 [D loss: (0.533)(R 0.561, F 0.506)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.482] [G acc: 0.109]\n",
      "3216 [D loss: (0.545)(R 0.654, F 0.436)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.452] [G acc: 0.125]\n",
      "3217 [D loss: (0.553)(R 0.462, F 0.645)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.323] [G acc: 0.094]\n",
      "3218 [D loss: (0.573)(R 0.618, F 0.529)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.436] [G acc: 0.031]\n",
      "3219 [D loss: (0.512)(R 0.593, F 0.432)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.422] [G acc: 0.156]\n",
      "3220 [D loss: (0.478)(R 0.525, F 0.431)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.394] [G acc: 0.109]\n",
      "3221 [D loss: (0.601)(R 0.575, F 0.628)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.424] [G acc: 0.125]\n",
      "3222 [D loss: (0.547)(R 0.561, F 0.534)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.389] [G acc: 0.062]\n",
      "3223 [D loss: (0.485)(R 0.573, F 0.397)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.388] [G acc: 0.078]\n",
      "3224 [D loss: (0.534)(R 0.487, F 0.581)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.457] [G acc: 0.078]\n",
      "3225 [D loss: (0.534)(R 0.553, F 0.514)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.318] [G acc: 0.094]\n",
      "3226 [D loss: (0.580)(R 0.621, F 0.539)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.225] [G acc: 0.188]\n",
      "3227 [D loss: (0.656)(R 0.712, F 0.600)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.160] [G acc: 0.141]\n",
      "3228 [D loss: (0.621)(R 0.671, F 0.571)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.266] [G acc: 0.125]\n",
      "3229 [D loss: (0.486)(R 0.435, F 0.537)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.392] [G acc: 0.141]\n",
      "3230 [D loss: (0.501)(R 0.460, F 0.543)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.402] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3231 [D loss: (0.509)(R 0.531, F 0.487)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.374] [G acc: 0.109]\n",
      "3232 [D loss: (0.472)(R 0.453, F 0.490)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.506] [G acc: 0.062]\n",
      "3233 [D loss: (0.572)(R 0.534, F 0.610)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.322] [G acc: 0.109]\n",
      "3234 [D loss: (0.603)(R 0.733, F 0.473)] [D acc: (0.648)(0.500, 0.797)] [G loss: 1.212] [G acc: 0.156]\n",
      "3235 [D loss: (0.475)(R 0.489, F 0.461)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.395] [G acc: 0.109]\n",
      "3236 [D loss: (0.530)(R 0.535, F 0.525)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.330] [G acc: 0.172]\n",
      "3237 [D loss: (0.619)(R 0.563, F 0.674)] [D acc: (0.680)(0.719, 0.641)] [G loss: 1.411] [G acc: 0.062]\n",
      "3238 [D loss: (0.549)(R 0.555, F 0.543)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.220] [G acc: 0.125]\n",
      "3239 [D loss: (0.569)(R 0.593, F 0.545)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.388] [G acc: 0.078]\n",
      "3240 [D loss: (0.508)(R 0.562, F 0.454)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.149] [G acc: 0.281]\n",
      "3241 [D loss: (0.723)(R 0.546, F 0.899)] [D acc: (0.609)(0.625, 0.594)] [G loss: 1.403] [G acc: 0.141]\n",
      "3242 [D loss: (0.592)(R 0.735, F 0.449)] [D acc: (0.672)(0.484, 0.859)] [G loss: 1.246] [G acc: 0.125]\n",
      "3243 [D loss: (0.554)(R 0.608, F 0.500)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.388] [G acc: 0.156]\n",
      "3244 [D loss: (0.571)(R 0.619, F 0.523)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.327] [G acc: 0.141]\n",
      "3245 [D loss: (0.553)(R 0.524, F 0.582)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.268] [G acc: 0.125]\n",
      "3246 [D loss: (0.572)(R 0.597, F 0.546)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.246] [G acc: 0.078]\n",
      "3247 [D loss: (0.519)(R 0.534, F 0.504)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.335] [G acc: 0.094]\n",
      "3248 [D loss: (0.537)(R 0.445, F 0.629)] [D acc: (0.695)(0.750, 0.641)] [G loss: 1.400] [G acc: 0.047]\n",
      "3249 [D loss: (0.602)(R 0.646, F 0.558)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.354] [G acc: 0.078]\n",
      "3250 [D loss: (0.551)(R 0.557, F 0.545)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.313] [G acc: 0.125]\n",
      "3251 [D loss: (0.570)(R 0.626, F 0.513)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.328] [G acc: 0.094]\n",
      "3252 [D loss: (0.520)(R 0.563, F 0.478)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.328] [G acc: 0.078]\n",
      "3253 [D loss: (0.627)(R 0.567, F 0.688)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.302] [G acc: 0.125]\n",
      "3254 [D loss: (0.570)(R 0.660, F 0.481)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.321] [G acc: 0.078]\n",
      "3255 [D loss: (0.555)(R 0.549, F 0.560)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.331] [G acc: 0.047]\n",
      "3256 [D loss: (0.612)(R 0.637, F 0.587)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.332] [G acc: 0.125]\n",
      "3257 [D loss: (0.490)(R 0.540, F 0.441)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.355] [G acc: 0.156]\n",
      "3258 [D loss: (0.518)(R 0.562, F 0.473)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.206] [G acc: 0.250]\n",
      "3259 [D loss: (0.534)(R 0.400, F 0.668)] [D acc: (0.711)(0.797, 0.625)] [G loss: 1.499] [G acc: 0.031]\n",
      "3260 [D loss: (0.513)(R 0.485, F 0.541)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.484] [G acc: 0.031]\n",
      "3261 [D loss: (0.596)(R 0.708, F 0.483)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.421] [G acc: 0.031]\n",
      "3262 [D loss: (0.549)(R 0.615, F 0.483)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.583] [G acc: 0.078]\n",
      "3263 [D loss: (0.479)(R 0.538, F 0.419)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.432] [G acc: 0.094]\n",
      "3264 [D loss: (0.479)(R 0.454, F 0.505)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.557] [G acc: 0.078]\n",
      "3265 [D loss: (0.480)(R 0.454, F 0.506)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.375] [G acc: 0.078]\n",
      "3266 [D loss: (0.558)(R 0.583, F 0.534)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.466] [G acc: 0.109]\n",
      "3267 [D loss: (0.510)(R 0.564, F 0.457)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.382] [G acc: 0.016]\n",
      "3268 [D loss: (0.461)(R 0.513, F 0.409)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.329] [G acc: 0.078]\n",
      "3269 [D loss: (0.510)(R 0.449, F 0.572)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.424] [G acc: 0.031]\n",
      "3270 [D loss: (0.489)(R 0.469, F 0.509)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.635] [G acc: 0.078]\n",
      "3271 [D loss: (0.615)(R 0.588, F 0.642)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.530] [G acc: 0.062]\n",
      "3272 [D loss: (0.528)(R 0.608, F 0.448)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.383] [G acc: 0.125]\n",
      "3273 [D loss: (0.522)(R 0.579, F 0.464)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.464] [G acc: 0.094]\n",
      "3274 [D loss: (0.508)(R 0.454, F 0.562)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.439] [G acc: 0.062]\n",
      "3275 [D loss: (0.474)(R 0.452, F 0.495)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.425] [G acc: 0.141]\n",
      "3276 [D loss: (0.513)(R 0.558, F 0.467)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.388] [G acc: 0.141]\n",
      "3277 [D loss: (0.495)(R 0.461, F 0.528)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.560] [G acc: 0.078]\n",
      "3278 [D loss: (0.516)(R 0.451, F 0.581)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.534] [G acc: 0.047]\n",
      "3279 [D loss: (0.498)(R 0.579, F 0.417)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.355] [G acc: 0.094]\n",
      "3280 [D loss: (0.544)(R 0.552, F 0.537)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.316] [G acc: 0.125]\n",
      "3281 [D loss: (0.555)(R 0.573, F 0.537)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.486] [G acc: 0.094]\n",
      "3282 [D loss: (0.541)(R 0.576, F 0.507)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.590] [G acc: 0.062]\n",
      "3283 [D loss: (0.522)(R 0.576, F 0.468)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.505] [G acc: 0.062]\n",
      "3284 [D loss: (0.572)(R 0.635, F 0.510)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.377] [G acc: 0.172]\n",
      "3285 [D loss: (0.676)(R 0.662, F 0.690)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.440] [G acc: 0.078]\n",
      "3286 [D loss: (0.652)(R 0.601, F 0.704)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.301] [G acc: 0.078]\n",
      "3287 [D loss: (0.562)(R 0.679, F 0.445)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.216] [G acc: 0.141]\n",
      "3288 [D loss: (0.666)(R 0.538, F 0.795)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.278] [G acc: 0.094]\n",
      "3289 [D loss: (0.638)(R 0.780, F 0.496)] [D acc: (0.641)(0.422, 0.859)] [G loss: 1.232] [G acc: 0.062]\n",
      "3290 [D loss: (0.549)(R 0.588, F 0.510)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.178] [G acc: 0.125]\n",
      "3291 [D loss: (0.616)(R 0.632, F 0.600)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.370] [G acc: 0.094]\n",
      "3292 [D loss: (0.594)(R 0.636, F 0.552)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.162] [G acc: 0.125]\n",
      "3293 [D loss: (0.595)(R 0.610, F 0.581)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.255] [G acc: 0.125]\n",
      "3294 [D loss: (0.582)(R 0.659, F 0.506)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.273] [G acc: 0.141]\n",
      "3295 [D loss: (0.586)(R 0.439, F 0.732)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.379] [G acc: 0.094]\n",
      "3296 [D loss: (0.578)(R 0.563, F 0.594)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.398] [G acc: 0.016]\n",
      "3297 [D loss: (0.543)(R 0.640, F 0.445)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.467] [G acc: 0.047]\n",
      "3298 [D loss: (0.530)(R 0.565, F 0.495)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.362] [G acc: 0.078]\n",
      "3299 [D loss: (0.499)(R 0.529, F 0.470)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.562] [G acc: 0.094]\n",
      "3300 [D loss: (0.576)(R 0.542, F 0.610)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.372] [G acc: 0.094]\n",
      "3301 [D loss: (0.606)(R 0.651, F 0.562)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.456] [G acc: 0.062]\n",
      "3302 [D loss: (0.589)(R 0.619, F 0.559)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.276] [G acc: 0.156]\n",
      "3303 [D loss: (0.575)(R 0.636, F 0.514)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.273] [G acc: 0.109]\n",
      "3304 [D loss: (0.569)(R 0.575, F 0.564)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.329] [G acc: 0.094]\n",
      "3305 [D loss: (0.549)(R 0.559, F 0.540)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.386] [G acc: 0.078]\n",
      "3306 [D loss: (0.580)(R 0.572, F 0.589)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.306] [G acc: 0.141]\n",
      "3307 [D loss: (0.505)(R 0.467, F 0.544)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.451] [G acc: 0.031]\n",
      "3308 [D loss: (0.580)(R 0.611, F 0.549)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.375] [G acc: 0.109]\n",
      "3309 [D loss: (0.519)(R 0.562, F 0.476)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.413] [G acc: 0.047]\n",
      "3310 [D loss: (0.529)(R 0.642, F 0.416)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.398] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3311 [D loss: (0.567)(R 0.538, F 0.596)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.219] [G acc: 0.156]\n",
      "3312 [D loss: (0.582)(R 0.636, F 0.528)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.424] [G acc: 0.078]\n",
      "3313 [D loss: (0.506)(R 0.568, F 0.443)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.396] [G acc: 0.125]\n",
      "3314 [D loss: (0.585)(R 0.594, F 0.577)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.346] [G acc: 0.078]\n",
      "3315 [D loss: (0.561)(R 0.566, F 0.556)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.327] [G acc: 0.094]\n",
      "3316 [D loss: (0.484)(R 0.480, F 0.487)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.346] [G acc: 0.109]\n",
      "3317 [D loss: (0.633)(R 0.605, F 0.662)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.473] [G acc: 0.047]\n",
      "3318 [D loss: (0.603)(R 0.634, F 0.573)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.418] [G acc: 0.094]\n",
      "3319 [D loss: (0.623)(R 0.706, F 0.539)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.268] [G acc: 0.109]\n",
      "3320 [D loss: (0.537)(R 0.573, F 0.500)] [D acc: (0.766)(0.625, 0.906)] [G loss: 1.293] [G acc: 0.109]\n",
      "3321 [D loss: (0.581)(R 0.534, F 0.627)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.305] [G acc: 0.094]\n",
      "3322 [D loss: (0.524)(R 0.526, F 0.521)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.316] [G acc: 0.109]\n",
      "3323 [D loss: (0.561)(R 0.522, F 0.601)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.450] [G acc: 0.094]\n",
      "3324 [D loss: (0.472)(R 0.457, F 0.486)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.380] [G acc: 0.094]\n",
      "3325 [D loss: (0.525)(R 0.601, F 0.449)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.413] [G acc: 0.094]\n",
      "3326 [D loss: (0.573)(R 0.535, F 0.610)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.355] [G acc: 0.062]\n",
      "3327 [D loss: (0.499)(R 0.572, F 0.427)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.443] [G acc: 0.094]\n",
      "3328 [D loss: (0.483)(R 0.479, F 0.488)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.433] [G acc: 0.141]\n",
      "3329 [D loss: (0.574)(R 0.565, F 0.584)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.275] [G acc: 0.156]\n",
      "3330 [D loss: (0.551)(R 0.510, F 0.593)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.291] [G acc: 0.078]\n",
      "3331 [D loss: (0.544)(R 0.547, F 0.542)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.345] [G acc: 0.109]\n",
      "3332 [D loss: (0.544)(R 0.627, F 0.461)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.344] [G acc: 0.125]\n",
      "3333 [D loss: (0.576)(R 0.606, F 0.545)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.282] [G acc: 0.109]\n",
      "3334 [D loss: (0.523)(R 0.571, F 0.475)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.332] [G acc: 0.047]\n",
      "3335 [D loss: (0.549)(R 0.531, F 0.567)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.261] [G acc: 0.125]\n",
      "3336 [D loss: (0.501)(R 0.574, F 0.428)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.366] [G acc: 0.141]\n",
      "3337 [D loss: (0.545)(R 0.544, F 0.545)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.197] [G acc: 0.250]\n",
      "3338 [D loss: (0.625)(R 0.616, F 0.635)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.209] [G acc: 0.188]\n",
      "3339 [D loss: (0.606)(R 0.654, F 0.559)] [D acc: (0.695)(0.531, 0.859)] [G loss: 1.415] [G acc: 0.031]\n",
      "3340 [D loss: (0.528)(R 0.511, F 0.545)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.291] [G acc: 0.094]\n",
      "3341 [D loss: (0.524)(R 0.585, F 0.463)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.240] [G acc: 0.094]\n",
      "3342 [D loss: (0.571)(R 0.502, F 0.639)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.385] [G acc: 0.078]\n",
      "3343 [D loss: (0.543)(R 0.583, F 0.503)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.387] [G acc: 0.094]\n",
      "3344 [D loss: (0.551)(R 0.549, F 0.553)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.283] [G acc: 0.141]\n",
      "3345 [D loss: (0.528)(R 0.545, F 0.511)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.330] [G acc: 0.094]\n",
      "3346 [D loss: (0.652)(R 0.520, F 0.785)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.285] [G acc: 0.125]\n",
      "3347 [D loss: (0.489)(R 0.524, F 0.453)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.243] [G acc: 0.156]\n",
      "3348 [D loss: (0.627)(R 0.512, F 0.743)] [D acc: (0.680)(0.688, 0.672)] [G loss: 1.329] [G acc: 0.047]\n",
      "3349 [D loss: (0.583)(R 0.708, F 0.459)] [D acc: (0.641)(0.500, 0.781)] [G loss: 1.271] [G acc: 0.094]\n",
      "3350 [D loss: (0.497)(R 0.494, F 0.501)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.253] [G acc: 0.094]\n",
      "3351 [D loss: (0.505)(R 0.486, F 0.524)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.310] [G acc: 0.188]\n",
      "3352 [D loss: (0.542)(R 0.541, F 0.543)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.318] [G acc: 0.094]\n",
      "3353 [D loss: (0.526)(R 0.533, F 0.520)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.292] [G acc: 0.125]\n",
      "3354 [D loss: (0.542)(R 0.608, F 0.476)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.308] [G acc: 0.062]\n",
      "3355 [D loss: (0.519)(R 0.461, F 0.576)] [D acc: (0.773)(0.812, 0.734)] [G loss: 1.427] [G acc: 0.062]\n",
      "3356 [D loss: (0.684)(R 0.662, F 0.706)] [D acc: (0.648)(0.672, 0.625)] [G loss: 1.238] [G acc: 0.141]\n",
      "3357 [D loss: (0.532)(R 0.590, F 0.475)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.313] [G acc: 0.109]\n",
      "3358 [D loss: (0.583)(R 0.547, F 0.618)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.201] [G acc: 0.172]\n",
      "3359 [D loss: (0.547)(R 0.626, F 0.467)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.248] [G acc: 0.141]\n",
      "3360 [D loss: (0.570)(R 0.604, F 0.536)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.421] [G acc: 0.078]\n",
      "3361 [D loss: (0.566)(R 0.541, F 0.591)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.406] [G acc: 0.047]\n",
      "3362 [D loss: (0.531)(R 0.624, F 0.437)] [D acc: (0.789)(0.641, 0.938)] [G loss: 1.232] [G acc: 0.109]\n",
      "3363 [D loss: (0.518)(R 0.506, F 0.530)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.280] [G acc: 0.078]\n",
      "3364 [D loss: (0.588)(R 0.518, F 0.658)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.229] [G acc: 0.141]\n",
      "3365 [D loss: (0.582)(R 0.668, F 0.496)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.540] [G acc: 0.000]\n",
      "3366 [D loss: (0.603)(R 0.654, F 0.552)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.289] [G acc: 0.109]\n",
      "3367 [D loss: (0.557)(R 0.649, F 0.465)] [D acc: (0.719)(0.547, 0.891)] [G loss: 1.421] [G acc: 0.062]\n",
      "3368 [D loss: (0.591)(R 0.587, F 0.595)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.129] [G acc: 0.188]\n",
      "3369 [D loss: (0.501)(R 0.480, F 0.523)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.371] [G acc: 0.062]\n",
      "3370 [D loss: (0.521)(R 0.475, F 0.567)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.334] [G acc: 0.109]\n",
      "3371 [D loss: (0.448)(R 0.415, F 0.480)] [D acc: (0.820)(0.812, 0.828)] [G loss: 1.346] [G acc: 0.062]\n",
      "3372 [D loss: (0.496)(R 0.438, F 0.554)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.354] [G acc: 0.094]\n",
      "3373 [D loss: (0.513)(R 0.525, F 0.502)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.423] [G acc: 0.062]\n",
      "3374 [D loss: (0.538)(R 0.657, F 0.418)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.275] [G acc: 0.094]\n",
      "3375 [D loss: (0.567)(R 0.549, F 0.585)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.423] [G acc: 0.094]\n",
      "3376 [D loss: (0.481)(R 0.570, F 0.392)] [D acc: (0.773)(0.625, 0.922)] [G loss: 1.289] [G acc: 0.094]\n",
      "3377 [D loss: (0.537)(R 0.493, F 0.582)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.401] [G acc: 0.125]\n",
      "3378 [D loss: (0.456)(R 0.512, F 0.400)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.421] [G acc: 0.141]\n",
      "3379 [D loss: (0.586)(R 0.608, F 0.564)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.459] [G acc: 0.062]\n",
      "3380 [D loss: (0.670)(R 0.576, F 0.763)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.354] [G acc: 0.062]\n",
      "3381 [D loss: (0.598)(R 0.688, F 0.509)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.412] [G acc: 0.094]\n",
      "3382 [D loss: (0.556)(R 0.687, F 0.426)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.231] [G acc: 0.141]\n",
      "3383 [D loss: (0.453)(R 0.441, F 0.466)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.305] [G acc: 0.125]\n",
      "3384 [D loss: (0.524)(R 0.461, F 0.587)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.381] [G acc: 0.078]\n",
      "3385 [D loss: (0.493)(R 0.541, F 0.446)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.336] [G acc: 0.141]\n",
      "3386 [D loss: (0.524)(R 0.537, F 0.511)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.373] [G acc: 0.156]\n",
      "3387 [D loss: (0.563)(R 0.629, F 0.498)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.274] [G acc: 0.094]\n",
      "3388 [D loss: (0.609)(R 0.687, F 0.531)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.411] [G acc: 0.156]\n",
      "3389 [D loss: (0.506)(R 0.566, F 0.446)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.385] [G acc: 0.094]\n",
      "3390 [D loss: (0.552)(R 0.590, F 0.514)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.152] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3391 [D loss: (0.581)(R 0.572, F 0.590)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.330] [G acc: 0.078]\n",
      "3392 [D loss: (0.552)(R 0.581, F 0.523)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.412] [G acc: 0.094]\n",
      "3393 [D loss: (0.456)(R 0.403, F 0.508)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.488] [G acc: 0.109]\n",
      "3394 [D loss: (0.454)(R 0.510, F 0.399)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.345] [G acc: 0.156]\n",
      "3395 [D loss: (0.542)(R 0.503, F 0.580)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.463] [G acc: 0.141]\n",
      "3396 [D loss: (0.585)(R 0.608, F 0.561)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.315] [G acc: 0.109]\n",
      "3397 [D loss: (0.564)(R 0.588, F 0.540)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.425] [G acc: 0.125]\n",
      "3398 [D loss: (0.652)(R 0.638, F 0.667)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.334] [G acc: 0.109]\n",
      "3399 [D loss: (0.627)(R 0.655, F 0.599)] [D acc: (0.609)(0.531, 0.688)] [G loss: 1.307] [G acc: 0.141]\n",
      "3400 [D loss: (0.509)(R 0.536, F 0.482)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.326] [G acc: 0.203]\n",
      "3401 [D loss: (0.470)(R 0.579, F 0.360)] [D acc: (0.805)(0.688, 0.922)] [G loss: 1.418] [G acc: 0.109]\n",
      "3402 [D loss: (0.604)(R 0.541, F 0.667)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.332] [G acc: 0.156]\n",
      "3403 [D loss: (0.544)(R 0.510, F 0.578)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.329] [G acc: 0.172]\n",
      "3404 [D loss: (0.563)(R 0.575, F 0.550)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.281] [G acc: 0.172]\n",
      "3405 [D loss: (0.530)(R 0.524, F 0.536)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.385] [G acc: 0.078]\n",
      "3406 [D loss: (0.561)(R 0.571, F 0.550)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.499] [G acc: 0.078]\n",
      "3407 [D loss: (0.486)(R 0.454, F 0.518)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.435] [G acc: 0.062]\n",
      "3408 [D loss: (0.562)(R 0.626, F 0.498)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.339] [G acc: 0.156]\n",
      "3409 [D loss: (0.524)(R 0.527, F 0.520)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.378] [G acc: 0.078]\n",
      "3410 [D loss: (0.526)(R 0.560, F 0.492)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.277] [G acc: 0.156]\n",
      "3411 [D loss: (0.561)(R 0.549, F 0.574)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.313] [G acc: 0.094]\n",
      "3412 [D loss: (0.658)(R 0.682, F 0.635)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.392] [G acc: 0.094]\n",
      "3413 [D loss: (0.569)(R 0.653, F 0.484)] [D acc: (0.656)(0.516, 0.797)] [G loss: 1.386] [G acc: 0.141]\n",
      "3414 [D loss: (0.529)(R 0.530, F 0.528)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.326] [G acc: 0.125]\n",
      "3415 [D loss: (0.580)(R 0.611, F 0.548)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.407] [G acc: 0.078]\n",
      "3416 [D loss: (0.528)(R 0.481, F 0.575)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.399] [G acc: 0.062]\n",
      "3417 [D loss: (0.529)(R 0.565, F 0.493)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.223] [G acc: 0.141]\n",
      "3418 [D loss: (0.589)(R 0.561, F 0.617)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.473] [G acc: 0.062]\n",
      "3419 [D loss: (0.510)(R 0.569, F 0.450)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.454] [G acc: 0.062]\n",
      "3420 [D loss: (0.571)(R 0.659, F 0.482)] [D acc: (0.711)(0.547, 0.875)] [G loss: 1.271] [G acc: 0.156]\n",
      "3421 [D loss: (0.528)(R 0.522, F 0.534)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.336] [G acc: 0.109]\n",
      "3422 [D loss: (0.542)(R 0.595, F 0.490)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.564] [G acc: 0.094]\n",
      "3423 [D loss: (0.571)(R 0.573, F 0.569)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.359] [G acc: 0.078]\n",
      "3424 [D loss: (0.647)(R 0.595, F 0.699)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.426] [G acc: 0.094]\n",
      "3425 [D loss: (0.519)(R 0.539, F 0.499)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.273] [G acc: 0.125]\n",
      "3426 [D loss: (0.593)(R 0.546, F 0.640)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.241] [G acc: 0.109]\n",
      "3427 [D loss: (0.587)(R 0.623, F 0.550)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.272] [G acc: 0.078]\n",
      "3428 [D loss: (0.493)(R 0.503, F 0.483)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.240] [G acc: 0.078]\n",
      "3429 [D loss: (0.620)(R 0.629, F 0.611)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.285] [G acc: 0.125]\n",
      "3430 [D loss: (0.556)(R 0.618, F 0.495)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.297] [G acc: 0.094]\n",
      "3431 [D loss: (0.537)(R 0.564, F 0.511)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.249] [G acc: 0.094]\n",
      "3432 [D loss: (0.548)(R 0.614, F 0.482)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.352] [G acc: 0.078]\n",
      "3433 [D loss: (0.466)(R 0.527, F 0.405)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.379] [G acc: 0.047]\n",
      "3434 [D loss: (0.568)(R 0.572, F 0.563)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.337] [G acc: 0.078]\n",
      "3435 [D loss: (0.547)(R 0.610, F 0.485)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.450] [G acc: 0.109]\n",
      "3436 [D loss: (0.552)(R 0.605, F 0.499)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.429] [G acc: 0.062]\n",
      "3437 [D loss: (0.477)(R 0.409, F 0.544)] [D acc: (0.820)(0.812, 0.828)] [G loss: 1.314] [G acc: 0.062]\n",
      "3438 [D loss: (0.571)(R 0.621, F 0.522)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.405] [G acc: 0.109]\n",
      "3439 [D loss: (0.682)(R 0.612, F 0.752)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.364] [G acc: 0.062]\n",
      "3440 [D loss: (0.585)(R 0.656, F 0.513)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.264] [G acc: 0.141]\n",
      "3441 [D loss: (0.551)(R 0.543, F 0.559)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.410] [G acc: 0.094]\n",
      "3442 [D loss: (0.503)(R 0.484, F 0.522)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.426] [G acc: 0.078]\n",
      "3443 [D loss: (0.542)(R 0.573, F 0.510)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.369] [G acc: 0.062]\n",
      "3444 [D loss: (0.531)(R 0.517, F 0.545)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.230] [G acc: 0.141]\n",
      "3445 [D loss: (0.539)(R 0.558, F 0.520)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.460] [G acc: 0.094]\n",
      "3446 [D loss: (0.520)(R 0.587, F 0.453)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.324] [G acc: 0.109]\n",
      "3447 [D loss: (0.564)(R 0.470, F 0.658)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.483] [G acc: 0.094]\n",
      "3448 [D loss: (0.612)(R 0.670, F 0.554)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.385] [G acc: 0.125]\n",
      "3449 [D loss: (0.538)(R 0.619, F 0.457)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.390] [G acc: 0.094]\n",
      "3450 [D loss: (0.588)(R 0.564, F 0.612)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.544] [G acc: 0.156]\n",
      "3451 [D loss: (0.492)(R 0.574, F 0.411)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.444] [G acc: 0.094]\n",
      "3452 [D loss: (0.578)(R 0.600, F 0.557)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.527] [G acc: 0.062]\n",
      "3453 [D loss: (0.620)(R 0.516, F 0.725)] [D acc: (0.664)(0.703, 0.625)] [G loss: 1.680] [G acc: 0.062]\n",
      "3454 [D loss: (0.561)(R 0.583, F 0.539)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.497] [G acc: 0.062]\n",
      "3455 [D loss: (0.534)(R 0.626, F 0.443)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.387] [G acc: 0.094]\n",
      "3456 [D loss: (0.520)(R 0.441, F 0.600)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.309] [G acc: 0.219]\n",
      "3457 [D loss: (0.556)(R 0.542, F 0.571)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.397] [G acc: 0.109]\n",
      "3458 [D loss: (0.541)(R 0.576, F 0.507)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.341] [G acc: 0.078]\n",
      "3459 [D loss: (0.563)(R 0.531, F 0.595)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.298] [G acc: 0.094]\n",
      "3460 [D loss: (0.514)(R 0.571, F 0.457)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.182] [G acc: 0.219]\n",
      "3461 [D loss: (0.544)(R 0.513, F 0.575)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.302] [G acc: 0.125]\n",
      "3462 [D loss: (0.546)(R 0.579, F 0.512)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.248] [G acc: 0.141]\n",
      "3463 [D loss: (0.511)(R 0.506, F 0.516)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.328] [G acc: 0.156]\n",
      "3464 [D loss: (0.587)(R 0.494, F 0.680)] [D acc: (0.703)(0.734, 0.672)] [G loss: 1.409] [G acc: 0.094]\n",
      "3465 [D loss: (0.534)(R 0.569, F 0.498)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.365] [G acc: 0.141]\n",
      "3466 [D loss: (0.478)(R 0.519, F 0.437)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.332] [G acc: 0.141]\n",
      "3467 [D loss: (0.481)(R 0.454, F 0.509)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.448] [G acc: 0.094]\n",
      "3468 [D loss: (0.587)(R 0.675, F 0.499)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.384] [G acc: 0.125]\n",
      "3469 [D loss: (0.519)(R 0.456, F 0.581)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.410] [G acc: 0.141]\n",
      "3470 [D loss: (0.524)(R 0.595, F 0.453)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.273] [G acc: 0.156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3471 [D loss: (0.523)(R 0.565, F 0.481)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.349] [G acc: 0.141]\n",
      "3472 [D loss: (0.680)(R 0.659, F 0.702)] [D acc: (0.625)(0.531, 0.719)] [G loss: 1.327] [G acc: 0.141]\n",
      "3473 [D loss: (0.582)(R 0.494, F 0.671)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.257] [G acc: 0.078]\n",
      "3474 [D loss: (0.569)(R 0.534, F 0.604)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.305] [G acc: 0.031]\n",
      "3475 [D loss: (0.593)(R 0.723, F 0.462)] [D acc: (0.648)(0.484, 0.812)] [G loss: 1.289] [G acc: 0.156]\n",
      "3476 [D loss: (0.504)(R 0.492, F 0.515)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.442] [G acc: 0.078]\n",
      "3477 [D loss: (0.509)(R 0.549, F 0.469)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.349] [G acc: 0.109]\n",
      "3478 [D loss: (0.508)(R 0.493, F 0.523)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.312] [G acc: 0.109]\n",
      "3479 [D loss: (0.478)(R 0.468, F 0.489)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.370] [G acc: 0.141]\n",
      "3480 [D loss: (0.518)(R 0.573, F 0.464)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.266] [G acc: 0.094]\n",
      "3481 [D loss: (0.491)(R 0.480, F 0.502)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.391] [G acc: 0.047]\n",
      "3482 [D loss: (0.566)(R 0.628, F 0.504)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.482] [G acc: 0.109]\n",
      "3483 [D loss: (0.419)(R 0.398, F 0.439)] [D acc: (0.812)(0.797, 0.828)] [G loss: 1.392] [G acc: 0.125]\n",
      "3484 [D loss: (0.518)(R 0.478, F 0.557)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.480] [G acc: 0.062]\n",
      "3485 [D loss: (0.541)(R 0.595, F 0.488)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.496] [G acc: 0.047]\n",
      "3486 [D loss: (0.470)(R 0.491, F 0.450)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.590] [G acc: 0.094]\n",
      "3487 [D loss: (0.584)(R 0.608, F 0.560)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.474] [G acc: 0.062]\n",
      "3488 [D loss: (0.454)(R 0.465, F 0.444)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.464] [G acc: 0.078]\n",
      "3489 [D loss: (0.565)(R 0.612, F 0.519)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.371] [G acc: 0.109]\n",
      "3490 [D loss: (0.542)(R 0.477, F 0.607)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.443] [G acc: 0.062]\n",
      "3491 [D loss: (0.551)(R 0.612, F 0.489)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.382] [G acc: 0.078]\n",
      "3492 [D loss: (0.553)(R 0.577, F 0.528)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.488] [G acc: 0.078]\n",
      "3493 [D loss: (0.584)(R 0.643, F 0.525)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.328] [G acc: 0.078]\n",
      "3494 [D loss: (0.494)(R 0.436, F 0.551)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.488] [G acc: 0.062]\n",
      "3495 [D loss: (0.615)(R 0.626, F 0.604)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.475] [G acc: 0.062]\n",
      "3496 [D loss: (0.635)(R 0.757, F 0.513)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.435] [G acc: 0.062]\n",
      "3497 [D loss: (0.549)(R 0.545, F 0.553)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.605] [G acc: 0.062]\n",
      "3498 [D loss: (0.561)(R 0.565, F 0.557)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.409] [G acc: 0.125]\n",
      "3499 [D loss: (0.494)(R 0.646, F 0.342)] [D acc: (0.805)(0.672, 0.938)] [G loss: 1.347] [G acc: 0.125]\n",
      "3500 [D loss: (0.571)(R 0.482, F 0.659)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.273] [G acc: 0.125]\n",
      "3501 [D loss: (0.558)(R 0.543, F 0.573)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.487] [G acc: 0.078]\n",
      "3502 [D loss: (0.572)(R 0.565, F 0.579)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.414] [G acc: 0.141]\n",
      "3503 [D loss: (0.568)(R 0.647, F 0.488)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.491] [G acc: 0.016]\n",
      "3504 [D loss: (0.642)(R 0.657, F 0.626)] [D acc: (0.641)(0.562, 0.719)] [G loss: 1.344] [G acc: 0.125]\n",
      "3505 [D loss: (0.493)(R 0.556, F 0.431)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.355] [G acc: 0.109]\n",
      "3506 [D loss: (0.577)(R 0.576, F 0.577)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.391] [G acc: 0.078]\n",
      "3507 [D loss: (0.438)(R 0.465, F 0.412)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.438] [G acc: 0.062]\n",
      "3508 [D loss: (0.506)(R 0.396, F 0.616)] [D acc: (0.727)(0.797, 0.656)] [G loss: 1.308] [G acc: 0.141]\n",
      "3509 [D loss: (0.518)(R 0.570, F 0.466)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.419] [G acc: 0.109]\n",
      "3510 [D loss: (0.480)(R 0.515, F 0.446)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.631] [G acc: 0.047]\n",
      "3511 [D loss: (0.469)(R 0.554, F 0.385)] [D acc: (0.789)(0.656, 0.922)] [G loss: 1.373] [G acc: 0.125]\n",
      "3512 [D loss: (0.622)(R 0.540, F 0.704)] [D acc: (0.656)(0.656, 0.656)] [G loss: 1.328] [G acc: 0.109]\n",
      "3513 [D loss: (0.549)(R 0.549, F 0.549)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.322] [G acc: 0.156]\n",
      "3514 [D loss: (0.534)(R 0.609, F 0.459)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.291] [G acc: 0.156]\n",
      "3515 [D loss: (0.559)(R 0.577, F 0.542)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.437] [G acc: 0.078]\n",
      "3516 [D loss: (0.546)(R 0.477, F 0.615)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.423] [G acc: 0.094]\n",
      "3517 [D loss: (0.619)(R 0.571, F 0.666)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.366] [G acc: 0.094]\n",
      "3518 [D loss: (0.594)(R 0.632, F 0.555)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.360] [G acc: 0.109]\n",
      "3519 [D loss: (0.525)(R 0.574, F 0.476)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.277] [G acc: 0.141]\n",
      "3520 [D loss: (0.629)(R 0.567, F 0.690)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.308] [G acc: 0.109]\n",
      "3521 [D loss: (0.615)(R 0.714, F 0.515)] [D acc: (0.641)(0.516, 0.766)] [G loss: 1.223] [G acc: 0.125]\n",
      "3522 [D loss: (0.518)(R 0.485, F 0.551)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.283] [G acc: 0.109]\n",
      "3523 [D loss: (0.603)(R 0.671, F 0.535)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.399] [G acc: 0.094]\n",
      "3524 [D loss: (0.592)(R 0.650, F 0.534)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.421] [G acc: 0.078]\n",
      "3525 [D loss: (0.605)(R 0.683, F 0.526)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.308] [G acc: 0.109]\n",
      "3526 [D loss: (0.628)(R 0.732, F 0.523)] [D acc: (0.656)(0.516, 0.797)] [G loss: 1.198] [G acc: 0.109]\n",
      "3527 [D loss: (0.572)(R 0.608, F 0.535)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.168] [G acc: 0.141]\n",
      "3528 [D loss: (0.531)(R 0.509, F 0.552)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.275] [G acc: 0.141]\n",
      "3529 [D loss: (0.524)(R 0.592, F 0.456)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.369] [G acc: 0.062]\n",
      "3530 [D loss: (0.572)(R 0.571, F 0.573)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.261] [G acc: 0.109]\n",
      "3531 [D loss: (0.578)(R 0.502, F 0.654)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.257] [G acc: 0.078]\n",
      "3532 [D loss: (0.492)(R 0.515, F 0.469)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.354] [G acc: 0.125]\n",
      "3533 [D loss: (0.553)(R 0.493, F 0.612)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.450] [G acc: 0.031]\n",
      "3534 [D loss: (0.559)(R 0.595, F 0.523)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.243] [G acc: 0.109]\n",
      "3535 [D loss: (0.524)(R 0.590, F 0.459)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.362] [G acc: 0.125]\n",
      "3536 [D loss: (0.566)(R 0.562, F 0.569)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.292] [G acc: 0.203]\n",
      "3537 [D loss: (0.523)(R 0.509, F 0.536)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.363] [G acc: 0.109]\n",
      "3538 [D loss: (0.468)(R 0.438, F 0.498)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.352] [G acc: 0.078]\n",
      "3539 [D loss: (0.471)(R 0.521, F 0.421)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.455] [G acc: 0.062]\n",
      "3540 [D loss: (0.610)(R 0.586, F 0.633)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.203] [G acc: 0.156]\n",
      "3541 [D loss: (0.549)(R 0.548, F 0.551)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.402] [G acc: 0.078]\n",
      "3542 [D loss: (0.527)(R 0.527, F 0.528)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.394] [G acc: 0.062]\n",
      "3543 [D loss: (0.517)(R 0.467, F 0.567)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.284] [G acc: 0.109]\n",
      "3544 [D loss: (0.516)(R 0.609, F 0.423)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.351] [G acc: 0.141]\n",
      "3545 [D loss: (0.545)(R 0.565, F 0.525)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.355] [G acc: 0.094]\n",
      "3546 [D loss: (0.650)(R 0.619, F 0.681)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.403] [G acc: 0.109]\n",
      "3547 [D loss: (0.529)(R 0.605, F 0.454)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.227] [G acc: 0.219]\n",
      "3548 [D loss: (0.484)(R 0.493, F 0.475)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.449] [G acc: 0.188]\n",
      "3549 [D loss: (0.525)(R 0.491, F 0.559)] [D acc: (0.703)(0.734, 0.672)] [G loss: 1.302] [G acc: 0.188]\n",
      "3550 [D loss: (0.584)(R 0.632, F 0.536)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.405] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3551 [D loss: (0.541)(R 0.523, F 0.559)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.376] [G acc: 0.047]\n",
      "3552 [D loss: (0.580)(R 0.579, F 0.580)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.323] [G acc: 0.109]\n",
      "3553 [D loss: (0.590)(R 0.576, F 0.605)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.243] [G acc: 0.156]\n",
      "3554 [D loss: (0.563)(R 0.495, F 0.631)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.425] [G acc: 0.062]\n",
      "3555 [D loss: (0.559)(R 0.541, F 0.578)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.374] [G acc: 0.109]\n",
      "3556 [D loss: (0.524)(R 0.579, F 0.469)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.387] [G acc: 0.094]\n",
      "3557 [D loss: (0.629)(R 0.624, F 0.635)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.505] [G acc: 0.094]\n",
      "3558 [D loss: (0.622)(R 0.729, F 0.515)] [D acc: (0.672)(0.531, 0.812)] [G loss: 1.353] [G acc: 0.094]\n",
      "3559 [D loss: (0.553)(R 0.597, F 0.508)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.313] [G acc: 0.109]\n",
      "3560 [D loss: (0.538)(R 0.503, F 0.572)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.350] [G acc: 0.094]\n",
      "3561 [D loss: (0.494)(R 0.517, F 0.470)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.326] [G acc: 0.141]\n",
      "3562 [D loss: (0.495)(R 0.454, F 0.536)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.261] [G acc: 0.109]\n",
      "3563 [D loss: (0.551)(R 0.607, F 0.496)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.423] [G acc: 0.125]\n",
      "3564 [D loss: (0.566)(R 0.620, F 0.511)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.251] [G acc: 0.172]\n",
      "3565 [D loss: (0.556)(R 0.533, F 0.579)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.215] [G acc: 0.156]\n",
      "3566 [D loss: (0.557)(R 0.571, F 0.544)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.495] [G acc: 0.062]\n",
      "3567 [D loss: (0.651)(R 0.690, F 0.612)] [D acc: (0.633)(0.531, 0.734)] [G loss: 1.254] [G acc: 0.125]\n",
      "3568 [D loss: (0.524)(R 0.516, F 0.532)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.395] [G acc: 0.047]\n",
      "3569 [D loss: (0.567)(R 0.595, F 0.539)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.361] [G acc: 0.109]\n",
      "3570 [D loss: (0.614)(R 0.617, F 0.612)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.267] [G acc: 0.109]\n",
      "3571 [D loss: (0.562)(R 0.564, F 0.561)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.298] [G acc: 0.078]\n",
      "3572 [D loss: (0.552)(R 0.596, F 0.508)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.245] [G acc: 0.141]\n",
      "3573 [D loss: (0.541)(R 0.447, F 0.634)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.193] [G acc: 0.141]\n",
      "3574 [D loss: (0.501)(R 0.536, F 0.467)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.373] [G acc: 0.078]\n",
      "3575 [D loss: (0.512)(R 0.464, F 0.559)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.343] [G acc: 0.078]\n",
      "3576 [D loss: (0.596)(R 0.620, F 0.571)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.383] [G acc: 0.094]\n",
      "3577 [D loss: (0.556)(R 0.599, F 0.512)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.147] [G acc: 0.156]\n",
      "3578 [D loss: (0.553)(R 0.548, F 0.559)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.391] [G acc: 0.078]\n",
      "3579 [D loss: (0.472)(R 0.441, F 0.503)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.303] [G acc: 0.141]\n",
      "3580 [D loss: (0.657)(R 0.557, F 0.757)] [D acc: (0.656)(0.672, 0.641)] [G loss: 1.444] [G acc: 0.078]\n",
      "3581 [D loss: (0.551)(R 0.654, F 0.448)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.296] [G acc: 0.109]\n",
      "3582 [D loss: (0.561)(R 0.569, F 0.553)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.296] [G acc: 0.078]\n",
      "3583 [D loss: (0.569)(R 0.545, F 0.593)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.317] [G acc: 0.062]\n",
      "3584 [D loss: (0.674)(R 0.781, F 0.567)] [D acc: (0.609)(0.438, 0.781)] [G loss: 1.279] [G acc: 0.125]\n",
      "3585 [D loss: (0.510)(R 0.625, F 0.396)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.361] [G acc: 0.125]\n",
      "3586 [D loss: (0.654)(R 0.564, F 0.744)] [D acc: (0.594)(0.641, 0.547)] [G loss: 1.345] [G acc: 0.094]\n",
      "3587 [D loss: (0.522)(R 0.595, F 0.448)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.320] [G acc: 0.125]\n",
      "3588 [D loss: (0.556)(R 0.565, F 0.547)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.316] [G acc: 0.078]\n",
      "3589 [D loss: (0.538)(R 0.571, F 0.504)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.234] [G acc: 0.156]\n",
      "3590 [D loss: (0.524)(R 0.478, F 0.570)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.332] [G acc: 0.078]\n",
      "3591 [D loss: (0.540)(R 0.614, F 0.465)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.252] [G acc: 0.188]\n",
      "3592 [D loss: (0.652)(R 0.584, F 0.721)] [D acc: (0.641)(0.656, 0.625)] [G loss: 1.332] [G acc: 0.109]\n",
      "3593 [D loss: (0.595)(R 0.706, F 0.485)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.228] [G acc: 0.125]\n",
      "3594 [D loss: (0.572)(R 0.595, F 0.549)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.217] [G acc: 0.188]\n",
      "3595 [D loss: (0.517)(R 0.517, F 0.517)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.306] [G acc: 0.125]\n",
      "3596 [D loss: (0.536)(R 0.502, F 0.569)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.407] [G acc: 0.125]\n",
      "3597 [D loss: (0.641)(R 0.693, F 0.589)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.303] [G acc: 0.109]\n",
      "3598 [D loss: (0.563)(R 0.666, F 0.461)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.358] [G acc: 0.094]\n",
      "3599 [D loss: (0.544)(R 0.584, F 0.504)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.250] [G acc: 0.156]\n",
      "3600 [D loss: (0.529)(R 0.499, F 0.559)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.378] [G acc: 0.078]\n",
      "3601 [D loss: (0.583)(R 0.640, F 0.525)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.351] [G acc: 0.062]\n",
      "3602 [D loss: (0.504)(R 0.475, F 0.534)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.337] [G acc: 0.156]\n",
      "3603 [D loss: (0.434)(R 0.443, F 0.425)] [D acc: (0.836)(0.797, 0.875)] [G loss: 1.393] [G acc: 0.125]\n",
      "3604 [D loss: (0.556)(R 0.560, F 0.553)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.385] [G acc: 0.078]\n",
      "3605 [D loss: (0.524)(R 0.587, F 0.461)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.423] [G acc: 0.094]\n",
      "3606 [D loss: (0.547)(R 0.610, F 0.484)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.297] [G acc: 0.109]\n",
      "3607 [D loss: (0.553)(R 0.514, F 0.593)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.473] [G acc: 0.047]\n",
      "3608 [D loss: (0.579)(R 0.583, F 0.575)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.349] [G acc: 0.047]\n",
      "3609 [D loss: (0.515)(R 0.565, F 0.466)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.639] [G acc: 0.047]\n",
      "3610 [D loss: (0.524)(R 0.588, F 0.461)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.453] [G acc: 0.078]\n",
      "3611 [D loss: (0.560)(R 0.500, F 0.619)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.286] [G acc: 0.094]\n",
      "3612 [D loss: (0.542)(R 0.669, F 0.414)] [D acc: (0.680)(0.469, 0.891)] [G loss: 1.457] [G acc: 0.172]\n",
      "3613 [D loss: (0.638)(R 0.522, F 0.754)] [D acc: (0.656)(0.672, 0.641)] [G loss: 1.448] [G acc: 0.062]\n",
      "3614 [D loss: (0.525)(R 0.596, F 0.453)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.390] [G acc: 0.047]\n",
      "3615 [D loss: (0.487)(R 0.540, F 0.435)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.361] [G acc: 0.109]\n",
      "3616 [D loss: (0.549)(R 0.634, F 0.464)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.442] [G acc: 0.109]\n",
      "3617 [D loss: (0.583)(R 0.647, F 0.518)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.451] [G acc: 0.031]\n",
      "3618 [D loss: (0.569)(R 0.532, F 0.605)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.368] [G acc: 0.062]\n",
      "3619 [D loss: (0.573)(R 0.617, F 0.528)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.449] [G acc: 0.016]\n",
      "3620 [D loss: (0.505)(R 0.608, F 0.402)] [D acc: (0.750)(0.578, 0.922)] [G loss: 1.372] [G acc: 0.078]\n",
      "3621 [D loss: (0.505)(R 0.457, F 0.553)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.400] [G acc: 0.094]\n",
      "3622 [D loss: (0.615)(R 0.638, F 0.591)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.274] [G acc: 0.109]\n",
      "3623 [D loss: (0.629)(R 0.628, F 0.631)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.323] [G acc: 0.141]\n",
      "3624 [D loss: (0.573)(R 0.611, F 0.536)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.241] [G acc: 0.141]\n",
      "3625 [D loss: (0.674)(R 0.659, F 0.689)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.307] [G acc: 0.094]\n",
      "3626 [D loss: (0.548)(R 0.572, F 0.525)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.234] [G acc: 0.125]\n",
      "3627 [D loss: (0.513)(R 0.516, F 0.511)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.349] [G acc: 0.078]\n",
      "3628 [D loss: (0.599)(R 0.655, F 0.544)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.268] [G acc: 0.125]\n",
      "3629 [D loss: (0.502)(R 0.522, F 0.481)] [D acc: (0.805)(0.750, 0.859)] [G loss: 1.348] [G acc: 0.125]\n",
      "3630 [D loss: (0.596)(R 0.546, F 0.646)] [D acc: (0.664)(0.672, 0.656)] [G loss: 1.280] [G acc: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3631 [D loss: (0.628)(R 0.715, F 0.541)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.400] [G acc: 0.062]\n",
      "3632 [D loss: (0.555)(R 0.623, F 0.487)] [D acc: (0.727)(0.562, 0.891)] [G loss: 1.290] [G acc: 0.203]\n",
      "3633 [D loss: (0.591)(R 0.611, F 0.570)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.307] [G acc: 0.141]\n",
      "3634 [D loss: (0.567)(R 0.538, F 0.597)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.339] [G acc: 0.062]\n",
      "3635 [D loss: (0.585)(R 0.704, F 0.466)] [D acc: (0.680)(0.531, 0.828)] [G loss: 1.127] [G acc: 0.141]\n",
      "3636 [D loss: (0.516)(R 0.469, F 0.563)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.351] [G acc: 0.094]\n",
      "3637 [D loss: (0.532)(R 0.596, F 0.467)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.318] [G acc: 0.109]\n",
      "3638 [D loss: (0.584)(R 0.590, F 0.578)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.302] [G acc: 0.094]\n",
      "3639 [D loss: (0.506)(R 0.507, F 0.506)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.287] [G acc: 0.141]\n",
      "3640 [D loss: (0.568)(R 0.466, F 0.670)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.277] [G acc: 0.125]\n",
      "3641 [D loss: (0.554)(R 0.648, F 0.460)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.295] [G acc: 0.078]\n",
      "3642 [D loss: (0.539)(R 0.519, F 0.559)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.408] [G acc: 0.156]\n",
      "3643 [D loss: (0.623)(R 0.709, F 0.537)] [D acc: (0.625)(0.531, 0.719)] [G loss: 1.289] [G acc: 0.172]\n",
      "3644 [D loss: (0.552)(R 0.492, F 0.613)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.209] [G acc: 0.141]\n",
      "3645 [D loss: (0.552)(R 0.570, F 0.534)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.250] [G acc: 0.125]\n",
      "3646 [D loss: (0.632)(R 0.710, F 0.554)] [D acc: (0.633)(0.531, 0.734)] [G loss: 1.441] [G acc: 0.078]\n",
      "3647 [D loss: (0.463)(R 0.460, F 0.466)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.351] [G acc: 0.141]\n",
      "3648 [D loss: (0.516)(R 0.533, F 0.498)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.278] [G acc: 0.156]\n",
      "3649 [D loss: (0.524)(R 0.428, F 0.619)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.362] [G acc: 0.078]\n",
      "3650 [D loss: (0.591)(R 0.637, F 0.545)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.457] [G acc: 0.172]\n",
      "3651 [D loss: (0.516)(R 0.502, F 0.530)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.380] [G acc: 0.016]\n",
      "3652 [D loss: (0.608)(R 0.693, F 0.523)] [D acc: (0.648)(0.547, 0.750)] [G loss: 1.296] [G acc: 0.094]\n",
      "3653 [D loss: (0.583)(R 0.544, F 0.622)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.323] [G acc: 0.078]\n",
      "3654 [D loss: (0.482)(R 0.513, F 0.452)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.323] [G acc: 0.109]\n",
      "3655 [D loss: (0.632)(R 0.598, F 0.665)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.471] [G acc: 0.062]\n",
      "3656 [D loss: (0.544)(R 0.579, F 0.508)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.234] [G acc: 0.141]\n",
      "3657 [D loss: (0.527)(R 0.520, F 0.534)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.228] [G acc: 0.156]\n",
      "3658 [D loss: (0.480)(R 0.524, F 0.435)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.280] [G acc: 0.156]\n",
      "3659 [D loss: (0.456)(R 0.467, F 0.445)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.414] [G acc: 0.141]\n",
      "3660 [D loss: (0.617)(R 0.563, F 0.672)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.369] [G acc: 0.094]\n",
      "3661 [D loss: (0.558)(R 0.539, F 0.578)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.454] [G acc: 0.141]\n",
      "3662 [D loss: (0.685)(R 0.748, F 0.623)] [D acc: (0.586)(0.500, 0.672)] [G loss: 1.294] [G acc: 0.125]\n",
      "3663 [D loss: (0.529)(R 0.515, F 0.543)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.427] [G acc: 0.125]\n",
      "3664 [D loss: (0.642)(R 0.788, F 0.496)] [D acc: (0.609)(0.438, 0.781)] [G loss: 1.363] [G acc: 0.062]\n",
      "3665 [D loss: (0.564)(R 0.564, F 0.565)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.287] [G acc: 0.078]\n",
      "3666 [D loss: (0.638)(R 0.656, F 0.621)] [D acc: (0.586)(0.516, 0.656)] [G loss: 1.279] [G acc: 0.125]\n",
      "3667 [D loss: (0.607)(R 0.710, F 0.503)] [D acc: (0.672)(0.516, 0.828)] [G loss: 1.376] [G acc: 0.078]\n",
      "3668 [D loss: (0.503)(R 0.489, F 0.518)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.276] [G acc: 0.109]\n",
      "3669 [D loss: (0.545)(R 0.428, F 0.662)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.395] [G acc: 0.109]\n",
      "3670 [D loss: (0.543)(R 0.616, F 0.469)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.358] [G acc: 0.078]\n",
      "3671 [D loss: (0.570)(R 0.612, F 0.528)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.294] [G acc: 0.078]\n",
      "3672 [D loss: (0.607)(R 0.589, F 0.625)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.321] [G acc: 0.094]\n",
      "3673 [D loss: (0.495)(R 0.462, F 0.527)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.359] [G acc: 0.125]\n",
      "3674 [D loss: (0.583)(R 0.602, F 0.564)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.309] [G acc: 0.062]\n",
      "3675 [D loss: (0.492)(R 0.554, F 0.430)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.430] [G acc: 0.031]\n",
      "3676 [D loss: (0.543)(R 0.532, F 0.553)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.482] [G acc: 0.078]\n",
      "3677 [D loss: (0.572)(R 0.491, F 0.653)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.518] [G acc: 0.109]\n",
      "3678 [D loss: (0.577)(R 0.696, F 0.458)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.420] [G acc: 0.078]\n",
      "3679 [D loss: (0.588)(R 0.632, F 0.545)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.359] [G acc: 0.062]\n",
      "3680 [D loss: (0.506)(R 0.616, F 0.395)] [D acc: (0.719)(0.516, 0.922)] [G loss: 1.323] [G acc: 0.141]\n",
      "3681 [D loss: (0.543)(R 0.541, F 0.545)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.231] [G acc: 0.141]\n",
      "3682 [D loss: (0.570)(R 0.600, F 0.541)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.217] [G acc: 0.078]\n",
      "3683 [D loss: (0.609)(R 0.470, F 0.747)] [D acc: (0.680)(0.734, 0.625)] [G loss: 1.343] [G acc: 0.078]\n",
      "3684 [D loss: (0.573)(R 0.723, F 0.423)] [D acc: (0.695)(0.516, 0.875)] [G loss: 1.264] [G acc: 0.109]\n",
      "3685 [D loss: (0.522)(R 0.485, F 0.560)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.335] [G acc: 0.125]\n",
      "3686 [D loss: (0.568)(R 0.545, F 0.591)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.247] [G acc: 0.094]\n",
      "3687 [D loss: (0.551)(R 0.586, F 0.516)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.128] [G acc: 0.125]\n",
      "3688 [D loss: (0.536)(R 0.523, F 0.549)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.382] [G acc: 0.078]\n",
      "3689 [D loss: (0.573)(R 0.532, F 0.614)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.353] [G acc: 0.078]\n",
      "3690 [D loss: (0.539)(R 0.560, F 0.519)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.278] [G acc: 0.078]\n",
      "3691 [D loss: (0.470)(R 0.456, F 0.484)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.431] [G acc: 0.156]\n",
      "3692 [D loss: (0.480)(R 0.469, F 0.491)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.417] [G acc: 0.078]\n",
      "3693 [D loss: (0.495)(R 0.549, F 0.441)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.545] [G acc: 0.094]\n",
      "3694 [D loss: (0.522)(R 0.541, F 0.503)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.375] [G acc: 0.078]\n",
      "3695 [D loss: (0.516)(R 0.385, F 0.648)] [D acc: (0.781)(0.844, 0.719)] [G loss: 1.505] [G acc: 0.062]\n",
      "3696 [D loss: (0.571)(R 0.598, F 0.545)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.404] [G acc: 0.062]\n",
      "3697 [D loss: (0.518)(R 0.613, F 0.422)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.353] [G acc: 0.141]\n",
      "3698 [D loss: (0.569)(R 0.537, F 0.600)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.405] [G acc: 0.094]\n",
      "3699 [D loss: (0.502)(R 0.567, F 0.436)] [D acc: (0.773)(0.641, 0.906)] [G loss: 1.432] [G acc: 0.109]\n",
      "3700 [D loss: (0.618)(R 0.616, F 0.620)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.461] [G acc: 0.141]\n",
      "3701 [D loss: (0.512)(R 0.570, F 0.454)] [D acc: (0.773)(0.641, 0.906)] [G loss: 1.451] [G acc: 0.141]\n",
      "3702 [D loss: (0.564)(R 0.570, F 0.558)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.316] [G acc: 0.188]\n",
      "3703 [D loss: (0.549)(R 0.539, F 0.559)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.323] [G acc: 0.109]\n",
      "3704 [D loss: (0.515)(R 0.580, F 0.449)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.457] [G acc: 0.062]\n",
      "3705 [D loss: (0.475)(R 0.489, F 0.461)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.509] [G acc: 0.047]\n",
      "3706 [D loss: (0.486)(R 0.501, F 0.472)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.455] [G acc: 0.125]\n",
      "3707 [D loss: (0.439)(R 0.395, F 0.484)] [D acc: (0.820)(0.844, 0.797)] [G loss: 1.529] [G acc: 0.141]\n",
      "3708 [D loss: (0.609)(R 0.555, F 0.663)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.463] [G acc: 0.031]\n",
      "3709 [D loss: (0.524)(R 0.605, F 0.444)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.491] [G acc: 0.109]\n",
      "3710 [D loss: (0.573)(R 0.655, F 0.492)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.553] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3711 [D loss: (0.624)(R 0.622, F 0.625)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.623] [G acc: 0.031]\n",
      "3712 [D loss: (0.625)(R 0.624, F 0.625)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.338] [G acc: 0.062]\n",
      "3713 [D loss: (0.473)(R 0.502, F 0.443)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.483] [G acc: 0.062]\n",
      "3714 [D loss: (0.442)(R 0.410, F 0.474)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.462] [G acc: 0.094]\n",
      "3715 [D loss: (0.464)(R 0.441, F 0.486)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.433] [G acc: 0.141]\n",
      "3716 [D loss: (0.489)(R 0.523, F 0.456)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.414] [G acc: 0.109]\n",
      "3717 [D loss: (0.493)(R 0.530, F 0.456)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.529] [G acc: 0.078]\n",
      "3718 [D loss: (0.427)(R 0.494, F 0.360)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.453] [G acc: 0.172]\n",
      "3719 [D loss: (0.561)(R 0.557, F 0.565)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.645] [G acc: 0.047]\n",
      "3720 [D loss: (0.521)(R 0.538, F 0.505)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.565] [G acc: 0.062]\n",
      "3721 [D loss: (0.548)(R 0.622, F 0.474)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.298] [G acc: 0.141]\n",
      "3722 [D loss: (0.516)(R 0.536, F 0.497)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.345] [G acc: 0.125]\n",
      "3723 [D loss: (0.571)(R 0.590, F 0.552)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.643] [G acc: 0.094]\n",
      "3724 [D loss: (0.520)(R 0.486, F 0.555)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.512] [G acc: 0.125]\n",
      "3725 [D loss: (0.469)(R 0.513, F 0.426)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.513] [G acc: 0.188]\n",
      "3726 [D loss: (0.557)(R 0.618, F 0.497)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.598] [G acc: 0.094]\n",
      "3727 [D loss: (0.521)(R 0.515, F 0.528)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.364] [G acc: 0.141]\n",
      "3728 [D loss: (0.568)(R 0.618, F 0.517)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.429] [G acc: 0.094]\n",
      "3729 [D loss: (0.559)(R 0.605, F 0.514)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.342] [G acc: 0.156]\n",
      "3730 [D loss: (0.647)(R 0.646, F 0.647)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.435] [G acc: 0.078]\n",
      "3731 [D loss: (0.530)(R 0.583, F 0.478)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.268] [G acc: 0.141]\n",
      "3732 [D loss: (0.530)(R 0.566, F 0.494)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.351] [G acc: 0.141]\n",
      "3733 [D loss: (0.512)(R 0.434, F 0.590)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.373] [G acc: 0.094]\n",
      "3734 [D loss: (0.419)(R 0.410, F 0.428)] [D acc: (0.844)(0.828, 0.859)] [G loss: 1.435] [G acc: 0.062]\n",
      "3735 [D loss: (0.505)(R 0.508, F 0.501)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.477] [G acc: 0.125]\n",
      "3736 [D loss: (0.484)(R 0.471, F 0.497)] [D acc: (0.820)(0.828, 0.812)] [G loss: 1.441] [G acc: 0.078]\n",
      "3737 [D loss: (0.541)(R 0.605, F 0.477)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.560] [G acc: 0.109]\n",
      "3738 [D loss: (0.627)(R 0.650, F 0.603)] [D acc: (0.633)(0.547, 0.719)] [G loss: 1.345] [G acc: 0.141]\n",
      "3739 [D loss: (0.544)(R 0.590, F 0.498)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.500] [G acc: 0.078]\n",
      "3740 [D loss: (0.608)(R 0.549, F 0.666)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.453] [G acc: 0.016]\n",
      "3741 [D loss: (0.641)(R 0.765, F 0.518)] [D acc: (0.609)(0.516, 0.703)] [G loss: 1.268] [G acc: 0.109]\n",
      "3742 [D loss: (0.485)(R 0.485, F 0.486)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.240] [G acc: 0.156]\n",
      "3743 [D loss: (0.552)(R 0.500, F 0.604)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.413] [G acc: 0.094]\n",
      "3744 [D loss: (0.546)(R 0.574, F 0.518)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.306] [G acc: 0.125]\n",
      "3745 [D loss: (0.552)(R 0.578, F 0.525)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.255] [G acc: 0.125]\n",
      "3746 [D loss: (0.565)(R 0.639, F 0.490)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.428] [G acc: 0.078]\n",
      "3747 [D loss: (0.490)(R 0.536, F 0.444)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.500] [G acc: 0.078]\n",
      "3748 [D loss: (0.500)(R 0.489, F 0.510)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.236] [G acc: 0.234]\n",
      "3749 [D loss: (0.619)(R 0.511, F 0.727)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.486] [G acc: 0.062]\n",
      "3750 [D loss: (0.627)(R 0.699, F 0.554)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.447] [G acc: 0.047]\n",
      "3751 [D loss: (0.483)(R 0.593, F 0.373)] [D acc: (0.805)(0.656, 0.953)] [G loss: 1.395] [G acc: 0.047]\n",
      "3752 [D loss: (0.503)(R 0.491, F 0.515)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.445] [G acc: 0.109]\n",
      "3753 [D loss: (0.489)(R 0.535, F 0.442)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.384] [G acc: 0.156]\n",
      "3754 [D loss: (0.502)(R 0.553, F 0.451)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.364] [G acc: 0.109]\n",
      "3755 [D loss: (0.609)(R 0.493, F 0.725)] [D acc: (0.656)(0.672, 0.641)] [G loss: 1.459] [G acc: 0.047]\n",
      "3756 [D loss: (0.582)(R 0.701, F 0.463)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.492] [G acc: 0.078]\n",
      "3757 [D loss: (0.633)(R 0.633, F 0.634)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.511] [G acc: 0.078]\n",
      "3758 [D loss: (0.522)(R 0.602, F 0.442)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.328] [G acc: 0.156]\n",
      "3759 [D loss: (0.591)(R 0.498, F 0.683)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.421] [G acc: 0.109]\n",
      "3760 [D loss: (0.535)(R 0.543, F 0.526)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.265] [G acc: 0.109]\n",
      "3761 [D loss: (0.538)(R 0.540, F 0.536)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.382] [G acc: 0.109]\n",
      "3762 [D loss: (0.538)(R 0.585, F 0.492)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.439] [G acc: 0.094]\n",
      "3763 [D loss: (0.582)(R 0.679, F 0.486)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.381] [G acc: 0.141]\n",
      "3764 [D loss: (0.588)(R 0.491, F 0.685)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.347] [G acc: 0.078]\n",
      "3765 [D loss: (0.567)(R 0.604, F 0.529)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.433] [G acc: 0.109]\n",
      "3766 [D loss: (0.528)(R 0.561, F 0.494)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.322] [G acc: 0.125]\n",
      "3767 [D loss: (0.530)(R 0.550, F 0.510)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.430] [G acc: 0.078]\n",
      "3768 [D loss: (0.649)(R 0.711, F 0.587)] [D acc: (0.633)(0.531, 0.734)] [G loss: 1.283] [G acc: 0.062]\n",
      "3769 [D loss: (0.542)(R 0.574, F 0.510)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.379] [G acc: 0.047]\n",
      "3770 [D loss: (0.481)(R 0.454, F 0.508)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.219] [G acc: 0.125]\n",
      "3771 [D loss: (0.645)(R 0.539, F 0.750)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.277] [G acc: 0.094]\n",
      "3772 [D loss: (0.566)(R 0.664, F 0.468)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.330] [G acc: 0.078]\n",
      "3773 [D loss: (0.526)(R 0.621, F 0.431)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.332] [G acc: 0.125]\n",
      "3774 [D loss: (0.535)(R 0.556, F 0.513)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.318] [G acc: 0.109]\n",
      "3775 [D loss: (0.585)(R 0.594, F 0.576)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.343] [G acc: 0.016]\n",
      "3776 [D loss: (0.552)(R 0.590, F 0.515)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.392] [G acc: 0.141]\n",
      "3777 [D loss: (0.581)(R 0.511, F 0.651)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.303] [G acc: 0.203]\n",
      "3778 [D loss: (0.563)(R 0.556, F 0.570)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.236] [G acc: 0.109]\n",
      "3779 [D loss: (0.436)(R 0.460, F 0.411)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.332] [G acc: 0.109]\n",
      "3780 [D loss: (0.483)(R 0.513, F 0.452)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.428] [G acc: 0.062]\n",
      "3781 [D loss: (0.588)(R 0.571, F 0.605)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.446] [G acc: 0.047]\n",
      "3782 [D loss: (0.526)(R 0.535, F 0.516)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.292] [G acc: 0.125]\n",
      "3783 [D loss: (0.544)(R 0.562, F 0.526)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.351] [G acc: 0.125]\n",
      "3784 [D loss: (0.503)(R 0.587, F 0.419)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.359] [G acc: 0.109]\n",
      "3785 [D loss: (0.471)(R 0.507, F 0.436)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.390] [G acc: 0.062]\n",
      "3786 [D loss: (0.523)(R 0.392, F 0.654)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.564] [G acc: 0.031]\n",
      "3787 [D loss: (0.518)(R 0.583, F 0.453)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.651] [G acc: 0.000]\n",
      "3788 [D loss: (0.543)(R 0.547, F 0.539)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.380] [G acc: 0.094]\n",
      "3789 [D loss: (0.500)(R 0.508, F 0.492)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.613] [G acc: 0.078]\n",
      "3790 [D loss: (0.550)(R 0.520, F 0.580)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.512] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3791 [D loss: (0.570)(R 0.617, F 0.522)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.546] [G acc: 0.062]\n",
      "3792 [D loss: (0.568)(R 0.561, F 0.574)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.456] [G acc: 0.109]\n",
      "3793 [D loss: (0.541)(R 0.560, F 0.522)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.388] [G acc: 0.156]\n",
      "3794 [D loss: (0.445)(R 0.492, F 0.399)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.301] [G acc: 0.141]\n",
      "3795 [D loss: (0.467)(R 0.432, F 0.503)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.327] [G acc: 0.172]\n",
      "3796 [D loss: (0.550)(R 0.500, F 0.601)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.443] [G acc: 0.125]\n",
      "3797 [D loss: (0.503)(R 0.613, F 0.393)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.492] [G acc: 0.141]\n",
      "3798 [D loss: (0.518)(R 0.548, F 0.487)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.446] [G acc: 0.031]\n",
      "3799 [D loss: (0.473)(R 0.566, F 0.379)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.574] [G acc: 0.141]\n",
      "3800 [D loss: (0.552)(R 0.512, F 0.592)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.458] [G acc: 0.219]\n",
      "3801 [D loss: (0.529)(R 0.555, F 0.503)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.620] [G acc: 0.125]\n",
      "3802 [D loss: (0.474)(R 0.361, F 0.588)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.465] [G acc: 0.109]\n",
      "3803 [D loss: (0.585)(R 0.644, F 0.526)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.381] [G acc: 0.062]\n",
      "3804 [D loss: (0.592)(R 0.666, F 0.518)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.364] [G acc: 0.141]\n",
      "3805 [D loss: (0.527)(R 0.471, F 0.584)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.337] [G acc: 0.125]\n",
      "3806 [D loss: (0.522)(R 0.529, F 0.514)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.362] [G acc: 0.094]\n",
      "3807 [D loss: (0.517)(R 0.459, F 0.576)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.534] [G acc: 0.094]\n",
      "3808 [D loss: (0.590)(R 0.615, F 0.566)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.344] [G acc: 0.156]\n",
      "3809 [D loss: (0.554)(R 0.616, F 0.492)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.291] [G acc: 0.219]\n",
      "3810 [D loss: (0.511)(R 0.495, F 0.527)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.320] [G acc: 0.141]\n",
      "3811 [D loss: (0.637)(R 0.594, F 0.680)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.322] [G acc: 0.047]\n",
      "3812 [D loss: (0.490)(R 0.516, F 0.464)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.513] [G acc: 0.078]\n",
      "3813 [D loss: (0.490)(R 0.480, F 0.500)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.467] [G acc: 0.125]\n",
      "3814 [D loss: (0.584)(R 0.555, F 0.613)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.464] [G acc: 0.047]\n",
      "3815 [D loss: (0.517)(R 0.624, F 0.409)] [D acc: (0.711)(0.547, 0.875)] [G loss: 1.436] [G acc: 0.109]\n",
      "3816 [D loss: (0.559)(R 0.553, F 0.564)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.476] [G acc: 0.125]\n",
      "3817 [D loss: (0.549)(R 0.594, F 0.504)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.501] [G acc: 0.141]\n",
      "3818 [D loss: (0.607)(R 0.615, F 0.599)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.429] [G acc: 0.078]\n",
      "3819 [D loss: (0.628)(R 0.642, F 0.614)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.298] [G acc: 0.125]\n",
      "3820 [D loss: (0.504)(R 0.564, F 0.444)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.374] [G acc: 0.156]\n",
      "3821 [D loss: (0.486)(R 0.534, F 0.438)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.279] [G acc: 0.234]\n",
      "3822 [D loss: (0.572)(R 0.492, F 0.652)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.335] [G acc: 0.094]\n",
      "3823 [D loss: (0.589)(R 0.662, F 0.517)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.362] [G acc: 0.172]\n",
      "3824 [D loss: (0.612)(R 0.559, F 0.665)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.452] [G acc: 0.125]\n",
      "3825 [D loss: (0.703)(R 0.684, F 0.722)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.332] [G acc: 0.078]\n",
      "3826 [D loss: (0.638)(R 0.796, F 0.480)] [D acc: (0.664)(0.500, 0.828)] [G loss: 1.368] [G acc: 0.141]\n",
      "3827 [D loss: (0.577)(R 0.560, F 0.594)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.385] [G acc: 0.078]\n",
      "3828 [D loss: (0.570)(R 0.658, F 0.481)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.307] [G acc: 0.125]\n",
      "3829 [D loss: (0.539)(R 0.544, F 0.535)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.219] [G acc: 0.188]\n",
      "3830 [D loss: (0.609)(R 0.635, F 0.584)] [D acc: (0.633)(0.531, 0.734)] [G loss: 1.326] [G acc: 0.141]\n",
      "3831 [D loss: (0.501)(R 0.463, F 0.539)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.357] [G acc: 0.172]\n",
      "3832 [D loss: (0.498)(R 0.441, F 0.555)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.380] [G acc: 0.125]\n",
      "3833 [D loss: (0.526)(R 0.594, F 0.458)] [D acc: (0.766)(0.625, 0.906)] [G loss: 1.367] [G acc: 0.062]\n",
      "3834 [D loss: (0.503)(R 0.537, F 0.469)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.305] [G acc: 0.141]\n",
      "3835 [D loss: (0.601)(R 0.669, F 0.534)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.552] [G acc: 0.031]\n",
      "3836 [D loss: (0.647)(R 0.780, F 0.514)] [D acc: (0.641)(0.500, 0.781)] [G loss: 1.244] [G acc: 0.109]\n",
      "3837 [D loss: (0.459)(R 0.372, F 0.546)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.336] [G acc: 0.094]\n",
      "3838 [D loss: (0.518)(R 0.499, F 0.536)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.393] [G acc: 0.062]\n",
      "3839 [D loss: (0.521)(R 0.493, F 0.549)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.290] [G acc: 0.094]\n",
      "3840 [D loss: (0.639)(R 0.652, F 0.627)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.241] [G acc: 0.156]\n",
      "3841 [D loss: (0.577)(R 0.593, F 0.561)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.384] [G acc: 0.078]\n",
      "3842 [D loss: (0.619)(R 0.590, F 0.649)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.428] [G acc: 0.062]\n",
      "3843 [D loss: (0.558)(R 0.590, F 0.525)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.339] [G acc: 0.125]\n",
      "3844 [D loss: (0.501)(R 0.420, F 0.581)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.323] [G acc: 0.062]\n",
      "3845 [D loss: (0.453)(R 0.458, F 0.448)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.346] [G acc: 0.078]\n",
      "3846 [D loss: (0.579)(R 0.565, F 0.593)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.409] [G acc: 0.078]\n",
      "3847 [D loss: (0.485)(R 0.512, F 0.457)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.519] [G acc: 0.078]\n",
      "3848 [D loss: (0.533)(R 0.520, F 0.547)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.323] [G acc: 0.141]\n",
      "3849 [D loss: (0.625)(R 0.647, F 0.603)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.373] [G acc: 0.188]\n",
      "3850 [D loss: (0.565)(R 0.619, F 0.510)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.589] [G acc: 0.094]\n",
      "3851 [D loss: (0.482)(R 0.518, F 0.446)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.345] [G acc: 0.172]\n",
      "3852 [D loss: (0.600)(R 0.474, F 0.727)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.414] [G acc: 0.078]\n",
      "3853 [D loss: (0.510)(R 0.583, F 0.437)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.434] [G acc: 0.109]\n",
      "3854 [D loss: (0.556)(R 0.580, F 0.531)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.462] [G acc: 0.047]\n",
      "3855 [D loss: (0.512)(R 0.572, F 0.451)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.425] [G acc: 0.156]\n",
      "3856 [D loss: (0.525)(R 0.483, F 0.566)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.252] [G acc: 0.250]\n",
      "3857 [D loss: (0.456)(R 0.471, F 0.440)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.561] [G acc: 0.094]\n",
      "3858 [D loss: (0.457)(R 0.515, F 0.400)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.306] [G acc: 0.172]\n",
      "3859 [D loss: (0.538)(R 0.464, F 0.612)] [D acc: (0.750)(0.781, 0.719)] [G loss: 1.385] [G acc: 0.172]\n",
      "3860 [D loss: (0.535)(R 0.563, F 0.507)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.340] [G acc: 0.250]\n",
      "3861 [D loss: (0.574)(R 0.604, F 0.543)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.274] [G acc: 0.141]\n",
      "3862 [D loss: (0.452)(R 0.448, F 0.456)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.333] [G acc: 0.109]\n",
      "3863 [D loss: (0.490)(R 0.578, F 0.402)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.306] [G acc: 0.203]\n",
      "3864 [D loss: (0.693)(R 0.639, F 0.746)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.504] [G acc: 0.062]\n",
      "3865 [D loss: (0.525)(R 0.549, F 0.501)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.446] [G acc: 0.188]\n",
      "3866 [D loss: (0.504)(R 0.508, F 0.500)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.294] [G acc: 0.125]\n",
      "3867 [D loss: (0.579)(R 0.615, F 0.543)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.300] [G acc: 0.172]\n",
      "3868 [D loss: (0.559)(R 0.588, F 0.530)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.257] [G acc: 0.125]\n",
      "3869 [D loss: (0.633)(R 0.636, F 0.631)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.209] [G acc: 0.156]\n",
      "3870 [D loss: (0.612)(R 0.594, F 0.631)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.536] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3871 [D loss: (0.655)(R 0.768, F 0.543)] [D acc: (0.641)(0.484, 0.797)] [G loss: 1.297] [G acc: 0.062]\n",
      "3872 [D loss: (0.615)(R 0.566, F 0.665)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.231] [G acc: 0.125]\n",
      "3873 [D loss: (0.514)(R 0.504, F 0.523)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.335] [G acc: 0.203]\n",
      "3874 [D loss: (0.616)(R 0.596, F 0.637)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.159] [G acc: 0.219]\n",
      "3875 [D loss: (0.493)(R 0.489, F 0.497)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.214] [G acc: 0.188]\n",
      "3876 [D loss: (0.584)(R 0.548, F 0.621)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.318] [G acc: 0.156]\n",
      "3877 [D loss: (0.581)(R 0.591, F 0.572)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.283] [G acc: 0.141]\n",
      "3878 [D loss: (0.581)(R 0.587, F 0.575)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.544] [G acc: 0.047]\n",
      "3879 [D loss: (0.503)(R 0.554, F 0.451)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.258] [G acc: 0.141]\n",
      "3880 [D loss: (0.512)(R 0.517, F 0.507)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.346] [G acc: 0.094]\n",
      "3881 [D loss: (0.452)(R 0.397, F 0.506)] [D acc: (0.750)(0.781, 0.719)] [G loss: 1.497] [G acc: 0.141]\n",
      "3882 [D loss: (0.461)(R 0.434, F 0.488)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.374] [G acc: 0.156]\n",
      "3883 [D loss: (0.530)(R 0.562, F 0.498)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.486] [G acc: 0.062]\n",
      "3884 [D loss: (0.468)(R 0.470, F 0.466)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.606] [G acc: 0.109]\n",
      "3885 [D loss: (0.474)(R 0.485, F 0.462)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.563] [G acc: 0.094]\n",
      "3886 [D loss: (0.542)(R 0.572, F 0.513)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.424] [G acc: 0.094]\n",
      "3887 [D loss: (0.575)(R 0.609, F 0.540)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.637] [G acc: 0.125]\n",
      "3888 [D loss: (0.542)(R 0.554, F 0.530)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.522] [G acc: 0.062]\n",
      "3889 [D loss: (0.523)(R 0.509, F 0.537)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.505] [G acc: 0.109]\n",
      "3890 [D loss: (0.554)(R 0.514, F 0.594)] [D acc: (0.734)(0.766, 0.703)] [G loss: 1.524] [G acc: 0.141]\n",
      "3891 [D loss: (0.539)(R 0.644, F 0.433)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.321] [G acc: 0.141]\n",
      "3892 [D loss: (0.595)(R 0.541, F 0.649)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.317] [G acc: 0.156]\n",
      "3893 [D loss: (0.520)(R 0.561, F 0.480)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.526] [G acc: 0.109]\n",
      "3894 [D loss: (0.507)(R 0.517, F 0.496)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.504] [G acc: 0.078]\n",
      "3895 [D loss: (0.559)(R 0.617, F 0.502)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.395] [G acc: 0.109]\n",
      "3896 [D loss: (0.574)(R 0.627, F 0.521)] [D acc: (0.672)(0.531, 0.812)] [G loss: 1.296] [G acc: 0.219]\n",
      "3897 [D loss: (0.611)(R 0.629, F 0.593)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.260] [G acc: 0.141]\n",
      "3898 [D loss: (0.569)(R 0.624, F 0.513)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.336] [G acc: 0.094]\n",
      "3899 [D loss: (0.549)(R 0.537, F 0.560)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.260] [G acc: 0.203]\n",
      "3900 [D loss: (0.545)(R 0.419, F 0.671)] [D acc: (0.750)(0.797, 0.703)] [G loss: 1.464] [G acc: 0.078]\n",
      "3901 [D loss: (0.483)(R 0.491, F 0.475)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.367] [G acc: 0.078]\n",
      "3902 [D loss: (0.655)(R 0.562, F 0.747)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.431] [G acc: 0.047]\n",
      "3903 [D loss: (0.505)(R 0.587, F 0.422)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.356] [G acc: 0.141]\n",
      "3904 [D loss: (0.545)(R 0.476, F 0.613)] [D acc: (0.766)(0.797, 0.734)] [G loss: 1.327] [G acc: 0.094]\n",
      "3905 [D loss: (0.543)(R 0.643, F 0.443)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.371] [G acc: 0.047]\n",
      "3906 [D loss: (0.572)(R 0.604, F 0.541)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.448] [G acc: 0.109]\n",
      "3907 [D loss: (0.493)(R 0.501, F 0.485)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.423] [G acc: 0.062]\n",
      "3908 [D loss: (0.531)(R 0.435, F 0.627)] [D acc: (0.703)(0.734, 0.672)] [G loss: 1.428] [G acc: 0.078]\n",
      "3909 [D loss: (0.598)(R 0.625, F 0.571)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.474] [G acc: 0.031]\n",
      "3910 [D loss: (0.584)(R 0.662, F 0.507)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.495] [G acc: 0.062]\n",
      "3911 [D loss: (0.543)(R 0.595, F 0.491)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.487] [G acc: 0.078]\n",
      "3912 [D loss: (0.556)(R 0.614, F 0.497)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.253] [G acc: 0.156]\n",
      "3913 [D loss: (0.529)(R 0.490, F 0.568)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.368] [G acc: 0.078]\n",
      "3914 [D loss: (0.522)(R 0.517, F 0.528)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.419] [G acc: 0.078]\n",
      "3915 [D loss: (0.531)(R 0.609, F 0.452)] [D acc: (0.695)(0.547, 0.844)] [G loss: 1.347] [G acc: 0.062]\n",
      "3916 [D loss: (0.544)(R 0.528, F 0.560)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.389] [G acc: 0.141]\n",
      "3917 [D loss: (0.567)(R 0.603, F 0.531)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.476] [G acc: 0.109]\n",
      "3918 [D loss: (0.601)(R 0.394, F 0.809)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.442] [G acc: 0.094]\n",
      "3919 [D loss: (0.587)(R 0.676, F 0.497)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.380] [G acc: 0.125]\n",
      "3920 [D loss: (0.494)(R 0.585, F 0.402)] [D acc: (0.773)(0.594, 0.953)] [G loss: 1.349] [G acc: 0.125]\n",
      "3921 [D loss: (0.468)(R 0.485, F 0.451)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.583] [G acc: 0.062]\n",
      "3922 [D loss: (0.478)(R 0.483, F 0.473)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.388] [G acc: 0.172]\n",
      "3923 [D loss: (0.477)(R 0.479, F 0.476)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.358] [G acc: 0.156]\n",
      "3924 [D loss: (0.569)(R 0.601, F 0.537)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.654] [G acc: 0.078]\n",
      "3925 [D loss: (0.566)(R 0.640, F 0.492)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.448] [G acc: 0.047]\n",
      "3926 [D loss: (0.572)(R 0.544, F 0.600)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.458] [G acc: 0.047]\n",
      "3927 [D loss: (0.526)(R 0.578, F 0.474)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.492] [G acc: 0.094]\n",
      "3928 [D loss: (0.489)(R 0.437, F 0.540)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.415] [G acc: 0.078]\n",
      "3929 [D loss: (0.483)(R 0.528, F 0.439)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.398] [G acc: 0.109]\n",
      "3930 [D loss: (0.524)(R 0.498, F 0.550)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.392] [G acc: 0.078]\n",
      "3931 [D loss: (0.486)(R 0.527, F 0.446)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.441] [G acc: 0.156]\n",
      "3932 [D loss: (0.524)(R 0.584, F 0.465)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.457] [G acc: 0.109]\n",
      "3933 [D loss: (0.516)(R 0.575, F 0.456)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.416] [G acc: 0.156]\n",
      "3934 [D loss: (0.612)(R 0.608, F 0.616)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.338] [G acc: 0.109]\n",
      "3935 [D loss: (0.504)(R 0.467, F 0.542)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.343] [G acc: 0.125]\n",
      "3936 [D loss: (0.558)(R 0.541, F 0.575)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.485] [G acc: 0.047]\n",
      "3937 [D loss: (0.567)(R 0.623, F 0.512)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.346] [G acc: 0.078]\n",
      "3938 [D loss: (0.592)(R 0.584, F 0.600)] [D acc: (0.609)(0.578, 0.641)] [G loss: 1.446] [G acc: 0.078]\n",
      "3939 [D loss: (0.521)(R 0.500, F 0.542)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.381] [G acc: 0.109]\n",
      "3940 [D loss: (0.476)(R 0.446, F 0.506)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.587] [G acc: 0.047]\n",
      "3941 [D loss: (0.534)(R 0.540, F 0.527)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.416] [G acc: 0.094]\n",
      "3942 [D loss: (0.510)(R 0.471, F 0.548)] [D acc: (0.805)(0.828, 0.781)] [G loss: 1.506] [G acc: 0.062]\n",
      "3943 [D loss: (0.586)(R 0.677, F 0.494)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.204] [G acc: 0.203]\n",
      "3944 [D loss: (0.603)(R 0.457, F 0.748)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.468] [G acc: 0.094]\n",
      "3945 [D loss: (0.530)(R 0.603, F 0.457)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.379] [G acc: 0.172]\n",
      "3946 [D loss: (0.468)(R 0.450, F 0.487)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.528] [G acc: 0.078]\n",
      "3947 [D loss: (0.526)(R 0.602, F 0.451)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.415] [G acc: 0.109]\n",
      "3948 [D loss: (0.554)(R 0.487, F 0.621)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.551] [G acc: 0.125]\n",
      "3949 [D loss: (0.613)(R 0.691, F 0.536)] [D acc: (0.648)(0.531, 0.766)] [G loss: 1.336] [G acc: 0.141]\n",
      "3950 [D loss: (0.488)(R 0.523, F 0.453)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.363] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3951 [D loss: (0.546)(R 0.570, F 0.522)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.414] [G acc: 0.109]\n",
      "3952 [D loss: (0.473)(R 0.417, F 0.529)] [D acc: (0.773)(0.828, 0.719)] [G loss: 1.566] [G acc: 0.125]\n",
      "3953 [D loss: (0.568)(R 0.559, F 0.578)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.448] [G acc: 0.094]\n",
      "3954 [D loss: (0.517)(R 0.582, F 0.452)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.357] [G acc: 0.141]\n",
      "3955 [D loss: (0.622)(R 0.729, F 0.516)] [D acc: (0.656)(0.484, 0.828)] [G loss: 1.460] [G acc: 0.062]\n",
      "3956 [D loss: (0.512)(R 0.610, F 0.415)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.554] [G acc: 0.094]\n",
      "3957 [D loss: (0.539)(R 0.501, F 0.576)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.371] [G acc: 0.062]\n",
      "3958 [D loss: (0.568)(R 0.637, F 0.500)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.412] [G acc: 0.078]\n",
      "3959 [D loss: (0.543)(R 0.477, F 0.609)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.375] [G acc: 0.125]\n",
      "3960 [D loss: (0.512)(R 0.527, F 0.497)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.371] [G acc: 0.156]\n",
      "3961 [D loss: (0.534)(R 0.535, F 0.533)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.374] [G acc: 0.125]\n",
      "3962 [D loss: (0.516)(R 0.519, F 0.513)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.421] [G acc: 0.078]\n",
      "3963 [D loss: (0.501)(R 0.437, F 0.564)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.506] [G acc: 0.094]\n",
      "3964 [D loss: (0.588)(R 0.707, F 0.469)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.466] [G acc: 0.094]\n",
      "3965 [D loss: (0.530)(R 0.582, F 0.478)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.428] [G acc: 0.094]\n",
      "3966 [D loss: (0.551)(R 0.580, F 0.521)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.354] [G acc: 0.078]\n",
      "3967 [D loss: (0.665)(R 0.679, F 0.651)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.430] [G acc: 0.109]\n",
      "3968 [D loss: (0.569)(R 0.648, F 0.489)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.293] [G acc: 0.156]\n",
      "3969 [D loss: (0.545)(R 0.550, F 0.539)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.373] [G acc: 0.125]\n",
      "3970 [D loss: (0.533)(R 0.617, F 0.449)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.421] [G acc: 0.156]\n",
      "3971 [D loss: (0.464)(R 0.468, F 0.461)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.391] [G acc: 0.094]\n",
      "3972 [D loss: (0.606)(R 0.582, F 0.630)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.300] [G acc: 0.109]\n",
      "3973 [D loss: (0.472)(R 0.486, F 0.458)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.532] [G acc: 0.109]\n",
      "3974 [D loss: (0.505)(R 0.581, F 0.428)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.399] [G acc: 0.125]\n",
      "3975 [D loss: (0.578)(R 0.423, F 0.733)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.489] [G acc: 0.078]\n",
      "3976 [D loss: (0.494)(R 0.533, F 0.456)] [D acc: (0.789)(0.672, 0.906)] [G loss: 1.531] [G acc: 0.031]\n",
      "3977 [D loss: (0.521)(R 0.507, F 0.536)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.509] [G acc: 0.047]\n",
      "3978 [D loss: (0.558)(R 0.604, F 0.513)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.371] [G acc: 0.141]\n",
      "3979 [D loss: (0.506)(R 0.515, F 0.497)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.419] [G acc: 0.109]\n",
      "3980 [D loss: (0.500)(R 0.545, F 0.455)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.478] [G acc: 0.094]\n",
      "3981 [D loss: (0.594)(R 0.502, F 0.687)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.528] [G acc: 0.031]\n",
      "3982 [D loss: (0.600)(R 0.652, F 0.549)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.381] [G acc: 0.109]\n",
      "3983 [D loss: (0.546)(R 0.572, F 0.521)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.389] [G acc: 0.062]\n",
      "3984 [D loss: (0.528)(R 0.596, F 0.459)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.499] [G acc: 0.094]\n",
      "3985 [D loss: (0.589)(R 0.653, F 0.524)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.469] [G acc: 0.109]\n",
      "3986 [D loss: (0.510)(R 0.456, F 0.564)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.395] [G acc: 0.141]\n",
      "3987 [D loss: (0.492)(R 0.510, F 0.473)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.382] [G acc: 0.094]\n",
      "3988 [D loss: (0.566)(R 0.637, F 0.495)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.394] [G acc: 0.109]\n",
      "3989 [D loss: (0.548)(R 0.574, F 0.522)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.320] [G acc: 0.203]\n",
      "3990 [D loss: (0.554)(R 0.560, F 0.547)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.325] [G acc: 0.156]\n",
      "3991 [D loss: (0.492)(R 0.531, F 0.453)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.344] [G acc: 0.125]\n",
      "3992 [D loss: (0.497)(R 0.570, F 0.424)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.241] [G acc: 0.156]\n",
      "3993 [D loss: (0.590)(R 0.507, F 0.673)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.450] [G acc: 0.062]\n",
      "3994 [D loss: (0.590)(R 0.685, F 0.495)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.370] [G acc: 0.188]\n",
      "3995 [D loss: (0.578)(R 0.456, F 0.700)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.343] [G acc: 0.109]\n",
      "3996 [D loss: (0.579)(R 0.602, F 0.557)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.337] [G acc: 0.141]\n",
      "3997 [D loss: (0.472)(R 0.532, F 0.412)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.370] [G acc: 0.203]\n",
      "3998 [D loss: (0.568)(R 0.485, F 0.651)] [D acc: (0.711)(0.750, 0.672)] [G loss: 1.390] [G acc: 0.109]\n",
      "3999 [D loss: (0.544)(R 0.576, F 0.512)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.358] [G acc: 0.141]\n",
      "4000 [D loss: (0.519)(R 0.582, F 0.456)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.335] [G acc: 0.141]\n",
      "4001 [D loss: (0.507)(R 0.497, F 0.517)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.445] [G acc: 0.078]\n",
      "4002 [D loss: (0.552)(R 0.598, F 0.505)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.457] [G acc: 0.109]\n",
      "4003 [D loss: (0.455)(R 0.467, F 0.442)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.461] [G acc: 0.156]\n",
      "4004 [D loss: (0.499)(R 0.430, F 0.568)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.463] [G acc: 0.078]\n",
      "4005 [D loss: (0.602)(R 0.663, F 0.540)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.317] [G acc: 0.109]\n",
      "4006 [D loss: (0.487)(R 0.494, F 0.480)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.479] [G acc: 0.094]\n",
      "4007 [D loss: (0.532)(R 0.455, F 0.609)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.351] [G acc: 0.141]\n",
      "4008 [D loss: (0.567)(R 0.589, F 0.544)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.470] [G acc: 0.016]\n",
      "4009 [D loss: (0.512)(R 0.574, F 0.450)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.365] [G acc: 0.078]\n",
      "4010 [D loss: (0.569)(R 0.519, F 0.619)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.353] [G acc: 0.141]\n",
      "4011 [D loss: (0.478)(R 0.459, F 0.496)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.451] [G acc: 0.109]\n",
      "4012 [D loss: (0.549)(R 0.591, F 0.508)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.361] [G acc: 0.047]\n",
      "4013 [D loss: (0.566)(R 0.523, F 0.608)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.250] [G acc: 0.109]\n",
      "4014 [D loss: (0.553)(R 0.607, F 0.499)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.323] [G acc: 0.125]\n",
      "4015 [D loss: (0.531)(R 0.496, F 0.566)] [D acc: (0.695)(0.750, 0.641)] [G loss: 1.364] [G acc: 0.188]\n",
      "4016 [D loss: (0.543)(R 0.640, F 0.447)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.373] [G acc: 0.125]\n",
      "4017 [D loss: (0.594)(R 0.600, F 0.588)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.290] [G acc: 0.094]\n",
      "4018 [D loss: (0.475)(R 0.553, F 0.396)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.227] [G acc: 0.141]\n",
      "4019 [D loss: (0.527)(R 0.544, F 0.510)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.202] [G acc: 0.203]\n",
      "4020 [D loss: (0.587)(R 0.574, F 0.601)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.210] [G acc: 0.094]\n",
      "4021 [D loss: (0.517)(R 0.486, F 0.549)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.293] [G acc: 0.156]\n",
      "4022 [D loss: (0.543)(R 0.503, F 0.583)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.296] [G acc: 0.047]\n",
      "4023 [D loss: (0.487)(R 0.445, F 0.529)] [D acc: (0.781)(0.797, 0.766)] [G loss: 1.522] [G acc: 0.062]\n",
      "4024 [D loss: (0.517)(R 0.593, F 0.441)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.315] [G acc: 0.094]\n",
      "4025 [D loss: (0.485)(R 0.470, F 0.501)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.379] [G acc: 0.188]\n",
      "4026 [D loss: (0.521)(R 0.527, F 0.516)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.383] [G acc: 0.062]\n",
      "4027 [D loss: (0.514)(R 0.577, F 0.451)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.460] [G acc: 0.062]\n",
      "4028 [D loss: (0.563)(R 0.654, F 0.472)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.363] [G acc: 0.141]\n",
      "4029 [D loss: (0.536)(R 0.549, F 0.522)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.612] [G acc: 0.016]\n",
      "4030 [D loss: (0.548)(R 0.568, F 0.528)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.382] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4031 [D loss: (0.600)(R 0.639, F 0.560)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.348] [G acc: 0.125]\n",
      "4032 [D loss: (0.591)(R 0.692, F 0.490)] [D acc: (0.680)(0.516, 0.844)] [G loss: 1.297] [G acc: 0.109]\n",
      "4033 [D loss: (0.510)(R 0.509, F 0.510)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.298] [G acc: 0.188]\n",
      "4034 [D loss: (0.474)(R 0.463, F 0.485)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.362] [G acc: 0.125]\n",
      "4035 [D loss: (0.470)(R 0.454, F 0.487)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.425] [G acc: 0.125]\n",
      "4036 [D loss: (0.487)(R 0.496, F 0.478)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.576] [G acc: 0.156]\n",
      "4037 [D loss: (0.541)(R 0.504, F 0.577)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.470] [G acc: 0.062]\n",
      "4038 [D loss: (0.686)(R 0.791, F 0.581)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.424] [G acc: 0.062]\n",
      "4039 [D loss: (0.528)(R 0.597, F 0.459)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.366] [G acc: 0.125]\n",
      "4040 [D loss: (0.486)(R 0.523, F 0.450)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.239] [G acc: 0.188]\n",
      "4041 [D loss: (0.531)(R 0.585, F 0.477)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.529] [G acc: 0.109]\n",
      "4042 [D loss: (0.492)(R 0.424, F 0.559)] [D acc: (0.805)(0.828, 0.781)] [G loss: 1.543] [G acc: 0.078]\n",
      "4043 [D loss: (0.581)(R 0.627, F 0.535)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.388] [G acc: 0.141]\n",
      "4044 [D loss: (0.600)(R 0.589, F 0.612)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.306] [G acc: 0.125]\n",
      "4045 [D loss: (0.574)(R 0.642, F 0.506)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.400] [G acc: 0.094]\n",
      "4046 [D loss: (0.556)(R 0.554, F 0.559)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.359] [G acc: 0.109]\n",
      "4047 [D loss: (0.578)(R 0.529, F 0.626)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.354] [G acc: 0.062]\n",
      "4048 [D loss: (0.503)(R 0.572, F 0.434)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.415] [G acc: 0.125]\n",
      "4049 [D loss: (0.478)(R 0.544, F 0.411)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.539] [G acc: 0.094]\n",
      "4050 [D loss: (0.539)(R 0.484, F 0.595)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.295] [G acc: 0.109]\n",
      "4051 [D loss: (0.606)(R 0.628, F 0.585)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.421] [G acc: 0.094]\n",
      "4052 [D loss: (0.556)(R 0.621, F 0.492)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.451] [G acc: 0.094]\n",
      "4053 [D loss: (0.558)(R 0.587, F 0.530)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.267] [G acc: 0.141]\n",
      "4054 [D loss: (0.507)(R 0.462, F 0.551)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.587] [G acc: 0.109]\n",
      "4055 [D loss: (0.521)(R 0.585, F 0.457)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.323] [G acc: 0.141]\n",
      "4056 [D loss: (0.451)(R 0.356, F 0.546)] [D acc: (0.781)(0.828, 0.734)] [G loss: 1.358] [G acc: 0.141]\n",
      "4057 [D loss: (0.461)(R 0.407, F 0.514)] [D acc: (0.789)(0.797, 0.781)] [G loss: 1.270] [G acc: 0.219]\n",
      "4058 [D loss: (0.612)(R 0.575, F 0.649)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.533] [G acc: 0.094]\n",
      "4059 [D loss: (0.506)(R 0.614, F 0.399)] [D acc: (0.750)(0.594, 0.906)] [G loss: 1.454] [G acc: 0.094]\n",
      "4060 [D loss: (0.598)(R 0.622, F 0.574)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.334] [G acc: 0.078]\n",
      "4061 [D loss: (0.526)(R 0.585, F 0.467)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.552] [G acc: 0.062]\n",
      "4062 [D loss: (0.544)(R 0.622, F 0.466)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.356] [G acc: 0.078]\n",
      "4063 [D loss: (0.524)(R 0.366, F 0.682)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.363] [G acc: 0.172]\n",
      "4064 [D loss: (0.580)(R 0.637, F 0.523)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.578] [G acc: 0.062]\n",
      "4065 [D loss: (0.512)(R 0.573, F 0.452)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.483] [G acc: 0.109]\n",
      "4066 [D loss: (0.547)(R 0.553, F 0.540)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.311] [G acc: 0.125]\n",
      "4067 [D loss: (0.522)(R 0.582, F 0.462)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.374] [G acc: 0.078]\n",
      "4068 [D loss: (0.537)(R 0.566, F 0.507)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.288] [G acc: 0.094]\n",
      "4069 [D loss: (0.611)(R 0.603, F 0.620)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.396] [G acc: 0.078]\n",
      "4070 [D loss: (0.578)(R 0.563, F 0.592)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.276] [G acc: 0.172]\n",
      "4071 [D loss: (0.572)(R 0.627, F 0.516)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.321] [G acc: 0.125]\n",
      "4072 [D loss: (0.494)(R 0.557, F 0.431)] [D acc: (0.805)(0.688, 0.922)] [G loss: 1.329] [G acc: 0.094]\n",
      "4073 [D loss: (0.524)(R 0.518, F 0.531)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.387] [G acc: 0.094]\n",
      "4074 [D loss: (0.585)(R 0.562, F 0.607)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.258] [G acc: 0.094]\n",
      "4075 [D loss: (0.470)(R 0.516, F 0.425)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.462] [G acc: 0.109]\n",
      "4076 [D loss: (0.509)(R 0.484, F 0.534)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.335] [G acc: 0.156]\n",
      "4077 [D loss: (0.602)(R 0.657, F 0.546)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.168] [G acc: 0.188]\n",
      "4078 [D loss: (0.478)(R 0.429, F 0.528)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.474] [G acc: 0.141]\n",
      "4079 [D loss: (0.530)(R 0.542, F 0.519)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.455] [G acc: 0.141]\n",
      "4080 [D loss: (0.512)(R 0.539, F 0.485)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.398] [G acc: 0.094]\n",
      "4081 [D loss: (0.538)(R 0.529, F 0.547)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.395] [G acc: 0.062]\n",
      "4082 [D loss: (0.602)(R 0.679, F 0.524)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.269] [G acc: 0.141]\n",
      "4083 [D loss: (0.511)(R 0.530, F 0.492)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.339] [G acc: 0.188]\n",
      "4084 [D loss: (0.573)(R 0.533, F 0.613)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.372] [G acc: 0.109]\n",
      "4085 [D loss: (0.620)(R 0.641, F 0.599)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.369] [G acc: 0.062]\n",
      "4086 [D loss: (0.530)(R 0.584, F 0.476)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.358] [G acc: 0.141]\n",
      "4087 [D loss: (0.555)(R 0.491, F 0.619)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.380] [G acc: 0.125]\n",
      "4088 [D loss: (0.577)(R 0.653, F 0.500)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.408] [G acc: 0.156]\n",
      "4089 [D loss: (0.544)(R 0.455, F 0.633)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.367] [G acc: 0.109]\n",
      "4090 [D loss: (0.708)(R 0.738, F 0.679)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.334] [G acc: 0.062]\n",
      "4091 [D loss: (0.554)(R 0.585, F 0.523)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.267] [G acc: 0.188]\n",
      "4092 [D loss: (0.617)(R 0.633, F 0.601)] [D acc: (0.609)(0.562, 0.656)] [G loss: 1.293] [G acc: 0.109]\n",
      "4093 [D loss: (0.496)(R 0.533, F 0.460)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.415] [G acc: 0.109]\n",
      "4094 [D loss: (0.505)(R 0.507, F 0.502)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.384] [G acc: 0.109]\n",
      "4095 [D loss: (0.507)(R 0.494, F 0.520)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.370] [G acc: 0.109]\n",
      "4096 [D loss: (0.532)(R 0.586, F 0.477)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.326] [G acc: 0.062]\n",
      "4097 [D loss: (0.563)(R 0.597, F 0.529)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.431] [G acc: 0.125]\n",
      "4098 [D loss: (0.431)(R 0.493, F 0.369)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.156] [G acc: 0.172]\n",
      "4099 [D loss: (0.634)(R 0.645, F 0.623)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.640] [G acc: 0.047]\n",
      "4100 [D loss: (0.750)(R 1.079, F 0.420)] [D acc: (0.602)(0.297, 0.906)] [G loss: 1.164] [G acc: 0.172]\n",
      "4101 [D loss: (0.538)(R 0.469, F 0.606)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.172] [G acc: 0.172]\n",
      "4102 [D loss: (0.567)(R 0.450, F 0.684)] [D acc: (0.703)(0.734, 0.672)] [G loss: 1.247] [G acc: 0.141]\n",
      "4103 [D loss: (0.572)(R 0.588, F 0.556)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.422] [G acc: 0.078]\n",
      "4104 [D loss: (0.538)(R 0.586, F 0.489)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.347] [G acc: 0.109]\n",
      "4105 [D loss: (0.525)(R 0.543, F 0.507)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.281] [G acc: 0.188]\n",
      "4106 [D loss: (0.518)(R 0.498, F 0.538)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.276] [G acc: 0.094]\n",
      "4107 [D loss: (0.567)(R 0.608, F 0.526)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.439] [G acc: 0.078]\n",
      "4108 [D loss: (0.565)(R 0.540, F 0.591)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.307] [G acc: 0.156]\n",
      "4109 [D loss: (0.480)(R 0.467, F 0.494)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.450] [G acc: 0.078]\n",
      "4110 [D loss: (0.565)(R 0.580, F 0.549)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.454] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4111 [D loss: (0.469)(R 0.460, F 0.478)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.596] [G acc: 0.078]\n",
      "4112 [D loss: (0.572)(R 0.517, F 0.626)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.628] [G acc: 0.062]\n",
      "4113 [D loss: (0.484)(R 0.581, F 0.386)] [D acc: (0.766)(0.625, 0.906)] [G loss: 1.493] [G acc: 0.141]\n",
      "4114 [D loss: (0.530)(R 0.547, F 0.513)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.513] [G acc: 0.141]\n",
      "4115 [D loss: (0.464)(R 0.484, F 0.445)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.475] [G acc: 0.094]\n",
      "4116 [D loss: (0.499)(R 0.461, F 0.538)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.360] [G acc: 0.094]\n",
      "4117 [D loss: (0.499)(R 0.500, F 0.497)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.451] [G acc: 0.125]\n",
      "4118 [D loss: (0.578)(R 0.497, F 0.659)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.575] [G acc: 0.125]\n",
      "4119 [D loss: (0.570)(R 0.612, F 0.529)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.339] [G acc: 0.141]\n",
      "4120 [D loss: (0.551)(R 0.544, F 0.558)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.513] [G acc: 0.047]\n",
      "4121 [D loss: (0.635)(R 0.769, F 0.502)] [D acc: (0.602)(0.453, 0.750)] [G loss: 1.357] [G acc: 0.109]\n",
      "4122 [D loss: (0.604)(R 0.596, F 0.613)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.250] [G acc: 0.109]\n",
      "4123 [D loss: (0.501)(R 0.531, F 0.472)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.263] [G acc: 0.156]\n",
      "4124 [D loss: (0.626)(R 0.617, F 0.635)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.346] [G acc: 0.156]\n",
      "4125 [D loss: (0.496)(R 0.435, F 0.556)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.268] [G acc: 0.141]\n",
      "4126 [D loss: (0.566)(R 0.603, F 0.529)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.436] [G acc: 0.062]\n",
      "4127 [D loss: (0.490)(R 0.425, F 0.555)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.341] [G acc: 0.141]\n",
      "4128 [D loss: (0.501)(R 0.499, F 0.502)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.471] [G acc: 0.062]\n",
      "4129 [D loss: (0.512)(R 0.561, F 0.463)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.548] [G acc: 0.125]\n",
      "4130 [D loss: (0.476)(R 0.574, F 0.378)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.308] [G acc: 0.141]\n",
      "4131 [D loss: (0.555)(R 0.449, F 0.660)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.516] [G acc: 0.078]\n",
      "4132 [D loss: (0.535)(R 0.585, F 0.484)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.355] [G acc: 0.188]\n",
      "4133 [D loss: (0.566)(R 0.529, F 0.603)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.412] [G acc: 0.031]\n",
      "4134 [D loss: (0.477)(R 0.530, F 0.423)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.378] [G acc: 0.125]\n",
      "4135 [D loss: (0.495)(R 0.422, F 0.568)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.339] [G acc: 0.125]\n",
      "4136 [D loss: (0.636)(R 0.632, F 0.640)] [D acc: (0.625)(0.594, 0.656)] [G loss: 1.346] [G acc: 0.141]\n",
      "4137 [D loss: (0.586)(R 0.612, F 0.560)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.392] [G acc: 0.031]\n",
      "4138 [D loss: (0.608)(R 0.583, F 0.632)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.345] [G acc: 0.109]\n",
      "4139 [D loss: (0.622)(R 0.676, F 0.569)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.259] [G acc: 0.094]\n",
      "4140 [D loss: (0.554)(R 0.595, F 0.513)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.250] [G acc: 0.094]\n",
      "4141 [D loss: (0.452)(R 0.475, F 0.429)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.186] [G acc: 0.141]\n",
      "4142 [D loss: (0.515)(R 0.520, F 0.511)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.334] [G acc: 0.156]\n",
      "4143 [D loss: (0.534)(R 0.536, F 0.532)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.362] [G acc: 0.109]\n",
      "4144 [D loss: (0.506)(R 0.590, F 0.422)] [D acc: (0.789)(0.672, 0.906)] [G loss: 1.436] [G acc: 0.078]\n",
      "4145 [D loss: (0.506)(R 0.470, F 0.542)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.393] [G acc: 0.078]\n",
      "4146 [D loss: (0.579)(R 0.576, F 0.582)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.418] [G acc: 0.125]\n",
      "4147 [D loss: (0.557)(R 0.524, F 0.591)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.308] [G acc: 0.156]\n",
      "4148 [D loss: (0.512)(R 0.558, F 0.465)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.462] [G acc: 0.078]\n",
      "4149 [D loss: (0.466)(R 0.441, F 0.492)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.516] [G acc: 0.094]\n",
      "4150 [D loss: (0.486)(R 0.572, F 0.401)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.434] [G acc: 0.078]\n",
      "4151 [D loss: (0.634)(R 0.549, F 0.720)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.504] [G acc: 0.047]\n",
      "4152 [D loss: (0.557)(R 0.658, F 0.457)] [D acc: (0.711)(0.547, 0.875)] [G loss: 1.464] [G acc: 0.062]\n",
      "4153 [D loss: (0.552)(R 0.549, F 0.554)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.449] [G acc: 0.125]\n",
      "4154 [D loss: (0.555)(R 0.637, F 0.474)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.482] [G acc: 0.094]\n",
      "4155 [D loss: (0.541)(R 0.591, F 0.490)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.481] [G acc: 0.031]\n",
      "4156 [D loss: (0.496)(R 0.524, F 0.469)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.297] [G acc: 0.109]\n",
      "4157 [D loss: (0.549)(R 0.556, F 0.541)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.503] [G acc: 0.078]\n",
      "4158 [D loss: (0.525)(R 0.567, F 0.483)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.299] [G acc: 0.172]\n",
      "4159 [D loss: (0.521)(R 0.508, F 0.533)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.352] [G acc: 0.094]\n",
      "4160 [D loss: (0.606)(R 0.489, F 0.723)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.510] [G acc: 0.078]\n",
      "4161 [D loss: (0.525)(R 0.577, F 0.472)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.351] [G acc: 0.094]\n",
      "4162 [D loss: (0.557)(R 0.580, F 0.534)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.357] [G acc: 0.078]\n",
      "4163 [D loss: (0.487)(R 0.520, F 0.453)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.346] [G acc: 0.125]\n",
      "4164 [D loss: (0.481)(R 0.544, F 0.419)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.308] [G acc: 0.141]\n",
      "4165 [D loss: (0.478)(R 0.471, F 0.486)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.479] [G acc: 0.125]\n",
      "4166 [D loss: (0.534)(R 0.478, F 0.590)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.569] [G acc: 0.062]\n",
      "4167 [D loss: (0.473)(R 0.467, F 0.478)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.336] [G acc: 0.156]\n",
      "4168 [D loss: (0.594)(R 0.555, F 0.633)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.696] [G acc: 0.109]\n",
      "4169 [D loss: (0.467)(R 0.522, F 0.412)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.521] [G acc: 0.094]\n",
      "4170 [D loss: (0.633)(R 0.565, F 0.702)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.681] [G acc: 0.031]\n",
      "4171 [D loss: (0.647)(R 0.706, F 0.589)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.341] [G acc: 0.094]\n",
      "4172 [D loss: (0.506)(R 0.615, F 0.396)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.508] [G acc: 0.094]\n",
      "4173 [D loss: (0.573)(R 0.575, F 0.570)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.504] [G acc: 0.094]\n",
      "4174 [D loss: (0.545)(R 0.576, F 0.515)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.401] [G acc: 0.125]\n",
      "4175 [D loss: (0.521)(R 0.567, F 0.475)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.382] [G acc: 0.156]\n",
      "4176 [D loss: (0.542)(R 0.632, F 0.451)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.481] [G acc: 0.172]\n",
      "4177 [D loss: (0.564)(R 0.568, F 0.560)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.434] [G acc: 0.109]\n",
      "4178 [D loss: (0.601)(R 0.712, F 0.490)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.260] [G acc: 0.188]\n",
      "4179 [D loss: (0.504)(R 0.521, F 0.487)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.400] [G acc: 0.109]\n",
      "4180 [D loss: (0.536)(R 0.457, F 0.615)] [D acc: (0.695)(0.734, 0.656)] [G loss: 1.649] [G acc: 0.031]\n",
      "4181 [D loss: (0.618)(R 0.645, F 0.591)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.426] [G acc: 0.094]\n",
      "4182 [D loss: (0.503)(R 0.580, F 0.427)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.320] [G acc: 0.156]\n",
      "4183 [D loss: (0.515)(R 0.536, F 0.493)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.475] [G acc: 0.094]\n",
      "4184 [D loss: (0.515)(R 0.509, F 0.521)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.279] [G acc: 0.141]\n",
      "4185 [D loss: (0.486)(R 0.459, F 0.513)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.463] [G acc: 0.141]\n",
      "4186 [D loss: (0.644)(R 0.656, F 0.632)] [D acc: (0.641)(0.562, 0.719)] [G loss: 1.322] [G acc: 0.125]\n",
      "4187 [D loss: (0.487)(R 0.457, F 0.518)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.419] [G acc: 0.094]\n",
      "4188 [D loss: (0.627)(R 0.594, F 0.659)] [D acc: (0.648)(0.656, 0.641)] [G loss: 1.508] [G acc: 0.047]\n",
      "4189 [D loss: (0.638)(R 0.739, F 0.536)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.440] [G acc: 0.109]\n",
      "4190 [D loss: (0.587)(R 0.594, F 0.579)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.298] [G acc: 0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4191 [D loss: (0.583)(R 0.672, F 0.493)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.372] [G acc: 0.047]\n",
      "4192 [D loss: (0.502)(R 0.516, F 0.489)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.246] [G acc: 0.141]\n",
      "4193 [D loss: (0.537)(R 0.534, F 0.539)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.257] [G acc: 0.172]\n",
      "4194 [D loss: (0.505)(R 0.515, F 0.496)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.234] [G acc: 0.109]\n",
      "4195 [D loss: (0.510)(R 0.544, F 0.477)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.371] [G acc: 0.094]\n",
      "4196 [D loss: (0.661)(R 0.621, F 0.700)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.339] [G acc: 0.094]\n",
      "4197 [D loss: (0.536)(R 0.617, F 0.454)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.373] [G acc: 0.078]\n",
      "4198 [D loss: (0.525)(R 0.505, F 0.544)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.263] [G acc: 0.094]\n",
      "4199 [D loss: (0.532)(R 0.582, F 0.482)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.382] [G acc: 0.109]\n",
      "4200 [D loss: (0.643)(R 0.517, F 0.770)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.261] [G acc: 0.156]\n",
      "4201 [D loss: (0.477)(R 0.504, F 0.450)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.472] [G acc: 0.078]\n",
      "4202 [D loss: (0.572)(R 0.564, F 0.580)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.251] [G acc: 0.141]\n",
      "4203 [D loss: (0.495)(R 0.455, F 0.536)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.324] [G acc: 0.109]\n",
      "4204 [D loss: (0.525)(R 0.590, F 0.460)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.361] [G acc: 0.094]\n",
      "4205 [D loss: (0.565)(R 0.460, F 0.670)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.321] [G acc: 0.109]\n",
      "4206 [D loss: (0.510)(R 0.567, F 0.454)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.456] [G acc: 0.062]\n",
      "4207 [D loss: (0.534)(R 0.535, F 0.532)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.451] [G acc: 0.172]\n",
      "4208 [D loss: (0.605)(R 0.589, F 0.622)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.495] [G acc: 0.047]\n",
      "4209 [D loss: (0.456)(R 0.540, F 0.373)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.405] [G acc: 0.109]\n",
      "4210 [D loss: (0.456)(R 0.441, F 0.471)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.545] [G acc: 0.047]\n",
      "4211 [D loss: (0.579)(R 0.668, F 0.491)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.331] [G acc: 0.125]\n",
      "4212 [D loss: (0.502)(R 0.458, F 0.547)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.274] [G acc: 0.109]\n",
      "4213 [D loss: (0.561)(R 0.636, F 0.486)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.200] [G acc: 0.156]\n",
      "4214 [D loss: (0.493)(R 0.477, F 0.509)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.343] [G acc: 0.125]\n",
      "4215 [D loss: (0.551)(R 0.463, F 0.640)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.436] [G acc: 0.109]\n",
      "4216 [D loss: (0.601)(R 0.686, F 0.517)] [D acc: (0.641)(0.562, 0.719)] [G loss: 1.520] [G acc: 0.047]\n",
      "4217 [D loss: (0.563)(R 0.693, F 0.434)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.311] [G acc: 0.141]\n",
      "4218 [D loss: (0.615)(R 0.588, F 0.642)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.444] [G acc: 0.109]\n",
      "4219 [D loss: (0.553)(R 0.679, F 0.427)] [D acc: (0.766)(0.594, 0.938)] [G loss: 1.279] [G acc: 0.047]\n",
      "4220 [D loss: (0.480)(R 0.418, F 0.541)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.322] [G acc: 0.094]\n",
      "4221 [D loss: (0.520)(R 0.556, F 0.484)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.580] [G acc: 0.016]\n",
      "4222 [D loss: (0.547)(R 0.438, F 0.657)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.464] [G acc: 0.062]\n",
      "4223 [D loss: (0.537)(R 0.616, F 0.459)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.409] [G acc: 0.062]\n",
      "4224 [D loss: (0.485)(R 0.506, F 0.465)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.421] [G acc: 0.062]\n",
      "4225 [D loss: (0.564)(R 0.469, F 0.659)] [D acc: (0.695)(0.734, 0.656)] [G loss: 1.313] [G acc: 0.125]\n",
      "4226 [D loss: (0.565)(R 0.694, F 0.435)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.418] [G acc: 0.062]\n",
      "4227 [D loss: (0.498)(R 0.523, F 0.473)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.470] [G acc: 0.062]\n",
      "4228 [D loss: (0.549)(R 0.564, F 0.535)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.585] [G acc: 0.062]\n",
      "4229 [D loss: (0.526)(R 0.575, F 0.477)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.338] [G acc: 0.109]\n",
      "4230 [D loss: (0.476)(R 0.432, F 0.521)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.477] [G acc: 0.062]\n",
      "4231 [D loss: (0.544)(R 0.520, F 0.568)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.386] [G acc: 0.188]\n",
      "4232 [D loss: (0.628)(R 0.590, F 0.665)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.451] [G acc: 0.047]\n",
      "4233 [D loss: (0.515)(R 0.574, F 0.457)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.317] [G acc: 0.219]\n",
      "4234 [D loss: (0.540)(R 0.511, F 0.569)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.522] [G acc: 0.078]\n",
      "4235 [D loss: (0.574)(R 0.657, F 0.491)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.480] [G acc: 0.047]\n",
      "4236 [D loss: (0.623)(R 0.677, F 0.569)] [D acc: (0.656)(0.516, 0.797)] [G loss: 1.271] [G acc: 0.141]\n",
      "4237 [D loss: (0.511)(R 0.544, F 0.478)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.369] [G acc: 0.031]\n",
      "4238 [D loss: (0.519)(R 0.482, F 0.555)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.603] [G acc: 0.078]\n",
      "4239 [D loss: (0.505)(R 0.565, F 0.445)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.365] [G acc: 0.047]\n",
      "4240 [D loss: (0.534)(R 0.548, F 0.519)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.365] [G acc: 0.094]\n",
      "4241 [D loss: (0.564)(R 0.521, F 0.607)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.529] [G acc: 0.094]\n",
      "4242 [D loss: (0.580)(R 0.580, F 0.579)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.622] [G acc: 0.047]\n",
      "4243 [D loss: (0.606)(R 0.671, F 0.541)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.356] [G acc: 0.109]\n",
      "4244 [D loss: (0.573)(R 0.631, F 0.514)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.370] [G acc: 0.094]\n",
      "4245 [D loss: (0.577)(R 0.648, F 0.507)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.355] [G acc: 0.078]\n",
      "4246 [D loss: (0.547)(R 0.586, F 0.508)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.235] [G acc: 0.188]\n",
      "4247 [D loss: (0.620)(R 0.621, F 0.618)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.195] [G acc: 0.156]\n",
      "4248 [D loss: (0.493)(R 0.554, F 0.431)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.165] [G acc: 0.125]\n",
      "4249 [D loss: (0.526)(R 0.483, F 0.570)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.396] [G acc: 0.109]\n",
      "4250 [D loss: (0.516)(R 0.522, F 0.509)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.343] [G acc: 0.109]\n",
      "4251 [D loss: (0.551)(R 0.491, F 0.611)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.607] [G acc: 0.047]\n",
      "4252 [D loss: (0.656)(R 0.686, F 0.626)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.357] [G acc: 0.125]\n",
      "4253 [D loss: (0.539)(R 0.590, F 0.488)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.289] [G acc: 0.172]\n",
      "4254 [D loss: (0.537)(R 0.495, F 0.579)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.285] [G acc: 0.094]\n",
      "4255 [D loss: (0.549)(R 0.595, F 0.502)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.408] [G acc: 0.094]\n",
      "4256 [D loss: (0.574)(R 0.493, F 0.654)] [D acc: (0.688)(0.734, 0.641)] [G loss: 1.461] [G acc: 0.016]\n",
      "4257 [D loss: (0.545)(R 0.584, F 0.507)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.330] [G acc: 0.094]\n",
      "4258 [D loss: (0.553)(R 0.549, F 0.557)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.323] [G acc: 0.109]\n",
      "4259 [D loss: (0.493)(R 0.528, F 0.457)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.369] [G acc: 0.109]\n",
      "4260 [D loss: (0.573)(R 0.532, F 0.613)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.418] [G acc: 0.047]\n",
      "4261 [D loss: (0.549)(R 0.489, F 0.608)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.585] [G acc: 0.016]\n",
      "4262 [D loss: (0.509)(R 0.527, F 0.491)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.384] [G acc: 0.078]\n",
      "4263 [D loss: (0.633)(R 0.609, F 0.657)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.415] [G acc: 0.125]\n",
      "4264 [D loss: (0.537)(R 0.550, F 0.524)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.510] [G acc: 0.000]\n",
      "4265 [D loss: (0.533)(R 0.642, F 0.423)] [D acc: (0.695)(0.547, 0.844)] [G loss: 1.326] [G acc: 0.125]\n",
      "4266 [D loss: (0.506)(R 0.545, F 0.468)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.451] [G acc: 0.156]\n",
      "4267 [D loss: (0.612)(R 0.617, F 0.607)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.325] [G acc: 0.188]\n",
      "4268 [D loss: (0.550)(R 0.573, F 0.528)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.614] [G acc: 0.047]\n",
      "4269 [D loss: (0.522)(R 0.626, F 0.419)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.428] [G acc: 0.156]\n",
      "4270 [D loss: (0.505)(R 0.457, F 0.554)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.150] [G acc: 0.266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4271 [D loss: (0.554)(R 0.507, F 0.601)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.556] [G acc: 0.078]\n",
      "4272 [D loss: (0.471)(R 0.474, F 0.468)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.338] [G acc: 0.172]\n",
      "4273 [D loss: (0.547)(R 0.461, F 0.633)] [D acc: (0.688)(0.719, 0.656)] [G loss: 1.464] [G acc: 0.078]\n",
      "4274 [D loss: (0.484)(R 0.496, F 0.473)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.561] [G acc: 0.062]\n",
      "4275 [D loss: (0.527)(R 0.674, F 0.380)] [D acc: (0.773)(0.625, 0.922)] [G loss: 1.351] [G acc: 0.141]\n",
      "4276 [D loss: (0.611)(R 0.544, F 0.679)] [D acc: (0.664)(0.703, 0.625)] [G loss: 1.445] [G acc: 0.062]\n",
      "4277 [D loss: (0.505)(R 0.558, F 0.453)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.489] [G acc: 0.094]\n",
      "4278 [D loss: (0.587)(R 0.570, F 0.604)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.432] [G acc: 0.125]\n",
      "4279 [D loss: (0.546)(R 0.640, F 0.453)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.297] [G acc: 0.141]\n",
      "4280 [D loss: (0.600)(R 0.589, F 0.612)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.343] [G acc: 0.141]\n",
      "4281 [D loss: (0.529)(R 0.565, F 0.493)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.252] [G acc: 0.172]\n",
      "4282 [D loss: (0.511)(R 0.453, F 0.570)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.374] [G acc: 0.062]\n",
      "4283 [D loss: (0.519)(R 0.520, F 0.518)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.360] [G acc: 0.141]\n",
      "4284 [D loss: (0.517)(R 0.593, F 0.441)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.296] [G acc: 0.109]\n",
      "4285 [D loss: (0.636)(R 0.677, F 0.596)] [D acc: (0.625)(0.547, 0.703)] [G loss: 1.196] [G acc: 0.109]\n",
      "4286 [D loss: (0.532)(R 0.501, F 0.562)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.255] [G acc: 0.125]\n",
      "4287 [D loss: (0.668)(R 0.671, F 0.665)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.285] [G acc: 0.141]\n",
      "4288 [D loss: (0.568)(R 0.558, F 0.579)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.303] [G acc: 0.141]\n",
      "4289 [D loss: (0.560)(R 0.591, F 0.529)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.224] [G acc: 0.188]\n",
      "4290 [D loss: (0.583)(R 0.485, F 0.681)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.384] [G acc: 0.094]\n",
      "4291 [D loss: (0.494)(R 0.512, F 0.475)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.463] [G acc: 0.125]\n",
      "4292 [D loss: (0.559)(R 0.518, F 0.599)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.319] [G acc: 0.109]\n",
      "4293 [D loss: (0.571)(R 0.504, F 0.637)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.476] [G acc: 0.078]\n",
      "4294 [D loss: (0.566)(R 0.677, F 0.454)] [D acc: (0.742)(0.594, 0.891)] [G loss: 1.420] [G acc: 0.188]\n",
      "4295 [D loss: (0.525)(R 0.558, F 0.492)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.438] [G acc: 0.141]\n",
      "4296 [D loss: (0.634)(R 0.693, F 0.576)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.409] [G acc: 0.125]\n",
      "4297 [D loss: (0.526)(R 0.543, F 0.510)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.360] [G acc: 0.078]\n",
      "4298 [D loss: (0.454)(R 0.439, F 0.469)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.260] [G acc: 0.125]\n",
      "4299 [D loss: (0.579)(R 0.602, F 0.556)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.565] [G acc: 0.062]\n",
      "4300 [D loss: (0.506)(R 0.563, F 0.449)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.393] [G acc: 0.203]\n",
      "4301 [D loss: (0.570)(R 0.473, F 0.667)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.293] [G acc: 0.172]\n",
      "4302 [D loss: (0.458)(R 0.484, F 0.432)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.481] [G acc: 0.109]\n",
      "4303 [D loss: (0.591)(R 0.625, F 0.557)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.343] [G acc: 0.156]\n",
      "4304 [D loss: (0.464)(R 0.471, F 0.457)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.595] [G acc: 0.047]\n",
      "4305 [D loss: (0.603)(R 0.726, F 0.481)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.414] [G acc: 0.094]\n",
      "4306 [D loss: (0.501)(R 0.603, F 0.399)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.296] [G acc: 0.141]\n",
      "4307 [D loss: (0.593)(R 0.616, F 0.571)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.450] [G acc: 0.141]\n",
      "4308 [D loss: (0.532)(R 0.487, F 0.577)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.384] [G acc: 0.094]\n",
      "4309 [D loss: (0.602)(R 0.561, F 0.644)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.171] [G acc: 0.219]\n",
      "4310 [D loss: (0.578)(R 0.626, F 0.529)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.402] [G acc: 0.094]\n",
      "4311 [D loss: (0.586)(R 0.518, F 0.654)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.299] [G acc: 0.078]\n",
      "4312 [D loss: (0.568)(R 0.635, F 0.502)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.308] [G acc: 0.188]\n",
      "4313 [D loss: (0.522)(R 0.580, F 0.464)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.406] [G acc: 0.094]\n",
      "4314 [D loss: (0.526)(R 0.508, F 0.544)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.331] [G acc: 0.094]\n",
      "4315 [D loss: (0.623)(R 0.671, F 0.576)] [D acc: (0.617)(0.500, 0.734)] [G loss: 1.177] [G acc: 0.188]\n",
      "4316 [D loss: (0.510)(R 0.537, F 0.483)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.374] [G acc: 0.094]\n",
      "4317 [D loss: (0.535)(R 0.510, F 0.560)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.562] [G acc: 0.047]\n",
      "4318 [D loss: (0.643)(R 0.709, F 0.578)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.305] [G acc: 0.188]\n",
      "4319 [D loss: (0.586)(R 0.604, F 0.567)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.301] [G acc: 0.156]\n",
      "4320 [D loss: (0.529)(R 0.550, F 0.507)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.307] [G acc: 0.172]\n",
      "4321 [D loss: (0.495)(R 0.415, F 0.575)] [D acc: (0.766)(0.797, 0.734)] [G loss: 1.483] [G acc: 0.078]\n",
      "4322 [D loss: (0.499)(R 0.577, F 0.420)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.283] [G acc: 0.172]\n",
      "4323 [D loss: (0.519)(R 0.490, F 0.548)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.425] [G acc: 0.094]\n",
      "4324 [D loss: (0.452)(R 0.506, F 0.399)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.452] [G acc: 0.031]\n",
      "4325 [D loss: (0.681)(R 0.716, F 0.646)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.277] [G acc: 0.188]\n",
      "4326 [D loss: (0.516)(R 0.499, F 0.533)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.341] [G acc: 0.125]\n",
      "4327 [D loss: (0.458)(R 0.459, F 0.457)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.396] [G acc: 0.094]\n",
      "4328 [D loss: (0.686)(R 0.644, F 0.729)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.473] [G acc: 0.125]\n",
      "4329 [D loss: (0.525)(R 0.570, F 0.481)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.408] [G acc: 0.062]\n",
      "4330 [D loss: (0.617)(R 0.659, F 0.575)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.322] [G acc: 0.094]\n",
      "4331 [D loss: (0.514)(R 0.532, F 0.497)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.524] [G acc: 0.078]\n",
      "4332 [D loss: (0.530)(R 0.541, F 0.519)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.464] [G acc: 0.094]\n",
      "4333 [D loss: (0.626)(R 0.740, F 0.511)] [D acc: (0.672)(0.500, 0.844)] [G loss: 1.434] [G acc: 0.125]\n",
      "4334 [D loss: (0.589)(R 0.572, F 0.605)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.547] [G acc: 0.031]\n",
      "4335 [D loss: (0.484)(R 0.496, F 0.472)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.505] [G acc: 0.109]\n",
      "4336 [D loss: (0.600)(R 0.611, F 0.589)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.297] [G acc: 0.125]\n",
      "4337 [D loss: (0.541)(R 0.604, F 0.479)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.358] [G acc: 0.172]\n",
      "4338 [D loss: (0.519)(R 0.399, F 0.638)] [D acc: (0.734)(0.781, 0.688)] [G loss: 1.556] [G acc: 0.062]\n",
      "4339 [D loss: (0.588)(R 0.640, F 0.537)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.421] [G acc: 0.094]\n",
      "4340 [D loss: (0.583)(R 0.723, F 0.443)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.217] [G acc: 0.188]\n",
      "4341 [D loss: (0.601)(R 0.688, F 0.514)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.424] [G acc: 0.094]\n",
      "4342 [D loss: (0.555)(R 0.520, F 0.591)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.445] [G acc: 0.062]\n",
      "4343 [D loss: (0.561)(R 0.608, F 0.514)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.387] [G acc: 0.109]\n",
      "4344 [D loss: (0.591)(R 0.566, F 0.615)] [D acc: (0.648)(0.672, 0.625)] [G loss: 1.505] [G acc: 0.078]\n",
      "4345 [D loss: (0.505)(R 0.534, F 0.477)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.537] [G acc: 0.094]\n",
      "4346 [D loss: (0.514)(R 0.494, F 0.534)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.478] [G acc: 0.047]\n",
      "4347 [D loss: (0.519)(R 0.615, F 0.423)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.391] [G acc: 0.094]\n",
      "4348 [D loss: (0.535)(R 0.543, F 0.528)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.429] [G acc: 0.094]\n",
      "4349 [D loss: (0.610)(R 0.655, F 0.566)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.237] [G acc: 0.172]\n",
      "4350 [D loss: (0.627)(R 0.630, F 0.624)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.586] [G acc: 0.047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4351 [D loss: (0.635)(R 0.715, F 0.555)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.358] [G acc: 0.047]\n",
      "4352 [D loss: (0.574)(R 0.612, F 0.536)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.383] [G acc: 0.141]\n",
      "4353 [D loss: (0.508)(R 0.550, F 0.467)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.321] [G acc: 0.172]\n",
      "4354 [D loss: (0.528)(R 0.549, F 0.507)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.341] [G acc: 0.078]\n",
      "4355 [D loss: (0.522)(R 0.523, F 0.520)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.492] [G acc: 0.062]\n",
      "4356 [D loss: (0.643)(R 0.778, F 0.508)] [D acc: (0.625)(0.469, 0.781)] [G loss: 1.292] [G acc: 0.156]\n",
      "4357 [D loss: (0.645)(R 0.653, F 0.637)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.367] [G acc: 0.109]\n",
      "4358 [D loss: (0.607)(R 0.664, F 0.550)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.417] [G acc: 0.062]\n",
      "4359 [D loss: (0.547)(R 0.561, F 0.532)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.363] [G acc: 0.109]\n",
      "4360 [D loss: (0.598)(R 0.618, F 0.577)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.343] [G acc: 0.109]\n",
      "4361 [D loss: (0.503)(R 0.516, F 0.489)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.341] [G acc: 0.047]\n",
      "4362 [D loss: (0.506)(R 0.455, F 0.558)] [D acc: (0.766)(0.781, 0.750)] [G loss: 1.190] [G acc: 0.188]\n",
      "4363 [D loss: (0.617)(R 0.601, F 0.633)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.322] [G acc: 0.156]\n",
      "4364 [D loss: (0.484)(R 0.480, F 0.488)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.314] [G acc: 0.109]\n",
      "4365 [D loss: (0.576)(R 0.570, F 0.582)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.333] [G acc: 0.125]\n",
      "4366 [D loss: (0.531)(R 0.545, F 0.517)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.265] [G acc: 0.188]\n",
      "4367 [D loss: (0.503)(R 0.476, F 0.529)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.371] [G acc: 0.156]\n",
      "4368 [D loss: (0.535)(R 0.519, F 0.552)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.285] [G acc: 0.125]\n",
      "4369 [D loss: (0.566)(R 0.574, F 0.557)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.338] [G acc: 0.141]\n",
      "4370 [D loss: (0.504)(R 0.506, F 0.501)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.453] [G acc: 0.125]\n",
      "4371 [D loss: (0.635)(R 0.516, F 0.754)] [D acc: (0.680)(0.703, 0.656)] [G loss: 1.634] [G acc: 0.047]\n",
      "4372 [D loss: (0.531)(R 0.654, F 0.408)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.308] [G acc: 0.172]\n",
      "4373 [D loss: (0.504)(R 0.551, F 0.457)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.364] [G acc: 0.078]\n",
      "4374 [D loss: (0.494)(R 0.461, F 0.528)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.260] [G acc: 0.094]\n",
      "4375 [D loss: (0.454)(R 0.483, F 0.425)] [D acc: (0.812)(0.719, 0.906)] [G loss: 1.475] [G acc: 0.156]\n",
      "4376 [D loss: (0.520)(R 0.474, F 0.566)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.325] [G acc: 0.172]\n",
      "4377 [D loss: (0.463)(R 0.483, F 0.442)] [D acc: (0.828)(0.781, 0.875)] [G loss: 1.495] [G acc: 0.109]\n",
      "4378 [D loss: (0.544)(R 0.534, F 0.554)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.376] [G acc: 0.094]\n",
      "4379 [D loss: (0.574)(R 0.714, F 0.434)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.394] [G acc: 0.094]\n",
      "4380 [D loss: (0.573)(R 0.656, F 0.490)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.255] [G acc: 0.125]\n",
      "4381 [D loss: (0.501)(R 0.458, F 0.544)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.343] [G acc: 0.125]\n",
      "4382 [D loss: (0.556)(R 0.460, F 0.653)] [D acc: (0.695)(0.734, 0.656)] [G loss: 1.520] [G acc: 0.109]\n",
      "4383 [D loss: (0.588)(R 0.529, F 0.647)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.351] [G acc: 0.109]\n",
      "4384 [D loss: (0.537)(R 0.629, F 0.445)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.353] [G acc: 0.156]\n",
      "4385 [D loss: (0.542)(R 0.512, F 0.572)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.476] [G acc: 0.078]\n",
      "4386 [D loss: (0.508)(R 0.627, F 0.390)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.440] [G acc: 0.078]\n",
      "4387 [D loss: (0.472)(R 0.409, F 0.536)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.501] [G acc: 0.125]\n",
      "4388 [D loss: (0.431)(R 0.429, F 0.433)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.505] [G acc: 0.109]\n",
      "4389 [D loss: (0.461)(R 0.369, F 0.553)] [D acc: (0.789)(0.844, 0.734)] [G loss: 1.420] [G acc: 0.109]\n",
      "4390 [D loss: (0.568)(R 0.587, F 0.549)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.497] [G acc: 0.094]\n",
      "4391 [D loss: (0.570)(R 0.582, F 0.558)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.412] [G acc: 0.062]\n",
      "4392 [D loss: (0.501)(R 0.557, F 0.444)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.376] [G acc: 0.141]\n",
      "4393 [D loss: (0.579)(R 0.531, F 0.627)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.480] [G acc: 0.109]\n",
      "4394 [D loss: (0.490)(R 0.445, F 0.535)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.469] [G acc: 0.094]\n",
      "4395 [D loss: (0.580)(R 0.611, F 0.549)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.477] [G acc: 0.078]\n",
      "4396 [D loss: (0.573)(R 0.639, F 0.507)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.362] [G acc: 0.125]\n",
      "4397 [D loss: (0.533)(R 0.475, F 0.591)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.459] [G acc: 0.062]\n",
      "4398 [D loss: (0.597)(R 0.613, F 0.581)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.528] [G acc: 0.109]\n",
      "4399 [D loss: (0.562)(R 0.576, F 0.549)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.383] [G acc: 0.094]\n",
      "4400 [D loss: (0.591)(R 0.636, F 0.547)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.288] [G acc: 0.125]\n",
      "4401 [D loss: (0.498)(R 0.558, F 0.437)] [D acc: (0.789)(0.641, 0.938)] [G loss: 1.158] [G acc: 0.234]\n",
      "4402 [D loss: (0.449)(R 0.439, F 0.459)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.380] [G acc: 0.125]\n",
      "4403 [D loss: (0.451)(R 0.453, F 0.448)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.538] [G acc: 0.062]\n",
      "4404 [D loss: (0.546)(R 0.488, F 0.604)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.407] [G acc: 0.141]\n",
      "4405 [D loss: (0.491)(R 0.416, F 0.567)] [D acc: (0.797)(0.797, 0.797)] [G loss: 1.382] [G acc: 0.141]\n",
      "4406 [D loss: (0.534)(R 0.638, F 0.429)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.346] [G acc: 0.156]\n",
      "4407 [D loss: (0.467)(R 0.483, F 0.451)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.463] [G acc: 0.125]\n",
      "4408 [D loss: (0.585)(R 0.572, F 0.597)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.669] [G acc: 0.125]\n",
      "4409 [D loss: (0.484)(R 0.518, F 0.450)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.651] [G acc: 0.016]\n",
      "4410 [D loss: (0.575)(R 0.535, F 0.615)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.352] [G acc: 0.062]\n",
      "4411 [D loss: (0.516)(R 0.527, F 0.505)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.482] [G acc: 0.047]\n",
      "4412 [D loss: (0.533)(R 0.510, F 0.556)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.419] [G acc: 0.125]\n",
      "4413 [D loss: (0.462)(R 0.433, F 0.491)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.435] [G acc: 0.094]\n",
      "4414 [D loss: (0.574)(R 0.623, F 0.524)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.523] [G acc: 0.078]\n",
      "4415 [D loss: (0.592)(R 0.569, F 0.615)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.532] [G acc: 0.062]\n",
      "4416 [D loss: (0.477)(R 0.525, F 0.428)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.364] [G acc: 0.078]\n",
      "4417 [D loss: (0.566)(R 0.544, F 0.588)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.433] [G acc: 0.109]\n",
      "4418 [D loss: (0.484)(R 0.573, F 0.394)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.413] [G acc: 0.125]\n",
      "4419 [D loss: (0.493)(R 0.570, F 0.416)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.497] [G acc: 0.047]\n",
      "4420 [D loss: (0.447)(R 0.373, F 0.521)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.548] [G acc: 0.094]\n",
      "4421 [D loss: (0.476)(R 0.494, F 0.459)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.549] [G acc: 0.078]\n",
      "4422 [D loss: (0.560)(R 0.489, F 0.630)] [D acc: (0.680)(0.703, 0.656)] [G loss: 1.452] [G acc: 0.094]\n",
      "4423 [D loss: (0.521)(R 0.563, F 0.478)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.545] [G acc: 0.109]\n",
      "4424 [D loss: (0.576)(R 0.524, F 0.628)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.396] [G acc: 0.109]\n",
      "4425 [D loss: (0.572)(R 0.652, F 0.491)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.579] [G acc: 0.062]\n",
      "4426 [D loss: (0.531)(R 0.560, F 0.501)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.549] [G acc: 0.141]\n",
      "4427 [D loss: (0.489)(R 0.449, F 0.530)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.370] [G acc: 0.156]\n",
      "4428 [D loss: (0.511)(R 0.553, F 0.469)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.429] [G acc: 0.109]\n",
      "4429 [D loss: (0.513)(R 0.501, F 0.525)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.445] [G acc: 0.125]\n",
      "4430 [D loss: (0.623)(R 0.650, F 0.595)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.347] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4431 [D loss: (0.516)(R 0.470, F 0.562)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.507] [G acc: 0.141]\n",
      "4432 [D loss: (0.486)(R 0.502, F 0.469)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.631] [G acc: 0.078]\n",
      "4433 [D loss: (0.600)(R 0.596, F 0.604)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.363] [G acc: 0.156]\n",
      "4434 [D loss: (0.555)(R 0.432, F 0.678)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.444] [G acc: 0.078]\n",
      "4435 [D loss: (0.559)(R 0.687, F 0.430)] [D acc: (0.695)(0.516, 0.875)] [G loss: 1.634] [G acc: 0.078]\n",
      "4436 [D loss: (0.619)(R 0.604, F 0.634)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.355] [G acc: 0.094]\n",
      "4437 [D loss: (0.554)(R 0.619, F 0.488)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.374] [G acc: 0.125]\n",
      "4438 [D loss: (0.527)(R 0.517, F 0.537)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.514] [G acc: 0.047]\n",
      "4439 [D loss: (0.478)(R 0.510, F 0.446)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.503] [G acc: 0.109]\n",
      "4440 [D loss: (0.481)(R 0.547, F 0.415)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.473] [G acc: 0.062]\n",
      "4441 [D loss: (0.492)(R 0.473, F 0.510)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.364] [G acc: 0.188]\n",
      "4442 [D loss: (0.503)(R 0.422, F 0.584)] [D acc: (0.766)(0.781, 0.750)] [G loss: 1.384] [G acc: 0.156]\n",
      "4443 [D loss: (0.613)(R 0.440, F 0.785)] [D acc: (0.773)(0.797, 0.750)] [G loss: 1.559] [G acc: 0.109]\n",
      "4444 [D loss: (0.653)(R 0.759, F 0.548)] [D acc: (0.664)(0.500, 0.828)] [G loss: 1.464] [G acc: 0.016]\n",
      "4445 [D loss: (0.575)(R 0.661, F 0.488)] [D acc: (0.664)(0.500, 0.828)] [G loss: 1.649] [G acc: 0.094]\n",
      "4446 [D loss: (0.537)(R 0.647, F 0.427)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.493] [G acc: 0.125]\n",
      "4447 [D loss: (0.499)(R 0.545, F 0.453)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.556] [G acc: 0.125]\n",
      "4448 [D loss: (0.530)(R 0.526, F 0.535)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.403] [G acc: 0.172]\n",
      "4449 [D loss: (0.494)(R 0.458, F 0.531)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.432] [G acc: 0.125]\n",
      "4450 [D loss: (0.432)(R 0.494, F 0.370)] [D acc: (0.820)(0.734, 0.906)] [G loss: 1.742] [G acc: 0.078]\n",
      "4451 [D loss: (0.601)(R 0.637, F 0.566)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.468] [G acc: 0.094]\n",
      "4452 [D loss: (0.537)(R 0.496, F 0.579)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.468] [G acc: 0.125]\n",
      "4453 [D loss: (0.598)(R 0.719, F 0.478)] [D acc: (0.672)(0.531, 0.812)] [G loss: 1.467] [G acc: 0.094]\n",
      "4454 [D loss: (0.490)(R 0.463, F 0.517)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.566] [G acc: 0.062]\n",
      "4455 [D loss: (0.546)(R 0.535, F 0.558)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.465] [G acc: 0.047]\n",
      "4456 [D loss: (0.502)(R 0.604, F 0.399)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.476] [G acc: 0.141]\n",
      "4457 [D loss: (0.490)(R 0.508, F 0.472)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.548] [G acc: 0.109]\n",
      "4458 [D loss: (0.568)(R 0.617, F 0.519)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.355] [G acc: 0.141]\n",
      "4459 [D loss: (0.551)(R 0.481, F 0.621)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.483] [G acc: 0.109]\n",
      "4460 [D loss: (0.570)(R 0.591, F 0.548)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.367] [G acc: 0.125]\n",
      "4461 [D loss: (0.545)(R 0.599, F 0.491)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.632] [G acc: 0.109]\n",
      "4462 [D loss: (0.553)(R 0.618, F 0.488)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.438] [G acc: 0.141]\n",
      "4463 [D loss: (0.531)(R 0.558, F 0.504)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.397] [G acc: 0.094]\n",
      "4464 [D loss: (0.553)(R 0.485, F 0.621)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.620] [G acc: 0.016]\n",
      "4465 [D loss: (0.469)(R 0.547, F 0.390)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.446] [G acc: 0.109]\n",
      "4466 [D loss: (0.550)(R 0.492, F 0.608)] [D acc: (0.688)(0.719, 0.656)] [G loss: 1.388] [G acc: 0.078]\n",
      "4467 [D loss: (0.675)(R 0.732, F 0.617)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.408] [G acc: 0.156]\n",
      "4468 [D loss: (0.545)(R 0.613, F 0.478)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.265] [G acc: 0.109]\n",
      "4469 [D loss: (0.696)(R 0.630, F 0.762)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.540] [G acc: 0.094]\n",
      "4470 [D loss: (0.500)(R 0.637, F 0.363)] [D acc: (0.797)(0.672, 0.922)] [G loss: 1.421] [G acc: 0.047]\n",
      "4471 [D loss: (0.600)(R 0.564, F 0.636)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.419] [G acc: 0.062]\n",
      "4472 [D loss: (0.539)(R 0.586, F 0.491)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.465] [G acc: 0.078]\n",
      "4473 [D loss: (0.493)(R 0.534, F 0.453)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.698] [G acc: 0.109]\n",
      "4474 [D loss: (0.513)(R 0.612, F 0.414)] [D acc: (0.773)(0.609, 0.938)] [G loss: 1.574] [G acc: 0.094]\n",
      "4475 [D loss: (0.467)(R 0.516, F 0.418)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.300] [G acc: 0.156]\n",
      "4476 [D loss: (0.437)(R 0.395, F 0.480)] [D acc: (0.805)(0.844, 0.766)] [G loss: 1.501] [G acc: 0.109]\n",
      "4477 [D loss: (0.632)(R 0.548, F 0.717)] [D acc: (0.664)(0.688, 0.641)] [G loss: 1.582] [G acc: 0.078]\n",
      "4478 [D loss: (0.624)(R 0.685, F 0.562)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.383] [G acc: 0.125]\n",
      "4479 [D loss: (0.538)(R 0.544, F 0.533)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.448] [G acc: 0.047]\n",
      "4480 [D loss: (0.550)(R 0.623, F 0.477)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.397] [G acc: 0.141]\n",
      "4481 [D loss: (0.510)(R 0.528, F 0.492)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.509] [G acc: 0.109]\n",
      "4482 [D loss: (0.462)(R 0.413, F 0.512)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.488] [G acc: 0.062]\n",
      "4483 [D loss: (0.427)(R 0.391, F 0.463)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.674] [G acc: 0.078]\n",
      "4484 [D loss: (0.513)(R 0.620, F 0.405)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.613] [G acc: 0.047]\n",
      "4485 [D loss: (0.633)(R 0.607, F 0.658)] [D acc: (0.656)(0.656, 0.656)] [G loss: 1.503] [G acc: 0.172]\n",
      "4486 [D loss: (0.536)(R 0.572, F 0.500)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.472] [G acc: 0.078]\n",
      "4487 [D loss: (0.599)(R 0.707, F 0.491)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.444] [G acc: 0.047]\n",
      "4488 [D loss: (0.507)(R 0.483, F 0.531)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.536] [G acc: 0.094]\n",
      "4489 [D loss: (0.543)(R 0.596, F 0.491)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.435] [G acc: 0.141]\n",
      "4490 [D loss: (0.500)(R 0.510, F 0.490)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.470] [G acc: 0.078]\n",
      "4491 [D loss: (0.514)(R 0.466, F 0.562)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.423] [G acc: 0.078]\n",
      "4492 [D loss: (0.542)(R 0.548, F 0.535)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.483] [G acc: 0.141]\n",
      "4493 [D loss: (0.525)(R 0.590, F 0.460)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.451] [G acc: 0.125]\n",
      "4494 [D loss: (0.540)(R 0.561, F 0.520)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.296] [G acc: 0.125]\n",
      "4495 [D loss: (0.511)(R 0.551, F 0.471)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.293] [G acc: 0.141]\n",
      "4496 [D loss: (0.629)(R 0.646, F 0.611)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.401] [G acc: 0.094]\n",
      "4497 [D loss: (0.538)(R 0.619, F 0.457)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.389] [G acc: 0.078]\n",
      "4498 [D loss: (0.705)(R 0.558, F 0.853)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.295] [G acc: 0.062]\n",
      "4499 [D loss: (0.494)(R 0.511, F 0.477)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.280] [G acc: 0.141]\n",
      "4500 [D loss: (0.543)(R 0.614, F 0.472)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.431] [G acc: 0.078]\n",
      "4501 [D loss: (0.560)(R 0.637, F 0.482)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.354] [G acc: 0.094]\n",
      "4502 [D loss: (0.553)(R 0.567, F 0.540)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.383] [G acc: 0.109]\n",
      "4503 [D loss: (0.472)(R 0.453, F 0.491)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.378] [G acc: 0.109]\n",
      "4504 [D loss: (0.565)(R 0.499, F 0.631)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.522] [G acc: 0.047]\n",
      "4505 [D loss: (0.624)(R 0.681, F 0.568)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.349] [G acc: 0.094]\n",
      "4506 [D loss: (0.519)(R 0.490, F 0.548)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.307] [G acc: 0.094]\n",
      "4507 [D loss: (0.568)(R 0.565, F 0.571)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.311] [G acc: 0.141]\n",
      "4508 [D loss: (0.457)(R 0.443, F 0.471)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.307] [G acc: 0.062]\n",
      "4509 [D loss: (0.577)(R 0.581, F 0.574)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.280] [G acc: 0.125]\n",
      "4510 [D loss: (0.522)(R 0.581, F 0.464)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.382] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4511 [D loss: (0.501)(R 0.554, F 0.448)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.313] [G acc: 0.125]\n",
      "4512 [D loss: (0.414)(R 0.423, F 0.404)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.249] [G acc: 0.141]\n",
      "4513 [D loss: (0.654)(R 0.384, F 0.924)] [D acc: (0.719)(0.766, 0.672)] [G loss: 1.406] [G acc: 0.078]\n",
      "4514 [D loss: (0.570)(R 0.676, F 0.463)] [D acc: (0.695)(0.547, 0.844)] [G loss: 1.476] [G acc: 0.062]\n",
      "4515 [D loss: (0.546)(R 0.604, F 0.487)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.235] [G acc: 0.109]\n",
      "4516 [D loss: (0.418)(R 0.437, F 0.399)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.376] [G acc: 0.125]\n",
      "4517 [D loss: (0.507)(R 0.493, F 0.521)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.560] [G acc: 0.062]\n",
      "4518 [D loss: (0.502)(R 0.550, F 0.454)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.360] [G acc: 0.141]\n",
      "4519 [D loss: (0.486)(R 0.508, F 0.464)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.473] [G acc: 0.078]\n",
      "4520 [D loss: (0.569)(R 0.569, F 0.569)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.460] [G acc: 0.109]\n",
      "4521 [D loss: (0.476)(R 0.477, F 0.475)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.556] [G acc: 0.062]\n",
      "4522 [D loss: (0.562)(R 0.665, F 0.459)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.240] [G acc: 0.234]\n",
      "4523 [D loss: (0.569)(R 0.471, F 0.667)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.428] [G acc: 0.125]\n",
      "4524 [D loss: (0.533)(R 0.580, F 0.487)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.428] [G acc: 0.062]\n",
      "4525 [D loss: (0.630)(R 0.510, F 0.751)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.440] [G acc: 0.125]\n",
      "4526 [D loss: (0.624)(R 0.738, F 0.509)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.311] [G acc: 0.109]\n",
      "4527 [D loss: (0.512)(R 0.519, F 0.504)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.302] [G acc: 0.141]\n",
      "4528 [D loss: (0.448)(R 0.409, F 0.488)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.450] [G acc: 0.109]\n",
      "4529 [D loss: (0.560)(R 0.484, F 0.635)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.355] [G acc: 0.094]\n",
      "4530 [D loss: (0.495)(R 0.512, F 0.478)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.365] [G acc: 0.094]\n",
      "4531 [D loss: (0.460)(R 0.506, F 0.414)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.567] [G acc: 0.062]\n",
      "4532 [D loss: (0.526)(R 0.471, F 0.580)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.488] [G acc: 0.062]\n",
      "4533 [D loss: (0.557)(R 0.586, F 0.529)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.300] [G acc: 0.125]\n",
      "4534 [D loss: (0.513)(R 0.491, F 0.534)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.474] [G acc: 0.125]\n",
      "4535 [D loss: (0.513)(R 0.545, F 0.482)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.457] [G acc: 0.078]\n",
      "4536 [D loss: (0.529)(R 0.550, F 0.507)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.471] [G acc: 0.094]\n",
      "4537 [D loss: (0.507)(R 0.516, F 0.498)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.385] [G acc: 0.062]\n",
      "4538 [D loss: (0.585)(R 0.594, F 0.575)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.491] [G acc: 0.078]\n",
      "4539 [D loss: (0.467)(R 0.535, F 0.398)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.244] [G acc: 0.094]\n",
      "4540 [D loss: (0.529)(R 0.533, F 0.525)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.329] [G acc: 0.203]\n",
      "4541 [D loss: (0.606)(R 0.552, F 0.661)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.490] [G acc: 0.109]\n",
      "4542 [D loss: (0.549)(R 0.567, F 0.531)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.390] [G acc: 0.078]\n",
      "4543 [D loss: (0.553)(R 0.591, F 0.515)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.475] [G acc: 0.094]\n",
      "4544 [D loss: (0.504)(R 0.498, F 0.510)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.349] [G acc: 0.078]\n",
      "4545 [D loss: (0.628)(R 0.524, F 0.731)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.387] [G acc: 0.094]\n",
      "4546 [D loss: (0.502)(R 0.597, F 0.407)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.461] [G acc: 0.094]\n",
      "4547 [D loss: (0.499)(R 0.505, F 0.493)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.457] [G acc: 0.156]\n",
      "4548 [D loss: (0.500)(R 0.450, F 0.549)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.587] [G acc: 0.078]\n",
      "4549 [D loss: (0.545)(R 0.574, F 0.516)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.526] [G acc: 0.109]\n",
      "4550 [D loss: (0.505)(R 0.584, F 0.426)] [D acc: (0.789)(0.672, 0.906)] [G loss: 1.505] [G acc: 0.078]\n",
      "4551 [D loss: (0.558)(R 0.570, F 0.545)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.444] [G acc: 0.094]\n",
      "4552 [D loss: (0.505)(R 0.521, F 0.489)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.483] [G acc: 0.109]\n",
      "4553 [D loss: (0.502)(R 0.506, F 0.499)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.303] [G acc: 0.156]\n",
      "4554 [D loss: (0.529)(R 0.421, F 0.638)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.464] [G acc: 0.109]\n",
      "4555 [D loss: (0.508)(R 0.523, F 0.494)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.351] [G acc: 0.125]\n",
      "4556 [D loss: (0.549)(R 0.629, F 0.469)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.442] [G acc: 0.109]\n",
      "4557 [D loss: (0.586)(R 0.564, F 0.609)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.342] [G acc: 0.047]\n",
      "4558 [D loss: (0.551)(R 0.658, F 0.444)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.353] [G acc: 0.094]\n",
      "4559 [D loss: (0.512)(R 0.521, F 0.504)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.284] [G acc: 0.078]\n",
      "4560 [D loss: (0.463)(R 0.426, F 0.499)] [D acc: (0.812)(0.797, 0.828)] [G loss: 1.643] [G acc: 0.141]\n",
      "4561 [D loss: (0.393)(R 0.425, F 0.360)] [D acc: (0.836)(0.766, 0.906)] [G loss: 1.644] [G acc: 0.047]\n",
      "4562 [D loss: (0.574)(R 0.481, F 0.667)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.610] [G acc: 0.047]\n",
      "4563 [D loss: (0.540)(R 0.585, F 0.495)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.641] [G acc: 0.109]\n",
      "4564 [D loss: (0.622)(R 0.689, F 0.555)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.475] [G acc: 0.047]\n",
      "4565 [D loss: (0.558)(R 0.672, F 0.445)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.468] [G acc: 0.062]\n",
      "4566 [D loss: (0.621)(R 0.635, F 0.607)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.242] [G acc: 0.094]\n",
      "4567 [D loss: (0.441)(R 0.414, F 0.468)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.350] [G acc: 0.078]\n",
      "4568 [D loss: (0.444)(R 0.386, F 0.503)] [D acc: (0.789)(0.797, 0.781)] [G loss: 1.287] [G acc: 0.125]\n",
      "4569 [D loss: (0.507)(R 0.478, F 0.537)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.463] [G acc: 0.094]\n",
      "4570 [D loss: (0.487)(R 0.464, F 0.509)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.365] [G acc: 0.109]\n",
      "4571 [D loss: (0.457)(R 0.524, F 0.391)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.248] [G acc: 0.156]\n",
      "4572 [D loss: (0.611)(R 0.557, F 0.665)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.456] [G acc: 0.078]\n",
      "4573 [D loss: (0.557)(R 0.636, F 0.478)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.365] [G acc: 0.000]\n",
      "4574 [D loss: (0.592)(R 0.624, F 0.560)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.348] [G acc: 0.125]\n",
      "4575 [D loss: (0.495)(R 0.529, F 0.462)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.162] [G acc: 0.219]\n",
      "4576 [D loss: (0.592)(R 0.532, F 0.653)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.413] [G acc: 0.062]\n",
      "4577 [D loss: (0.491)(R 0.502, F 0.481)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.440] [G acc: 0.016]\n",
      "4578 [D loss: (0.482)(R 0.451, F 0.512)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.567] [G acc: 0.094]\n",
      "4579 [D loss: (0.493)(R 0.558, F 0.429)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.496] [G acc: 0.047]\n",
      "4580 [D loss: (0.592)(R 0.709, F 0.475)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.360] [G acc: 0.062]\n",
      "4581 [D loss: (0.580)(R 0.523, F 0.637)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.403] [G acc: 0.078]\n",
      "4582 [D loss: (0.545)(R 0.583, F 0.507)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.342] [G acc: 0.125]\n",
      "4583 [D loss: (0.540)(R 0.514, F 0.567)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.263] [G acc: 0.047]\n",
      "4584 [D loss: (0.509)(R 0.578, F 0.441)] [D acc: (0.773)(0.641, 0.906)] [G loss: 1.437] [G acc: 0.125]\n",
      "4585 [D loss: (0.609)(R 0.673, F 0.546)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.438] [G acc: 0.047]\n",
      "4586 [D loss: (0.533)(R 0.623, F 0.442)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.193] [G acc: 0.125]\n",
      "4587 [D loss: (0.574)(R 0.563, F 0.585)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.284] [G acc: 0.094]\n",
      "4588 [D loss: (0.505)(R 0.501, F 0.509)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.312] [G acc: 0.125]\n",
      "4589 [D loss: (0.532)(R 0.462, F 0.602)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.339] [G acc: 0.078]\n",
      "4590 [D loss: (0.540)(R 0.570, F 0.509)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.426] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4591 [D loss: (0.511)(R 0.543, F 0.480)] [D acc: (0.820)(0.734, 0.906)] [G loss: 1.442] [G acc: 0.062]\n",
      "4592 [D loss: (0.521)(R 0.593, F 0.449)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.448] [G acc: 0.078]\n",
      "4593 [D loss: (0.600)(R 0.502, F 0.697)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.470] [G acc: 0.031]\n",
      "4594 [D loss: (0.562)(R 0.635, F 0.489)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.547] [G acc: 0.031]\n",
      "4595 [D loss: (0.490)(R 0.583, F 0.398)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.589] [G acc: 0.062]\n",
      "4596 [D loss: (0.566)(R 0.490, F 0.641)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.463] [G acc: 0.078]\n",
      "4597 [D loss: (0.543)(R 0.645, F 0.441)] [D acc: (0.695)(0.547, 0.844)] [G loss: 1.425] [G acc: 0.094]\n",
      "4598 [D loss: (0.467)(R 0.513, F 0.421)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.516] [G acc: 0.078]\n",
      "4599 [D loss: (0.575)(R 0.625, F 0.526)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.379] [G acc: 0.094]\n",
      "4600 [D loss: (0.467)(R 0.489, F 0.444)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.315] [G acc: 0.125]\n",
      "4601 [D loss: (0.548)(R 0.496, F 0.601)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.362] [G acc: 0.109]\n",
      "4602 [D loss: (0.535)(R 0.569, F 0.502)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.329] [G acc: 0.156]\n",
      "4603 [D loss: (0.513)(R 0.571, F 0.455)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.552] [G acc: 0.062]\n",
      "4604 [D loss: (0.538)(R 0.478, F 0.598)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.412] [G acc: 0.094]\n",
      "4605 [D loss: (0.603)(R 0.635, F 0.571)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.558] [G acc: 0.125]\n",
      "4606 [D loss: (0.578)(R 0.594, F 0.562)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.415] [G acc: 0.109]\n",
      "4607 [D loss: (0.480)(R 0.424, F 0.535)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.444] [G acc: 0.047]\n",
      "4608 [D loss: (0.539)(R 0.573, F 0.506)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.374] [G acc: 0.125]\n",
      "4609 [D loss: (0.589)(R 0.685, F 0.493)] [D acc: (0.633)(0.484, 0.781)] [G loss: 1.397] [G acc: 0.109]\n",
      "4610 [D loss: (0.524)(R 0.534, F 0.515)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.340] [G acc: 0.047]\n",
      "4611 [D loss: (0.618)(R 0.600, F 0.637)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.554] [G acc: 0.078]\n",
      "4612 [D loss: (0.551)(R 0.665, F 0.438)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.438] [G acc: 0.125]\n",
      "4613 [D loss: (0.611)(R 0.586, F 0.636)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.479] [G acc: 0.078]\n",
      "4614 [D loss: (0.553)(R 0.589, F 0.517)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.434] [G acc: 0.062]\n",
      "4615 [D loss: (0.508)(R 0.529, F 0.486)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.358] [G acc: 0.094]\n",
      "4616 [D loss: (0.555)(R 0.603, F 0.507)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.341] [G acc: 0.109]\n",
      "4617 [D loss: (0.474)(R 0.423, F 0.525)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.269] [G acc: 0.188]\n",
      "4618 [D loss: (0.517)(R 0.508, F 0.526)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.456] [G acc: 0.109]\n",
      "4619 [D loss: (0.532)(R 0.576, F 0.488)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.316] [G acc: 0.109]\n",
      "4620 [D loss: (0.567)(R 0.468, F 0.666)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.443] [G acc: 0.062]\n",
      "4621 [D loss: (0.616)(R 0.613, F 0.620)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.451] [G acc: 0.062]\n",
      "4622 [D loss: (0.532)(R 0.622, F 0.442)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.547] [G acc: 0.062]\n",
      "4623 [D loss: (0.460)(R 0.513, F 0.406)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.504] [G acc: 0.156]\n",
      "4624 [D loss: (0.591)(R 0.648, F 0.534)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.510] [G acc: 0.078]\n",
      "4625 [D loss: (0.662)(R 0.694, F 0.630)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.337] [G acc: 0.094]\n",
      "4626 [D loss: (0.581)(R 0.607, F 0.555)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.450] [G acc: 0.094]\n",
      "4627 [D loss: (0.464)(R 0.434, F 0.495)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.391] [G acc: 0.078]\n",
      "4628 [D loss: (0.540)(R 0.580, F 0.499)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.443] [G acc: 0.078]\n",
      "4629 [D loss: (0.576)(R 0.609, F 0.543)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.373] [G acc: 0.047]\n",
      "4630 [D loss: (0.428)(R 0.440, F 0.416)] [D acc: (0.805)(0.750, 0.859)] [G loss: 1.321] [G acc: 0.109]\n",
      "4631 [D loss: (0.504)(R 0.421, F 0.586)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.443] [G acc: 0.094]\n",
      "4632 [D loss: (0.551)(R 0.531, F 0.572)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.390] [G acc: 0.047]\n",
      "4633 [D loss: (0.532)(R 0.589, F 0.474)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.341] [G acc: 0.062]\n",
      "4634 [D loss: (0.535)(R 0.521, F 0.550)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.669] [G acc: 0.078]\n",
      "4635 [D loss: (0.506)(R 0.587, F 0.425)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.387] [G acc: 0.047]\n",
      "4636 [D loss: (0.589)(R 0.563, F 0.615)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.419] [G acc: 0.156]\n",
      "4637 [D loss: (0.557)(R 0.689, F 0.424)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.294] [G acc: 0.109]\n",
      "4638 [D loss: (0.566)(R 0.635, F 0.497)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.210] [G acc: 0.219]\n",
      "4639 [D loss: (0.475)(R 0.435, F 0.514)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.470] [G acc: 0.062]\n",
      "4640 [D loss: (0.519)(R 0.533, F 0.505)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.245] [G acc: 0.141]\n",
      "4641 [D loss: (0.536)(R 0.532, F 0.540)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.422] [G acc: 0.078]\n",
      "4642 [D loss: (0.497)(R 0.613, F 0.381)] [D acc: (0.773)(0.625, 0.922)] [G loss: 1.323] [G acc: 0.062]\n",
      "4643 [D loss: (0.566)(R 0.524, F 0.609)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.344] [G acc: 0.094]\n",
      "4644 [D loss: (0.541)(R 0.583, F 0.499)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.269] [G acc: 0.172]\n",
      "4645 [D loss: (0.643)(R 0.622, F 0.664)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.395] [G acc: 0.125]\n",
      "4646 [D loss: (0.583)(R 0.462, F 0.704)] [D acc: (0.750)(0.781, 0.719)] [G loss: 1.415] [G acc: 0.094]\n",
      "4647 [D loss: (0.540)(R 0.659, F 0.421)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.324] [G acc: 0.078]\n",
      "4648 [D loss: (0.525)(R 0.509, F 0.541)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.414] [G acc: 0.047]\n",
      "4649 [D loss: (0.469)(R 0.481, F 0.457)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.337] [G acc: 0.125]\n",
      "4650 [D loss: (0.501)(R 0.518, F 0.484)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.509] [G acc: 0.062]\n",
      "4651 [D loss: (0.558)(R 0.422, F 0.693)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.433] [G acc: 0.109]\n",
      "4652 [D loss: (0.488)(R 0.595, F 0.381)] [D acc: (0.781)(0.625, 0.938)] [G loss: 1.487] [G acc: 0.109]\n",
      "4653 [D loss: (0.555)(R 0.601, F 0.510)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.355] [G acc: 0.172]\n",
      "4654 [D loss: (0.607)(R 0.579, F 0.635)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.446] [G acc: 0.094]\n",
      "4655 [D loss: (0.548)(R 0.614, F 0.482)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.491] [G acc: 0.031]\n",
      "4656 [D loss: (0.581)(R 0.629, F 0.534)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.492] [G acc: 0.047]\n",
      "4657 [D loss: (0.459)(R 0.513, F 0.405)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.371] [G acc: 0.078]\n",
      "4658 [D loss: (0.489)(R 0.489, F 0.489)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.196] [G acc: 0.203]\n",
      "4659 [D loss: (0.545)(R 0.583, F 0.507)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.373] [G acc: 0.078]\n",
      "4660 [D loss: (0.442)(R 0.431, F 0.454)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.607] [G acc: 0.094]\n",
      "4661 [D loss: (0.583)(R 0.547, F 0.619)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.322] [G acc: 0.094]\n",
      "4662 [D loss: (0.543)(R 0.538, F 0.547)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.438] [G acc: 0.078]\n",
      "4663 [D loss: (0.666)(R 0.512, F 0.821)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.424] [G acc: 0.047]\n",
      "4664 [D loss: (0.550)(R 0.683, F 0.416)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.359] [G acc: 0.172]\n",
      "4665 [D loss: (0.562)(R 0.570, F 0.554)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.513] [G acc: 0.062]\n",
      "4666 [D loss: (0.505)(R 0.550, F 0.459)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.411] [G acc: 0.047]\n",
      "4667 [D loss: (0.533)(R 0.489, F 0.577)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.283] [G acc: 0.156]\n",
      "4668 [D loss: (0.477)(R 0.483, F 0.471)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.331] [G acc: 0.109]\n",
      "4669 [D loss: (0.650)(R 0.676, F 0.625)] [D acc: (0.617)(0.547, 0.688)] [G loss: 1.497] [G acc: 0.094]\n",
      "4670 [D loss: (0.534)(R 0.658, F 0.411)] [D acc: (0.758)(0.609, 0.906)] [G loss: 1.317] [G acc: 0.047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4671 [D loss: (0.503)(R 0.565, F 0.440)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.396] [G acc: 0.156]\n",
      "4672 [D loss: (0.594)(R 0.618, F 0.570)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.365] [G acc: 0.109]\n",
      "4673 [D loss: (0.567)(R 0.453, F 0.682)] [D acc: (0.703)(0.750, 0.656)] [G loss: 1.335] [G acc: 0.125]\n",
      "4674 [D loss: (0.586)(R 0.714, F 0.458)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.427] [G acc: 0.062]\n",
      "4675 [D loss: (0.575)(R 0.493, F 0.658)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.402] [G acc: 0.047]\n",
      "4676 [D loss: (0.574)(R 0.691, F 0.456)] [D acc: (0.656)(0.531, 0.781)] [G loss: 1.310] [G acc: 0.141]\n",
      "4677 [D loss: (0.517)(R 0.516, F 0.519)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.386] [G acc: 0.141]\n",
      "4678 [D loss: (0.542)(R 0.545, F 0.539)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.448] [G acc: 0.156]\n",
      "4679 [D loss: (0.476)(R 0.528, F 0.424)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.259] [G acc: 0.156]\n",
      "4680 [D loss: (0.589)(R 0.603, F 0.575)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.291] [G acc: 0.078]\n",
      "4681 [D loss: (0.548)(R 0.565, F 0.530)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.369] [G acc: 0.109]\n",
      "4682 [D loss: (0.553)(R 0.570, F 0.536)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.356] [G acc: 0.109]\n",
      "4683 [D loss: (0.483)(R 0.513, F 0.454)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.281] [G acc: 0.109]\n",
      "4684 [D loss: (0.548)(R 0.538, F 0.558)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.300] [G acc: 0.125]\n",
      "4685 [D loss: (0.561)(R 0.498, F 0.624)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.299] [G acc: 0.078]\n",
      "4686 [D loss: (0.506)(R 0.495, F 0.517)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.426] [G acc: 0.047]\n",
      "4687 [D loss: (0.649)(R 0.682, F 0.616)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.280] [G acc: 0.109]\n",
      "4688 [D loss: (0.541)(R 0.621, F 0.461)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.305] [G acc: 0.094]\n",
      "4689 [D loss: (0.495)(R 0.454, F 0.535)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.299] [G acc: 0.109]\n",
      "4690 [D loss: (0.491)(R 0.400, F 0.582)] [D acc: (0.758)(0.781, 0.734)] [G loss: 1.459] [G acc: 0.078]\n",
      "4691 [D loss: (0.560)(R 0.614, F 0.506)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.338] [G acc: 0.141]\n",
      "4692 [D loss: (0.654)(R 0.629, F 0.680)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.327] [G acc: 0.109]\n",
      "4693 [D loss: (0.541)(R 0.618, F 0.464)] [D acc: (0.703)(0.547, 0.859)] [G loss: 1.314] [G acc: 0.078]\n",
      "4694 [D loss: (0.587)(R 0.589, F 0.584)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.304] [G acc: 0.125]\n",
      "4695 [D loss: (0.556)(R 0.623, F 0.490)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.426] [G acc: 0.094]\n",
      "4696 [D loss: (0.562)(R 0.581, F 0.543)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.261] [G acc: 0.141]\n",
      "4697 [D loss: (0.496)(R 0.489, F 0.502)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.522] [G acc: 0.047]\n",
      "4698 [D loss: (0.572)(R 0.671, F 0.474)] [D acc: (0.680)(0.516, 0.844)] [G loss: 1.453] [G acc: 0.078]\n",
      "4699 [D loss: (0.418)(R 0.408, F 0.427)] [D acc: (0.844)(0.828, 0.859)] [G loss: 1.527] [G acc: 0.094]\n",
      "4700 [D loss: (0.531)(R 0.613, F 0.449)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.434] [G acc: 0.094]\n",
      "4701 [D loss: (0.492)(R 0.576, F 0.408)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.331] [G acc: 0.109]\n",
      "4702 [D loss: (0.579)(R 0.384, F 0.775)] [D acc: (0.695)(0.766, 0.625)] [G loss: 1.372] [G acc: 0.062]\n",
      "4703 [D loss: (0.595)(R 0.704, F 0.485)] [D acc: (0.625)(0.469, 0.781)] [G loss: 1.484] [G acc: 0.062]\n",
      "4704 [D loss: (0.500)(R 0.547, F 0.453)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.434] [G acc: 0.125]\n",
      "4705 [D loss: (0.544)(R 0.489, F 0.600)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.430] [G acc: 0.141]\n",
      "4706 [D loss: (0.588)(R 0.688, F 0.488)] [D acc: (0.703)(0.547, 0.859)] [G loss: 1.312] [G acc: 0.062]\n",
      "4707 [D loss: (0.486)(R 0.559, F 0.413)] [D acc: (0.820)(0.719, 0.922)] [G loss: 1.498] [G acc: 0.078]\n",
      "4708 [D loss: (0.567)(R 0.563, F 0.572)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.457] [G acc: 0.062]\n",
      "4709 [D loss: (0.545)(R 0.543, F 0.547)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.484] [G acc: 0.062]\n",
      "4710 [D loss: (0.539)(R 0.530, F 0.548)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.507] [G acc: 0.078]\n",
      "4711 [D loss: (0.521)(R 0.533, F 0.509)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.501] [G acc: 0.094]\n",
      "4712 [D loss: (0.589)(R 0.600, F 0.578)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.451] [G acc: 0.188]\n",
      "4713 [D loss: (0.486)(R 0.469, F 0.503)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.456] [G acc: 0.062]\n",
      "4714 [D loss: (0.568)(R 0.672, F 0.464)] [D acc: (0.680)(0.516, 0.844)] [G loss: 1.369] [G acc: 0.094]\n",
      "4715 [D loss: (0.562)(R 0.517, F 0.608)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.339] [G acc: 0.141]\n",
      "4716 [D loss: (0.582)(R 0.646, F 0.519)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.353] [G acc: 0.062]\n",
      "4717 [D loss: (0.504)(R 0.564, F 0.443)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.312] [G acc: 0.078]\n",
      "4718 [D loss: (0.478)(R 0.445, F 0.510)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.381] [G acc: 0.031]\n",
      "4719 [D loss: (0.521)(R 0.425, F 0.617)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.513] [G acc: 0.062]\n",
      "4720 [D loss: (0.605)(R 0.531, F 0.680)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.424] [G acc: 0.078]\n",
      "4721 [D loss: (0.554)(R 0.597, F 0.511)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.422] [G acc: 0.094]\n",
      "4722 [D loss: (0.577)(R 0.575, F 0.579)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.393] [G acc: 0.047]\n",
      "4723 [D loss: (0.555)(R 0.558, F 0.551)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.407] [G acc: 0.047]\n",
      "4724 [D loss: (0.535)(R 0.598, F 0.471)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.371] [G acc: 0.078]\n",
      "4725 [D loss: (0.529)(R 0.565, F 0.494)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.326] [G acc: 0.141]\n",
      "4726 [D loss: (0.639)(R 0.600, F 0.679)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.510] [G acc: 0.062]\n",
      "4727 [D loss: (0.484)(R 0.527, F 0.440)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.361] [G acc: 0.109]\n",
      "4728 [D loss: (0.550)(R 0.573, F 0.526)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.316] [G acc: 0.109]\n",
      "4729 [D loss: (0.522)(R 0.540, F 0.505)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.440] [G acc: 0.078]\n",
      "4730 [D loss: (0.484)(R 0.480, F 0.489)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.501] [G acc: 0.062]\n",
      "4731 [D loss: (0.639)(R 0.606, F 0.673)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.541] [G acc: 0.047]\n",
      "4732 [D loss: (0.502)(R 0.466, F 0.537)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.562] [G acc: 0.016]\n",
      "4733 [D loss: (0.728)(R 1.009, F 0.448)] [D acc: (0.562)(0.312, 0.812)] [G loss: 1.404] [G acc: 0.109]\n",
      "4734 [D loss: (0.528)(R 0.590, F 0.466)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.340] [G acc: 0.094]\n",
      "4735 [D loss: (0.565)(R 0.537, F 0.593)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.357] [G acc: 0.141]\n",
      "4736 [D loss: (0.515)(R 0.499, F 0.532)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.339] [G acc: 0.078]\n",
      "4737 [D loss: (0.558)(R 0.631, F 0.484)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.432] [G acc: 0.078]\n",
      "4738 [D loss: (0.476)(R 0.489, F 0.463)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.354] [G acc: 0.078]\n",
      "4739 [D loss: (0.583)(R 0.487, F 0.680)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.327] [G acc: 0.094]\n",
      "4740 [D loss: (0.499)(R 0.572, F 0.425)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.372] [G acc: 0.062]\n",
      "4741 [D loss: (0.553)(R 0.590, F 0.516)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.321] [G acc: 0.125]\n",
      "4742 [D loss: (0.582)(R 0.672, F 0.491)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.323] [G acc: 0.156]\n",
      "4743 [D loss: (0.536)(R 0.541, F 0.532)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.414] [G acc: 0.141]\n",
      "4744 [D loss: (0.585)(R 0.616, F 0.555)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.397] [G acc: 0.047]\n",
      "4745 [D loss: (0.501)(R 0.554, F 0.447)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.296] [G acc: 0.172]\n",
      "4746 [D loss: (0.562)(R 0.502, F 0.622)] [D acc: (0.680)(0.734, 0.625)] [G loss: 1.413] [G acc: 0.125]\n",
      "4747 [D loss: (0.515)(R 0.518, F 0.512)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.347] [G acc: 0.094]\n",
      "4748 [D loss: (0.605)(R 0.630, F 0.580)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.396] [G acc: 0.094]\n",
      "4749 [D loss: (0.529)(R 0.561, F 0.497)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.311] [G acc: 0.156]\n",
      "4750 [D loss: (0.523)(R 0.446, F 0.599)] [D acc: (0.766)(0.812, 0.719)] [G loss: 1.542] [G acc: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4751 [D loss: (0.481)(R 0.517, F 0.446)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.498] [G acc: 0.047]\n",
      "4752 [D loss: (0.673)(R 0.614, F 0.733)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.206] [G acc: 0.172]\n",
      "4753 [D loss: (0.579)(R 0.579, F 0.578)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.402] [G acc: 0.094]\n",
      "4754 [D loss: (0.505)(R 0.538, F 0.473)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.276] [G acc: 0.109]\n",
      "4755 [D loss: (0.587)(R 0.612, F 0.561)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.384] [G acc: 0.078]\n",
      "4756 [D loss: (0.405)(R 0.466, F 0.345)] [D acc: (0.844)(0.719, 0.969)] [G loss: 1.337] [G acc: 0.156]\n",
      "4757 [D loss: (0.538)(R 0.437, F 0.640)] [D acc: (0.734)(0.766, 0.703)] [G loss: 1.367] [G acc: 0.109]\n",
      "4758 [D loss: (0.594)(R 0.644, F 0.543)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.363] [G acc: 0.172]\n",
      "4759 [D loss: (0.578)(R 0.616, F 0.539)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.393] [G acc: 0.141]\n",
      "4760 [D loss: (0.493)(R 0.526, F 0.461)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.337] [G acc: 0.188]\n",
      "4761 [D loss: (0.556)(R 0.541, F 0.571)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.334] [G acc: 0.125]\n",
      "4762 [D loss: (0.553)(R 0.527, F 0.580)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.440] [G acc: 0.078]\n",
      "4763 [D loss: (0.628)(R 0.549, F 0.707)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.438] [G acc: 0.078]\n",
      "4764 [D loss: (0.582)(R 0.695, F 0.469)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.190] [G acc: 0.125]\n",
      "4765 [D loss: (0.508)(R 0.536, F 0.479)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.416] [G acc: 0.109]\n",
      "4766 [D loss: (0.532)(R 0.523, F 0.542)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.420] [G acc: 0.062]\n",
      "4767 [D loss: (0.568)(R 0.590, F 0.546)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.329] [G acc: 0.109]\n",
      "4768 [D loss: (0.512)(R 0.561, F 0.463)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.433] [G acc: 0.141]\n",
      "4769 [D loss: (0.542)(R 0.584, F 0.499)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.637] [G acc: 0.094]\n",
      "4770 [D loss: (0.424)(R 0.458, F 0.390)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.501] [G acc: 0.109]\n",
      "4771 [D loss: (0.550)(R 0.517, F 0.584)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.281] [G acc: 0.156]\n",
      "4772 [D loss: (0.533)(R 0.449, F 0.617)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.504] [G acc: 0.109]\n",
      "4773 [D loss: (0.469)(R 0.521, F 0.417)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.515] [G acc: 0.109]\n",
      "4774 [D loss: (0.562)(R 0.558, F 0.566)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.372] [G acc: 0.141]\n",
      "4775 [D loss: (0.569)(R 0.614, F 0.524)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.440] [G acc: 0.078]\n",
      "4776 [D loss: (0.444)(R 0.458, F 0.430)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.474] [G acc: 0.125]\n",
      "4777 [D loss: (0.552)(R 0.577, F 0.526)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.448] [G acc: 0.094]\n",
      "4778 [D loss: (0.603)(R 0.692, F 0.513)] [D acc: (0.695)(0.531, 0.859)] [G loss: 1.364] [G acc: 0.172]\n",
      "4779 [D loss: (0.485)(R 0.555, F 0.414)] [D acc: (0.758)(0.594, 0.922)] [G loss: 1.359] [G acc: 0.109]\n",
      "4780 [D loss: (0.511)(R 0.495, F 0.527)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.356] [G acc: 0.094]\n",
      "4781 [D loss: (0.668)(R 0.612, F 0.723)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.374] [G acc: 0.141]\n",
      "4782 [D loss: (0.535)(R 0.619, F 0.451)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.407] [G acc: 0.109]\n",
      "4783 [D loss: (0.622)(R 0.592, F 0.653)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.202] [G acc: 0.125]\n",
      "4784 [D loss: (0.534)(R 0.553, F 0.514)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.428] [G acc: 0.078]\n",
      "4785 [D loss: (0.573)(R 0.698, F 0.447)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.348] [G acc: 0.109]\n",
      "4786 [D loss: (0.478)(R 0.513, F 0.444)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.268] [G acc: 0.109]\n",
      "4787 [D loss: (0.544)(R 0.548, F 0.540)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.354] [G acc: 0.109]\n",
      "4788 [D loss: (0.518)(R 0.444, F 0.592)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.243] [G acc: 0.188]\n",
      "4789 [D loss: (0.474)(R 0.453, F 0.495)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.302] [G acc: 0.094]\n",
      "4790 [D loss: (0.448)(R 0.458, F 0.439)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.395] [G acc: 0.078]\n",
      "4791 [D loss: (0.401)(R 0.375, F 0.427)] [D acc: (0.828)(0.766, 0.891)] [G loss: 1.456] [G acc: 0.109]\n",
      "4792 [D loss: (0.496)(R 0.425, F 0.568)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.511] [G acc: 0.031]\n",
      "4793 [D loss: (0.567)(R 0.563, F 0.571)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.417] [G acc: 0.141]\n",
      "4794 [D loss: (0.605)(R 0.599, F 0.611)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.577] [G acc: 0.078]\n",
      "4795 [D loss: (0.467)(R 0.532, F 0.402)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.443] [G acc: 0.062]\n",
      "4796 [D loss: (0.402)(R 0.417, F 0.388)] [D acc: (0.852)(0.781, 0.922)] [G loss: 1.418] [G acc: 0.125]\n",
      "4797 [D loss: (0.542)(R 0.581, F 0.503)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.633] [G acc: 0.141]\n",
      "4798 [D loss: (0.474)(R 0.500, F 0.447)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.568] [G acc: 0.047]\n",
      "4799 [D loss: (0.618)(R 0.549, F 0.686)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.658] [G acc: 0.062]\n",
      "4800 [D loss: (0.459)(R 0.516, F 0.401)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.519] [G acc: 0.062]\n",
      "4801 [D loss: (0.592)(R 0.618, F 0.567)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.504] [G acc: 0.062]\n",
      "4802 [D loss: (0.502)(R 0.506, F 0.499)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.575] [G acc: 0.094]\n",
      "4803 [D loss: (0.550)(R 0.625, F 0.474)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.450] [G acc: 0.109]\n",
      "4804 [D loss: (0.503)(R 0.553, F 0.454)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.338] [G acc: 0.109]\n",
      "4805 [D loss: (0.400)(R 0.355, F 0.445)] [D acc: (0.812)(0.797, 0.828)] [G loss: 1.526] [G acc: 0.062]\n",
      "4806 [D loss: (0.566)(R 0.484, F 0.649)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.757] [G acc: 0.031]\n",
      "4807 [D loss: (0.519)(R 0.642, F 0.396)] [D acc: (0.766)(0.609, 0.922)] [G loss: 1.617] [G acc: 0.016]\n",
      "4808 [D loss: (0.522)(R 0.518, F 0.526)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.628] [G acc: 0.031]\n",
      "4809 [D loss: (0.543)(R 0.564, F 0.521)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.500] [G acc: 0.094]\n",
      "4810 [D loss: (0.510)(R 0.559, F 0.460)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.484] [G acc: 0.078]\n",
      "4811 [D loss: (0.467)(R 0.493, F 0.442)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.414] [G acc: 0.094]\n",
      "4812 [D loss: (0.610)(R 0.648, F 0.571)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.407] [G acc: 0.156]\n",
      "4813 [D loss: (0.544)(R 0.567, F 0.522)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.367] [G acc: 0.109]\n",
      "4814 [D loss: (0.564)(R 0.597, F 0.531)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.453] [G acc: 0.109]\n",
      "4815 [D loss: (0.521)(R 0.477, F 0.566)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.435] [G acc: 0.109]\n",
      "4816 [D loss: (0.499)(R 0.433, F 0.565)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.569] [G acc: 0.141]\n",
      "4817 [D loss: (0.543)(R 0.577, F 0.510)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.455] [G acc: 0.141]\n",
      "4818 [D loss: (0.547)(R 0.618, F 0.476)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.484] [G acc: 0.062]\n",
      "4819 [D loss: (0.587)(R 0.698, F 0.476)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.337] [G acc: 0.109]\n",
      "4820 [D loss: (0.548)(R 0.434, F 0.662)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.605] [G acc: 0.125]\n",
      "4821 [D loss: (0.408)(R 0.504, F 0.311)] [D acc: (0.828)(0.688, 0.969)] [G loss: 1.730] [G acc: 0.016]\n",
      "4822 [D loss: (0.561)(R 0.535, F 0.587)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.413] [G acc: 0.047]\n",
      "4823 [D loss: (0.482)(R 0.536, F 0.428)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.557] [G acc: 0.062]\n",
      "4824 [D loss: (0.611)(R 0.645, F 0.578)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.428] [G acc: 0.031]\n",
      "4825 [D loss: (0.584)(R 0.669, F 0.500)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.388] [G acc: 0.078]\n",
      "4826 [D loss: (0.535)(R 0.577, F 0.493)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.378] [G acc: 0.094]\n",
      "4827 [D loss: (0.467)(R 0.495, F 0.440)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.483] [G acc: 0.094]\n",
      "4828 [D loss: (0.558)(R 0.580, F 0.535)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.482] [G acc: 0.062]\n",
      "4829 [D loss: (0.589)(R 0.615, F 0.563)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.384] [G acc: 0.109]\n",
      "4830 [D loss: (0.510)(R 0.523, F 0.497)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.445] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4831 [D loss: (0.542)(R 0.582, F 0.502)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.398] [G acc: 0.047]\n",
      "4832 [D loss: (0.581)(R 0.649, F 0.513)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.368] [G acc: 0.141]\n",
      "4833 [D loss: (0.449)(R 0.416, F 0.482)] [D acc: (0.828)(0.812, 0.844)] [G loss: 1.322] [G acc: 0.188]\n",
      "4834 [D loss: (0.480)(R 0.447, F 0.513)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.381] [G acc: 0.047]\n",
      "4835 [D loss: (0.524)(R 0.584, F 0.463)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.449] [G acc: 0.125]\n",
      "4836 [D loss: (0.534)(R 0.648, F 0.419)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.385] [G acc: 0.125]\n",
      "4837 [D loss: (0.501)(R 0.437, F 0.564)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.457] [G acc: 0.047]\n",
      "4838 [D loss: (0.554)(R 0.625, F 0.482)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.304] [G acc: 0.047]\n",
      "4839 [D loss: (0.530)(R 0.563, F 0.496)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.315] [G acc: 0.078]\n",
      "4840 [D loss: (0.561)(R 0.555, F 0.568)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.392] [G acc: 0.172]\n",
      "4841 [D loss: (0.535)(R 0.508, F 0.563)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.387] [G acc: 0.078]\n",
      "4842 [D loss: (0.536)(R 0.557, F 0.516)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.384] [G acc: 0.109]\n",
      "4843 [D loss: (0.591)(R 0.547, F 0.635)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.408] [G acc: 0.125]\n",
      "4844 [D loss: (0.533)(R 0.532, F 0.535)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.407] [G acc: 0.141]\n",
      "4845 [D loss: (0.488)(R 0.524, F 0.451)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.531] [G acc: 0.016]\n",
      "4846 [D loss: (0.579)(R 0.550, F 0.609)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.367] [G acc: 0.109]\n",
      "4847 [D loss: (0.491)(R 0.528, F 0.454)] [D acc: (0.797)(0.656, 0.938)] [G loss: 1.457] [G acc: 0.062]\n",
      "4848 [D loss: (0.575)(R 0.522, F 0.628)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.437] [G acc: 0.078]\n",
      "4849 [D loss: (0.633)(R 0.590, F 0.675)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.368] [G acc: 0.047]\n",
      "4850 [D loss: (0.585)(R 0.692, F 0.478)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.441] [G acc: 0.078]\n",
      "4851 [D loss: (0.634)(R 0.597, F 0.672)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.535] [G acc: 0.062]\n",
      "4852 [D loss: (0.489)(R 0.550, F 0.427)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.361] [G acc: 0.109]\n",
      "4853 [D loss: (0.500)(R 0.487, F 0.512)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.569] [G acc: 0.016]\n",
      "4854 [D loss: (0.577)(R 0.574, F 0.580)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.531] [G acc: 0.047]\n",
      "4855 [D loss: (0.522)(R 0.522, F 0.523)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.356] [G acc: 0.094]\n",
      "4856 [D loss: (0.597)(R 0.681, F 0.513)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.373] [G acc: 0.094]\n",
      "4857 [D loss: (0.537)(R 0.519, F 0.555)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.393] [G acc: 0.109]\n",
      "4858 [D loss: (0.504)(R 0.517, F 0.491)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.479] [G acc: 0.078]\n",
      "4859 [D loss: (0.522)(R 0.591, F 0.453)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.370] [G acc: 0.094]\n",
      "4860 [D loss: (0.646)(R 0.677, F 0.614)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.430] [G acc: 0.094]\n",
      "4861 [D loss: (0.544)(R 0.502, F 0.586)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.481] [G acc: 0.047]\n",
      "4862 [D loss: (0.593)(R 0.618, F 0.567)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.376] [G acc: 0.078]\n",
      "4863 [D loss: (0.538)(R 0.619, F 0.458)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.266] [G acc: 0.125]\n",
      "4864 [D loss: (0.551)(R 0.526, F 0.577)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.618] [G acc: 0.062]\n",
      "4865 [D loss: (0.584)(R 0.546, F 0.623)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.496] [G acc: 0.047]\n",
      "4866 [D loss: (0.487)(R 0.586, F 0.388)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.314] [G acc: 0.125]\n",
      "4867 [D loss: (0.586)(R 0.644, F 0.527)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.421] [G acc: 0.062]\n",
      "4868 [D loss: (0.458)(R 0.497, F 0.419)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.326] [G acc: 0.062]\n",
      "4869 [D loss: (0.485)(R 0.509, F 0.461)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.330] [G acc: 0.141]\n",
      "4870 [D loss: (0.687)(R 0.659, F 0.714)] [D acc: (0.586)(0.578, 0.594)] [G loss: 1.419] [G acc: 0.016]\n",
      "4871 [D loss: (0.587)(R 0.702, F 0.472)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.329] [G acc: 0.109]\n",
      "4872 [D loss: (0.507)(R 0.515, F 0.498)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.325] [G acc: 0.094]\n",
      "4873 [D loss: (0.539)(R 0.593, F 0.485)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.314] [G acc: 0.109]\n",
      "4874 [D loss: (0.537)(R 0.590, F 0.484)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.377] [G acc: 0.062]\n",
      "4875 [D loss: (0.542)(R 0.567, F 0.517)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.357] [G acc: 0.094]\n",
      "4876 [D loss: (0.555)(R 0.584, F 0.526)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.515] [G acc: 0.016]\n",
      "4877 [D loss: (0.590)(R 0.570, F 0.611)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.267] [G acc: 0.078]\n",
      "4878 [D loss: (0.581)(R 0.546, F 0.617)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.346] [G acc: 0.094]\n",
      "4879 [D loss: (0.512)(R 0.599, F 0.425)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.444] [G acc: 0.109]\n",
      "4880 [D loss: (0.516)(R 0.480, F 0.551)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.398] [G acc: 0.094]\n",
      "4881 [D loss: (0.565)(R 0.530, F 0.599)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.377] [G acc: 0.109]\n",
      "4882 [D loss: (0.542)(R 0.616, F 0.467)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.267] [G acc: 0.188]\n",
      "4883 [D loss: (0.458)(R 0.467, F 0.448)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.376] [G acc: 0.062]\n",
      "4884 [D loss: (0.503)(R 0.585, F 0.421)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.238] [G acc: 0.141]\n",
      "4885 [D loss: (0.709)(R 0.600, F 0.818)] [D acc: (0.617)(0.609, 0.625)] [G loss: 1.435] [G acc: 0.125]\n",
      "4886 [D loss: (0.543)(R 0.613, F 0.473)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.255] [G acc: 0.141]\n",
      "4887 [D loss: (0.652)(R 0.596, F 0.709)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.423] [G acc: 0.062]\n",
      "4888 [D loss: (0.537)(R 0.666, F 0.408)] [D acc: (0.719)(0.531, 0.906)] [G loss: 1.456] [G acc: 0.047]\n",
      "4889 [D loss: (0.467)(R 0.459, F 0.476)] [D acc: (0.820)(0.781, 0.859)] [G loss: 1.269] [G acc: 0.109]\n",
      "4890 [D loss: (0.506)(R 0.507, F 0.506)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.301] [G acc: 0.078]\n",
      "4891 [D loss: (0.588)(R 0.566, F 0.609)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.341] [G acc: 0.094]\n",
      "4892 [D loss: (0.629)(R 0.705, F 0.553)] [D acc: (0.648)(0.516, 0.781)] [G loss: 1.312] [G acc: 0.094]\n",
      "4893 [D loss: (0.548)(R 0.675, F 0.421)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.408] [G acc: 0.094]\n",
      "4894 [D loss: (0.512)(R 0.396, F 0.628)] [D acc: (0.727)(0.766, 0.688)] [G loss: 1.273] [G acc: 0.172]\n",
      "4895 [D loss: (0.579)(R 0.701, F 0.457)] [D acc: (0.711)(0.531, 0.891)] [G loss: 1.226] [G acc: 0.141]\n",
      "4896 [D loss: (0.475)(R 0.488, F 0.462)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.384] [G acc: 0.156]\n",
      "4897 [D loss: (0.513)(R 0.520, F 0.505)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.293] [G acc: 0.094]\n",
      "4898 [D loss: (0.497)(R 0.468, F 0.526)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.323] [G acc: 0.172]\n",
      "4899 [D loss: (0.507)(R 0.541, F 0.473)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.262] [G acc: 0.109]\n",
      "4900 [D loss: (0.686)(R 0.684, F 0.689)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.414] [G acc: 0.078]\n",
      "4901 [D loss: (0.519)(R 0.608, F 0.429)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.388] [G acc: 0.094]\n",
      "4902 [D loss: (0.587)(R 0.671, F 0.502)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.429] [G acc: 0.094]\n",
      "4903 [D loss: (0.532)(R 0.508, F 0.556)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.313] [G acc: 0.188]\n",
      "4904 [D loss: (0.571)(R 0.630, F 0.513)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.365] [G acc: 0.125]\n",
      "4905 [D loss: (0.526)(R 0.658, F 0.394)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.417] [G acc: 0.078]\n",
      "4906 [D loss: (0.511)(R 0.446, F 0.576)] [D acc: (0.781)(0.797, 0.766)] [G loss: 1.383] [G acc: 0.125]\n",
      "4907 [D loss: (0.534)(R 0.609, F 0.458)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.402] [G acc: 0.156]\n",
      "4908 [D loss: (0.577)(R 0.568, F 0.586)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.259] [G acc: 0.125]\n",
      "4909 [D loss: (0.632)(R 0.623, F 0.641)] [D acc: (0.648)(0.547, 0.750)] [G loss: 1.452] [G acc: 0.141]\n",
      "4910 [D loss: (0.592)(R 0.686, F 0.498)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.397] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4911 [D loss: (0.510)(R 0.432, F 0.589)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.486] [G acc: 0.094]\n",
      "4912 [D loss: (0.535)(R 0.516, F 0.555)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.501] [G acc: 0.062]\n",
      "4913 [D loss: (0.555)(R 0.564, F 0.545)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.388] [G acc: 0.031]\n",
      "4914 [D loss: (0.535)(R 0.494, F 0.577)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.306] [G acc: 0.141]\n",
      "4915 [D loss: (0.435)(R 0.453, F 0.418)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.435] [G acc: 0.125]\n",
      "4916 [D loss: (0.566)(R 0.537, F 0.594)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.368] [G acc: 0.062]\n",
      "4917 [D loss: (0.481)(R 0.504, F 0.457)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.432] [G acc: 0.141]\n",
      "4918 [D loss: (0.474)(R 0.489, F 0.458)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.546] [G acc: 0.125]\n",
      "4919 [D loss: (0.512)(R 0.495, F 0.530)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.566] [G acc: 0.078]\n",
      "4920 [D loss: (0.633)(R 0.689, F 0.578)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.626] [G acc: 0.031]\n",
      "4921 [D loss: (0.555)(R 0.589, F 0.520)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.287] [G acc: 0.125]\n",
      "4922 [D loss: (0.487)(R 0.446, F 0.527)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.500] [G acc: 0.016]\n",
      "4923 [D loss: (0.478)(R 0.479, F 0.477)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.448] [G acc: 0.094]\n",
      "4924 [D loss: (0.531)(R 0.561, F 0.501)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.374] [G acc: 0.094]\n",
      "4925 [D loss: (0.538)(R 0.630, F 0.446)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.556] [G acc: 0.109]\n",
      "4926 [D loss: (0.546)(R 0.491, F 0.600)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.468] [G acc: 0.156]\n",
      "4927 [D loss: (0.519)(R 0.526, F 0.511)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.402] [G acc: 0.062]\n",
      "4928 [D loss: (0.571)(R 0.540, F 0.603)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.554] [G acc: 0.047]\n",
      "4929 [D loss: (0.447)(R 0.505, F 0.388)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.390] [G acc: 0.109]\n",
      "4930 [D loss: (0.416)(R 0.403, F 0.428)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.447] [G acc: 0.125]\n",
      "4931 [D loss: (0.503)(R 0.555, F 0.450)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.500] [G acc: 0.047]\n",
      "4932 [D loss: (0.518)(R 0.497, F 0.539)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.474] [G acc: 0.047]\n",
      "4933 [D loss: (0.525)(R 0.456, F 0.595)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.487] [G acc: 0.016]\n",
      "4934 [D loss: (0.525)(R 0.548, F 0.503)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.584] [G acc: 0.094]\n",
      "4935 [D loss: (0.497)(R 0.592, F 0.401)] [D acc: (0.703)(0.547, 0.859)] [G loss: 1.352] [G acc: 0.188]\n",
      "4936 [D loss: (0.495)(R 0.482, F 0.508)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.594] [G acc: 0.047]\n",
      "4937 [D loss: (0.639)(R 0.609, F 0.669)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.535] [G acc: 0.062]\n",
      "4938 [D loss: (0.518)(R 0.487, F 0.549)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.469] [G acc: 0.047]\n",
      "4939 [D loss: (0.639)(R 0.785, F 0.494)] [D acc: (0.633)(0.453, 0.812)] [G loss: 1.478] [G acc: 0.078]\n",
      "4940 [D loss: (0.583)(R 0.628, F 0.538)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.393] [G acc: 0.062]\n",
      "4941 [D loss: (0.478)(R 0.505, F 0.451)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.451] [G acc: 0.062]\n",
      "4942 [D loss: (0.506)(R 0.550, F 0.462)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.446] [G acc: 0.109]\n",
      "4943 [D loss: (0.479)(R 0.441, F 0.516)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.395] [G acc: 0.094]\n",
      "4944 [D loss: (0.529)(R 0.615, F 0.444)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.366] [G acc: 0.125]\n",
      "4945 [D loss: (0.584)(R 0.644, F 0.524)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.383] [G acc: 0.078]\n",
      "4946 [D loss: (0.540)(R 0.647, F 0.434)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.399] [G acc: 0.109]\n",
      "4947 [D loss: (0.496)(R 0.381, F 0.612)] [D acc: (0.711)(0.750, 0.672)] [G loss: 1.404] [G acc: 0.078]\n",
      "4948 [D loss: (0.517)(R 0.614, F 0.420)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.294] [G acc: 0.109]\n",
      "4949 [D loss: (0.487)(R 0.450, F 0.524)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.262] [G acc: 0.109]\n",
      "4950 [D loss: (0.488)(R 0.550, F 0.426)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.362] [G acc: 0.078]\n",
      "4951 [D loss: (0.473)(R 0.491, F 0.456)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.310] [G acc: 0.078]\n",
      "4952 [D loss: (0.476)(R 0.416, F 0.536)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.457] [G acc: 0.094]\n",
      "4953 [D loss: (0.485)(R 0.451, F 0.520)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.254] [G acc: 0.141]\n",
      "4954 [D loss: (0.400)(R 0.364, F 0.437)] [D acc: (0.828)(0.812, 0.844)] [G loss: 1.514] [G acc: 0.031]\n",
      "4955 [D loss: (0.478)(R 0.471, F 0.485)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.524] [G acc: 0.062]\n",
      "4956 [D loss: (0.558)(R 0.489, F 0.627)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.595] [G acc: 0.125]\n",
      "4957 [D loss: (0.505)(R 0.581, F 0.429)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.666] [G acc: 0.047]\n",
      "4958 [D loss: (0.544)(R 0.532, F 0.557)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.661] [G acc: 0.062]\n",
      "4959 [D loss: (0.507)(R 0.603, F 0.411)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.619] [G acc: 0.094]\n",
      "4960 [D loss: (0.602)(R 0.646, F 0.558)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.442] [G acc: 0.016]\n",
      "4961 [D loss: (0.542)(R 0.604, F 0.480)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.383] [G acc: 0.094]\n",
      "4962 [D loss: (0.514)(R 0.502, F 0.527)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.457] [G acc: 0.078]\n",
      "4963 [D loss: (0.523)(R 0.503, F 0.544)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.610] [G acc: 0.078]\n",
      "4964 [D loss: (0.518)(R 0.571, F 0.466)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.457] [G acc: 0.141]\n",
      "4965 [D loss: (0.669)(R 0.522, F 0.815)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.475] [G acc: 0.016]\n",
      "4966 [D loss: (0.623)(R 0.809, F 0.437)] [D acc: (0.656)(0.422, 0.891)] [G loss: 1.461] [G acc: 0.078]\n",
      "4967 [D loss: (0.556)(R 0.596, F 0.517)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.204] [G acc: 0.234]\n",
      "4968 [D loss: (0.477)(R 0.418, F 0.535)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.453] [G acc: 0.141]\n",
      "4969 [D loss: (0.539)(R 0.614, F 0.465)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.293] [G acc: 0.219]\n",
      "4970 [D loss: (0.444)(R 0.413, F 0.476)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.476] [G acc: 0.156]\n",
      "4971 [D loss: (0.592)(R 0.622, F 0.562)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.349] [G acc: 0.109]\n",
      "4972 [D loss: (0.670)(R 0.731, F 0.608)] [D acc: (0.672)(0.516, 0.828)] [G loss: 1.423] [G acc: 0.062]\n",
      "4973 [D loss: (0.506)(R 0.501, F 0.510)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.301] [G acc: 0.203]\n",
      "4974 [D loss: (0.526)(R 0.554, F 0.499)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.318] [G acc: 0.141]\n",
      "4975 [D loss: (0.496)(R 0.516, F 0.476)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.527] [G acc: 0.109]\n",
      "4976 [D loss: (0.546)(R 0.733, F 0.359)] [D acc: (0.719)(0.516, 0.922)] [G loss: 1.591] [G acc: 0.016]\n",
      "4977 [D loss: (0.520)(R 0.505, F 0.534)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.295] [G acc: 0.188]\n",
      "4978 [D loss: (0.447)(R 0.444, F 0.450)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.445] [G acc: 0.078]\n",
      "4979 [D loss: (0.509)(R 0.472, F 0.545)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.496] [G acc: 0.062]\n",
      "4980 [D loss: (0.564)(R 0.619, F 0.508)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.374] [G acc: 0.094]\n",
      "4981 [D loss: (0.582)(R 0.670, F 0.493)] [D acc: (0.656)(0.531, 0.781)] [G loss: 1.396] [G acc: 0.094]\n",
      "4982 [D loss: (0.536)(R 0.594, F 0.477)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.210] [G acc: 0.109]\n",
      "4983 [D loss: (0.510)(R 0.465, F 0.555)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.342] [G acc: 0.172]\n",
      "4984 [D loss: (0.607)(R 0.628, F 0.585)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.339] [G acc: 0.125]\n",
      "4985 [D loss: (0.502)(R 0.470, F 0.533)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.482] [G acc: 0.094]\n",
      "4986 [D loss: (0.456)(R 0.503, F 0.409)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.280] [G acc: 0.172]\n",
      "4987 [D loss: (0.570)(R 0.517, F 0.622)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.558] [G acc: 0.109]\n",
      "4988 [D loss: (0.546)(R 0.558, F 0.534)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.382] [G acc: 0.078]\n",
      "4989 [D loss: (0.512)(R 0.453, F 0.570)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.385] [G acc: 0.125]\n",
      "4990 [D loss: (0.432)(R 0.389, F 0.474)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.416] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4991 [D loss: (0.539)(R 0.615, F 0.463)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.493] [G acc: 0.156]\n",
      "4992 [D loss: (0.552)(R 0.484, F 0.619)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.604] [G acc: 0.016]\n",
      "4993 [D loss: (0.638)(R 0.766, F 0.510)] [D acc: (0.656)(0.516, 0.797)] [G loss: 1.406] [G acc: 0.141]\n",
      "4994 [D loss: (0.505)(R 0.509, F 0.501)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.607] [G acc: 0.078]\n",
      "4995 [D loss: (0.545)(R 0.607, F 0.483)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.372] [G acc: 0.125]\n",
      "4996 [D loss: (0.612)(R 0.605, F 0.618)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.329] [G acc: 0.094]\n",
      "4997 [D loss: (0.545)(R 0.588, F 0.502)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.430] [G acc: 0.141]\n",
      "4998 [D loss: (0.509)(R 0.545, F 0.472)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.403] [G acc: 0.062]\n",
      "4999 [D loss: (0.556)(R 0.480, F 0.633)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.423] [G acc: 0.062]\n",
      "5000 [D loss: (0.606)(R 0.633, F 0.579)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.435] [G acc: 0.062]\n",
      "5001 [D loss: (0.521)(R 0.564, F 0.478)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.399] [G acc: 0.062]\n",
      "5002 [D loss: (0.501)(R 0.469, F 0.532)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.397] [G acc: 0.078]\n",
      "5003 [D loss: (0.569)(R 0.607, F 0.531)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.449] [G acc: 0.031]\n",
      "5004 [D loss: (0.514)(R 0.487, F 0.541)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.477] [G acc: 0.156]\n",
      "5005 [D loss: (0.560)(R 0.630, F 0.491)] [D acc: (0.656)(0.531, 0.781)] [G loss: 1.376] [G acc: 0.094]\n",
      "5006 [D loss: (0.545)(R 0.492, F 0.598)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.430] [G acc: 0.078]\n",
      "5007 [D loss: (0.624)(R 0.585, F 0.663)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.427] [G acc: 0.094]\n",
      "5008 [D loss: (0.563)(R 0.657, F 0.469)] [D acc: (0.656)(0.516, 0.797)] [G loss: 1.351] [G acc: 0.078]\n",
      "5009 [D loss: (0.455)(R 0.527, F 0.382)] [D acc: (0.789)(0.656, 0.922)] [G loss: 1.468] [G acc: 0.062]\n",
      "5010 [D loss: (0.525)(R 0.577, F 0.473)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.635] [G acc: 0.094]\n",
      "5011 [D loss: (0.419)(R 0.422, F 0.417)] [D acc: (0.836)(0.797, 0.875)] [G loss: 1.573] [G acc: 0.094]\n",
      "5012 [D loss: (0.499)(R 0.451, F 0.548)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.491] [G acc: 0.062]\n",
      "5013 [D loss: (0.565)(R 0.563, F 0.566)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.359] [G acc: 0.109]\n",
      "5014 [D loss: (0.480)(R 0.522, F 0.438)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.428] [G acc: 0.047]\n",
      "5015 [D loss: (0.452)(R 0.463, F 0.441)] [D acc: (0.820)(0.781, 0.859)] [G loss: 1.635] [G acc: 0.031]\n",
      "5016 [D loss: (0.592)(R 0.610, F 0.573)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.444] [G acc: 0.094]\n",
      "5017 [D loss: (0.657)(R 0.546, F 0.768)] [D acc: (0.625)(0.625, 0.625)] [G loss: 1.559] [G acc: 0.047]\n",
      "5018 [D loss: (0.626)(R 0.802, F 0.449)] [D acc: (0.641)(0.391, 0.891)] [G loss: 1.429] [G acc: 0.031]\n",
      "5019 [D loss: (0.644)(R 0.609, F 0.679)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.356] [G acc: 0.094]\n",
      "5020 [D loss: (0.609)(R 0.661, F 0.557)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.347] [G acc: 0.125]\n",
      "5021 [D loss: (0.654)(R 0.754, F 0.554)] [D acc: (0.656)(0.516, 0.797)] [G loss: 1.235] [G acc: 0.156]\n",
      "5022 [D loss: (0.535)(R 0.646, F 0.424)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.259] [G acc: 0.125]\n",
      "5023 [D loss: (0.550)(R 0.517, F 0.583)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.285] [G acc: 0.109]\n",
      "5024 [D loss: (0.550)(R 0.557, F 0.542)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.398] [G acc: 0.078]\n",
      "5025 [D loss: (0.581)(R 0.611, F 0.551)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.414] [G acc: 0.109]\n",
      "5026 [D loss: (0.519)(R 0.593, F 0.444)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.330] [G acc: 0.109]\n",
      "5027 [D loss: (0.501)(R 0.531, F 0.470)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.171] [G acc: 0.203]\n",
      "5028 [D loss: (0.624)(R 0.585, F 0.662)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.372] [G acc: 0.062]\n",
      "5029 [D loss: (0.598)(R 0.579, F 0.617)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.334] [G acc: 0.109]\n",
      "5030 [D loss: (0.463)(R 0.490, F 0.437)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.421] [G acc: 0.078]\n",
      "5031 [D loss: (0.544)(R 0.609, F 0.479)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.368] [G acc: 0.125]\n",
      "5032 [D loss: (0.490)(R 0.502, F 0.477)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.363] [G acc: 0.141]\n",
      "5033 [D loss: (0.493)(R 0.476, F 0.510)] [D acc: (0.820)(0.766, 0.875)] [G loss: 1.361] [G acc: 0.188]\n",
      "5034 [D loss: (0.525)(R 0.501, F 0.550)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.271] [G acc: 0.219]\n",
      "5035 [D loss: (0.583)(R 0.589, F 0.577)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.445] [G acc: 0.062]\n",
      "5036 [D loss: (0.577)(R 0.635, F 0.520)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.255] [G acc: 0.188]\n",
      "5037 [D loss: (0.576)(R 0.593, F 0.560)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.341] [G acc: 0.141]\n",
      "5038 [D loss: (0.511)(R 0.442, F 0.579)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.656] [G acc: 0.031]\n",
      "5039 [D loss: (0.524)(R 0.629, F 0.418)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.422] [G acc: 0.016]\n",
      "5040 [D loss: (0.591)(R 0.638, F 0.545)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.289] [G acc: 0.125]\n",
      "5041 [D loss: (0.553)(R 0.615, F 0.492)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.440] [G acc: 0.094]\n",
      "5042 [D loss: (0.549)(R 0.549, F 0.548)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.335] [G acc: 0.094]\n",
      "5043 [D loss: (0.500)(R 0.521, F 0.479)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.417] [G acc: 0.094]\n",
      "5044 [D loss: (0.527)(R 0.534, F 0.520)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.364] [G acc: 0.078]\n",
      "5045 [D loss: (0.543)(R 0.564, F 0.522)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.367] [G acc: 0.109]\n",
      "5046 [D loss: (0.553)(R 0.512, F 0.595)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.322] [G acc: 0.125]\n",
      "5047 [D loss: (0.545)(R 0.609, F 0.481)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.431] [G acc: 0.078]\n",
      "5048 [D loss: (0.548)(R 0.492, F 0.604)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.478] [G acc: 0.094]\n",
      "5049 [D loss: (0.514)(R 0.590, F 0.437)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.502] [G acc: 0.078]\n",
      "5050 [D loss: (0.587)(R 0.701, F 0.474)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.279] [G acc: 0.109]\n",
      "5051 [D loss: (0.535)(R 0.508, F 0.563)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.425] [G acc: 0.062]\n",
      "5052 [D loss: (0.518)(R 0.538, F 0.499)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.340] [G acc: 0.094]\n",
      "5053 [D loss: (0.593)(R 0.698, F 0.487)] [D acc: (0.680)(0.516, 0.844)] [G loss: 1.432] [G acc: 0.094]\n",
      "5054 [D loss: (0.432)(R 0.395, F 0.469)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.412] [G acc: 0.141]\n",
      "5055 [D loss: (0.587)(R 0.590, F 0.583)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.300] [G acc: 0.094]\n",
      "5056 [D loss: (0.489)(R 0.508, F 0.469)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.389] [G acc: 0.125]\n",
      "5057 [D loss: (0.427)(R 0.399, F 0.456)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.333] [G acc: 0.156]\n",
      "5058 [D loss: (0.560)(R 0.463, F 0.657)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.406] [G acc: 0.047]\n",
      "5059 [D loss: (0.531)(R 0.552, F 0.511)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.522] [G acc: 0.125]\n",
      "5060 [D loss: (0.532)(R 0.503, F 0.560)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.455] [G acc: 0.078]\n",
      "5061 [D loss: (0.634)(R 0.615, F 0.653)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.458] [G acc: 0.078]\n",
      "5062 [D loss: (0.631)(R 0.851, F 0.410)] [D acc: (0.656)(0.453, 0.859)] [G loss: 1.375] [G acc: 0.094]\n",
      "5063 [D loss: (0.536)(R 0.497, F 0.574)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.223] [G acc: 0.188]\n",
      "5064 [D loss: (0.566)(R 0.606, F 0.526)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.183] [G acc: 0.125]\n",
      "5065 [D loss: (0.543)(R 0.530, F 0.557)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.316] [G acc: 0.156]\n",
      "5066 [D loss: (0.511)(R 0.544, F 0.478)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.406] [G acc: 0.094]\n",
      "5067 [D loss: (0.468)(R 0.498, F 0.437)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.389] [G acc: 0.094]\n",
      "5068 [D loss: (0.508)(R 0.593, F 0.424)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.237] [G acc: 0.172]\n",
      "5069 [D loss: (0.546)(R 0.571, F 0.521)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.262] [G acc: 0.109]\n",
      "5070 [D loss: (0.519)(R 0.509, F 0.530)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.309] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5071 [D loss: (0.632)(R 0.524, F 0.739)] [D acc: (0.633)(0.641, 0.625)] [G loss: 1.307] [G acc: 0.125]\n",
      "5072 [D loss: (0.591)(R 0.670, F 0.512)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.468] [G acc: 0.125]\n",
      "5073 [D loss: (0.465)(R 0.431, F 0.499)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.478] [G acc: 0.062]\n",
      "5074 [D loss: (0.496)(R 0.532, F 0.461)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.449] [G acc: 0.062]\n",
      "5075 [D loss: (0.549)(R 0.632, F 0.467)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.263] [G acc: 0.172]\n",
      "5076 [D loss: (0.501)(R 0.534, F 0.469)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.329] [G acc: 0.094]\n",
      "5077 [D loss: (0.484)(R 0.492, F 0.477)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.427] [G acc: 0.109]\n",
      "5078 [D loss: (0.518)(R 0.545, F 0.492)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.480] [G acc: 0.062]\n",
      "5079 [D loss: (0.619)(R 0.617, F 0.622)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.380] [G acc: 0.141]\n",
      "5080 [D loss: (0.545)(R 0.583, F 0.507)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.388] [G acc: 0.094]\n",
      "5081 [D loss: (0.588)(R 0.583, F 0.593)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.409] [G acc: 0.141]\n",
      "5082 [D loss: (0.536)(R 0.602, F 0.469)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.275] [G acc: 0.203]\n",
      "5083 [D loss: (0.612)(R 0.598, F 0.627)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.423] [G acc: 0.141]\n",
      "5084 [D loss: (0.549)(R 0.627, F 0.470)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.364] [G acc: 0.156]\n",
      "5085 [D loss: (0.566)(R 0.575, F 0.557)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.449] [G acc: 0.141]\n",
      "5086 [D loss: (0.489)(R 0.477, F 0.501)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.339] [G acc: 0.125]\n",
      "5087 [D loss: (0.459)(R 0.444, F 0.474)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.315] [G acc: 0.172]\n",
      "5088 [D loss: (0.597)(R 0.686, F 0.507)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.577] [G acc: 0.109]\n",
      "5089 [D loss: (0.539)(R 0.531, F 0.547)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.344] [G acc: 0.156]\n",
      "5090 [D loss: (0.545)(R 0.478, F 0.612)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.507] [G acc: 0.062]\n",
      "5091 [D loss: (0.604)(R 0.685, F 0.523)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.257] [G acc: 0.141]\n",
      "5092 [D loss: (0.569)(R 0.574, F 0.564)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.373] [G acc: 0.109]\n",
      "5093 [D loss: (0.630)(R 0.551, F 0.709)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.439] [G acc: 0.062]\n",
      "5094 [D loss: (0.645)(R 0.664, F 0.626)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.404] [G acc: 0.094]\n",
      "5095 [D loss: (0.559)(R 0.596, F 0.521)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.394] [G acc: 0.125]\n",
      "5096 [D loss: (0.538)(R 0.570, F 0.507)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.312] [G acc: 0.172]\n",
      "5097 [D loss: (0.614)(R 0.574, F 0.653)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.394] [G acc: 0.125]\n",
      "5098 [D loss: (0.509)(R 0.505, F 0.513)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.399] [G acc: 0.078]\n",
      "5099 [D loss: (0.622)(R 0.658, F 0.585)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.306] [G acc: 0.156]\n",
      "5100 [D loss: (0.600)(R 0.678, F 0.521)] [D acc: (0.672)(0.531, 0.812)] [G loss: 1.398] [G acc: 0.094]\n",
      "5101 [D loss: (0.463)(R 0.480, F 0.446)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.426] [G acc: 0.109]\n",
      "5102 [D loss: (0.513)(R 0.577, F 0.448)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.516] [G acc: 0.047]\n",
      "5103 [D loss: (0.531)(R 0.605, F 0.458)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.359] [G acc: 0.094]\n",
      "5104 [D loss: (0.495)(R 0.440, F 0.550)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.342] [G acc: 0.094]\n",
      "5105 [D loss: (0.570)(R 0.603, F 0.537)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.595] [G acc: 0.094]\n",
      "5106 [D loss: (0.490)(R 0.550, F 0.431)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.283] [G acc: 0.125]\n",
      "5107 [D loss: (0.610)(R 0.477, F 0.742)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.546] [G acc: 0.062]\n",
      "5108 [D loss: (0.551)(R 0.675, F 0.427)] [D acc: (0.742)(0.594, 0.891)] [G loss: 1.483] [G acc: 0.016]\n",
      "5109 [D loss: (0.563)(R 0.629, F 0.496)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.506] [G acc: 0.031]\n",
      "5110 [D loss: (0.584)(R 0.696, F 0.472)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.284] [G acc: 0.156]\n",
      "5111 [D loss: (0.612)(R 0.641, F 0.583)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.362] [G acc: 0.109]\n",
      "5112 [D loss: (0.585)(R 0.512, F 0.659)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.332] [G acc: 0.125]\n",
      "5113 [D loss: (0.536)(R 0.618, F 0.455)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.277] [G acc: 0.078]\n",
      "5114 [D loss: (0.539)(R 0.561, F 0.517)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.592] [G acc: 0.078]\n",
      "5115 [D loss: (0.497)(R 0.517, F 0.476)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.408] [G acc: 0.156]\n",
      "5116 [D loss: (0.540)(R 0.498, F 0.582)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.500] [G acc: 0.109]\n",
      "5117 [D loss: (0.580)(R 0.594, F 0.566)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.390] [G acc: 0.109]\n",
      "5118 [D loss: (0.536)(R 0.567, F 0.505)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.361] [G acc: 0.156]\n",
      "5119 [D loss: (0.540)(R 0.552, F 0.529)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.327] [G acc: 0.156]\n",
      "5120 [D loss: (0.501)(R 0.507, F 0.495)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.419] [G acc: 0.062]\n",
      "5121 [D loss: (0.555)(R 0.599, F 0.512)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.352] [G acc: 0.125]\n",
      "5122 [D loss: (0.539)(R 0.452, F 0.626)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.375] [G acc: 0.094]\n",
      "5123 [D loss: (0.677)(R 0.671, F 0.683)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.251] [G acc: 0.141]\n",
      "5124 [D loss: (0.553)(R 0.569, F 0.537)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.350] [G acc: 0.172]\n",
      "5125 [D loss: (0.506)(R 0.476, F 0.535)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.387] [G acc: 0.188]\n",
      "5126 [D loss: (0.567)(R 0.636, F 0.497)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.425] [G acc: 0.047]\n",
      "5127 [D loss: (0.649)(R 0.642, F 0.656)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.344] [G acc: 0.062]\n",
      "5128 [D loss: (0.491)(R 0.542, F 0.439)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.295] [G acc: 0.141]\n",
      "5129 [D loss: (0.498)(R 0.547, F 0.448)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.507] [G acc: 0.078]\n",
      "5130 [D loss: (0.556)(R 0.585, F 0.528)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.394] [G acc: 0.094]\n",
      "5131 [D loss: (0.483)(R 0.462, F 0.504)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.433] [G acc: 0.094]\n",
      "5132 [D loss: (0.492)(R 0.536, F 0.448)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.602] [G acc: 0.062]\n",
      "5133 [D loss: (0.594)(R 0.465, F 0.723)] [D acc: (0.664)(0.672, 0.656)] [G loss: 1.410] [G acc: 0.062]\n",
      "5134 [D loss: (0.610)(R 0.635, F 0.584)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.508] [G acc: 0.078]\n",
      "5135 [D loss: (0.512)(R 0.561, F 0.463)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.417] [G acc: 0.078]\n",
      "5136 [D loss: (0.622)(R 0.636, F 0.608)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.293] [G acc: 0.109]\n",
      "5137 [D loss: (0.556)(R 0.622, F 0.491)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.463] [G acc: 0.047]\n",
      "5138 [D loss: (0.587)(R 0.624, F 0.549)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.331] [G acc: 0.109]\n",
      "5139 [D loss: (0.578)(R 0.554, F 0.602)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.354] [G acc: 0.031]\n",
      "5140 [D loss: (0.532)(R 0.611, F 0.452)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.372] [G acc: 0.156]\n",
      "5141 [D loss: (0.558)(R 0.462, F 0.655)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.417] [G acc: 0.094]\n",
      "5142 [D loss: (0.494)(R 0.511, F 0.477)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.454] [G acc: 0.094]\n",
      "5143 [D loss: (0.451)(R 0.444, F 0.459)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.453] [G acc: 0.109]\n",
      "5144 [D loss: (0.457)(R 0.445, F 0.469)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.517] [G acc: 0.078]\n",
      "5145 [D loss: (0.498)(R 0.511, F 0.484)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.509] [G acc: 0.078]\n",
      "5146 [D loss: (0.509)(R 0.511, F 0.508)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.430] [G acc: 0.141]\n",
      "5147 [D loss: (0.485)(R 0.500, F 0.470)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.564] [G acc: 0.094]\n",
      "5148 [D loss: (0.561)(R 0.609, F 0.513)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.615] [G acc: 0.047]\n",
      "5149 [D loss: (0.477)(R 0.454, F 0.501)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.480] [G acc: 0.094]\n",
      "5150 [D loss: (0.726)(R 0.580, F 0.873)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.467] [G acc: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151 [D loss: (0.609)(R 0.710, F 0.507)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.395] [G acc: 0.078]\n",
      "5152 [D loss: (0.627)(R 0.662, F 0.591)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.450] [G acc: 0.062]\n",
      "5153 [D loss: (0.459)(R 0.490, F 0.428)] [D acc: (0.820)(0.750, 0.891)] [G loss: 1.287] [G acc: 0.156]\n",
      "5154 [D loss: (0.651)(R 0.561, F 0.740)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.391] [G acc: 0.125]\n",
      "5155 [D loss: (0.543)(R 0.590, F 0.495)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.532] [G acc: 0.062]\n",
      "5156 [D loss: (0.554)(R 0.523, F 0.585)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.652] [G acc: 0.062]\n",
      "5157 [D loss: (0.573)(R 0.748, F 0.398)] [D acc: (0.695)(0.547, 0.844)] [G loss: 1.550] [G acc: 0.016]\n",
      "5158 [D loss: (0.499)(R 0.439, F 0.558)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.385] [G acc: 0.141]\n",
      "5159 [D loss: (0.530)(R 0.555, F 0.505)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.432] [G acc: 0.109]\n",
      "5160 [D loss: (0.587)(R 0.675, F 0.499)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.293] [G acc: 0.125]\n",
      "5161 [D loss: (0.557)(R 0.548, F 0.566)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.221] [G acc: 0.141]\n",
      "5162 [D loss: (0.503)(R 0.551, F 0.454)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.459] [G acc: 0.094]\n",
      "5163 [D loss: (0.430)(R 0.360, F 0.499)] [D acc: (0.812)(0.828, 0.797)] [G loss: 1.323] [G acc: 0.109]\n",
      "5164 [D loss: (0.591)(R 0.537, F 0.645)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.241] [G acc: 0.156]\n",
      "5165 [D loss: (0.429)(R 0.434, F 0.424)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.274] [G acc: 0.188]\n",
      "5166 [D loss: (0.575)(R 0.457, F 0.693)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.357] [G acc: 0.078]\n",
      "5167 [D loss: (0.544)(R 0.614, F 0.475)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.346] [G acc: 0.094]\n",
      "5168 [D loss: (0.497)(R 0.521, F 0.474)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.626] [G acc: 0.062]\n",
      "5169 [D loss: (0.461)(R 0.471, F 0.451)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.453] [G acc: 0.141]\n",
      "5170 [D loss: (0.416)(R 0.424, F 0.408)] [D acc: (0.820)(0.781, 0.859)] [G loss: 1.488] [G acc: 0.109]\n",
      "5171 [D loss: (0.666)(R 0.646, F 0.685)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.600] [G acc: 0.062]\n",
      "5172 [D loss: (0.529)(R 0.563, F 0.494)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.475] [G acc: 0.125]\n",
      "5173 [D loss: (0.601)(R 0.761, F 0.442)] [D acc: (0.711)(0.516, 0.906)] [G loss: 1.413] [G acc: 0.125]\n",
      "5174 [D loss: (0.496)(R 0.518, F 0.474)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.558] [G acc: 0.094]\n",
      "5175 [D loss: (0.565)(R 0.633, F 0.497)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.462] [G acc: 0.016]\n",
      "5176 [D loss: (0.509)(R 0.530, F 0.487)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.398] [G acc: 0.125]\n",
      "5177 [D loss: (0.600)(R 0.613, F 0.586)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.234] [G acc: 0.109]\n",
      "5178 [D loss: (0.595)(R 0.617, F 0.572)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.519] [G acc: 0.078]\n",
      "5179 [D loss: (0.529)(R 0.587, F 0.471)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.334] [G acc: 0.047]\n",
      "5180 [D loss: (0.547)(R 0.430, F 0.663)] [D acc: (0.789)(0.797, 0.781)] [G loss: 1.265] [G acc: 0.141]\n",
      "5181 [D loss: (0.510)(R 0.574, F 0.447)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.326] [G acc: 0.125]\n",
      "5182 [D loss: (0.565)(R 0.525, F 0.604)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.426] [G acc: 0.047]\n",
      "5183 [D loss: (0.599)(R 0.697, F 0.502)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.180] [G acc: 0.188]\n",
      "5184 [D loss: (0.629)(R 0.527, F 0.731)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.248] [G acc: 0.172]\n",
      "5185 [D loss: (0.550)(R 0.569, F 0.530)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.278] [G acc: 0.203]\n",
      "5186 [D loss: (0.523)(R 0.600, F 0.447)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.341] [G acc: 0.016]\n",
      "5187 [D loss: (0.577)(R 0.499, F 0.655)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.903] [G acc: 0.062]\n",
      "5188 [D loss: (0.619)(R 0.838, F 0.401)] [D acc: (0.688)(0.469, 0.906)] [G loss: 1.503] [G acc: 0.031]\n",
      "5189 [D loss: (0.504)(R 0.561, F 0.448)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.328] [G acc: 0.125]\n",
      "5190 [D loss: (0.612)(R 0.568, F 0.655)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.537] [G acc: 0.062]\n",
      "5191 [D loss: (0.604)(R 0.578, F 0.630)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.447] [G acc: 0.047]\n",
      "5192 [D loss: (0.551)(R 0.627, F 0.475)] [D acc: (0.750)(0.594, 0.906)] [G loss: 1.303] [G acc: 0.078]\n",
      "5193 [D loss: (0.582)(R 0.632, F 0.531)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.372] [G acc: 0.141]\n",
      "5194 [D loss: (0.451)(R 0.432, F 0.471)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.618] [G acc: 0.016]\n",
      "5195 [D loss: (0.497)(R 0.551, F 0.443)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.300] [G acc: 0.109]\n",
      "5196 [D loss: (0.580)(R 0.515, F 0.646)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.367] [G acc: 0.156]\n",
      "5197 [D loss: (0.566)(R 0.563, F 0.570)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.513] [G acc: 0.094]\n",
      "5198 [D loss: (0.508)(R 0.630, F 0.386)] [D acc: (0.789)(0.672, 0.906)] [G loss: 1.518] [G acc: 0.047]\n",
      "5199 [D loss: (0.505)(R 0.496, F 0.515)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.349] [G acc: 0.125]\n",
      "5200 [D loss: (0.519)(R 0.523, F 0.514)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.377] [G acc: 0.109]\n",
      "5201 [D loss: (0.508)(R 0.499, F 0.517)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.473] [G acc: 0.125]\n",
      "5202 [D loss: (0.492)(R 0.438, F 0.546)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.384] [G acc: 0.094]\n",
      "5203 [D loss: (0.556)(R 0.565, F 0.547)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.310] [G acc: 0.141]\n",
      "5204 [D loss: (0.571)(R 0.572, F 0.569)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.311] [G acc: 0.109]\n",
      "5205 [D loss: (0.542)(R 0.504, F 0.579)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.290] [G acc: 0.109]\n",
      "5206 [D loss: (0.523)(R 0.637, F 0.409)] [D acc: (0.758)(0.609, 0.906)] [G loss: 1.402] [G acc: 0.094]\n",
      "5207 [D loss: (0.543)(R 0.431, F 0.654)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.375] [G acc: 0.078]\n",
      "5208 [D loss: (0.466)(R 0.441, F 0.490)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.543] [G acc: 0.094]\n",
      "5209 [D loss: (0.616)(R 0.678, F 0.553)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.396] [G acc: 0.125]\n",
      "5210 [D loss: (0.612)(R 0.562, F 0.661)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.402] [G acc: 0.078]\n",
      "5211 [D loss: (0.607)(R 0.683, F 0.531)] [D acc: (0.617)(0.516, 0.719)] [G loss: 1.335] [G acc: 0.078]\n",
      "5212 [D loss: (0.502)(R 0.539, F 0.465)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.405] [G acc: 0.062]\n",
      "5213 [D loss: (0.519)(R 0.453, F 0.586)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.515] [G acc: 0.016]\n",
      "5214 [D loss: (0.518)(R 0.581, F 0.454)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.391] [G acc: 0.062]\n",
      "5215 [D loss: (0.487)(R 0.490, F 0.484)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.399] [G acc: 0.047]\n",
      "5216 [D loss: (0.677)(R 0.817, F 0.537)] [D acc: (0.633)(0.469, 0.797)] [G loss: 1.526] [G acc: 0.062]\n",
      "5217 [D loss: (0.629)(R 0.765, F 0.494)] [D acc: (0.648)(0.484, 0.812)] [G loss: 1.275] [G acc: 0.141]\n",
      "5218 [D loss: (0.583)(R 0.663, F 0.504)] [D acc: (0.641)(0.516, 0.766)] [G loss: 1.236] [G acc: 0.172]\n",
      "5219 [D loss: (0.563)(R 0.476, F 0.650)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.317] [G acc: 0.094]\n",
      "5220 [D loss: (0.527)(R 0.578, F 0.477)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.324] [G acc: 0.094]\n",
      "5221 [D loss: (0.509)(R 0.565, F 0.453)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.355] [G acc: 0.109]\n",
      "5222 [D loss: (0.519)(R 0.584, F 0.454)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.447] [G acc: 0.094]\n",
      "5223 [D loss: (0.581)(R 0.670, F 0.492)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.283] [G acc: 0.109]\n",
      "5224 [D loss: (0.565)(R 0.521, F 0.609)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.282] [G acc: 0.109]\n",
      "5225 [D loss: (0.579)(R 0.523, F 0.636)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.303] [G acc: 0.125]\n",
      "5226 [D loss: (0.593)(R 0.521, F 0.665)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.477] [G acc: 0.078]\n",
      "5227 [D loss: (0.619)(R 0.700, F 0.539)] [D acc: (0.609)(0.453, 0.766)] [G loss: 1.371] [G acc: 0.062]\n",
      "5228 [D loss: (0.573)(R 0.598, F 0.548)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.446] [G acc: 0.047]\n",
      "5229 [D loss: (0.668)(R 0.552, F 0.784)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.439] [G acc: 0.141]\n",
      "5230 [D loss: (0.551)(R 0.557, F 0.546)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.356] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5231 [D loss: (0.560)(R 0.553, F 0.568)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.512] [G acc: 0.094]\n",
      "5232 [D loss: (0.438)(R 0.493, F 0.383)] [D acc: (0.820)(0.719, 0.922)] [G loss: 1.457] [G acc: 0.078]\n",
      "5233 [D loss: (0.573)(R 0.718, F 0.428)] [D acc: (0.695)(0.531, 0.859)] [G loss: 1.341] [G acc: 0.156]\n",
      "5234 [D loss: (0.548)(R 0.496, F 0.600)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.337] [G acc: 0.141]\n",
      "5235 [D loss: (0.571)(R 0.602, F 0.541)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.335] [G acc: 0.125]\n",
      "5236 [D loss: (0.553)(R 0.402, F 0.704)] [D acc: (0.703)(0.812, 0.594)] [G loss: 1.376] [G acc: 0.047]\n",
      "5237 [D loss: (0.461)(R 0.509, F 0.412)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.447] [G acc: 0.094]\n",
      "5238 [D loss: (0.482)(R 0.524, F 0.439)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.362] [G acc: 0.156]\n",
      "5239 [D loss: (0.573)(R 0.552, F 0.594)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.252] [G acc: 0.109]\n",
      "5240 [D loss: (0.528)(R 0.482, F 0.574)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.311] [G acc: 0.141]\n",
      "5241 [D loss: (0.574)(R 0.678, F 0.469)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.472] [G acc: 0.156]\n",
      "5242 [D loss: (0.536)(R 0.558, F 0.514)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.435] [G acc: 0.062]\n",
      "5243 [D loss: (0.544)(R 0.478, F 0.609)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.348] [G acc: 0.109]\n",
      "5244 [D loss: (0.578)(R 0.606, F 0.551)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.323] [G acc: 0.125]\n",
      "5245 [D loss: (0.594)(R 0.649, F 0.538)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.468] [G acc: 0.016]\n",
      "5246 [D loss: (0.661)(R 0.514, F 0.809)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.339] [G acc: 0.094]\n",
      "5247 [D loss: (0.505)(R 0.581, F 0.428)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.277] [G acc: 0.188]\n",
      "5248 [D loss: (0.536)(R 0.624, F 0.448)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.226] [G acc: 0.141]\n",
      "5249 [D loss: (0.504)(R 0.463, F 0.545)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.579] [G acc: 0.109]\n",
      "5250 [D loss: (0.541)(R 0.549, F 0.534)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.327] [G acc: 0.125]\n",
      "5251 [D loss: (0.497)(R 0.402, F 0.592)] [D acc: (0.742)(0.797, 0.688)] [G loss: 1.625] [G acc: 0.094]\n",
      "5252 [D loss: (0.581)(R 0.598, F 0.564)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.493] [G acc: 0.047]\n",
      "5253 [D loss: (0.577)(R 0.705, F 0.449)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.386] [G acc: 0.125]\n",
      "5254 [D loss: (0.601)(R 0.550, F 0.653)] [D acc: (0.695)(0.734, 0.656)] [G loss: 1.338] [G acc: 0.062]\n",
      "5255 [D loss: (0.555)(R 0.541, F 0.570)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.389] [G acc: 0.094]\n",
      "5256 [D loss: (0.558)(R 0.627, F 0.489)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.423] [G acc: 0.125]\n",
      "5257 [D loss: (0.622)(R 0.643, F 0.600)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.255] [G acc: 0.078]\n",
      "5258 [D loss: (0.617)(R 0.635, F 0.600)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.306] [G acc: 0.125]\n",
      "5259 [D loss: (0.609)(R 0.592, F 0.625)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.196] [G acc: 0.141]\n",
      "5260 [D loss: (0.584)(R 0.593, F 0.575)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.338] [G acc: 0.125]\n",
      "5261 [D loss: (0.574)(R 0.682, F 0.466)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.273] [G acc: 0.062]\n",
      "5262 [D loss: (0.543)(R 0.545, F 0.542)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.287] [G acc: 0.078]\n",
      "5263 [D loss: (0.572)(R 0.623, F 0.522)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.329] [G acc: 0.125]\n",
      "5264 [D loss: (0.526)(R 0.493, F 0.558)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.243] [G acc: 0.125]\n",
      "5265 [D loss: (0.620)(R 0.738, F 0.502)] [D acc: (0.641)(0.500, 0.781)] [G loss: 1.233] [G acc: 0.109]\n",
      "5266 [D loss: (0.545)(R 0.472, F 0.618)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.303] [G acc: 0.109]\n",
      "5267 [D loss: (0.526)(R 0.607, F 0.446)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.252] [G acc: 0.172]\n",
      "5268 [D loss: (0.541)(R 0.475, F 0.608)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.229] [G acc: 0.109]\n",
      "5269 [D loss: (0.501)(R 0.512, F 0.490)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.300] [G acc: 0.156]\n",
      "5270 [D loss: (0.553)(R 0.552, F 0.553)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.228] [G acc: 0.141]\n",
      "5271 [D loss: (0.591)(R 0.571, F 0.610)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.269] [G acc: 0.125]\n",
      "5272 [D loss: (0.550)(R 0.530, F 0.569)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.239] [G acc: 0.094]\n",
      "5273 [D loss: (0.559)(R 0.570, F 0.549)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.267] [G acc: 0.109]\n",
      "5274 [D loss: (0.552)(R 0.517, F 0.588)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.309] [G acc: 0.125]\n",
      "5275 [D loss: (0.496)(R 0.528, F 0.464)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.336] [G acc: 0.125]\n",
      "5276 [D loss: (0.506)(R 0.504, F 0.508)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.346] [G acc: 0.062]\n",
      "5277 [D loss: (0.533)(R 0.594, F 0.473)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.327] [G acc: 0.125]\n",
      "5278 [D loss: (0.588)(R 0.593, F 0.584)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.538] [G acc: 0.047]\n",
      "5279 [D loss: (0.483)(R 0.482, F 0.484)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.309] [G acc: 0.109]\n",
      "5280 [D loss: (0.543)(R 0.600, F 0.486)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.223] [G acc: 0.172]\n",
      "5281 [D loss: (0.566)(R 0.572, F 0.561)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.241] [G acc: 0.125]\n",
      "5282 [D loss: (0.547)(R 0.538, F 0.556)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.373] [G acc: 0.078]\n",
      "5283 [D loss: (0.514)(R 0.449, F 0.579)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.372] [G acc: 0.109]\n",
      "5284 [D loss: (0.527)(R 0.540, F 0.514)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.240] [G acc: 0.156]\n",
      "5285 [D loss: (0.491)(R 0.436, F 0.545)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.506] [G acc: 0.047]\n",
      "5286 [D loss: (0.611)(R 0.682, F 0.540)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.384] [G acc: 0.094]\n",
      "5287 [D loss: (0.504)(R 0.558, F 0.450)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.448] [G acc: 0.125]\n",
      "5288 [D loss: (0.505)(R 0.503, F 0.507)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.278] [G acc: 0.125]\n",
      "5289 [D loss: (0.609)(R 0.525, F 0.693)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.465] [G acc: 0.062]\n",
      "5290 [D loss: (0.510)(R 0.607, F 0.414)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.419] [G acc: 0.062]\n",
      "5291 [D loss: (0.519)(R 0.553, F 0.484)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.334] [G acc: 0.094]\n",
      "5292 [D loss: (0.560)(R 0.579, F 0.540)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.339] [G acc: 0.109]\n",
      "5293 [D loss: (0.556)(R 0.611, F 0.501)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.373] [G acc: 0.109]\n",
      "5294 [D loss: (0.648)(R 0.584, F 0.711)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.486] [G acc: 0.031]\n",
      "5295 [D loss: (0.560)(R 0.676, F 0.443)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.390] [G acc: 0.094]\n",
      "5296 [D loss: (0.546)(R 0.566, F 0.527)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.366] [G acc: 0.109]\n",
      "5297 [D loss: (0.560)(R 0.614, F 0.506)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.231] [G acc: 0.141]\n",
      "5298 [D loss: (0.536)(R 0.534, F 0.539)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.172] [G acc: 0.188]\n",
      "5299 [D loss: (0.468)(R 0.413, F 0.524)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.320] [G acc: 0.141]\n",
      "5300 [D loss: (0.605)(R 0.659, F 0.552)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.207] [G acc: 0.125]\n",
      "5301 [D loss: (0.629)(R 0.512, F 0.747)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.440] [G acc: 0.062]\n",
      "5302 [D loss: (0.523)(R 0.540, F 0.506)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.342] [G acc: 0.062]\n",
      "5303 [D loss: (0.575)(R 0.569, F 0.582)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.554] [G acc: 0.047]\n",
      "5304 [D loss: (0.517)(R 0.588, F 0.446)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.475] [G acc: 0.047]\n",
      "5305 [D loss: (0.440)(R 0.471, F 0.408)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.357] [G acc: 0.172]\n",
      "5306 [D loss: (0.497)(R 0.407, F 0.587)] [D acc: (0.781)(0.812, 0.750)] [G loss: 1.381] [G acc: 0.062]\n",
      "5307 [D loss: (0.516)(R 0.500, F 0.532)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.504] [G acc: 0.062]\n",
      "5308 [D loss: (0.542)(R 0.620, F 0.463)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.445] [G acc: 0.078]\n",
      "5309 [D loss: (0.549)(R 0.583, F 0.514)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.539] [G acc: 0.047]\n",
      "5310 [D loss: (0.413)(R 0.441, F 0.386)] [D acc: (0.836)(0.766, 0.906)] [G loss: 1.354] [G acc: 0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311 [D loss: (0.484)(R 0.476, F 0.491)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.326] [G acc: 0.141]\n",
      "5312 [D loss: (0.466)(R 0.498, F 0.434)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.529] [G acc: 0.062]\n",
      "5313 [D loss: (0.608)(R 0.629, F 0.587)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.380] [G acc: 0.062]\n",
      "5314 [D loss: (0.536)(R 0.595, F 0.477)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.353] [G acc: 0.172]\n",
      "5315 [D loss: (0.451)(R 0.408, F 0.494)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.410] [G acc: 0.141]\n",
      "5316 [D loss: (0.590)(R 0.629, F 0.552)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.352] [G acc: 0.156]\n",
      "5317 [D loss: (0.555)(R 0.492, F 0.617)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.454] [G acc: 0.156]\n",
      "5318 [D loss: (0.488)(R 0.451, F 0.526)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.601] [G acc: 0.062]\n",
      "5319 [D loss: (0.542)(R 0.514, F 0.569)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.580] [G acc: 0.078]\n",
      "5320 [D loss: (0.616)(R 0.642, F 0.589)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.507] [G acc: 0.016]\n",
      "5321 [D loss: (0.586)(R 0.646, F 0.525)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.400] [G acc: 0.078]\n",
      "5322 [D loss: (0.503)(R 0.584, F 0.422)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.389] [G acc: 0.094]\n",
      "5323 [D loss: (0.510)(R 0.547, F 0.473)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.453] [G acc: 0.156]\n",
      "5324 [D loss: (0.551)(R 0.497, F 0.605)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.465] [G acc: 0.062]\n",
      "5325 [D loss: (0.602)(R 0.536, F 0.669)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.329] [G acc: 0.094]\n",
      "5326 [D loss: (0.541)(R 0.562, F 0.521)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.472] [G acc: 0.047]\n",
      "5327 [D loss: (0.529)(R 0.508, F 0.551)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.296] [G acc: 0.078]\n",
      "5328 [D loss: (0.557)(R 0.594, F 0.520)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.264] [G acc: 0.156]\n",
      "5329 [D loss: (0.471)(R 0.456, F 0.486)] [D acc: (0.828)(0.781, 0.875)] [G loss: 1.441] [G acc: 0.062]\n",
      "5330 [D loss: (0.561)(R 0.533, F 0.588)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.554] [G acc: 0.031]\n",
      "5331 [D loss: (0.483)(R 0.537, F 0.429)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.579] [G acc: 0.062]\n",
      "5332 [D loss: (0.617)(R 0.728, F 0.506)] [D acc: (0.648)(0.500, 0.797)] [G loss: 1.366] [G acc: 0.109]\n",
      "5333 [D loss: (0.541)(R 0.518, F 0.563)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.367] [G acc: 0.062]\n",
      "5334 [D loss: (0.641)(R 0.620, F 0.661)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.503] [G acc: 0.031]\n",
      "5335 [D loss: (0.519)(R 0.543, F 0.496)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.372] [G acc: 0.141]\n",
      "5336 [D loss: (0.503)(R 0.539, F 0.468)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.413] [G acc: 0.078]\n",
      "5337 [D loss: (0.553)(R 0.520, F 0.587)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.421] [G acc: 0.047]\n",
      "5338 [D loss: (0.544)(R 0.621, F 0.467)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.467] [G acc: 0.062]\n",
      "5339 [D loss: (0.480)(R 0.451, F 0.508)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.551] [G acc: 0.141]\n",
      "5340 [D loss: (0.568)(R 0.612, F 0.524)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.573] [G acc: 0.062]\n",
      "5341 [D loss: (0.569)(R 0.564, F 0.573)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.313] [G acc: 0.078]\n",
      "5342 [D loss: (0.544)(R 0.567, F 0.521)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.436] [G acc: 0.062]\n",
      "5343 [D loss: (0.465)(R 0.518, F 0.411)] [D acc: (0.836)(0.750, 0.922)] [G loss: 1.445] [G acc: 0.094]\n",
      "5344 [D loss: (0.537)(R 0.570, F 0.504)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.460] [G acc: 0.109]\n",
      "5345 [D loss: (0.524)(R 0.494, F 0.553)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.391] [G acc: 0.062]\n",
      "5346 [D loss: (0.606)(R 0.557, F 0.654)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.452] [G acc: 0.156]\n",
      "5347 [D loss: (0.536)(R 0.607, F 0.465)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.580] [G acc: 0.047]\n",
      "5348 [D loss: (0.436)(R 0.426, F 0.446)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.634] [G acc: 0.047]\n",
      "5349 [D loss: (0.597)(R 0.625, F 0.570)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.475] [G acc: 0.094]\n",
      "5350 [D loss: (0.608)(R 0.738, F 0.478)] [D acc: (0.672)(0.516, 0.828)] [G loss: 1.361] [G acc: 0.078]\n",
      "5351 [D loss: (0.544)(R 0.598, F 0.489)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.319] [G acc: 0.125]\n",
      "5352 [D loss: (0.617)(R 0.584, F 0.650)] [D acc: (0.617)(0.594, 0.641)] [G loss: 1.399] [G acc: 0.156]\n",
      "5353 [D loss: (0.606)(R 0.523, F 0.689)] [D acc: (0.672)(0.734, 0.609)] [G loss: 1.335] [G acc: 0.188]\n",
      "5354 [D loss: (0.477)(R 0.526, F 0.428)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.413] [G acc: 0.125]\n",
      "5355 [D loss: (0.569)(R 0.474, F 0.665)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.407] [G acc: 0.078]\n",
      "5356 [D loss: (0.516)(R 0.574, F 0.459)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.401] [G acc: 0.094]\n",
      "5357 [D loss: (0.493)(R 0.509, F 0.478)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.366] [G acc: 0.125]\n",
      "5358 [D loss: (0.540)(R 0.459, F 0.621)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.522] [G acc: 0.109]\n",
      "5359 [D loss: (0.537)(R 0.599, F 0.474)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.512] [G acc: 0.156]\n",
      "5360 [D loss: (0.598)(R 0.645, F 0.550)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.385] [G acc: 0.031]\n",
      "5361 [D loss: (0.527)(R 0.467, F 0.587)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.416] [G acc: 0.078]\n",
      "5362 [D loss: (0.542)(R 0.617, F 0.468)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.309] [G acc: 0.078]\n",
      "5363 [D loss: (0.571)(R 0.594, F 0.549)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.377] [G acc: 0.125]\n",
      "5364 [D loss: (0.531)(R 0.598, F 0.463)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.479] [G acc: 0.062]\n",
      "5365 [D loss: (0.523)(R 0.506, F 0.539)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.480] [G acc: 0.125]\n",
      "5366 [D loss: (0.546)(R 0.464, F 0.627)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.430] [G acc: 0.016]\n",
      "5367 [D loss: (0.600)(R 0.756, F 0.443)] [D acc: (0.688)(0.516, 0.859)] [G loss: 1.328] [G acc: 0.078]\n",
      "5368 [D loss: (0.515)(R 0.541, F 0.488)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.470] [G acc: 0.109]\n",
      "5369 [D loss: (0.445)(R 0.432, F 0.457)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.426] [G acc: 0.047]\n",
      "5370 [D loss: (0.523)(R 0.490, F 0.555)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.486] [G acc: 0.109]\n",
      "5371 [D loss: (0.559)(R 0.546, F 0.571)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.458] [G acc: 0.031]\n",
      "5372 [D loss: (0.588)(R 0.683, F 0.493)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.455] [G acc: 0.062]\n",
      "5373 [D loss: (0.569)(R 0.591, F 0.546)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.362] [G acc: 0.109]\n",
      "5374 [D loss: (0.583)(R 0.608, F 0.558)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.489] [G acc: 0.141]\n",
      "5375 [D loss: (0.542)(R 0.580, F 0.503)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.437] [G acc: 0.016]\n",
      "5376 [D loss: (0.483)(R 0.509, F 0.458)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.314] [G acc: 0.094]\n",
      "5377 [D loss: (0.530)(R 0.517, F 0.542)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.388] [G acc: 0.203]\n",
      "5378 [D loss: (0.553)(R 0.567, F 0.540)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.421] [G acc: 0.141]\n",
      "5379 [D loss: (0.553)(R 0.558, F 0.548)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.318] [G acc: 0.156]\n",
      "5380 [D loss: (0.574)(R 0.653, F 0.496)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.390] [G acc: 0.078]\n",
      "5381 [D loss: (0.508)(R 0.526, F 0.489)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.377] [G acc: 0.094]\n",
      "5382 [D loss: (0.561)(R 0.591, F 0.531)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.439] [G acc: 0.094]\n",
      "5383 [D loss: (0.447)(R 0.449, F 0.446)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.337] [G acc: 0.094]\n",
      "5384 [D loss: (0.481)(R 0.418, F 0.545)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.425] [G acc: 0.109]\n",
      "5385 [D loss: (0.563)(R 0.454, F 0.672)] [D acc: (0.727)(0.766, 0.688)] [G loss: 1.517] [G acc: 0.078]\n",
      "5386 [D loss: (0.510)(R 0.533, F 0.488)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.509] [G acc: 0.094]\n",
      "5387 [D loss: (0.608)(R 0.714, F 0.502)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.343] [G acc: 0.141]\n",
      "5388 [D loss: (0.670)(R 0.628, F 0.712)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.439] [G acc: 0.141]\n",
      "5389 [D loss: (0.628)(R 0.711, F 0.546)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.315] [G acc: 0.094]\n",
      "5390 [D loss: (0.469)(R 0.473, F 0.464)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.465] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5391 [D loss: (0.495)(R 0.506, F 0.485)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.420] [G acc: 0.078]\n",
      "5392 [D loss: (0.596)(R 0.627, F 0.565)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.342] [G acc: 0.047]\n",
      "5393 [D loss: (0.441)(R 0.460, F 0.422)] [D acc: (0.805)(0.750, 0.859)] [G loss: 1.237] [G acc: 0.188]\n",
      "5394 [D loss: (0.507)(R 0.424, F 0.590)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.416] [G acc: 0.156]\n",
      "5395 [D loss: (0.563)(R 0.635, F 0.492)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.379] [G acc: 0.156]\n",
      "5396 [D loss: (0.617)(R 0.690, F 0.544)] [D acc: (0.648)(0.531, 0.766)] [G loss: 1.470] [G acc: 0.094]\n",
      "5397 [D loss: (0.511)(R 0.486, F 0.536)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.382] [G acc: 0.094]\n",
      "5398 [D loss: (0.645)(R 0.687, F 0.604)] [D acc: (0.625)(0.547, 0.703)] [G loss: 1.292] [G acc: 0.094]\n",
      "5399 [D loss: (0.490)(R 0.489, F 0.491)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.372] [G acc: 0.141]\n",
      "5400 [D loss: (0.701)(R 0.595, F 0.808)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.325] [G acc: 0.094]\n",
      "5401 [D loss: (0.567)(R 0.592, F 0.542)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.389] [G acc: 0.016]\n",
      "5402 [D loss: (0.493)(R 0.483, F 0.503)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.236] [G acc: 0.188]\n",
      "5403 [D loss: (0.505)(R 0.532, F 0.478)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.181] [G acc: 0.203]\n",
      "5404 [D loss: (0.550)(R 0.580, F 0.520)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.305] [G acc: 0.172]\n",
      "5405 [D loss: (0.611)(R 0.611, F 0.611)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.291] [G acc: 0.125]\n",
      "5406 [D loss: (0.522)(R 0.504, F 0.541)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.281] [G acc: 0.141]\n",
      "5407 [D loss: (0.481)(R 0.448, F 0.515)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.154] [G acc: 0.219]\n",
      "5408 [D loss: (0.527)(R 0.424, F 0.630)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.484] [G acc: 0.094]\n",
      "5409 [D loss: (0.524)(R 0.500, F 0.549)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.415] [G acc: 0.109]\n",
      "5410 [D loss: (0.584)(R 0.660, F 0.508)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.384] [G acc: 0.078]\n",
      "5411 [D loss: (0.552)(R 0.628, F 0.476)] [D acc: (0.742)(0.594, 0.891)] [G loss: 1.364] [G acc: 0.125]\n",
      "5412 [D loss: (0.552)(R 0.477, F 0.627)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.445] [G acc: 0.078]\n",
      "5413 [D loss: (0.522)(R 0.572, F 0.473)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.508] [G acc: 0.047]\n",
      "5414 [D loss: (0.530)(R 0.464, F 0.596)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.427] [G acc: 0.141]\n",
      "5415 [D loss: (0.554)(R 0.642, F 0.466)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.566] [G acc: 0.016]\n",
      "5416 [D loss: (0.561)(R 0.535, F 0.586)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.530] [G acc: 0.125]\n",
      "5417 [D loss: (0.595)(R 0.616, F 0.574)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.501] [G acc: 0.062]\n",
      "5418 [D loss: (0.527)(R 0.561, F 0.492)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.353] [G acc: 0.078]\n",
      "5419 [D loss: (0.588)(R 0.664, F 0.513)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.488] [G acc: 0.156]\n",
      "5420 [D loss: (0.538)(R 0.606, F 0.470)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.446] [G acc: 0.094]\n",
      "5421 [D loss: (0.490)(R 0.548, F 0.432)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.359] [G acc: 0.062]\n",
      "5422 [D loss: (0.595)(R 0.617, F 0.573)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.279] [G acc: 0.188]\n",
      "5423 [D loss: (0.526)(R 0.538, F 0.515)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.302] [G acc: 0.141]\n",
      "5424 [D loss: (0.532)(R 0.560, F 0.504)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.435] [G acc: 0.141]\n",
      "5425 [D loss: (0.478)(R 0.500, F 0.457)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.593] [G acc: 0.031]\n",
      "5426 [D loss: (0.600)(R 0.585, F 0.614)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.461] [G acc: 0.109]\n",
      "5427 [D loss: (0.616)(R 0.610, F 0.622)] [D acc: (0.648)(0.672, 0.625)] [G loss: 1.352] [G acc: 0.125]\n",
      "5428 [D loss: (0.610)(R 0.609, F 0.611)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.304] [G acc: 0.172]\n",
      "5429 [D loss: (0.549)(R 0.617, F 0.481)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.438] [G acc: 0.078]\n",
      "5430 [D loss: (0.560)(R 0.532, F 0.588)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.325] [G acc: 0.141]\n",
      "5431 [D loss: (0.489)(R 0.469, F 0.509)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.205] [G acc: 0.203]\n",
      "5432 [D loss: (0.562)(R 0.603, F 0.521)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.251] [G acc: 0.078]\n",
      "5433 [D loss: (0.517)(R 0.517, F 0.517)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.388] [G acc: 0.078]\n",
      "5434 [D loss: (0.420)(R 0.422, F 0.418)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.429] [G acc: 0.062]\n",
      "5435 [D loss: (0.536)(R 0.494, F 0.578)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.525] [G acc: 0.094]\n",
      "5436 [D loss: (0.486)(R 0.511, F 0.461)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.380] [G acc: 0.094]\n",
      "5437 [D loss: (0.559)(R 0.532, F 0.586)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.415] [G acc: 0.125]\n",
      "5438 [D loss: (0.609)(R 0.678, F 0.541)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.502] [G acc: 0.078]\n",
      "5439 [D loss: (0.599)(R 0.597, F 0.601)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.425] [G acc: 0.125]\n",
      "5440 [D loss: (0.561)(R 0.608, F 0.514)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.372] [G acc: 0.078]\n",
      "5441 [D loss: (0.482)(R 0.507, F 0.457)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.510] [G acc: 0.047]\n",
      "5442 [D loss: (0.556)(R 0.600, F 0.512)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.452] [G acc: 0.078]\n",
      "5443 [D loss: (0.508)(R 0.526, F 0.489)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.320] [G acc: 0.125]\n",
      "5444 [D loss: (0.445)(R 0.498, F 0.392)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.573] [G acc: 0.094]\n",
      "5445 [D loss: (0.521)(R 0.395, F 0.647)] [D acc: (0.711)(0.750, 0.672)] [G loss: 1.575] [G acc: 0.078]\n",
      "5446 [D loss: (0.564)(R 0.629, F 0.498)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.508] [G acc: 0.078]\n",
      "5447 [D loss: (0.485)(R 0.602, F 0.368)] [D acc: (0.789)(0.656, 0.922)] [G loss: 1.465] [G acc: 0.094]\n",
      "5448 [D loss: (0.570)(R 0.581, F 0.560)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.390] [G acc: 0.031]\n",
      "5449 [D loss: (0.550)(R 0.489, F 0.610)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.461] [G acc: 0.094]\n",
      "5450 [D loss: (0.524)(R 0.570, F 0.478)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.470] [G acc: 0.078]\n",
      "5451 [D loss: (0.551)(R 0.615, F 0.487)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.369] [G acc: 0.094]\n",
      "5452 [D loss: (0.610)(R 0.560, F 0.660)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.431] [G acc: 0.047]\n",
      "5453 [D loss: (0.559)(R 0.502, F 0.616)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.511] [G acc: 0.094]\n",
      "5454 [D loss: (0.592)(R 0.608, F 0.576)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.419] [G acc: 0.094]\n",
      "5455 [D loss: (0.501)(R 0.510, F 0.491)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.616] [G acc: 0.062]\n",
      "5456 [D loss: (0.492)(R 0.545, F 0.438)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.567] [G acc: 0.062]\n",
      "5457 [D loss: (0.451)(R 0.398, F 0.505)] [D acc: (0.828)(0.828, 0.828)] [G loss: 1.345] [G acc: 0.156]\n",
      "5458 [D loss: (0.497)(R 0.553, F 0.442)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.677] [G acc: 0.031]\n",
      "5459 [D loss: (0.541)(R 0.540, F 0.541)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.531] [G acc: 0.062]\n",
      "5460 [D loss: (0.612)(R 0.407, F 0.816)] [D acc: (0.758)(0.797, 0.719)] [G loss: 1.640] [G acc: 0.047]\n",
      "5461 [D loss: (0.560)(R 0.696, F 0.425)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.747] [G acc: 0.031]\n",
      "5462 [D loss: (0.519)(R 0.589, F 0.449)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.556] [G acc: 0.094]\n",
      "5463 [D loss: (0.573)(R 0.661, F 0.484)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.452] [G acc: 0.156]\n",
      "5464 [D loss: (0.459)(R 0.386, F 0.533)] [D acc: (0.797)(0.812, 0.781)] [G loss: 1.566] [G acc: 0.078]\n",
      "5465 [D loss: (0.546)(R 0.637, F 0.455)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.418] [G acc: 0.125]\n",
      "5466 [D loss: (0.527)(R 0.470, F 0.583)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.263] [G acc: 0.172]\n",
      "5467 [D loss: (0.603)(R 0.549, F 0.658)] [D acc: (0.664)(0.703, 0.625)] [G loss: 1.600] [G acc: 0.078]\n",
      "5468 [D loss: (0.529)(R 0.621, F 0.437)] [D acc: (0.727)(0.562, 0.891)] [G loss: 1.470] [G acc: 0.062]\n",
      "5469 [D loss: (0.523)(R 0.466, F 0.581)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.352] [G acc: 0.125]\n",
      "5470 [D loss: (0.473)(R 0.424, F 0.523)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.421] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5471 [D loss: (0.565)(R 0.570, F 0.561)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.444] [G acc: 0.109]\n",
      "5472 [D loss: (0.527)(R 0.530, F 0.524)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.451] [G acc: 0.109]\n",
      "5473 [D loss: (0.471)(R 0.505, F 0.436)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.503] [G acc: 0.109]\n",
      "5474 [D loss: (0.652)(R 0.622, F 0.683)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.542] [G acc: 0.031]\n",
      "5475 [D loss: (0.477)(R 0.535, F 0.420)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.458] [G acc: 0.109]\n",
      "5476 [D loss: (0.608)(R 0.520, F 0.697)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.495] [G acc: 0.109]\n",
      "5477 [D loss: (0.581)(R 0.682, F 0.480)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.496] [G acc: 0.094]\n",
      "5478 [D loss: (0.481)(R 0.499, F 0.463)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.483] [G acc: 0.094]\n",
      "5479 [D loss: (0.579)(R 0.583, F 0.574)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.438] [G acc: 0.094]\n",
      "5480 [D loss: (0.589)(R 0.656, F 0.522)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.507] [G acc: 0.062]\n",
      "5481 [D loss: (0.526)(R 0.528, F 0.524)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.402] [G acc: 0.109]\n",
      "5482 [D loss: (0.516)(R 0.519, F 0.512)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.433] [G acc: 0.156]\n",
      "5483 [D loss: (0.549)(R 0.530, F 0.567)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.495] [G acc: 0.016]\n",
      "5484 [D loss: (0.578)(R 0.641, F 0.516)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.477] [G acc: 0.062]\n",
      "5485 [D loss: (0.527)(R 0.576, F 0.477)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.273] [G acc: 0.188]\n",
      "5486 [D loss: (0.591)(R 0.588, F 0.595)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.448] [G acc: 0.078]\n",
      "5487 [D loss: (0.648)(R 0.585, F 0.712)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.334] [G acc: 0.109]\n",
      "5488 [D loss: (0.565)(R 0.610, F 0.520)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.378] [G acc: 0.047]\n",
      "5489 [D loss: (0.479)(R 0.465, F 0.493)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.234] [G acc: 0.141]\n",
      "5490 [D loss: (0.598)(R 0.565, F 0.630)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.368] [G acc: 0.062]\n",
      "5491 [D loss: (0.547)(R 0.647, F 0.447)] [D acc: (0.711)(0.547, 0.875)] [G loss: 1.250] [G acc: 0.141]\n",
      "5492 [D loss: (0.584)(R 0.542, F 0.626)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.636] [G acc: 0.078]\n",
      "5493 [D loss: (0.526)(R 0.611, F 0.441)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.525] [G acc: 0.078]\n",
      "5494 [D loss: (0.559)(R 0.553, F 0.565)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.405] [G acc: 0.062]\n",
      "5495 [D loss: (0.445)(R 0.366, F 0.523)] [D acc: (0.797)(0.797, 0.797)] [G loss: 1.326] [G acc: 0.141]\n",
      "5496 [D loss: (0.503)(R 0.597, F 0.409)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.330] [G acc: 0.141]\n",
      "5497 [D loss: (0.461)(R 0.456, F 0.467)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.562] [G acc: 0.016]\n",
      "5498 [D loss: (0.453)(R 0.516, F 0.390)] [D acc: (0.766)(0.625, 0.906)] [G loss: 1.452] [G acc: 0.078]\n",
      "5499 [D loss: (0.617)(R 0.593, F 0.641)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.645] [G acc: 0.109]\n",
      "5500 [D loss: (0.528)(R 0.570, F 0.485)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.420] [G acc: 0.109]\n",
      "5501 [D loss: (0.429)(R 0.437, F 0.421)] [D acc: (0.852)(0.797, 0.906)] [G loss: 1.555] [G acc: 0.062]\n",
      "5502 [D loss: (0.577)(R 0.582, F 0.572)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.321] [G acc: 0.156]\n",
      "5503 [D loss: (0.600)(R 0.678, F 0.523)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.357] [G acc: 0.078]\n",
      "5504 [D loss: (0.532)(R 0.409, F 0.656)] [D acc: (0.766)(0.828, 0.703)] [G loss: 1.352] [G acc: 0.188]\n",
      "5505 [D loss: (0.530)(R 0.562, F 0.498)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.500] [G acc: 0.062]\n",
      "5506 [D loss: (0.501)(R 0.512, F 0.490)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.465] [G acc: 0.109]\n",
      "5507 [D loss: (0.527)(R 0.563, F 0.492)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.511] [G acc: 0.062]\n",
      "5508 [D loss: (0.486)(R 0.496, F 0.477)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.395] [G acc: 0.109]\n",
      "5509 [D loss: (0.633)(R 0.549, F 0.716)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.517] [G acc: 0.109]\n",
      "5510 [D loss: (0.517)(R 0.683, F 0.350)] [D acc: (0.758)(0.609, 0.906)] [G loss: 1.414] [G acc: 0.125]\n",
      "5511 [D loss: (0.538)(R 0.536, F 0.541)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.262] [G acc: 0.172]\n",
      "5512 [D loss: (0.533)(R 0.554, F 0.512)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.388] [G acc: 0.125]\n",
      "5513 [D loss: (0.497)(R 0.483, F 0.511)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.548] [G acc: 0.141]\n",
      "5514 [D loss: (0.488)(R 0.477, F 0.498)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.448] [G acc: 0.094]\n",
      "5515 [D loss: (0.487)(R 0.540, F 0.434)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.591] [G acc: 0.125]\n",
      "5516 [D loss: (0.540)(R 0.586, F 0.494)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.363] [G acc: 0.094]\n",
      "5517 [D loss: (0.510)(R 0.499, F 0.521)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.361] [G acc: 0.156]\n",
      "5518 [D loss: (0.611)(R 0.634, F 0.587)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.463] [G acc: 0.094]\n",
      "5519 [D loss: (0.564)(R 0.604, F 0.523)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.475] [G acc: 0.078]\n",
      "5520 [D loss: (0.579)(R 0.557, F 0.600)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.487] [G acc: 0.094]\n",
      "5521 [D loss: (0.566)(R 0.686, F 0.445)] [D acc: (0.680)(0.531, 0.828)] [G loss: 1.321] [G acc: 0.141]\n",
      "5522 [D loss: (0.473)(R 0.486, F 0.460)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.586] [G acc: 0.062]\n",
      "5523 [D loss: (0.649)(R 0.648, F 0.649)] [D acc: (0.633)(0.609, 0.656)] [G loss: 1.465] [G acc: 0.078]\n",
      "5524 [D loss: (0.504)(R 0.601, F 0.408)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.399] [G acc: 0.141]\n",
      "5525 [D loss: (0.485)(R 0.568, F 0.401)] [D acc: (0.805)(0.703, 0.906)] [G loss: 1.450] [G acc: 0.172]\n",
      "5526 [D loss: (0.541)(R 0.488, F 0.594)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.465] [G acc: 0.109]\n",
      "5527 [D loss: (0.522)(R 0.567, F 0.476)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.364] [G acc: 0.078]\n",
      "5528 [D loss: (0.561)(R 0.565, F 0.557)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.449] [G acc: 0.109]\n",
      "5529 [D loss: (0.594)(R 0.550, F 0.637)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.455] [G acc: 0.062]\n",
      "5530 [D loss: (0.545)(R 0.605, F 0.486)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.298] [G acc: 0.094]\n",
      "5531 [D loss: (0.528)(R 0.575, F 0.480)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.475] [G acc: 0.062]\n",
      "5532 [D loss: (0.482)(R 0.559, F 0.405)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.601] [G acc: 0.047]\n",
      "5533 [D loss: (0.463)(R 0.422, F 0.504)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.608] [G acc: 0.031]\n",
      "5534 [D loss: (0.503)(R 0.475, F 0.530)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.480] [G acc: 0.109]\n",
      "5535 [D loss: (0.577)(R 0.628, F 0.527)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.438] [G acc: 0.078]\n",
      "5536 [D loss: (0.526)(R 0.531, F 0.520)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.436] [G acc: 0.109]\n",
      "5537 [D loss: (0.589)(R 0.593, F 0.585)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.469] [G acc: 0.109]\n",
      "5538 [D loss: (0.517)(R 0.523, F 0.512)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.471] [G acc: 0.047]\n",
      "5539 [D loss: (0.538)(R 0.655, F 0.420)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.548] [G acc: 0.047]\n",
      "5540 [D loss: (0.516)(R 0.486, F 0.547)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.501] [G acc: 0.078]\n",
      "5541 [D loss: (0.544)(R 0.607, F 0.480)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.395] [G acc: 0.156]\n",
      "5542 [D loss: (0.653)(R 0.553, F 0.753)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.516] [G acc: 0.000]\n",
      "5543 [D loss: (0.591)(R 0.750, F 0.433)] [D acc: (0.719)(0.547, 0.891)] [G loss: 1.379] [G acc: 0.094]\n",
      "5544 [D loss: (0.481)(R 0.480, F 0.483)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.427] [G acc: 0.078]\n",
      "5545 [D loss: (0.459)(R 0.538, F 0.381)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.407] [G acc: 0.094]\n",
      "5546 [D loss: (0.586)(R 0.583, F 0.590)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.401] [G acc: 0.156]\n",
      "5547 [D loss: (0.607)(R 0.636, F 0.579)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.273] [G acc: 0.141]\n",
      "5548 [D loss: (0.601)(R 0.643, F 0.559)] [D acc: (0.633)(0.562, 0.703)] [G loss: 1.266] [G acc: 0.141]\n",
      "5549 [D loss: (0.562)(R 0.527, F 0.597)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.381] [G acc: 0.047]\n",
      "5550 [D loss: (0.611)(R 0.627, F 0.595)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.194] [G acc: 0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5551 [D loss: (0.556)(R 0.627, F 0.485)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.364] [G acc: 0.188]\n",
      "5552 [D loss: (0.504)(R 0.532, F 0.477)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.348] [G acc: 0.141]\n",
      "5553 [D loss: (0.508)(R 0.488, F 0.527)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.488] [G acc: 0.047]\n",
      "5554 [D loss: (0.775)(R 0.589, F 0.962)] [D acc: (0.633)(0.672, 0.594)] [G loss: 1.540] [G acc: 0.078]\n",
      "5555 [D loss: (0.584)(R 0.692, F 0.476)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.430] [G acc: 0.094]\n",
      "5556 [D loss: (0.549)(R 0.598, F 0.501)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.285] [G acc: 0.188]\n",
      "5557 [D loss: (0.553)(R 0.556, F 0.549)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.327] [G acc: 0.078]\n",
      "5558 [D loss: (0.577)(R 0.589, F 0.564)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.409] [G acc: 0.094]\n",
      "5559 [D loss: (0.564)(R 0.652, F 0.475)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.375] [G acc: 0.172]\n",
      "5560 [D loss: (0.585)(R 0.643, F 0.528)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.320] [G acc: 0.094]\n",
      "5561 [D loss: (0.500)(R 0.476, F 0.525)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.342] [G acc: 0.125]\n",
      "5562 [D loss: (0.513)(R 0.539, F 0.486)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.412] [G acc: 0.047]\n",
      "5563 [D loss: (0.572)(R 0.586, F 0.558)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.452] [G acc: 0.141]\n",
      "5564 [D loss: (0.491)(R 0.547, F 0.436)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.387] [G acc: 0.125]\n",
      "5565 [D loss: (0.567)(R 0.592, F 0.541)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.420] [G acc: 0.078]\n",
      "5566 [D loss: (0.544)(R 0.530, F 0.558)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.343] [G acc: 0.141]\n",
      "5567 [D loss: (0.486)(R 0.571, F 0.401)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.439] [G acc: 0.062]\n",
      "5568 [D loss: (0.612)(R 0.555, F 0.669)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.357] [G acc: 0.016]\n",
      "5569 [D loss: (0.554)(R 0.619, F 0.489)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.454] [G acc: 0.125]\n",
      "5570 [D loss: (0.492)(R 0.518, F 0.466)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.490] [G acc: 0.078]\n",
      "5571 [D loss: (0.495)(R 0.508, F 0.481)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.624] [G acc: 0.062]\n",
      "5572 [D loss: (0.565)(R 0.576, F 0.554)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.281] [G acc: 0.125]\n",
      "5573 [D loss: (0.462)(R 0.441, F 0.483)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.421] [G acc: 0.062]\n",
      "5574 [D loss: (0.564)(R 0.604, F 0.525)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.302] [G acc: 0.125]\n",
      "5575 [D loss: (0.524)(R 0.458, F 0.589)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.444] [G acc: 0.078]\n",
      "5576 [D loss: (0.582)(R 0.708, F 0.457)] [D acc: (0.695)(0.547, 0.844)] [G loss: 1.387] [G acc: 0.125]\n",
      "5577 [D loss: (0.628)(R 0.607, F 0.648)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.386] [G acc: 0.094]\n",
      "5578 [D loss: (0.601)(R 0.679, F 0.523)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.335] [G acc: 0.156]\n",
      "5579 [D loss: (0.572)(R 0.622, F 0.523)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.396] [G acc: 0.109]\n",
      "5580 [D loss: (0.610)(R 0.664, F 0.556)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.389] [G acc: 0.094]\n",
      "5581 [D loss: (0.511)(R 0.594, F 0.428)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.433] [G acc: 0.094]\n",
      "5582 [D loss: (0.495)(R 0.526, F 0.463)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.336] [G acc: 0.125]\n",
      "5583 [D loss: (0.513)(R 0.445, F 0.580)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.355] [G acc: 0.047]\n",
      "5584 [D loss: (0.570)(R 0.629, F 0.511)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.407] [G acc: 0.078]\n",
      "5585 [D loss: (0.502)(R 0.487, F 0.518)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.347] [G acc: 0.125]\n",
      "5586 [D loss: (0.482)(R 0.425, F 0.539)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.539] [G acc: 0.047]\n",
      "5587 [D loss: (0.500)(R 0.552, F 0.448)] [D acc: (0.766)(0.609, 0.922)] [G loss: 1.525] [G acc: 0.062]\n",
      "5588 [D loss: (0.537)(R 0.502, F 0.571)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.497] [G acc: 0.125]\n",
      "5589 [D loss: (0.570)(R 0.552, F 0.587)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.407] [G acc: 0.047]\n",
      "5590 [D loss: (0.592)(R 0.752, F 0.432)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.522] [G acc: 0.062]\n",
      "5591 [D loss: (0.532)(R 0.534, F 0.530)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.401] [G acc: 0.062]\n",
      "5592 [D loss: (0.490)(R 0.498, F 0.483)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.573] [G acc: 0.141]\n",
      "5593 [D loss: (0.430)(R 0.450, F 0.411)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.621] [G acc: 0.031]\n",
      "5594 [D loss: (0.534)(R 0.482, F 0.585)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.346] [G acc: 0.109]\n",
      "5595 [D loss: (0.605)(R 0.632, F 0.578)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.349] [G acc: 0.125]\n",
      "5596 [D loss: (0.499)(R 0.536, F 0.463)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.473] [G acc: 0.078]\n",
      "5597 [D loss: (0.562)(R 0.496, F 0.627)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.373] [G acc: 0.125]\n",
      "5598 [D loss: (0.489)(R 0.572, F 0.405)] [D acc: (0.758)(0.609, 0.906)] [G loss: 1.333] [G acc: 0.094]\n",
      "5599 [D loss: (0.588)(R 0.617, F 0.559)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.468] [G acc: 0.078]\n",
      "5600 [D loss: (0.555)(R 0.607, F 0.502)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.432] [G acc: 0.062]\n",
      "5601 [D loss: (0.655)(R 0.819, F 0.491)] [D acc: (0.617)(0.453, 0.781)] [G loss: 1.363] [G acc: 0.156]\n",
      "5602 [D loss: (0.516)(R 0.548, F 0.484)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.407] [G acc: 0.047]\n",
      "5603 [D loss: (0.505)(R 0.507, F 0.504)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.518] [G acc: 0.062]\n",
      "5604 [D loss: (0.510)(R 0.500, F 0.520)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.403] [G acc: 0.047]\n",
      "5605 [D loss: (0.598)(R 0.564, F 0.631)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.496] [G acc: 0.094]\n",
      "5606 [D loss: (0.548)(R 0.668, F 0.427)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.389] [G acc: 0.062]\n",
      "5607 [D loss: (0.465)(R 0.520, F 0.411)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.261] [G acc: 0.141]\n",
      "5608 [D loss: (0.471)(R 0.424, F 0.518)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.476] [G acc: 0.109]\n",
      "5609 [D loss: (0.509)(R 0.492, F 0.527)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.491] [G acc: 0.016]\n",
      "5610 [D loss: (0.525)(R 0.604, F 0.446)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.351] [G acc: 0.047]\n",
      "5611 [D loss: (0.493)(R 0.538, F 0.448)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.544] [G acc: 0.062]\n",
      "5612 [D loss: (0.572)(R 0.632, F 0.513)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.344] [G acc: 0.141]\n",
      "5613 [D loss: (0.551)(R 0.595, F 0.506)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.290] [G acc: 0.094]\n",
      "5614 [D loss: (0.529)(R 0.562, F 0.496)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.266] [G acc: 0.125]\n",
      "5615 [D loss: (0.542)(R 0.550, F 0.533)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.317] [G acc: 0.062]\n",
      "5616 [D loss: (0.518)(R 0.523, F 0.513)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.472] [G acc: 0.078]\n",
      "5617 [D loss: (0.495)(R 0.465, F 0.526)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.470] [G acc: 0.031]\n",
      "5618 [D loss: (0.554)(R 0.595, F 0.513)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.438] [G acc: 0.125]\n",
      "5619 [D loss: (0.565)(R 0.605, F 0.525)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.471] [G acc: 0.078]\n",
      "5620 [D loss: (0.560)(R 0.516, F 0.604)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.488] [G acc: 0.094]\n",
      "5621 [D loss: (0.600)(R 0.671, F 0.530)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.433] [G acc: 0.078]\n",
      "5622 [D loss: (0.450)(R 0.468, F 0.432)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.485] [G acc: 0.125]\n",
      "5623 [D loss: (0.525)(R 0.402, F 0.648)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.567] [G acc: 0.047]\n",
      "5624 [D loss: (0.569)(R 0.567, F 0.571)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.406] [G acc: 0.094]\n",
      "5625 [D loss: (0.549)(R 0.684, F 0.413)] [D acc: (0.695)(0.547, 0.844)] [G loss: 1.440] [G acc: 0.047]\n",
      "5626 [D loss: (0.547)(R 0.545, F 0.549)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.541] [G acc: 0.094]\n",
      "5627 [D loss: (0.534)(R 0.615, F 0.453)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.516] [G acc: 0.062]\n",
      "5628 [D loss: (0.694)(R 0.592, F 0.795)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.424] [G acc: 0.141]\n",
      "5629 [D loss: (0.521)(R 0.585, F 0.457)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.232] [G acc: 0.172]\n",
      "5630 [D loss: (0.536)(R 0.582, F 0.490)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.405] [G acc: 0.031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5631 [D loss: (0.546)(R 0.514, F 0.578)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.353] [G acc: 0.125]\n",
      "5632 [D loss: (0.528)(R 0.496, F 0.560)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.445] [G acc: 0.062]\n",
      "5633 [D loss: (0.564)(R 0.591, F 0.536)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.269] [G acc: 0.156]\n",
      "5634 [D loss: (0.609)(R 0.521, F 0.697)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.397] [G acc: 0.047]\n",
      "5635 [D loss: (0.576)(R 0.625, F 0.527)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.386] [G acc: 0.125]\n",
      "5636 [D loss: (0.540)(R 0.594, F 0.486)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.512] [G acc: 0.125]\n",
      "5637 [D loss: (0.578)(R 0.705, F 0.452)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.288] [G acc: 0.062]\n",
      "5638 [D loss: (0.520)(R 0.498, F 0.542)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.502] [G acc: 0.094]\n",
      "5639 [D loss: (0.481)(R 0.442, F 0.519)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.344] [G acc: 0.141]\n",
      "5640 [D loss: (0.498)(R 0.471, F 0.524)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.456] [G acc: 0.078]\n",
      "5641 [D loss: (0.575)(R 0.637, F 0.513)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.481] [G acc: 0.031]\n",
      "5642 [D loss: (0.573)(R 0.580, F 0.566)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.424] [G acc: 0.047]\n",
      "5643 [D loss: (0.480)(R 0.447, F 0.513)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.437] [G acc: 0.047]\n",
      "5644 [D loss: (0.524)(R 0.498, F 0.549)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.294] [G acc: 0.109]\n",
      "5645 [D loss: (0.577)(R 0.505, F 0.650)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.420] [G acc: 0.062]\n",
      "5646 [D loss: (0.483)(R 0.580, F 0.387)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.418] [G acc: 0.125]\n",
      "5647 [D loss: (0.503)(R 0.540, F 0.465)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.334] [G acc: 0.109]\n",
      "5648 [D loss: (0.504)(R 0.512, F 0.497)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.427] [G acc: 0.062]\n",
      "5649 [D loss: (0.528)(R 0.522, F 0.533)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.430] [G acc: 0.188]\n",
      "5650 [D loss: (0.486)(R 0.513, F 0.458)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.328] [G acc: 0.078]\n",
      "5651 [D loss: (0.646)(R 0.662, F 0.630)] [D acc: (0.625)(0.516, 0.734)] [G loss: 1.443] [G acc: 0.062]\n",
      "5652 [D loss: (0.483)(R 0.548, F 0.417)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.395] [G acc: 0.078]\n",
      "5653 [D loss: (0.647)(R 0.600, F 0.695)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.388] [G acc: 0.109]\n",
      "5654 [D loss: (0.629)(R 0.755, F 0.504)] [D acc: (0.656)(0.516, 0.797)] [G loss: 1.298] [G acc: 0.125]\n",
      "5655 [D loss: (0.525)(R 0.572, F 0.477)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.290] [G acc: 0.094]\n",
      "5656 [D loss: (0.521)(R 0.570, F 0.471)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.394] [G acc: 0.078]\n",
      "5657 [D loss: (0.575)(R 0.450, F 0.699)] [D acc: (0.789)(0.797, 0.781)] [G loss: 1.427] [G acc: 0.094]\n",
      "5658 [D loss: (0.493)(R 0.568, F 0.418)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.403] [G acc: 0.031]\n",
      "5659 [D loss: (0.621)(R 0.380, F 0.863)] [D acc: (0.758)(0.828, 0.688)] [G loss: 1.413] [G acc: 0.078]\n",
      "5660 [D loss: (0.573)(R 0.644, F 0.503)] [D acc: (0.766)(0.609, 0.922)] [G loss: 1.435] [G acc: 0.031]\n",
      "5661 [D loss: (0.565)(R 0.609, F 0.520)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.477] [G acc: 0.047]\n",
      "5662 [D loss: (0.490)(R 0.570, F 0.410)] [D acc: (0.734)(0.562, 0.906)] [G loss: 1.486] [G acc: 0.047]\n",
      "5663 [D loss: (0.501)(R 0.471, F 0.530)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.532] [G acc: 0.094]\n",
      "5664 [D loss: (0.613)(R 0.627, F 0.599)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.529] [G acc: 0.031]\n",
      "5665 [D loss: (0.585)(R 0.618, F 0.552)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.458] [G acc: 0.078]\n",
      "5666 [D loss: (0.460)(R 0.457, F 0.464)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.419] [G acc: 0.125]\n",
      "5667 [D loss: (0.513)(R 0.535, F 0.490)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.488] [G acc: 0.047]\n",
      "5668 [D loss: (0.441)(R 0.411, F 0.471)] [D acc: (0.820)(0.781, 0.859)] [G loss: 1.370] [G acc: 0.141]\n",
      "5669 [D loss: (0.493)(R 0.532, F 0.454)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.362] [G acc: 0.172]\n",
      "5670 [D loss: (0.532)(R 0.614, F 0.450)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.407] [G acc: 0.109]\n",
      "5671 [D loss: (0.525)(R 0.479, F 0.572)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.296] [G acc: 0.109]\n",
      "5672 [D loss: (0.587)(R 0.540, F 0.634)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.476] [G acc: 0.078]\n",
      "5673 [D loss: (0.488)(R 0.472, F 0.505)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.436] [G acc: 0.062]\n",
      "5674 [D loss: (0.559)(R 0.669, F 0.449)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.407] [G acc: 0.078]\n",
      "5675 [D loss: (0.593)(R 0.479, F 0.708)] [D acc: (0.672)(0.719, 0.625)] [G loss: 1.476] [G acc: 0.078]\n",
      "5676 [D loss: (0.615)(R 0.782, F 0.448)] [D acc: (0.680)(0.500, 0.859)] [G loss: 1.447] [G acc: 0.078]\n",
      "5677 [D loss: (0.507)(R 0.481, F 0.533)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.447] [G acc: 0.062]\n",
      "5678 [D loss: (0.545)(R 0.583, F 0.507)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.241] [G acc: 0.141]\n",
      "5679 [D loss: (0.627)(R 0.662, F 0.593)] [D acc: (0.633)(0.562, 0.703)] [G loss: 1.324] [G acc: 0.094]\n",
      "5680 [D loss: (0.471)(R 0.460, F 0.482)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.494] [G acc: 0.047]\n",
      "5681 [D loss: (0.444)(R 0.489, F 0.400)] [D acc: (0.820)(0.750, 0.891)] [G loss: 1.502] [G acc: 0.094]\n",
      "5682 [D loss: (0.574)(R 0.618, F 0.529)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.485] [G acc: 0.062]\n",
      "5683 [D loss: (0.624)(R 0.729, F 0.520)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.203] [G acc: 0.219]\n",
      "5684 [D loss: (0.582)(R 0.663, F 0.501)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.195] [G acc: 0.219]\n",
      "5685 [D loss: (0.495)(R 0.417, F 0.572)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.338] [G acc: 0.109]\n",
      "5686 [D loss: (0.572)(R 0.640, F 0.505)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.385] [G acc: 0.109]\n",
      "5687 [D loss: (0.543)(R 0.582, F 0.505)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.349] [G acc: 0.062]\n",
      "5688 [D loss: (0.511)(R 0.501, F 0.520)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.334] [G acc: 0.047]\n",
      "5689 [D loss: (0.553)(R 0.611, F 0.494)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.388] [G acc: 0.125]\n",
      "5690 [D loss: (0.503)(R 0.437, F 0.570)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.452] [G acc: 0.078]\n",
      "5691 [D loss: (0.581)(R 0.692, F 0.471)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.413] [G acc: 0.141]\n",
      "5692 [D loss: (0.451)(R 0.468, F 0.434)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.532] [G acc: 0.125]\n",
      "5693 [D loss: (0.541)(R 0.488, F 0.593)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.330] [G acc: 0.094]\n",
      "5694 [D loss: (0.551)(R 0.454, F 0.649)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.369] [G acc: 0.172]\n",
      "5695 [D loss: (0.596)(R 0.577, F 0.614)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.466] [G acc: 0.109]\n",
      "5696 [D loss: (0.527)(R 0.579, F 0.475)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.447] [G acc: 0.109]\n",
      "5697 [D loss: (0.534)(R 0.481, F 0.587)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.511] [G acc: 0.094]\n",
      "5698 [D loss: (0.505)(R 0.585, F 0.424)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.510] [G acc: 0.062]\n",
      "5699 [D loss: (0.529)(R 0.605, F 0.454)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.581] [G acc: 0.156]\n",
      "5700 [D loss: (0.487)(R 0.562, F 0.411)] [D acc: (0.766)(0.609, 0.922)] [G loss: 1.766] [G acc: 0.016]\n",
      "5701 [D loss: (0.509)(R 0.456, F 0.562)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.627] [G acc: 0.047]\n",
      "5702 [D loss: (0.505)(R 0.427, F 0.584)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.514] [G acc: 0.062]\n",
      "5703 [D loss: (0.524)(R 0.572, F 0.477)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.558] [G acc: 0.094]\n",
      "5704 [D loss: (0.611)(R 0.676, F 0.546)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.404] [G acc: 0.094]\n",
      "5705 [D loss: (0.530)(R 0.504, F 0.557)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.366] [G acc: 0.141]\n",
      "5706 [D loss: (0.481)(R 0.492, F 0.470)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.404] [G acc: 0.125]\n",
      "5707 [D loss: (0.526)(R 0.522, F 0.529)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.649] [G acc: 0.078]\n",
      "5708 [D loss: (0.442)(R 0.492, F 0.391)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.699] [G acc: 0.000]\n",
      "5709 [D loss: (0.515)(R 0.468, F 0.561)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.576] [G acc: 0.078]\n",
      "5710 [D loss: (0.550)(R 0.668, F 0.432)] [D acc: (0.719)(0.531, 0.906)] [G loss: 1.404] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5711 [D loss: (0.552)(R 0.398, F 0.706)] [D acc: (0.727)(0.781, 0.672)] [G loss: 1.537] [G acc: 0.094]\n",
      "5712 [D loss: (0.491)(R 0.521, F 0.460)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.463] [G acc: 0.047]\n",
      "5713 [D loss: (0.548)(R 0.582, F 0.515)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.520] [G acc: 0.078]\n",
      "5714 [D loss: (0.538)(R 0.537, F 0.540)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.546] [G acc: 0.078]\n",
      "5715 [D loss: (0.629)(R 0.636, F 0.621)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.569] [G acc: 0.062]\n",
      "5716 [D loss: (0.624)(R 0.737, F 0.511)] [D acc: (0.602)(0.453, 0.750)] [G loss: 1.486] [G acc: 0.062]\n",
      "5717 [D loss: (0.554)(R 0.650, F 0.458)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.540] [G acc: 0.078]\n",
      "5718 [D loss: (0.578)(R 0.557, F 0.598)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.500] [G acc: 0.031]\n",
      "5719 [D loss: (0.572)(R 0.636, F 0.507)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.423] [G acc: 0.078]\n",
      "5720 [D loss: (0.567)(R 0.673, F 0.462)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.453] [G acc: 0.047]\n",
      "5721 [D loss: (0.626)(R 0.647, F 0.605)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.295] [G acc: 0.141]\n",
      "5722 [D loss: (0.529)(R 0.535, F 0.524)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.432] [G acc: 0.047]\n",
      "5723 [D loss: (0.559)(R 0.638, F 0.481)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.299] [G acc: 0.156]\n",
      "5724 [D loss: (0.477)(R 0.477, F 0.476)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.290] [G acc: 0.125]\n",
      "5725 [D loss: (0.488)(R 0.400, F 0.576)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.382] [G acc: 0.141]\n",
      "5726 [D loss: (0.509)(R 0.495, F 0.524)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.471] [G acc: 0.141]\n",
      "5727 [D loss: (0.551)(R 0.544, F 0.559)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.525] [G acc: 0.062]\n",
      "5728 [D loss: (0.560)(R 0.658, F 0.462)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.394] [G acc: 0.078]\n",
      "5729 [D loss: (0.514)(R 0.648, F 0.380)] [D acc: (0.750)(0.547, 0.953)] [G loss: 1.392] [G acc: 0.062]\n",
      "5730 [D loss: (0.603)(R 0.584, F 0.622)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.377] [G acc: 0.062]\n",
      "5731 [D loss: (0.565)(R 0.616, F 0.514)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.375] [G acc: 0.078]\n",
      "5732 [D loss: (0.481)(R 0.479, F 0.483)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.347] [G acc: 0.109]\n",
      "5733 [D loss: (0.574)(R 0.603, F 0.546)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.425] [G acc: 0.094]\n",
      "5734 [D loss: (0.499)(R 0.479, F 0.519)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.273] [G acc: 0.141]\n",
      "5735 [D loss: (0.547)(R 0.548, F 0.547)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.412] [G acc: 0.094]\n",
      "5736 [D loss: (0.616)(R 0.682, F 0.549)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.417] [G acc: 0.047]\n",
      "5737 [D loss: (0.579)(R 0.652, F 0.506)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.240] [G acc: 0.109]\n",
      "5738 [D loss: (0.529)(R 0.479, F 0.580)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.357] [G acc: 0.094]\n",
      "5739 [D loss: (0.549)(R 0.530, F 0.569)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.354] [G acc: 0.125]\n",
      "5740 [D loss: (0.539)(R 0.575, F 0.504)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.385] [G acc: 0.078]\n",
      "5741 [D loss: (0.483)(R 0.533, F 0.433)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.367] [G acc: 0.156]\n",
      "5742 [D loss: (0.608)(R 0.665, F 0.551)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.287] [G acc: 0.109]\n",
      "5743 [D loss: (0.523)(R 0.523, F 0.523)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.327] [G acc: 0.078]\n",
      "5744 [D loss: (0.492)(R 0.460, F 0.524)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.344] [G acc: 0.125]\n",
      "5745 [D loss: (0.483)(R 0.467, F 0.499)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.331] [G acc: 0.094]\n",
      "5746 [D loss: (0.504)(R 0.514, F 0.493)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.855] [G acc: 0.078]\n",
      "5747 [D loss: (0.483)(R 0.593, F 0.373)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.622] [G acc: 0.031]\n",
      "5748 [D loss: (0.449)(R 0.365, F 0.533)] [D acc: (0.805)(0.812, 0.797)] [G loss: 1.556] [G acc: 0.047]\n",
      "5749 [D loss: (0.522)(R 0.539, F 0.504)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.366] [G acc: 0.109]\n",
      "5750 [D loss: (0.497)(R 0.446, F 0.548)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.518] [G acc: 0.094]\n",
      "5751 [D loss: (0.498)(R 0.486, F 0.511)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.459] [G acc: 0.047]\n",
      "5752 [D loss: (0.527)(R 0.629, F 0.426)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.392] [G acc: 0.203]\n",
      "5753 [D loss: (0.481)(R 0.482, F 0.479)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.487] [G acc: 0.078]\n",
      "5754 [D loss: (0.473)(R 0.453, F 0.493)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.578] [G acc: 0.094]\n",
      "5755 [D loss: (0.547)(R 0.524, F 0.569)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.456] [G acc: 0.062]\n",
      "5756 [D loss: (0.560)(R 0.589, F 0.531)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.344] [G acc: 0.172]\n",
      "5757 [D loss: (0.532)(R 0.620, F 0.444)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.360] [G acc: 0.172]\n",
      "5758 [D loss: (0.516)(R 0.457, F 0.575)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.534] [G acc: 0.078]\n",
      "5759 [D loss: (0.493)(R 0.449, F 0.537)] [D acc: (0.766)(0.812, 0.719)] [G loss: 1.351] [G acc: 0.109]\n",
      "5760 [D loss: (0.538)(R 0.568, F 0.508)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.637] [G acc: 0.047]\n",
      "5761 [D loss: (0.399)(R 0.410, F 0.389)] [D acc: (0.836)(0.797, 0.875)] [G loss: 1.519] [G acc: 0.078]\n",
      "5762 [D loss: (0.569)(R 0.385, F 0.752)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.510] [G acc: 0.031]\n",
      "5763 [D loss: (0.583)(R 0.799, F 0.366)] [D acc: (0.656)(0.453, 0.859)] [G loss: 1.402] [G acc: 0.125]\n",
      "5764 [D loss: (0.400)(R 0.386, F 0.415)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.452] [G acc: 0.078]\n",
      "5765 [D loss: (0.420)(R 0.380, F 0.460)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.564] [G acc: 0.109]\n",
      "5766 [D loss: (0.520)(R 0.506, F 0.534)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.609] [G acc: 0.125]\n",
      "5767 [D loss: (0.517)(R 0.644, F 0.391)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.630] [G acc: 0.031]\n",
      "5768 [D loss: (0.584)(R 0.515, F 0.653)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.409] [G acc: 0.109]\n",
      "5769 [D loss: (0.488)(R 0.546, F 0.430)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.687] [G acc: 0.047]\n",
      "5770 [D loss: (0.465)(R 0.519, F 0.411)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.547] [G acc: 0.156]\n",
      "5771 [D loss: (0.481)(R 0.470, F 0.491)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.521] [G acc: 0.094]\n",
      "5772 [D loss: (0.552)(R 0.408, F 0.697)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.577] [G acc: 0.094]\n",
      "5773 [D loss: (0.517)(R 0.602, F 0.432)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.740] [G acc: 0.047]\n",
      "5774 [D loss: (0.653)(R 0.608, F 0.697)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.544] [G acc: 0.125]\n",
      "5775 [D loss: (0.505)(R 0.552, F 0.458)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.646] [G acc: 0.031]\n",
      "5776 [D loss: (0.478)(R 0.474, F 0.483)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.347] [G acc: 0.188]\n",
      "5777 [D loss: (0.409)(R 0.417, F 0.400)] [D acc: (0.812)(0.719, 0.906)] [G loss: 1.705] [G acc: 0.125]\n",
      "5778 [D loss: (0.456)(R 0.479, F 0.433)] [D acc: (0.797)(0.688, 0.906)] [G loss: 1.631] [G acc: 0.109]\n",
      "5779 [D loss: (0.458)(R 0.432, F 0.483)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.684] [G acc: 0.062]\n",
      "5780 [D loss: (0.552)(R 0.571, F 0.532)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.557] [G acc: 0.094]\n",
      "5781 [D loss: (0.472)(R 0.504, F 0.439)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.561] [G acc: 0.031]\n",
      "5782 [D loss: (0.510)(R 0.442, F 0.578)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.521] [G acc: 0.094]\n",
      "5783 [D loss: (0.489)(R 0.508, F 0.470)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.471] [G acc: 0.094]\n",
      "5784 [D loss: (0.576)(R 0.513, F 0.639)] [D acc: (0.695)(0.734, 0.656)] [G loss: 1.454] [G acc: 0.141]\n",
      "5785 [D loss: (0.545)(R 0.613, F 0.477)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.631] [G acc: 0.031]\n",
      "5786 [D loss: (0.546)(R 0.600, F 0.492)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.548] [G acc: 0.062]\n",
      "5787 [D loss: (0.516)(R 0.563, F 0.468)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.565] [G acc: 0.109]\n",
      "5788 [D loss: (0.471)(R 0.526, F 0.416)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.636] [G acc: 0.062]\n",
      "5789 [D loss: (0.462)(R 0.501, F 0.423)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.629] [G acc: 0.062]\n",
      "5790 [D loss: (0.655)(R 0.513, F 0.797)] [D acc: (0.633)(0.641, 0.625)] [G loss: 1.623] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5791 [D loss: (0.529)(R 0.702, F 0.356)] [D acc: (0.734)(0.578, 0.891)] [G loss: 1.609] [G acc: 0.031]\n",
      "5792 [D loss: (0.516)(R 0.586, F 0.445)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.434] [G acc: 0.156]\n",
      "5793 [D loss: (0.489)(R 0.464, F 0.513)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.419] [G acc: 0.109]\n",
      "5794 [D loss: (0.606)(R 0.665, F 0.547)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.452] [G acc: 0.109]\n",
      "5795 [D loss: (0.528)(R 0.624, F 0.431)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.378] [G acc: 0.109]\n",
      "5796 [D loss: (0.533)(R 0.483, F 0.584)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.526] [G acc: 0.109]\n",
      "5797 [D loss: (0.515)(R 0.579, F 0.451)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.657] [G acc: 0.047]\n",
      "5798 [D loss: (0.509)(R 0.550, F 0.467)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.358] [G acc: 0.141]\n",
      "5799 [D loss: (0.627)(R 0.607, F 0.647)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.591] [G acc: 0.047]\n",
      "5800 [D loss: (0.558)(R 0.625, F 0.490)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.341] [G acc: 0.094]\n",
      "5801 [D loss: (0.591)(R 0.622, F 0.560)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.515] [G acc: 0.078]\n",
      "5802 [D loss: (0.456)(R 0.537, F 0.375)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.477] [G acc: 0.078]\n",
      "5803 [D loss: (0.482)(R 0.434, F 0.530)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.249] [G acc: 0.156]\n",
      "5804 [D loss: (0.505)(R 0.523, F 0.488)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.326] [G acc: 0.125]\n",
      "5805 [D loss: (0.603)(R 0.615, F 0.592)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.633] [G acc: 0.094]\n",
      "5806 [D loss: (0.558)(R 0.651, F 0.465)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.518] [G acc: 0.047]\n",
      "5807 [D loss: (0.490)(R 0.545, F 0.435)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.240] [G acc: 0.188]\n",
      "5808 [D loss: (0.521)(R 0.492, F 0.550)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.543] [G acc: 0.047]\n",
      "5809 [D loss: (0.533)(R 0.552, F 0.514)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.572] [G acc: 0.016]\n",
      "5810 [D loss: (0.494)(R 0.537, F 0.450)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.422] [G acc: 0.109]\n",
      "5811 [D loss: (0.435)(R 0.398, F 0.472)] [D acc: (0.820)(0.719, 0.922)] [G loss: 1.558] [G acc: 0.047]\n",
      "5812 [D loss: (0.481)(R 0.522, F 0.440)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.451] [G acc: 0.047]\n",
      "5813 [D loss: (0.484)(R 0.552, F 0.416)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.435] [G acc: 0.125]\n",
      "5814 [D loss: (0.569)(R 0.539, F 0.599)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.554] [G acc: 0.047]\n",
      "5815 [D loss: (0.445)(R 0.463, F 0.426)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.375] [G acc: 0.109]\n",
      "5816 [D loss: (0.532)(R 0.561, F 0.502)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.530] [G acc: 0.094]\n",
      "5817 [D loss: (0.562)(R 0.633, F 0.490)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.545] [G acc: 0.062]\n",
      "5818 [D loss: (0.557)(R 0.521, F 0.593)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.547] [G acc: 0.062]\n",
      "5819 [D loss: (0.607)(R 0.700, F 0.514)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.449] [G acc: 0.109]\n",
      "5820 [D loss: (0.437)(R 0.428, F 0.445)] [D acc: (0.836)(0.812, 0.859)] [G loss: 1.477] [G acc: 0.125]\n",
      "5821 [D loss: (0.472)(R 0.470, F 0.474)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.528] [G acc: 0.141]\n",
      "5822 [D loss: (0.570)(R 0.666, F 0.475)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.516] [G acc: 0.094]\n",
      "5823 [D loss: (0.503)(R 0.542, F 0.465)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.373] [G acc: 0.125]\n",
      "5824 [D loss: (0.539)(R 0.601, F 0.477)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.389] [G acc: 0.156]\n",
      "5825 [D loss: (0.503)(R 0.516, F 0.491)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.413] [G acc: 0.078]\n",
      "5826 [D loss: (0.461)(R 0.439, F 0.483)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.507] [G acc: 0.078]\n",
      "5827 [D loss: (0.523)(R 0.580, F 0.466)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.474] [G acc: 0.141]\n",
      "5828 [D loss: (0.481)(R 0.435, F 0.526)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.623] [G acc: 0.078]\n",
      "5829 [D loss: (0.631)(R 0.548, F 0.714)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.650] [G acc: 0.062]\n",
      "5830 [D loss: (0.486)(R 0.571, F 0.401)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.613] [G acc: 0.062]\n",
      "5831 [D loss: (0.535)(R 0.529, F 0.540)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.592] [G acc: 0.078]\n",
      "5832 [D loss: (0.566)(R 0.610, F 0.521)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.661] [G acc: 0.000]\n",
      "5833 [D loss: (0.530)(R 0.439, F 0.621)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.567] [G acc: 0.109]\n",
      "5834 [D loss: (0.614)(R 0.677, F 0.550)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.634] [G acc: 0.016]\n",
      "5835 [D loss: (0.512)(R 0.454, F 0.570)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.618] [G acc: 0.031]\n",
      "5836 [D loss: (0.542)(R 0.605, F 0.478)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.561] [G acc: 0.078]\n",
      "5837 [D loss: (0.664)(R 0.740, F 0.587)] [D acc: (0.633)(0.516, 0.750)] [G loss: 1.554] [G acc: 0.094]\n",
      "5838 [D loss: (0.494)(R 0.584, F 0.405)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.544] [G acc: 0.109]\n",
      "5839 [D loss: (0.569)(R 0.453, F 0.685)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.566] [G acc: 0.031]\n",
      "5840 [D loss: (0.580)(R 0.654, F 0.505)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.480] [G acc: 0.094]\n",
      "5841 [D loss: (0.489)(R 0.526, F 0.452)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.446] [G acc: 0.109]\n",
      "5842 [D loss: (0.512)(R 0.537, F 0.487)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.509] [G acc: 0.109]\n",
      "5843 [D loss: (0.467)(R 0.525, F 0.408)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.469] [G acc: 0.094]\n",
      "5844 [D loss: (0.512)(R 0.499, F 0.525)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.518] [G acc: 0.094]\n",
      "5845 [D loss: (0.561)(R 0.548, F 0.574)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.518] [G acc: 0.078]\n",
      "5846 [D loss: (0.555)(R 0.562, F 0.548)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.639] [G acc: 0.078]\n",
      "5847 [D loss: (0.483)(R 0.541, F 0.425)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.504] [G acc: 0.031]\n",
      "5848 [D loss: (0.485)(R 0.537, F 0.432)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.387] [G acc: 0.094]\n",
      "5849 [D loss: (0.485)(R 0.404, F 0.566)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.543] [G acc: 0.094]\n",
      "5850 [D loss: (0.455)(R 0.510, F 0.400)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.600] [G acc: 0.094]\n",
      "5851 [D loss: (0.586)(R 0.693, F 0.479)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.418] [G acc: 0.094]\n",
      "5852 [D loss: (0.498)(R 0.503, F 0.494)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.401] [G acc: 0.109]\n",
      "5853 [D loss: (0.560)(R 0.538, F 0.582)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.410] [G acc: 0.109]\n",
      "5854 [D loss: (0.533)(R 0.544, F 0.522)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.959] [G acc: 0.016]\n",
      "5855 [D loss: (0.410)(R 0.524, F 0.297)] [D acc: (0.789)(0.641, 0.938)] [G loss: 1.656] [G acc: 0.031]\n",
      "5856 [D loss: (0.449)(R 0.449, F 0.448)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.698] [G acc: 0.000]\n",
      "5857 [D loss: (0.559)(R 0.432, F 0.685)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.517] [G acc: 0.094]\n",
      "5858 [D loss: (0.701)(R 0.660, F 0.741)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.485] [G acc: 0.078]\n",
      "5859 [D loss: (0.650)(R 0.790, F 0.510)] [D acc: (0.602)(0.391, 0.812)] [G loss: 1.173] [G acc: 0.203]\n",
      "5860 [D loss: (0.541)(R 0.411, F 0.670)] [D acc: (0.750)(0.781, 0.719)] [G loss: 1.442] [G acc: 0.094]\n",
      "5861 [D loss: (0.602)(R 0.661, F 0.543)] [D acc: (0.648)(0.547, 0.750)] [G loss: 1.445] [G acc: 0.109]\n",
      "5862 [D loss: (0.613)(R 0.773, F 0.453)] [D acc: (0.703)(0.547, 0.859)] [G loss: 1.382] [G acc: 0.062]\n",
      "5863 [D loss: (0.534)(R 0.503, F 0.566)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.471] [G acc: 0.094]\n",
      "5864 [D loss: (0.486)(R 0.557, F 0.416)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.291] [G acc: 0.109]\n",
      "5865 [D loss: (0.509)(R 0.409, F 0.608)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.460] [G acc: 0.078]\n",
      "5866 [D loss: (0.518)(R 0.549, F 0.486)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.378] [G acc: 0.078]\n",
      "5867 [D loss: (0.604)(R 0.532, F 0.675)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.555] [G acc: 0.078]\n",
      "5868 [D loss: (0.505)(R 0.546, F 0.463)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.352] [G acc: 0.141]\n",
      "5869 [D loss: (0.534)(R 0.615, F 0.453)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.352] [G acc: 0.094]\n",
      "5870 [D loss: (0.545)(R 0.605, F 0.485)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.273] [G acc: 0.156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5871 [D loss: (0.450)(R 0.506, F 0.393)] [D acc: (0.812)(0.672, 0.953)] [G loss: 1.522] [G acc: 0.109]\n",
      "5872 [D loss: (0.467)(R 0.415, F 0.519)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.541] [G acc: 0.047]\n",
      "5873 [D loss: (0.483)(R 0.422, F 0.543)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.449] [G acc: 0.047]\n",
      "5874 [D loss: (0.568)(R 0.615, F 0.522)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.401] [G acc: 0.094]\n",
      "5875 [D loss: (0.619)(R 0.560, F 0.678)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.496] [G acc: 0.109]\n",
      "5876 [D loss: (0.440)(R 0.522, F 0.358)] [D acc: (0.828)(0.750, 0.906)] [G loss: 1.372] [G acc: 0.109]\n",
      "5877 [D loss: (0.588)(R 0.445, F 0.730)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.659] [G acc: 0.047]\n",
      "5878 [D loss: (0.619)(R 0.612, F 0.626)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.517] [G acc: 0.062]\n",
      "5879 [D loss: (0.530)(R 0.593, F 0.467)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.416] [G acc: 0.109]\n",
      "5880 [D loss: (0.538)(R 0.526, F 0.550)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.485] [G acc: 0.109]\n",
      "5881 [D loss: (0.543)(R 0.617, F 0.468)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.455] [G acc: 0.062]\n",
      "5882 [D loss: (0.531)(R 0.510, F 0.553)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.506] [G acc: 0.078]\n",
      "5883 [D loss: (0.594)(R 0.653, F 0.535)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.460] [G acc: 0.062]\n",
      "5884 [D loss: (0.602)(R 0.577, F 0.628)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.568] [G acc: 0.047]\n",
      "5885 [D loss: (0.596)(R 0.622, F 0.570)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.573] [G acc: 0.031]\n",
      "5886 [D loss: (0.548)(R 0.613, F 0.483)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.371] [G acc: 0.141]\n",
      "5887 [D loss: (0.504)(R 0.518, F 0.489)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.294] [G acc: 0.078]\n",
      "5888 [D loss: (0.498)(R 0.441, F 0.555)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.388] [G acc: 0.109]\n",
      "5889 [D loss: (0.464)(R 0.487, F 0.442)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.343] [G acc: 0.156]\n",
      "5890 [D loss: (0.509)(R 0.478, F 0.541)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.441] [G acc: 0.141]\n",
      "5891 [D loss: (0.470)(R 0.502, F 0.438)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.656] [G acc: 0.062]\n",
      "5892 [D loss: (0.551)(R 0.571, F 0.531)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.440] [G acc: 0.078]\n",
      "5893 [D loss: (0.481)(R 0.427, F 0.535)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.423] [G acc: 0.094]\n",
      "5894 [D loss: (0.503)(R 0.507, F 0.499)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.714] [G acc: 0.062]\n",
      "5895 [D loss: (0.555)(R 0.689, F 0.421)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.535] [G acc: 0.062]\n",
      "5896 [D loss: (0.579)(R 0.597, F 0.562)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.470] [G acc: 0.109]\n",
      "5897 [D loss: (0.550)(R 0.634, F 0.466)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.472] [G acc: 0.078]\n",
      "5898 [D loss: (0.620)(R 0.623, F 0.618)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.432] [G acc: 0.109]\n",
      "5899 [D loss: (0.505)(R 0.543, F 0.466)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.283] [G acc: 0.125]\n",
      "5900 [D loss: (0.601)(R 0.608, F 0.594)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.378] [G acc: 0.094]\n",
      "5901 [D loss: (0.544)(R 0.582, F 0.506)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.487] [G acc: 0.031]\n",
      "5902 [D loss: (0.632)(R 0.665, F 0.599)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.338] [G acc: 0.094]\n",
      "5903 [D loss: (0.592)(R 0.632, F 0.552)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.385] [G acc: 0.047]\n",
      "5904 [D loss: (0.537)(R 0.574, F 0.499)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.404] [G acc: 0.078]\n",
      "5905 [D loss: (0.572)(R 0.621, F 0.524)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.342] [G acc: 0.141]\n",
      "5906 [D loss: (0.595)(R 0.600, F 0.590)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.402] [G acc: 0.078]\n",
      "5907 [D loss: (0.497)(R 0.493, F 0.502)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.579] [G acc: 0.078]\n",
      "5908 [D loss: (0.446)(R 0.511, F 0.381)] [D acc: (0.812)(0.703, 0.922)] [G loss: 1.512] [G acc: 0.094]\n",
      "5909 [D loss: (0.473)(R 0.519, F 0.428)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.579] [G acc: 0.094]\n",
      "5910 [D loss: (0.477)(R 0.461, F 0.492)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.546] [G acc: 0.109]\n",
      "5911 [D loss: (0.573)(R 0.526, F 0.620)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.400] [G acc: 0.125]\n",
      "5912 [D loss: (0.596)(R 0.736, F 0.456)] [D acc: (0.695)(0.531, 0.859)] [G loss: 1.511] [G acc: 0.062]\n",
      "5913 [D loss: (0.540)(R 0.494, F 0.587)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.487] [G acc: 0.062]\n",
      "5914 [D loss: (0.597)(R 0.538, F 0.656)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.522] [G acc: 0.094]\n",
      "5915 [D loss: (0.518)(R 0.612, F 0.424)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.390] [G acc: 0.062]\n",
      "5916 [D loss: (0.485)(R 0.442, F 0.527)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.474] [G acc: 0.125]\n",
      "5917 [D loss: (0.512)(R 0.565, F 0.460)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.418] [G acc: 0.078]\n",
      "5918 [D loss: (0.512)(R 0.527, F 0.497)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.523] [G acc: 0.062]\n",
      "5919 [D loss: (0.457)(R 0.504, F 0.409)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.484] [G acc: 0.047]\n",
      "5920 [D loss: (0.535)(R 0.564, F 0.505)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.539] [G acc: 0.016]\n",
      "5921 [D loss: (0.461)(R 0.462, F 0.459)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.452] [G acc: 0.094]\n",
      "5922 [D loss: (0.554)(R 0.564, F 0.544)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.300] [G acc: 0.078]\n",
      "5923 [D loss: (0.570)(R 0.561, F 0.578)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.499] [G acc: 0.062]\n",
      "5924 [D loss: (0.450)(R 0.463, F 0.436)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.471] [G acc: 0.094]\n",
      "5925 [D loss: (0.559)(R 0.581, F 0.536)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.418] [G acc: 0.109]\n",
      "5926 [D loss: (0.612)(R 0.658, F 0.565)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.199] [G acc: 0.125]\n",
      "5927 [D loss: (0.499)(R 0.517, F 0.482)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.408] [G acc: 0.125]\n",
      "5928 [D loss: (0.474)(R 0.329, F 0.618)] [D acc: (0.789)(0.844, 0.734)] [G loss: 1.384] [G acc: 0.141]\n",
      "5929 [D loss: (0.526)(R 0.516, F 0.536)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.712] [G acc: 0.016]\n",
      "5930 [D loss: (0.437)(R 0.540, F 0.334)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.725] [G acc: 0.031]\n",
      "5931 [D loss: (0.498)(R 0.521, F 0.474)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.521] [G acc: 0.016]\n",
      "5932 [D loss: (0.471)(R 0.526, F 0.416)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.512] [G acc: 0.109]\n",
      "5933 [D loss: (0.509)(R 0.398, F 0.621)] [D acc: (0.695)(0.766, 0.625)] [G loss: 1.468] [G acc: 0.125]\n",
      "5934 [D loss: (0.577)(R 0.671, F 0.482)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.551] [G acc: 0.094]\n",
      "5935 [D loss: (0.511)(R 0.525, F 0.497)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.512] [G acc: 0.094]\n",
      "5936 [D loss: (0.530)(R 0.538, F 0.521)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.411] [G acc: 0.078]\n",
      "5937 [D loss: (0.526)(R 0.630, F 0.422)] [D acc: (0.664)(0.516, 0.812)] [G loss: 1.540] [G acc: 0.094]\n",
      "5938 [D loss: (0.514)(R 0.455, F 0.573)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.515] [G acc: 0.062]\n",
      "5939 [D loss: (0.509)(R 0.585, F 0.433)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.841] [G acc: 0.062]\n",
      "5940 [D loss: (0.568)(R 0.759, F 0.376)] [D acc: (0.719)(0.531, 0.906)] [G loss: 1.735] [G acc: 0.031]\n",
      "5941 [D loss: (0.537)(R 0.579, F 0.495)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.556] [G acc: 0.109]\n",
      "5942 [D loss: (0.472)(R 0.395, F 0.548)] [D acc: (0.758)(0.781, 0.734)] [G loss: 1.375] [G acc: 0.125]\n",
      "5943 [D loss: (0.576)(R 0.564, F 0.588)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.536] [G acc: 0.094]\n",
      "5944 [D loss: (0.558)(R 0.633, F 0.482)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.345] [G acc: 0.141]\n",
      "5945 [D loss: (0.485)(R 0.436, F 0.533)] [D acc: (0.766)(0.781, 0.750)] [G loss: 1.394] [G acc: 0.094]\n",
      "5946 [D loss: (0.599)(R 0.584, F 0.614)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.565] [G acc: 0.094]\n",
      "5947 [D loss: (0.528)(R 0.640, F 0.416)] [D acc: (0.766)(0.625, 0.906)] [G loss: 1.364] [G acc: 0.141]\n",
      "5948 [D loss: (0.505)(R 0.502, F 0.509)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.359] [G acc: 0.094]\n",
      "5949 [D loss: (0.491)(R 0.519, F 0.462)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.423] [G acc: 0.141]\n",
      "5950 [D loss: (0.554)(R 0.523, F 0.586)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.521] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5951 [D loss: (0.578)(R 0.612, F 0.543)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.470] [G acc: 0.062]\n",
      "5952 [D loss: (0.590)(R 0.567, F 0.612)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.386] [G acc: 0.141]\n",
      "5953 [D loss: (0.525)(R 0.634, F 0.416)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.500] [G acc: 0.016]\n",
      "5954 [D loss: (0.582)(R 0.505, F 0.660)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.438] [G acc: 0.031]\n",
      "5955 [D loss: (0.514)(R 0.610, F 0.418)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.391] [G acc: 0.109]\n",
      "5956 [D loss: (0.471)(R 0.426, F 0.516)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.419] [G acc: 0.078]\n",
      "5957 [D loss: (0.480)(R 0.474, F 0.487)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.456] [G acc: 0.109]\n",
      "5958 [D loss: (0.551)(R 0.497, F 0.606)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.386] [G acc: 0.047]\n",
      "5959 [D loss: (0.584)(R 0.607, F 0.560)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.373] [G acc: 0.125]\n",
      "5960 [D loss: (0.499)(R 0.520, F 0.478)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.429] [G acc: 0.094]\n",
      "5961 [D loss: (0.547)(R 0.538, F 0.556)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.373] [G acc: 0.078]\n",
      "5962 [D loss: (0.569)(R 0.571, F 0.567)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.503] [G acc: 0.125]\n",
      "5963 [D loss: (0.526)(R 0.546, F 0.506)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.476] [G acc: 0.047]\n",
      "5964 [D loss: (0.585)(R 0.677, F 0.492)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.449] [G acc: 0.062]\n",
      "5965 [D loss: (0.497)(R 0.521, F 0.474)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.392] [G acc: 0.078]\n",
      "5966 [D loss: (0.627)(R 0.575, F 0.679)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.289] [G acc: 0.109]\n",
      "5967 [D loss: (0.569)(R 0.636, F 0.502)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.379] [G acc: 0.047]\n",
      "5968 [D loss: (0.532)(R 0.553, F 0.511)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.302] [G acc: 0.172]\n",
      "5969 [D loss: (0.554)(R 0.553, F 0.555)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.373] [G acc: 0.109]\n",
      "5970 [D loss: (0.536)(R 0.572, F 0.500)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.300] [G acc: 0.125]\n",
      "5971 [D loss: (0.547)(R 0.482, F 0.613)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.251] [G acc: 0.156]\n",
      "5972 [D loss: (0.567)(R 0.424, F 0.710)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.368] [G acc: 0.062]\n",
      "5973 [D loss: (0.600)(R 0.608, F 0.593)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.264] [G acc: 0.141]\n",
      "5974 [D loss: (0.607)(R 0.647, F 0.566)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.422] [G acc: 0.094]\n",
      "5975 [D loss: (0.550)(R 0.628, F 0.471)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.349] [G acc: 0.156]\n",
      "5976 [D loss: (0.593)(R 0.604, F 0.583)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.464] [G acc: 0.062]\n",
      "5977 [D loss: (0.524)(R 0.524, F 0.523)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.495] [G acc: 0.141]\n",
      "5978 [D loss: (0.487)(R 0.512, F 0.462)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.422] [G acc: 0.094]\n",
      "5979 [D loss: (0.536)(R 0.472, F 0.600)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.138] [G acc: 0.266]\n",
      "5980 [D loss: (0.473)(R 0.388, F 0.558)] [D acc: (0.758)(0.797, 0.719)] [G loss: 1.399] [G acc: 0.172]\n",
      "5981 [D loss: (0.519)(R 0.606, F 0.433)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.407] [G acc: 0.047]\n",
      "5982 [D loss: (0.518)(R 0.561, F 0.475)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.464] [G acc: 0.141]\n",
      "5983 [D loss: (0.558)(R 0.620, F 0.496)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.567] [G acc: 0.047]\n",
      "5984 [D loss: (0.438)(R 0.410, F 0.467)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.445] [G acc: 0.094]\n",
      "5985 [D loss: (0.545)(R 0.588, F 0.501)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.472] [G acc: 0.125]\n",
      "5986 [D loss: (0.413)(R 0.361, F 0.465)] [D acc: (0.828)(0.828, 0.828)] [G loss: 1.513] [G acc: 0.047]\n",
      "5987 [D loss: (0.475)(R 0.525, F 0.425)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.522] [G acc: 0.062]\n",
      "5988 [D loss: (0.513)(R 0.511, F 0.515)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.532] [G acc: 0.125]\n",
      "5989 [D loss: (0.537)(R 0.551, F 0.523)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.557] [G acc: 0.016]\n",
      "5990 [D loss: (0.521)(R 0.618, F 0.424)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.395] [G acc: 0.094]\n",
      "5991 [D loss: (0.652)(R 0.671, F 0.634)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.383] [G acc: 0.062]\n",
      "5992 [D loss: (0.509)(R 0.548, F 0.470)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.486] [G acc: 0.078]\n",
      "5993 [D loss: (0.560)(R 0.521, F 0.598)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.579] [G acc: 0.109]\n",
      "5994 [D loss: (0.537)(R 0.616, F 0.458)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.515] [G acc: 0.062]\n",
      "5995 [D loss: (0.431)(R 0.383, F 0.479)] [D acc: (0.789)(0.797, 0.781)] [G loss: 1.418] [G acc: 0.172]\n",
      "5996 [D loss: (0.600)(R 0.472, F 0.729)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.661] [G acc: 0.062]\n",
      "5997 [D loss: (0.506)(R 0.512, F 0.500)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.620] [G acc: 0.062]\n",
      "5998 [D loss: (0.560)(R 0.676, F 0.445)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.463] [G acc: 0.078]\n",
      "5999 [D loss: (0.460)(R 0.501, F 0.420)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.494] [G acc: 0.109]\n"
     ]
    }
   ],
   "source": [
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[0] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "plt.ylim(0, 2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[3] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "plt.plot([x[4] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[5] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[1] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('accuracy', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
