{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization, LeakyReLU, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype(np.float32) / 255.\n",
    "x_test = x_test.astype(np.float32) / 255.\n",
    "\n",
    "y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture - Simple Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(32, 32, 3))\n",
    "\n",
    "conv_layer_1 = Conv2D(\n",
    "    filters=10,\n",
    "    kernel_size=(4, 4),\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    activation='relu'\n",
    "    )(input_layer)\n",
    "\n",
    "conv_layer_2 = Conv2D(\n",
    "    filters=20,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    activation='relu'\n",
    "    )(conv_layer_1)\n",
    "\n",
    "flatten_layer = Flatten()(conv_layer_2)\n",
    "\n",
    "output_layer = Dense(units=10, activation='softmax')(flatten_layer)\n",
    "\n",
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=.0005)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=50,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = np.array(['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "predictions_single = CLASSES[np.argmax(predictions, axis=-1)]\n",
    "actuals_single = CLASSES[np.argmax(y_test, axis=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(x_test)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    img = x_test[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, 'pred = ' + str(predictions_single[idx]), fontsize=10, ha='center', transform=ax.transAxes) \n",
    "    ax.text(0.5, -0.7, 'act = ' + str(actuals_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "    ax.imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture - Embelish with Dropout and Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(32, 32, 3))\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=(3, 3), strides=1, padding=\"same\")(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=(3, 3), strides=2, padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), strides=2, padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate=.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation(\"softmax\")(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=.0005)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=50,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = np.array(['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "predictions_single = CLASSES[np.argmax(predictions, axis=-1)]\n",
    "actuals_single = CLASSES[np.argmax(y_test, axis=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(x_test)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    img = x_test[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, 'pred = ' + str(predictions_single[idx]), fontsize=10, ha='center', transform=ax.transAxes) \n",
    "    ax.text(0.5, -0.7, 'act = ' + str(actuals_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "    ax.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
