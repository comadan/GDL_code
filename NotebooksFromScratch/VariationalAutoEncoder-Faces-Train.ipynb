{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "from models.VariationalAutoEncoder import VariationalAutoEncoder\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Run Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'vae'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'faces'\n",
    "if not os.path.exists(\"run\"):\n",
    "    os.mkdir(\"run\")\n",
    "if not os.path.exists(f\"run/{SECTION}\"):\n",
    "    os.mkdir(f\"run/{SECTION}\")\n",
    "RUN_FOLDER = f'run/{SECTION}/'\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "MODE =  'build' #'load' #\n",
    "\n",
    "DATA_FOLDER = './data/celeb/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (128, 128, 3)\n",
    "batch_size = 32\n",
    "reconstruction_loss_multiplier = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = np.array(glob(os.path.join(DATA_FOLDER, '*/*.jpg')))\n",
    "\n",
    "NUM_IMAGES = len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "data_flow = data_gen.flow_from_directory(DATA_FOLDER, \n",
    "                                         target_size = input_dim[:2], \n",
    "                                         batch_size = batch_size, \n",
    "                                         shuffle = True, \n",
    "                                         class_mode = 'input', \n",
    "                                         subset = \"training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the structure of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_architecture = [\n",
    "    {'filter': 32, 'kernel': (3, 3), 'stride': 2},\n",
    "    {'filter': 64, 'kernel': (3, 3), 'stride': 2},\n",
    "    {'filter': 64, 'kernel': (3, 3), 'stride': 2},\n",
    "    {'filter': 64, 'kernel': (3, 3), 'stride': 2},\n",
    "    ]\n",
    "decoder_architecture = [\n",
    "    {'filter': 64, 'kernel': (3, 3), 'stride': 2},\n",
    "    {'filter': 64, 'kernel': (3, 3), 'stride': 2},\n",
    "    {'filter': 32, 'kernel': (3, 3), 'stride': 2},\n",
    "    {'filter': 3, 'kernel': (3, 3), 'stride': 2},\n",
    "    ]\n",
    "latent_dim = 200\n",
    "use_batch_norm = True\n",
    "use_dropout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = VariationalAutoEncoder(\n",
    "    input_dim=input_dim,\n",
    "    latent_dim=latent_dim,\n",
    "    encoder_params=encoder_architecture,\n",
    "    decoder_params=decoder_architecture,\n",
    "    use_batch_norm=use_batch_norm,\n",
    "    use_dropout=use_dropout,\n",
    "    reconstruction_loss_multiplier=reconstruction_loss_multiplier,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == 'build':\n",
    "    ae.save(RUN_FOLDER)\n",
    "else:\n",
    "    ae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ae.autoencoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 32\n",
    "INITIAL_EPOCH = 0\n",
    "TOTAL_EPOCHS = 200\n",
    "PRINT_EVERY_N_BATCHES = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.compile(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ae.train_with_generator(     \n",
    "    data_flow\n",
    "    , epochs = TOTAL_EPOCHS\n",
    "    , steps_per_epoch = NUM_IMAGES / BATCH_SIZE\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , initial_epoch = INITIAL_EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
