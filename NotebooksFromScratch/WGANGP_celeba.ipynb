{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN-GP Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.WGANGP import WGANGP\n",
    "from utils.loaders import load_celeb\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'wgan'\n",
    "RUN_ID = '0003'\n",
    "DATA_NAME = 'celeb'\n",
    "RUN_FOLDER = f'run/{SECTION}/'\n",
    "RUN_FOLDER += f'{RUN_ID}_{DATA_NAME}'\n",
    "\n",
    "for p in ['run', f'run/{SECTION}']:\n",
    "    if not os.path.exists(p):\n",
    "        os.mkdir(p)\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_celeb(DATA_NAME, IMAGE_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((x_train[0][0][0]+1)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dim = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "latent_dim = 100\n",
    "\n",
    "generator_initial_dim = (4, 4, 512)\n",
    "\n",
    "generator_activation = 'leaky_relu'\n",
    "critic_activation = 'leaky_relu'\n",
    "\n",
    "critic_learning_rate = 0.0002,\n",
    "generator_learning_rate = 0.0002,\n",
    "generator_batch_norm_momentum = 0.9\n",
    "critic_batch_norm_momentum = None\n",
    "critic_dense_dim = 0\n",
    "generator_dropout_rate = None\n",
    "critic_dropout_rate = None\n",
    "\n",
    "gradient_penalty_weight = 10.\n",
    "\n",
    "generator_convolutional_params = [\n",
    "    {'strides': (2, 2), 'filters': 256, 'kernel_size': (5, 5), 'upsample': 1, 'transpose': True,},\n",
    "    {'strides': (2, 2), 'filters': 128, 'kernel_size': (5, 5), 'upsample': 1, 'transpose': True,},\n",
    "    {'strides': (2, 2), 'filters': 64, 'kernel_size': (5, 5), 'upsample': 1, 'transpose': True,},\n",
    "    {'strides': (2, 2), 'filters': 3, 'kernel_size': (5, 5), 'upsample': 1, 'transpose': True,},\n",
    "    ]\n",
    "\n",
    "critic_convolutional_params = [\n",
    "    {'strides': (2, 2), 'filters': 64, 'kernel_size': (5, 5),},\n",
    "    {'strides': (2, 2), 'filters': 128, 'kernel_size': (5, 5),},\n",
    "    {'strides': (2, 2), 'filters': 256, 'kernel_size': (5, 5),},\n",
    "    {'strides': (2, 2), 'filters': 512, 'kernel_size': (5, 5),},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gan = WGANGP(\n",
    "    image_dim=image_dim,\n",
    "    latent_dim=latent_dim,\n",
    "    generator_initial_dim=generator_initial_dim,\n",
    "    critic_dense_dim=critic_dense_dim,\n",
    "    generator_activation=generator_activation,\n",
    "    critic_activation=critic_activation,\n",
    "    generator_convolutional_params=generator_convolutional_params,\n",
    "    critic_learning_rate = critic_learning_rate,\n",
    "    generator_learning_rate = generator_learning_rate,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    critic_convolutional_params=critic_convolutional_params,\n",
    "    generator_batch_norm_momentum=generator_batch_norm_momentum,\n",
    "    critic_batch_norm_momentum=critic_batch_norm_momentum,\n",
    "    generator_dropout_rate=generator_dropout_rate,\n",
    "    critic_dropout_rate=critic_dropout_rate,\n",
    "    gradient_penalty_weight=gradient_penalty_weight,\n",
    "    )\n",
    "\n",
    "if mode == 'build':\n",
    "    gan.save(RUN_FOLDER)\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.critic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.critic_gp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generator_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 6000\n",
    "PRINT_EVERY_N_BATCHES = 5\n",
    "N_CRITIC = 5\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , critic_training_steps=N_CRITIC\n",
    "    , using_generator = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.critic_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.critic_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.critic_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[0] for x in gan.generator_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "# plt.ylim(0, 2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
