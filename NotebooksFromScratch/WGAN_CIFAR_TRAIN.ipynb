{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.WassersteinGenerativeAdversarialNetwork import WassersteinGenerativeAdversarialNetwork as WGAN\n",
    "from utils.loaders import load_cifar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'wgan'\n",
    "RUN_ID = '0002'\n",
    "DATA_NAME = 'horses'\n",
    "RUN_FOLDER = f'run/{RUN_ID}/'\n",
    "RUN_FOLDER += f'{RUN_ID}_{DATA_NAME}'\n",
    "\n",
    "for p in ['run', f'run/{RUN_ID}']:\n",
    "    if not os.path.exists(p):\n",
    "        os.mkdir(p)\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_NAME == 'cars':\n",
    "    label = 1\n",
    "elif DATA_NAME == 'horses':\n",
    "    label = 7\n",
    "(x_train, y_train) = load_cifar(label, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((x_train[150,:,:,:]+1)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dim = (32,32,3)\n",
    "latent_dim = 100\n",
    "\n",
    "generator_initial_dim = (4, 4, 128)\n",
    "\n",
    "generator_activation = 'leaky_relu'\n",
    "critic_activation = 'leaky_relu'\n",
    "\n",
    "critic_learning_rate = 0.00005,\n",
    "generator_learning_rate = 0.00005,\n",
    "generator_batch_norm_momentum = 0.8\n",
    "critic_batch_norm_momentum = None\n",
    "critic_dense_dim = 0\n",
    "generator_dropout_rate = None\n",
    "critic_dropout_rate = None\n",
    "\n",
    "generator_convolutional_params = [\n",
    "    {'strides': (1, 1), 'filters': 128, 'kernel_size': (5, 5), 'upsample': 2, },\n",
    "    {'strides': (1, 1), 'filters': 64, 'kernel_size': (5, 5), 'upsample': 2, },\n",
    "    {'strides': (1, 1), 'filters': 32, 'kernel_size': (5, 5), 'upsample': 2, },\n",
    "    {'strides': (1, 1), 'filters': 3, 'kernel_size': (5, 5), 'upsample': 1, },\n",
    "    ]\n",
    "\n",
    "critic_convolutional_params = [\n",
    "    {'strides': (2, 2), 'filters': 32, 'kernel_size': (5, 5),},\n",
    "    {'strides': (2, 2), 'filters': 64, 'kernel_size': (5, 5),},\n",
    "    {'strides': (2, 2), 'filters': 128, 'kernel_size': (5, 5),},\n",
    "    {'strides': (1, 1), 'filters': 128, 'kernel_size': (5, 5),},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'build':\n",
    "    gan = WGAN(\n",
    "        image_dim=image_dim,\n",
    "        latent_dim=latent_dim,\n",
    "        generator_initial_dim=generator_initial_dim,\n",
    "        critic_dense_dim=critic_dense_dim,\n",
    "        generator_activation=generator_activation,\n",
    "        critic_activation=critic_activation,\n",
    "        generator_convolutional_params=generator_convolutional_params,\n",
    "        critic_learning_rate = critic_learning_rate,\n",
    "        generator_learning_rate = generator_learning_rate,\n",
    "        critic_convolutional_params=critic_convolutional_params,\n",
    "        generator_batch_norm_momentum=generator_batch_norm_momentum,\n",
    "        critic_batch_norm_momentum=critic_batch_norm_momentum,\n",
    "        generator_dropout_rate=generator_dropout_rate,\n",
    "        critic_dropout_rate=critic_dropout_rate,\n",
    "        )\n",
    "    gan.save(RUN_FOLDER)\n",
    "\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.critic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generator_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 6000\n",
    "PRINT_EVERY_N_BATCHES = 5\n",
    "N_CRITIC = 5\n",
    "CLIP_THRESHOLD = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size=BATCH_SIZE\n",
    "    , epochs=EPOCHS\n",
    "    , run_folder=RUN_FOLDER\n",
    "    , print_every_n_batches=PRINT_EVERY_N_BATCHES\n",
    "    , critic_training_steps=N_CRITIC\n",
    "    , clip_threshold=CLIP_THRESHOLD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.sample_images(RUN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.critic_valid_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.critic_valid_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[0] for x in gan.critic_generated_losses], color='red', linewidth=0.25)\n",
    "plt.plot(gan.generator_losses, color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "# plt.xlim(0, 2000)\n",
    "# plt.ylim(0, 2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(img1, img2):\n",
    "    return np.mean(np.abs(img1 - img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r, c = 5, 5\n",
    "\n",
    "idx = np.random.randint(0, x_train.shape[0], BATCH_SIZE)\n",
    "true_imgs = (x_train[idx] + 1) *0.5\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(true_imgs[cnt], cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/real.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 5, 5\n",
    "noise = np.random.normal(0, 1, (r * c, gan.latent_dim))\n",
    "gen_imgs = gan.generator_model.predict(noise)\n",
    "\n",
    "#Rescale images 0 - 1\n",
    "\n",
    "gen_imgs = 0.5 * (gen_imgs + 1)\n",
    "# gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]), cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/sample.png\"))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        c_diff = 99999\n",
    "        c_img = None\n",
    "        for k_idx, k in enumerate((x_train + 1) * 0.5):\n",
    "            \n",
    "            diff = compare_images(gen_imgs[cnt, :,:,:], k)\n",
    "            if diff < c_diff:\n",
    "                c_img = np.copy(k)\n",
    "                c_diff = diff\n",
    "        axs[i,j].imshow(c_img, cmap = 'gray_r')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "\n",
    "fig.savefig(os.path.join(RUN_FOLDER, \"images/sample_closest.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
